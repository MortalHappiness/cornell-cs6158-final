[
  {
    "tvm_api": "tvm._ffi.registry.register_func",
    "torch_api": null,
    "mapping_type": "no_mapping",
    "direction": "tvm_to_torch",
    "tvm_pattern": null,
    "torch_pattern": null,
    "arg_mapping": {},
    "example_pairs": [],
    "constraints": "Not convertible",
    "notes": "NO_MAPPING: TVM's register_func is for registering global C++ functions via FFI, part of its internal extensibility. The PyTorch candidate register_func is for registering Aten ops within a nested internal system, which is a different domain and purpose. No direct semantic equivalent.",
    "confidence": 0.2
  },
  {
    "tvm_api": "tvm.auto_scheduler.measure_record.main",
    "torch_api": null,
    "mapping_type": "no_mapping",
    "direction": "tvm_to_torch",
    "tvm_pattern": null,
    "torch_pattern": null,
    "arg_mapping": {},
    "example_pairs": [],
    "constraints": "Not convertible",
    "notes": "NO_MAPPING: This TVM 'main' function is a CLI entry point for auto-scheduler record file manipulation (e.g., distilling best records). The PyTorch 'main' candidates are also CLI/script entry points for PyTorch's build system, CI, or internal tools. There is no direct functional or conceptual mapping between these high-level, domain-specific script entry points.",
    "confidence": 0.2
  },
  {
    "tvm_api": "tvm.auto_scheduler.testing.tune_onnx.main",
    "torch_api": null,
    "mapping_type": "no_mapping",
    "direction": "tvm_to_torch",
    "tvm_pattern": null,
    "torch_pattern": null,
    "arg_mapping": {},
    "example_pairs": [],
    "constraints": "Not convertible",
    "notes": "NO_MAPPING: This TVM 'main' function is a CLI entry point for auto-tuning ONNX models with TVM's auto-scheduler. The PyTorch 'main' candidates are unrelated CLI/script entry points for PyTorch's build system, CI, or internal tools. No direct functional or conceptual mapping.",
    "confidence": 0.2
  },
  {
    "tvm_api": "tvm.auto_scheduler.testing.tune_relay.main",
    "torch_api": null,
    "mapping_type": "no_mapping",
    "direction": "tvm_to_torch",
    "tvm_pattern": null,
    "torch_pattern": null,
    "arg_mapping": {},
    "example_pairs": [],
    "constraints": "Not convertible",
    "notes": "NO_MAPPING: This TVM 'main' function is a CLI entry point for auto-tuning Relay models with TVM's auto-scheduler. The PyTorch 'main' candidates are unrelated CLI/script entry points for PyTorch's build system, CI, or internal tools. No direct functional or conceptual mapping.",
    "confidence": 0.2
  },
  {
    "tvm_api": "tvm.auto_scheduler.testing.tune_te.main",
    "torch_api": null,
    "mapping_type": "no_mapping",
    "direction": "tvm_to_torch",
    "tvm_pattern": null,
    "torch_pattern": null,
    "arg_mapping": {},
    "example_pairs": [],
    "constraints": "Not convertible",
    "notes": "NO_MAPPING: This TVM 'main' function is a CLI entry point for auto-tuning Tensor Expression models with TVM's auto-scheduler. The PyTorch 'main' candidates are unrelated CLI/script entry points for PyTorch's build system, CI, or internal tools. No direct functional or conceptual mapping.",
    "confidence": 0.2
  },
  {
    "tvm_api": "tvm.autotvm.tophub.context",
    "torch_api": null,
    "mapping_type": "no_mapping",
    "direction": "tvm_to_torch",
    "tvm_pattern": null,
    "torch_pattern": null,
    "arg_mapping": {},
    "example_pairs": [],
    "constraints": "Not convertible",
    "notes": "NO_MAPPING: TVM's context function here provides a dispatch context for auto-tuning parameters (TopHub). The PyTorch candidate 'context' is a generic contextlib.contextmanager utility for error handling in torchgen, serving a completely different purpose. No direct mapping.",
    "confidence": 0.2
  },
  {
    "tvm_api": "tvm.autotvm.task.task.template",
    "torch_api": null,
    "mapping_type": "no_mapping",
    "direction": "tvm_to_torch",
    "tvm_pattern": null,
    "torch_pattern": null,
    "arg_mapping": {},
    "example_pairs": [],
    "constraints": "Not convertible",
    "notes": "NO_MAPPING: TVM's 'template' is a decorator for defining tunable schedule templates within its auto-tuning framework. The PyTorch candidate 'template' is used for compiling Triton templates within TorchInductor, which is a different domain of code generation and optimization. No direct mapping.",
    "confidence": 0.2
  },
  {
    "tvm_api": "tvm.autotvm.testing.tune_relay.main",
    "torch_api": null,
    "mapping_type": "no_mapping",
    "direction": "tvm_to_torch",
    "tvm_pattern": null,
    "torch_pattern": null,
    "arg_mapping": {},
    "example_pairs": [],
    "constraints": "Not convertible",
    "notes": "NO_MAPPING: This TVM 'main' function is a CLI entry point for auto-tuning Relay models using AutoTVM. The PyTorch 'main' candidates are unrelated CLI/script entry points for PyTorch's build system, CI, or internal tools. No direct functional or conceptual mapping.",
    "confidence": 0.2
  },
  {
    "tvm_api": "tvm.driver.tvmc.main.main",
    "torch_api": null,
    "mapping_type": "no_mapping",
    "direction": "tvm_to_torch",
    "tvm_pattern": null,
    "torch_pattern": null,
    "arg_mapping": {},
    "example_pairs": [],
    "constraints": "Not convertible",
    "notes": "NO_MAPPING: This TVM 'main' function is the entry point for the TVMC command-line driver, a high-level compiler interface for TVM. The PyTorch 'main' candidates are unrelated CLI/script entry points for PyTorch's build system, CI, or internal tools. No direct functional or conceptual mapping.",
    "confidence": 0.2
  },
  {
    "tvm_api": "tvm.exec.measure_peak.main",
    "torch_api": null,
    "mapping_type": "no_mapping",
    "direction": "tvm_to_torch",
    "tvm_pattern": null,
    "torch_pattern": null,
    "arg_mapping": {},
    "example_pairs": [],
    "constraints": "Not convertible",
    "notes": "NO_MAPPING: This TVM 'main' function is a CLI entry point for measuring peak performance on a target device using TVM. The PyTorch 'main' candidates are unrelated CLI/script entry points for PyTorch's build system, CI, or internal tools. No direct functional or conceptual mapping.",
    "confidence": 0.2
  },
  {
    "tvm_api": "tvm.exec.microtvm_debug_shell.main",
    "torch_api": null,
    "mapping_type": "no_mapping",
    "direction": "tvm_to_torch",
    "tvm_pattern": null,
    "torch_pattern": null,
    "arg_mapping": {},
    "example_pairs": [],
    "constraints": "Not convertible",
    "notes": "NO_MAPPING: This TVM 'main' function is a CLI entry point for the microTVM debug shell, which interacts with microcontrollers. The PyTorch 'main' candidates are unrelated CLI/script entry points for PyTorch's build system, CI, or internal tools. No direct functional or conceptual mapping.",
    "confidence": 0.2
  },
  {
    "tvm_api": "tvm.exec.popen_worker.main",
    "torch_api": null,
    "mapping_type": "no_mapping",
    "direction": "tvm_to_torch",
    "tvm_pattern": null,
    "torch_pattern": null,
    "arg_mapping": {},
    "example_pairs": [],
    "constraints": "Not convertible",
    "notes": "NO_MAPPING: This TVM 'main' function is a CLI entry point for a Popen worker, part of TVM's distributed RPC infrastructure. The PyTorch 'main' candidates are unrelated CLI/script entry points for PyTorch's build system, CI, or internal tools. No direct functional or conceptual mapping.",
    "confidence": 0.2
  },
  {
    "tvm_api": "tvm.exec.query_rpc_tracker.main",
    "torch_api": null,
    "mapping_type": "no_mapping",
    "direction": "tvm_to_torch",
    "tvm_pattern": null,
    "torch_pattern": null,
    "arg_mapping": {},
    "example_pairs": [],
    "constraints": "Not convertible",
    "notes": "NO_MAPPING: This TVM 'main' function is a CLI entry point for querying an RPC tracker in TVM's distributed compilation system. The PyTorch 'main' candidates are unrelated CLI/script entry points for PyTorch's build system, CI, or internal tools. No direct functional or conceptual mapping.",
    "confidence": 0.2
  },
  {
    "tvm_api": "tvm.exec.rpc_proxy.main",
    "torch_api": null,
    "mapping_type": "no_mapping",
    "direction": "tvm_to_torch",
    "tvm_pattern": null,
    "torch_pattern": null,
    "arg_mapping": {},
    "example_pairs": [],
    "constraints": "Not convertible",
    "notes": "NO_MAPPING: This TVM 'main' function is a CLI entry point for starting an RPC proxy server, part of TVM's distributed RPC infrastructure. The PyTorch 'main' candidates are unrelated CLI/script entry points for PyTorch's build system, CI, or internal tools. No direct functional or conceptual mapping.",
    "confidence": 0.2
  },
  {
    "tvm_api": "tvm.exec.rpc_server.main",
    "torch_api": null,
    "mapping_type": "no_mapping",
    "direction": "tvm_to_torch",
    "tvm_pattern": null,
    "torch_pattern": null,
    "arg_mapping": {},
    "example_pairs": [],
    "constraints": "Not convertible",
    "notes": "NO_MAPPING: This TVM 'main' function is a CLI entry point for starting an RPC server, part of TVM's distributed RPC infrastructure. The PyTorch 'main' candidates are unrelated CLI/script entry points for PyTorch's build system, CI, or internal tools. No direct functional or conceptual mapping.",
    "confidence": 0.2
  },
  {
    "tvm_api": "tvm.exec.rpc_tracker.main",
    "torch_api": null,
    "mapping_type": "no_mapping",
    "direction": "tvm_to_torch",
    "tvm_pattern": null,
    "torch_pattern": null,
    "arg_mapping": {},
    "example_pairs": [],
    "constraints": "Not convertible",
    "notes": "NO_MAPPING: This TVM 'main' function is a CLI entry point for starting an RPC tracker, part of TVM's distributed RPC infrastructure. The PyTorch 'main' candidates are unrelated CLI/script entry points for PyTorch's build system, CI, or internal tools. No direct functional or conceptual mapping.",
    "confidence": 0.2
  },
  {
    "tvm_api": "tvm.meta_schedule.testing.dataset_collect_models.main",
    "torch_api": null,
    "mapping_type": "no_mapping",
    "direction": "tvm_to_torch",
    "tvm_pattern": null,
    "torch_pattern": null,
    "arg_mapping": {},
    "example_pairs": [],
    "constraints": "Not convertible",
    "notes": "NO_MAPPING: This TVM 'main' function is a CLI entry point for collecting models for MetaSchedule benchmarking. The PyTorch 'main' candidates are unrelated CLI/script entry points for PyTorch's build system, CI, or internal tools. No direct functional or conceptual mapping.",
    "confidence": 0.2
  },
  {
    "tvm_api": "tvm.meta_schedule.testing.dataset_extract_tasks.main",
    "torch_api": null,
    "mapping_type": "no_mapping",
    "direction": "tvm_to_torch",
    "tvm_pattern": null,
    "torch_pattern": null,
    "arg_mapping": {},
    "example_pairs": [],
    "constraints": "Not convertible",
    "notes": "NO_MAPPING: This TVM 'main' function is a CLI entry point for extracting tasks from models for MetaSchedule benchmarking. The PyTorch 'main' candidates are unrelated CLI/script entry points for PyTorch's build system, CI, or internal tools. No direct functional or conceptual mapping.",
    "confidence": 0.2
  },
  {
    "tvm_api": "tvm.meta_schedule.testing.dataset_sample_candidates.main",
    "torch_api": null,
    "mapping_type": "no_mapping",
    "direction": "tvm_to_torch",
    "tvm_pattern": null,
    "torch_pattern": null,
    "arg_mapping": {},
    "example_pairs": [],
    "constraints": "Not convertible",
    "notes": "NO_MAPPING: This TVM 'main' function is a CLI entry point for sampling candidates for MetaSchedule. The PyTorch 'main' candidates are unrelated CLI/script entry points for PyTorch's build system, CI, or internal tools. No direct functional or conceptual mapping.",
    "confidence": 0.2
  },
  {
    "tvm_api": "tvm.meta_schedule.testing.distributed_measure_candidates.main",
    "torch_api": null,
    "mapping_type": "no_mapping",
    "direction": "tvm_to_torch",
    "tvm_pattern": null,
    "torch_pattern": null,
    "arg_mapping": {},
    "example_pairs": [],
    "constraints": "Not convertible",
    "notes": "NO_MAPPING: This TVM 'main' function is a CLI entry point for distributed measurement of candidates for MetaSchedule. The PyTorch 'main' candidates are unrelated CLI/script entry points for PyTorch's build system, CI, or internal tools. No direct functional or conceptual mapping.",
    "confidence": 0.2
  },
  {
    "tvm_api": "tvm.meta_schedule.testing.te_workload.matmul",
    "torch_api": null,
    "mapping_type": "no_mapping",
    "direction": "tvm_to_torch",
    "tvm_pattern": null,
    "torch_pattern": null,
    "arg_mapping": {},
    "example_pairs": [],
    "constraints": "Not convertible",
    "notes": "NO_MAPPING: TVM's 'matmul' here is a function to *define* a matrix multiplication computation using the Tensor Expression (TE) language, which describes the computation for a TVM schedule. PyTorch's 'matmul' is an *operator* that executes matrix multiplication on existing tensors. These are fundamentally different levels of abstraction (definition vs. execution).",
    "confidence": 0.2
  },
  {
    "tvm_api": "tvm.meta_schedule.testing.tune_onnx.main",
    "torch_api": null,
    "mapping_type": "no_mapping",
    "direction": "tvm_to_torch",
    "tvm_pattern": null,
    "torch_pattern": null,
    "arg_mapping": {},
    "example_pairs": [],
    "constraints": "Not convertible",
    "notes": "NO_MAPPING: This TVM 'main' function is a CLI entry point for tuning ONNX models with MetaSchedule. The PyTorch 'main' candidates are unrelated CLI/script entry points for PyTorch's build system, CI, or internal tools. No direct functional or conceptual mapping.",
    "confidence": 0.2
  },
  {
    "tvm_api": "tvm.meta_schedule.testing.tune_relay.main",
    "torch_api": null,
    "mapping_type": "no_mapping",
    "direction": "tvm_to_torch",
    "tvm_pattern": null,
    "torch_pattern": null,
    "arg_mapping": {},
    "example_pairs": [],
    "constraints": "Not convertible",
    "notes": "NO_MAPPING: This TVM 'main' function is a CLI entry point for tuning Relay models with MetaSchedule. The PyTorch 'main' candidates are unrelated CLI/script entry points for PyTorch's build system, CI, or internal tools. No direct functional or conceptual mapping.",
    "confidence": 0.2
  },
  {
    "tvm_api": "tvm.meta_schedule.testing.tune_te.main",
    "torch_api": null,
    "mapping_type": "no_mapping",
    "direction": "tvm_to_torch",
    "tvm_pattern": null,
    "torch_pattern": null,
    "arg_mapping": {},
    "example_pairs": [],
    "constraints": "Not convertible",
    "notes": "NO_MAPPING: This TVM 'main' function is a CLI entry point for tuning Tensor Expression workloads with MetaSchedule. The PyTorch 'main' candidates are unrelated CLI/script entry points for PyTorch's build system, CI, or internal tools. No direct functional or conceptual mapping.",
    "confidence": 0.2
  },
  {
    "tvm_api": "tvm.meta_schedule.testing.validate_database.main",
    "torch_api": null,
    "mapping_type": "no_mapping",
    "direction": "tvm_to_torch",
    "tvm_pattern": null,
    "torch_pattern": null,
    "arg_mapping": {},
    "example_pairs": [],
    "constraints": "Not convertible",
    "notes": "NO_MAPPING: This TVM 'main' function is a CLI entry point for validating the MetaSchedule tuning database. The PyTorch 'main' candidates are unrelated CLI/script entry points for PyTorch's build system, CI, or internal tools. No direct functional or conceptual mapping.",
    "confidence": 0.2
  },
  {
    "tvm_api": "tvm.meta_schedule.testing.torchbench.run.main",
    "torch_api": null,
    "mapping_type": "no_mapping",
    "direction": "tvm_to_torch",
    "tvm_pattern": null,
    "torch_pattern": null,
    "arg_mapping": {},
    "example_pairs": [],
    "constraints": "Not convertible",
    "notes": "NO_MAPPING: This TVM 'main' function is a CLI entry point for running TorchBench benchmarks using TVM MetaSchedule. The PyTorch 'main' candidates are unrelated CLI/script entry points for PyTorch's build system, CI, or internal tools. No direct functional or conceptual mapping.",
    "confidence": 0.2
  },
  {
    "tvm_api": "tvm.micro.project_api.server.main",
    "torch_api": null,
    "mapping_type": "no_mapping",
    "direction": "tvm_to_torch",
    "tvm_pattern": null,
    "torch_pattern": null,
    "arg_mapping": {},
    "example_pairs": [],
    "constraints": "Not convertible",
    "notes": "NO_MAPPING: This TVM 'main' function is a CLI entry point for starting a microTVM Project API server. The PyTorch 'main' candidates are unrelated CLI/script entry points for PyTorch's build system, CI, or internal tools. No direct functional or conceptual mapping.",
    "confidence": 0.2
  },
  {
    "tvm_api": "tvm.parser.__init__.parse",
    "torch_api": null,
    "mapping_type": "no_mapping",
    "direction": "tvm_to_torch",
    "tvm_pattern": null,
    "torch_pattern": null,
    "arg_mapping": {},
    "example_pairs": [],
    "constraints": "Not convertible",
    "notes": "NO_MAPPING: TVM's 'parse' is for parsing TVM IRModule source code. The PyTorch candidate functions named 'parse' are for parsing ONNX graphs or packaging versions. These operate on different input types and serve different internal parsing needs, so no direct mapping.",
    "confidence": 0.2
  },
  {
    "tvm_api": "tvm.relay.build_module.optimize",
    "torch_api": null,
    "mapping_type": "no_mapping",
    "direction": "tvm_to_torch",
    "tvm_pattern": null,
    "torch_pattern": null,
    "arg_mapping": {},
    "example_pairs": [],
    "constraints": "Not convertible",
    "notes": "NO_MAPPING: TVM's 'optimize' performs optimization passes on a Relay IRModule, targeting TVM's compilation pipeline. PyTorch's 'optimize' (torch._dynamo.optimize or torch.compile) operates on Python callables (PyTorch models) to optimize their execution via graph capture. While both aim for optimization, the input types, intermediate representations, and underlying mechanisms are fundamentally different, preventing a direct API argument mapping.",
    "confidence": 0.2
  },
  {
    "tvm_api": "tvm.relay.expr.var",
    "torch_api": null,
    "mapping_type": "no_mapping",
    "direction": "tvm_to_torch",
    "tvm_pattern": null,
    "torch_pattern": null,
    "arg_mapping": {},
    "example_pairs": [],
    "constraints": "Not convertible",
    "notes": "NO_MAPPING: TVM's 'var' creates a variable expression within the Relay IR graph. The PyTorch candidate 'var' calculates variance of a tensor. The 'var' in `torch.fx.experimental.unification.variable` is for internal FX graph variable creation, which is not a direct user-facing equivalent for general Relay IR construction.",
    "confidence": 0.2
  },
  {
    "tvm_api": "tvm.relay.expr.bind",
    "torch_api": null,
    "mapping_type": "no_mapping",
    "direction": "tvm_to_torch",
    "tvm_pattern": null,
    "torch_pattern": null,
    "arg_mapping": {},
    "example_pairs": [],
    "constraints": "Not convertible",
    "notes": "NO_MAPPING: TVM's 'bind' function binds free variables or function arguments within a Relay expression. The PyTorch candidate 'bind' is a utility for handling Optional types or part of PackedSequence. These are unrelated functionalities.",
    "confidence": 0.2
  },
  {
    "tvm_api": "tvm.relay.loops.while_loop",
    "torch_api": "torch.while_loop",
    "mapping_type": "direct",
    "direction": "tvm_to_torch",
    "tvm_pattern": "tvm.relay.loops.while_loop({{cond}}, {{loop_vars}}, {{loop_bodies}})",
    "torch_pattern": "torch.while_loop({{cond}}, {{loop_bodies}}, {{loop_vars}})",
    "arg_mapping": {
      "cond": "cond",
      "loop_vars": "carried_inputs",
      "loop_bodies": "body_fn"
    },
    "example_pairs": [
      {
        "tvm": "result = tvm.relay.loops.while_loop(cond_fn, initial_vars, body_fn)",
        "torch": "result = torch.while_loop(cond_fn, body_fn, initial_vars)"
      }
    ],
    "constraints": "The order of loop_vars/carried_inputs and loop_bodies/body_fn is swapped between TVM and PyTorch. Both cond_fn and body_fn must be callables. PyTorch's `while_loop` is a prototype feature with limitations.",
    "notes": "Direct mapping with argument reordering. TVM's `loop_vars` are PyTorch's `carried_inputs`, and TVM's `loop_bodies` is PyTorch's `body_fn`.",
    "confidence": 0.85
  },
  {
    "tvm_api": "tvm.relay.backend.te_compiler.get_shape",
    "torch_api": "torch.Tensor.shape",
    "mapping_type": "direct",
    "direction": "tvm_to_torch",
    "tvm_pattern": "tvm.relay.backend.te_compiler.get_shape({{input_tensor}}.shape)",
    "torch_pattern": "{{input_tensor}}.shape",
    "arg_mapping": {
      "input_tensor": "input_tensor"
    },
    "example_pairs": [
      {
        "tvm": "shape = tvm.relay.backend.te_compiler.get_shape(x.shape)",
        "torch": "shape = x.shape"
      }
    ],
    "constraints": "TVM's get_shape primarily handles TVM IR dimensions and converts them. For a direct mapping to PyTorch's .shape, the TVM input must be convertible to a PyTorch tensor, and the complexity of TVM's internal handling of `IntImm` vs `Any` dimensions is abstracted.",
    "notes": "For a PyTorch tensor, the shape is directly accessed via the `.shape` attribute. The TVM function converts symbolic shapes from its IR to concrete forms; the PyTorch equivalent is simply accessing the tensor's shape. The PyTorch candidate `get_shape` in `flop_counter.py` takes a generic `i` and returns `i.shape` if it's a tensor, aligning with the concept.",
    "confidence": 0.8
  },
  {
    "tvm_api": "tvm.relay.backend.vm.compile",
    "torch_api": null,
    "mapping_type": "no_mapping",
    "direction": "tvm_to_torch",
    "tvm_pattern": null,
    "torch_pattern": null,
    "arg_mapping": {},
    "example_pairs": [],
    "constraints": "Not convertible",
    "notes": "NO_MAPPING: TVM's `compile` builds a Relay IRModule into a VM executable. PyTorch's `torch.compile` is for optimizing a Python callable (a PyTorch model). The input types and the compilation targets (Relay IRModule vs. Python callable) are distinct, preventing a direct API argument mapping for conversion.",
    "confidence": 0.2
  },
  {
    "tvm_api": "tvm.relay.data_dep_optimization.bsr_conv2d.convert",
    "torch_api": null,
    "mapping_type": "no_mapping",
    "direction": "tvm_to_torch",
    "tvm_pattern": null,
    "torch_pattern": null,
    "arg_mapping": {},
    "example_pairs": [],
    "constraints": "Not convertible",
    "notes": "NO_MAPPING: TVM's 'convert' here transforms a dense conv2d operation into a block-sparse representation within the Relay IR. The PyTorch candidate 'convert' functions are related to quantization (e.g., converting float models to quantized models). These are entirely different optimization domains and semantic transformations. No direct mapping.",
    "confidence": 0.2
  },
  {
    "tvm_api": "tvm.relay.data_dep_optimization.bsr_dense.convert",
    "torch_api": null,
    "mapping_type": "no_mapping",
    "direction": "tvm_to_torch",
    "tvm_pattern": null,
    "torch_pattern": null,
    "arg_mapping": {},
    "example_pairs": [],
    "constraints": "Not convertible",
    "notes": "NO_MAPPING: TVM's 'convert' here transforms a dense operation into a block-sparse representation within the Relay IR. The PyTorch candidate 'convert' functions are related to quantization (e.g., converting float models to quantized models). These are entirely different optimization domains and semantic transformations. No direct mapping.",
    "confidence": 0.2
  },
  {
    "tvm_api": "tvm.relay.data_dep_optimization.simplify_fc_transpose.convert",
    "torch_api": null,
    "mapping_type": "no_mapping",
    "direction": "tvm_to_torch",
    "tvm_pattern": null,
    "torch_pattern": null,
    "arg_mapping": {},
    "example_pairs": [],
    "constraints": "Not convertible",
    "notes": "NO_MAPPING: TVM's 'convert' here is an optimization pass that rewrites `dense(x, transpose(w, [1,0]))` to `dense(x, wt)` within the Relay IR. The PyTorch candidate 'convert' functions are related to quantization. These are entirely different optimization domains and semantic transformations. No direct mapping.",
    "confidence": 0.2
  },
  {
    "tvm_api": "tvm.relay.frontend.onnx.layer_norm",
    "torch_api": "torch.nn.functional.layer_norm",
    "mapping_type": "direct",
    "direction": "tvm_to_torch",
    "tvm_pattern": "tvm.relay.frontend.onnx.layer_norm({{x}}, {{eps}}, {{gamma}}, {{beta}})",
    "torch_pattern": "torch.nn.functional.layer_norm({{x}}, normalized_shape={{x}}.shape[{{axis_start}}:], weight={{gamma}}, bias={{beta}}, eps={{eps}})",
    "arg_mapping": {
      "x": "input",
      "eps": "eps",
      "gamma": "weight",
      "beta": "bias",
      "axis_start": "dim"
    },
    "example_pairs": [
      {
        "tvm": "output = tvm.relay.frontend.onnx.layer_norm(x, 1e-5, gamma_tensor, beta_tensor)",
        "torch": "output = torch.nn.functional.layer_norm(x, normalized_shape=x.shape[-1:], weight=gamma_tensor, bias=beta_tensor, eps=1e-5)"
      }
    ],
    "constraints": "TVM's layer_norm assumes `axis=-1` for normalization (last dimension). PyTorch's `normalized_shape` must be explicitly specified (e.g., `input.shape[axis_start:]`). The provided TVM snippet only shows `axis=-1` implicit in `mean_variance(x, axis=-1)`. `normalized_shape` argument requires knowing the number of dimensions to normalize over.",
    "notes": "TVM's internal layer_norm implementation uses `_op.mean_variance` on `axis=-1`. PyTorch's `layer_norm` explicitly takes `normalized_shape` (a list of dimensions to normalize) and `weight`/`bias` (gamma/beta). Assuming default `axis=-1` in TVM, PyTorch's `normalized_shape` would be `x.shape[-1:]`.",
    "confidence": 0.85
  },
  {
    "tvm_api": "tvm.relay.op.algorithm.sort",
    "torch_api": "torch.sort",
    "mapping_type": "direct",
    "direction": "tvm_to_torch",
    "tvm_pattern": "tvm.relay.op.algorithm.sort({{data}}, axis={{axis}}, is_ascend={{is_ascend}})",
    "torch_pattern": "torch.sort({{data}}, dim={{axis}}, descending={{descending}})",
    "arg_mapping": {
      "data": "input",
      "axis": "dim",
      "is_ascend": "!descending"
    },
    "example_pairs": [
      {
        "tvm": "sorted_data = tvm.relay.op.algorithm.sort(x, axis=1, is_ascend=True)",
        "torch": "sorted_data, _ = torch.sort(x, dim=1, descending=False)"
      },
      {
        "tvm": "sorted_data = tvm.relay.op.algorithm.sort(x, axis=0, is_ascend=False)",
        "torch": "sorted_data, _ = torch.sort(x, dim=0, descending=True)"
      }
    ],
    "constraints": "PyTorch's `torch.sort` returns a tuple `(values, indices)`, while TVM's `sort` returns only the sorted data. If indices are not needed, they can be ignored in PyTorch (e.g., `values, _ = torch.sort(...)`). `is_ascend=True` maps to `descending=False`, and `is_ascend=False` maps to `descending=True`.",
    "notes": "The mapping between `is_ascend` and `descending` is inverse. PyTorch's `dim` is equivalent to TVM's `axis`.",
    "confidence": 0.95
  },
  {
    "tvm_api": "tvm.relay.op.algorithm.argsort",
    "torch_api": "torch.argsort",
    "mapping_type": "direct",
    "direction": "tvm_to_torch",
    "tvm_pattern": "tvm.relay.op.algorithm.argsort({{data}}, axis={{axis}}, is_ascend={{is_ascend}}, dtype={{dtype}})",
    "torch_pattern": "torch.argsort({{data}}, dim={{axis}}, descending={{descending}})",
    "arg_mapping": {
      "data": "input",
      "axis": "dim",
      "is_ascend": "!descending",
      "dtype": "dtype_of_indices"
    },
    "example_pairs": [
      {
        "tvm": "indices = tvm.relay.op.algorithm.argsort(x, axis=1, is_ascend=True, dtype='int32')",
        "torch": "indices = torch.argsort(x, dim=1, descending=False)"
      },
      {
        "tvm": "indices = tvm.relay.op.algorithm.argsort(x, axis=-1, is_ascend=False)",
        "torch": "indices = torch.argsort(x, dim=-1, descending=True)"
      }
    ],
    "constraints": "PyTorch's `argsort` returns indices with `torch.long` dtype by default. If a specific `dtype` (like `int32`) is required, an explicit `.to(dtype)` conversion might be needed in PyTorch. `is_ascend=True` maps to `descending=False`, and `is_ascend=False` maps to `descending=True`.",
    "notes": "Direct mapping with inverse logic for `is_ascend`/`descending`. `dtype` in TVM specifies output index dtype, while PyTorch's `argsort` defaults to `long`.",
    "confidence": 0.95
  },
  {
    "tvm_api": "tvm.relay.op.algorithm.topk",
    "torch_api": "torch.topk",
    "mapping_type": "direct",
    "direction": "tvm_to_torch",
    "tvm_pattern": "tvm.relay.op.algorithm.topk({{data}}, k={{k}}, axis={{axis}}, ret_type={{ret_type}}, is_ascend={{is_ascend}}, dtype={{dtype}})",
    "torch_pattern": "torch.topk({{data}}, k={{k}}, dim={{axis}}, largest={{largest}}, sorted=True)",
    "arg_mapping": {
      "data": "input",
      "k": "k",
      "axis": "dim",
      "ret_type": "return_values_or_indices",
      "is_ascend": "!largest",
      "dtype": "dtype_of_indices"
    },
    "example_pairs": [
      {
        "tvm": "values, indices = tvm.relay.op.algorithm.topk(x, k=3, axis=1, ret_type='both', is_ascend=False)",
        "torch": "values, indices = torch.topk(x, k=3, dim=1, largest=True, sorted=True)"
      },
      {
        "tvm": "min_values = tvm.relay.op.algorithm.topk(x, k=1, axis=0, ret_type='values', is_ascend=True)",
        "torch": "min_values, _ = torch.topk(x, k=1, dim=0, largest=False, sorted=True)"
      }
    ],
    "constraints": "TVM's `is_ascend` is the inverse of PyTorch's `largest` (`is_ascend=True` implies `largest=False`). PyTorch's `topk` always returns sorted results, matching TVM's behavior implicitly. TVM's `ret_type` ('both', 'values', 'indices') needs to be handled: PyTorch always returns `(values, indices)`, so for 'values' or 'indices' only, the other return value needs to be discarded. TVM `dtype` for indices matches PyTorch's default `long` or requires `.to(dtype)`.",
    "notes": "Direct mapping for `data`, `k`, `axis`. `is_ascend` is inverted for `largest`. PyTorch's `topk` implicitly returns sorted results, and always returns both values and indices.",
    "confidence": 0.9
  },
  {
    "tvm_api": "tvm.relay.op.algorithm.searchsorted",
    "torch_api": "torch.searchsorted",
    "mapping_type": "direct",
    "direction": "tvm_to_torch",
    "tvm_pattern": "tvm.relay.op.algorithm.searchsorted({{sorted_sequence}}, {{values}}, right={{right}}, dtype={{dtype}})",
    "torch_pattern": "torch.searchsorted({{sorted_sequence}}, {{values}}, right={{right}})",
    "arg_mapping": {
      "sorted_sequence": "sorted_sequence",
      "values": "input",
      "right": "right",
      "dtype": "dtype_of_indices"
    },
    "example_pairs": [
      {
        "tvm": "indices = tvm.relay.op.algorithm.searchsorted(seq_tensor, val_tensor, right=False, dtype='int32')",
        "torch": "indices = torch.searchsorted(seq_tensor, val_tensor, right=False)"
      }
    ],
    "constraints": "PyTorch's `searchsorted` defaults to `torch.long` for indices. If TVM's `dtype` (e.g., `int32`) needs to be matched, an explicit `.to(dtype)` conversion on the result might be necessary. The `values` argument in TVM maps to `input` in PyTorch's `searchsorted`.",
    "notes": "Direct mapping for core functionality. `sorted_sequence` and `values` map to `sorted_sequence` and `input` respectively, and `right` directly maps. PyTorch doesn't have a direct `dtype` argument for the output indices for `searchsorted`, defaulting to `long`.",
    "confidence": 0.95
  },
  {
    "tvm_api": "tvm.relay.op.reduce.argmax",
    "torch_api": "torch.argmax",
    "mapping_type": "direct",
    "direction": "tvm_to_torch",
    "tvm_pattern": "tvm.relay.op.reduce.argmax({{data}}, axis={{axis}}, keepdims={{keepdims}}, exclude={{exclude}}, select_last_index={{select_last_index}})",
    "torch_pattern": "torch.argmax({{data}}, dim={{axis}}, keepdim={{keepdims}})",
    "arg_mapping": {
      "data": "input",
      "axis": "dim",
      "keepdims": "keepdim"
    },
    "example_pairs": [
      {
        "tvm": "idx = tvm.relay.op.reduce.argmax(x, axis=1, keepdims=False)",
        "torch": "idx = torch.argmax(x, dim=1, keepdim=False)"
      },
      {
        "tvm": "idx = tvm.relay.op.reduce.argmax(x, axis=None, keepdims=True)",
        "torch": "idx = torch.argmax(x, keepdim=True)"
      }
    ],
    "constraints": "TVM's `exclude` and `select_last_index` parameters are not directly supported by `torch.argmax`. PyTorch's `argmax` always selects the first index if multiple maximums exist, so `select_last_index=True` in TVM would require a composite mapping or special handling not covered by a direct API. `axis=None` in TVM is equivalent to flattening the tensor before argmax, which is the default behavior of `torch.argmax` when `dim` is not provided.",
    "notes": "Direct mapping for `data`, `axis`, `keepdims`. `exclude` and `select_last_index` are not directly supported in PyTorch `argmax`. `axis=None` in TVM implies reduction over all elements, mirroring PyTorch's default when `dim` is omitted.",
    "confidence": 0.85
  },
  {
    "tvm_api": "tvm.relay.op.reduce.argmin",
    "torch_api": "torch.argmin",
    "mapping_type": "direct",
    "direction": "tvm_to_torch",
    "tvm_pattern": "tvm.relay.op.reduce.argmin({{data}}, axis={{axis}}, keepdims={{keepdims}}, exclude={{exclude}}, select_last_index={{select_last_index}})",
    "torch_pattern": "torch.argmin({{data}}, dim={{axis}}, keepdim={{keepdims}})",
    "arg_mapping": {
      "data": "input",
      "axis": "dim",
      "keepdims": "keepdim"
    },
    "example_pairs": [
      {
        "tvm": "idx = tvm.relay.op.reduce.argmin(x, axis=1, keepdims=False)",
        "torch": "idx = torch.argmin(x, dim=1, keepdim=False)"
      },
      {
        "tvm": "idx = tvm.relay.op.reduce.argmin(x, axis=None, keepdims=True)",
        "torch": "idx = torch.argmin(x, keepdim=True)"
      }
    ],
    "constraints": "TVM's `exclude` and `select_last_index` parameters are not directly supported by `torch.argmin`. PyTorch's `argmin` always selects the first index if multiple minimums exist, so `select_last_index=True` in TVM would require a composite mapping or special handling not covered by a direct API. `axis=None` in TVM is equivalent to flattening the tensor before argmin, which is the default behavior of `torch.argmin` when `dim` is not provided.",
    "notes": "Direct mapping for `data`, `axis`, `keepdims`. `exclude` and `select_last_index` are not directly supported in PyTorch `argmin`. `axis=None` in TVM implies reduction over all elements, mirroring PyTorch's default when `dim` is omitted.",
    "confidence": 0.85
  },
  {
    "tvm_api": "tvm.relay.op.reduce.sum",
    "torch_api": "torch.sum",
    "mapping_type": "direct",
    "direction": "tvm_to_torch",
    "tvm_pattern": "tvm.relay.op.reduce.sum({{data}}, axis={{axis}}, keepdims={{keepdims}}, exclude={{exclude}})",
    "torch_pattern": "torch.sum({{data}}, dim={{axis}}, keepdim={{keepdims}})",
    "arg_mapping": {
      "data": "input",
      "axis": "dim",
      "keepdims": "keepdim"
    },
    "example_pairs": [
      {
        "tvm": "s = tvm.relay.op.reduce.sum(x, axis=1, keepdims=False)",
        "torch": "s = torch.sum(x, dim=1, keepdim=False)"
      },
      {
        "tvm": "s = tvm.relay.op.reduce.sum(x, axis=None, keepdims=True)",
        "torch": "s = torch.sum(x, keepdim=True)"
      }
    ],
    "constraints": "TVM's `exclude` parameter is not directly supported by `torch.sum`. If `exclude` is True, a composite mapping to sum over all axes *except* those specified in `axis` would be needed.",
    "notes": "Direct mapping for `data`, `axis`, `keepdims`. `axis=None` in TVM means sum over all elements, which is the default behavior of `torch.sum` when `dim` is not provided. TVM `exclude` parameter would require logic to determine non-excluded dimensions for PyTorch `dim`.",
    "confidence": 0.9
  },
  {
    "tvm_api": "tvm.relay.op.reduce.all",
    "torch_api": "torch.all",
    "mapping_type": "direct",
    "direction": "tvm_to_torch",
    "tvm_pattern": "tvm.relay.op.reduce.all({{data}}, axis={{axis}}, keepdims={{keepdims}}, exclude={{exclude}})",
    "torch_pattern": "torch.all({{data}}, dim={{axis}}, keepdim={{keepdims}})",
    "arg_mapping": {
      "data": "input",
      "axis": "dim",
      "keepdims": "keepdim"
    },
    "example_pairs": [
      {
        "tvm": "res = tvm.relay.op.reduce.all(x, axis=1, keepdims=False)",
        "torch": "res = torch.all(x, dim=1, keepdim=False)"
      },
      {
        "tvm": "res = tvm.relay.op.reduce.all(x, axis=None, keepdims=True)",
        "torch": "res = torch.all(x, keepdim=True)"
      }
    ],
    "constraints": "TVM's `exclude` parameter is not directly supported by `torch.all`. If `exclude` is True, a composite mapping to perform 'all' over all axes *except* those specified in `axis` would be needed.",
    "notes": "Direct mapping for `data`, `axis`, `keepdims`. `axis=None` in TVM means 'all' over all elements, mirroring PyTorch's default when `dim` is not provided. TVM `exclude` parameter would require logic to determine non-excluded dimensions for PyTorch `dim`.",
    "confidence": 0.9
  },
  {
    "tvm_api": "tvm.relay.op.reduce.any",
    "torch_api": "torch.any",
    "mapping_type": "direct",
    "direction": "tvm_to_torch",
    "tvm_pattern": "tvm.relay.op.reduce.any({{data}}, axis={{axis}}, keepdims={{keepdims}}, exclude={{exclude}})",
    "torch_pattern": "torch.any({{data}}, dim={{axis}}, keepdim={{keepdims}})",
    "arg_mapping": {
      "data": "input",
      "axis": "dim",
      "keepdims": "keepdim"
    },
    "example_pairs": [
      {
        "tvm": "res = tvm.relay.op.reduce.any(x, axis=1, keepdims=False)",
        "torch": "res = torch.any(x, dim=1, keepdim=False)"
      },
      {
        "tvm": "res = tvm.relay.op.reduce.any(x, axis=None, keepdims=True)",
        "torch": "res = torch.any(x, keepdim=True)"
      }
    ],
    "constraints": "TVM's `exclude` parameter is not directly supported by `torch.any`. If `exclude` is True, a composite mapping to perform 'any' over all axes *except* those specified in `axis` would be needed.",
    "notes": "Direct mapping for `data`, `axis`, `keepdims`. `axis=None` in TVM means 'any' over all elements, mirroring PyTorch's default when `dim` is not provided. TVM `exclude` parameter would require logic to determine non-excluded dimensions for PyTorch `dim`.",
    "confidence": 0.9
  },
  {
    "tvm_api": "tvm.relay.op.reduce.max",
    "torch_api": "torch.max",
    "mapping_type": "direct",
    "direction": "tvm_to_torch",
    "tvm_pattern": "tvm.relay.op.reduce.max({{data}}, axis={{axis}}, keepdims={{keepdims}}, exclude={{exclude}})",
    "torch_pattern": "torch.max({{data}}, dim={{axis}}, keepdim={{keepdims}})[0]",
    "arg_mapping": {
      "data": "input",
      "axis": "dim",
      "keepdims": "keepdim"
    },
    "example_pairs": [
      {
        "tvm": "m = tvm.relay.op.reduce.max(x, axis=1, keepdims=False)",
        "torch": "m = torch.max(x, dim=1, keepdim=False)[0]"
      },
      {
        "tvm": "m = tvm.relay.op.reduce.max(x, axis=None, keepdims=True)",
        "torch": "m = torch.max(x, keepdim=True)[0]"
      }
    ],
    "constraints": "TVM's `exclude` parameter is not directly supported by `torch.max`. If `exclude` is True, a composite mapping to find the maximum over all axes *except* those specified in `axis` would be needed. PyTorch's `torch.max(input, dim)` returns a tuple `(values, indices)`, so `[0]` is needed to get only the values.",
    "notes": "Direct mapping for `data`, `axis`, `keepdims`. `axis=None` in TVM means max over all elements, mirroring PyTorch's default when `dim` is not provided. TVM `exclude` parameter would require logic to determine non-excluded dimensions for PyTorch `dim`. Note PyTorch `max` for reduction returns a tuple.",
    "confidence": 0.9
  },
  {
    "tvm_api": "tvm.relay.op.reduce.min",
    "torch_api": "torch.min",
    "mapping_type": "direct",
    "direction": "tvm_to_torch",
    "tvm_pattern": "tvm.relay.op.reduce.min({{data}}, axis={{axis}}, keepdims={{keepdims}}, exclude={{exclude}})",
    "torch_pattern": "torch.min({{data}}, dim={{axis}}, keepdim={{keepdims}})[0]",
    "arg_mapping": {
      "data": "input",
      "axis": "dim",
      "keepdims": "keepdim"
    },
    "example_pairs": [
      {
        "tvm": "m = tvm.relay.op.reduce.min(x, axis=1, keepdims=False)",
        "torch": "m = torch.min(x, dim=1, keepdim=False)[0]"
      },
      {
        "tvm": "m = tvm.relay.op.reduce.min(x, axis=None, keepdims=True)",
        "torch": "m = torch.min(x, keepdim=True)[0]"
      }
    ],
    "constraints": "TVM's `exclude` parameter is not directly supported by `torch.min`. If `exclude` is True, a composite mapping to find the minimum over all axes *except* those specified in `axis` would be needed. PyTorch's `torch.min(input, dim)` returns a tuple `(values, indices)`, so `[0]` is needed to get only the values.",
    "notes": "Direct mapping for `data`, `axis`, `keepdims`. `axis=None` in TVM means min over all elements, mirroring PyTorch's default when `dim` is not provided. TVM `exclude` parameter would require logic to determine non-excluded dimensions for PyTorch `dim`. Note PyTorch `min` for reduction returns a tuple.",
    "confidence": 0.9
  },
  {
    "tvm_api": "tvm.relay.op.reduce.mean",
    "torch_api": "torch.mean",
    "mapping_type": "direct",
    "direction": "tvm_to_torch",
    "tvm_pattern": "tvm.relay.op.reduce.mean({{data}}, axis={{axis}}, keepdims={{keepdims}}, exclude={{exclude}})",
    "torch_pattern": "torch.mean({{data}}, dim={{axis}}, keepdim={{keepdims}})",
    "arg_mapping": {
      "data": "input",
      "axis": "dim",
      "keepdims": "keepdim"
    },
    "example_pairs": [
      {
        "tvm": "m = tvm.relay.op.reduce.mean(x, axis=1, keepdims=False)",
        "torch": "m = torch.mean(x, dim=1, keepdim=False)"
      },
      {
        "tvm": "m = tvm.relay.op.reduce.mean(x, axis=None, keepdims=True)",
        "torch": "m = torch.mean(x, keepdim=True)"
      }
    ],
    "constraints": "TVM's `exclude` parameter is not directly supported by `torch.mean`. If `exclude` is True, a composite mapping to find the mean over all axes *except* those specified in `axis` would be needed.",
    "notes": "Direct mapping for `data`, `axis`, `keepdims`. `axis=None` in TVM means mean over all elements, mirroring PyTorch's default when `dim` is not provided. TVM `exclude` parameter would require logic to determine non-excluded dimensions for PyTorch `dim`.",
    "confidence": 0.9
  },
  {
    "tvm_api": "tvm.relay.op.tensor.log",
    "torch_api": "torch.log",
    "mapping_type": "direct",
    "direction": "tvm_to_torch",
    "tvm_pattern": "tvm.relay.op.tensor.log({{data}})",
    "torch_pattern": "torch.log({{input}})",
    "arg_mapping": {
      "data": "input"
    },
    "example_pairs": [
      {
        "tvm": "y = tvm.relay.op.tensor.log(x)",
        "torch": "y = torch.log(x)"
      }
    ],
    "constraints": "",
    "notes": "Direct element-wise logarithm function.",
    "confidence": 0.99
  },
  {
    "tvm_api": "tvm.relay.op.tensor.log2",
    "torch_api": "torch.log2",
    "mapping_type": "direct",
    "direction": "tvm_to_torch",
    "tvm_pattern": "tvm.relay.op.tensor.log2({{data}})",
    "torch_pattern": "torch.log2({{input}})",
    "arg_mapping": {
      "data": "input"
    },
    "example_pairs": [
      {
        "tvm": "y = tvm.relay.op.tensor.log2(x)",
        "torch": "y = torch.log2(x)"
      }
    ],
    "constraints": "",
    "notes": "Direct element-wise base-2 logarithm function.",
    "confidence": 0.99
  },
  {
    "tvm_api": "tvm.relay.op.tensor.exp",
    "torch_api": "torch.exp",
    "mapping_type": "direct",
    "direction": "tvm_to_torch",
    "tvm_pattern": "tvm.relay.op.tensor.exp({{data}})",
    "torch_pattern": "torch.exp({{input}})",
    "arg_mapping": {
      "data": "input"
    },
    "example_pairs": [
      {
        "tvm": "y = tvm.relay.op.tensor.exp(x)",
        "torch": "y = torch.exp(x)"
      }
    ],
    "constraints": "",
    "notes": "Direct element-wise exponential function.",
    "confidence": 0.99
  },
  {
    "tvm_api": "tvm.relay.op.tensor.erf",
    "torch_api": "torch.erf",
    "mapping_type": "direct",
    "direction": "tvm_to_torch",
    "tvm_pattern": "tvm.relay.op.tensor.erf({{data}})",
    "torch_pattern": "torch.erf({{input}})",
    "arg_mapping": {
      "data": "input"
    },
    "example_pairs": [
      {
        "tvm": "y = tvm.relay.op.tensor.erf(x)",
        "torch": "y = torch.erf(x)"
      }
    ],
    "constraints": "",
    "notes": "Direct element-wise error function.",
    "confidence": 0.99
  },
  {
    "tvm_api": "tvm.relay.op.tensor.sqrt",
    "torch_api": "torch.sqrt",
    "mapping_type": "direct",
    "direction": "tvm_to_torch",
    "tvm_pattern": "tvm.relay.op.tensor.sqrt({{data}})",
    "torch_pattern": "torch.sqrt({{input}})",
    "arg_mapping": {
      "data": "input"
    },
    "example_pairs": [
      {
        "tvm": "y = tvm.relay.op.tensor.sqrt(x)",
        "torch": "y = torch.sqrt(x)"
      }
    ],
    "constraints": "",
    "notes": "Direct element-wise square root function.",
    "confidence": 0.99
  },
  {
    "tvm_api": "tvm.relay.op.tensor.rsqrt",
    "torch_api": "torch.rsqrt",
    "mapping_type": "direct",
    "direction": "tvm_to_torch",
    "tvm_pattern": "tvm.relay.op.tensor.rsqrt({{data}})",
    "torch_pattern": "torch.rsqrt({{input}})",
    "arg_mapping": {
      "data": "input"
    },
    "example_pairs": [
      {
        "tvm": "y = tvm.relay.op.tensor.rsqrt(x)",
        "torch": "y = torch.rsqrt(x)"
      }
    ],
    "constraints": "",
    "notes": "Direct element-wise reciprocal square root function.",
    "confidence": 0.99
  },
  {
    "tvm_api": "tvm.relay.op.tensor.sigmoid",
    "torch_api": "torch.sigmoid",
    "mapping_type": "direct",
    "direction": "tvm_to_torch",
    "tvm_pattern": "tvm.relay.op.tensor.sigmoid({{data}})",
    "torch_pattern": "torch.sigmoid({{input}})",
    "arg_mapping": {
      "data": "input"
    },
    "example_pairs": [
      {
        "tvm": "y = tvm.relay.op.tensor.sigmoid(x)",
        "torch": "y = torch.sigmoid(x)"
      }
    ],
    "constraints": "",
    "notes": "Direct element-wise sigmoid function.",
    "confidence": 0.99
  },
  {
    "tvm_api": "tvm.relay.op.tensor.floor",
    "torch_api": "torch.floor",
    "mapping_type": "direct",
    "direction": "tvm_to_torch",
    "tvm_pattern": "tvm.relay.op.tensor.floor({{data}})",
    "torch_pattern": "torch.floor({{input}})",
    "arg_mapping": {
      "data": "input"
    },
    "example_pairs": [
      {
        "tvm": "y = tvm.relay.op.tensor.floor(x)",
        "torch": "y = torch.floor(x)"
      }
    ],
    "constraints": "",
    "notes": "Direct element-wise floor function.",
    "confidence": 0.99
  },
  {
    "tvm_api": "tvm.relay.op.tensor.ceil",
    "torch_api": "torch.ceil",
    "mapping_type": "direct",
    "direction": "tvm_to_torch",
    "tvm_pattern": "tvm.relay.op.tensor.ceil({{data}})",
    "torch_pattern": "torch.ceil({{input}})",
    "arg_mapping": {
      "data": "input"
    },
    "example_pairs": [
      {
        "tvm": "y = tvm.relay.op.tensor.ceil(x)",
        "torch": "y = torch.ceil(x)"
      }
    ],
    "constraints": "",
    "notes": "Direct element-wise ceil function.",
    "confidence": 0.99
  },
  {
    "tvm_api": "tvm.relay.op.tensor.trunc",
    "torch_api": "torch.trunc",
    "mapping_type": "direct",
    "direction": "tvm_to_torch",
    "tvm_pattern": "tvm.relay.op.tensor.trunc({{data}})",
    "torch_pattern": "torch.trunc({{input}})",
    "arg_mapping": {
      "data": "input"
    },
    "example_pairs": [
      {
        "tvm": "y = tvm.relay.op.tensor.trunc(x)",
        "torch": "y = torch.trunc(x)"
      }
    ],
    "constraints": "",
    "notes": "Direct element-wise truncation function.",
    "confidence": 0.99
  },
  {
    "tvm_api": "tvm.relay.op.tensor.round",
    "torch_api": "torch.round",
    "mapping_type": "direct",
    "direction": "tvm_to_torch",
    "tvm_pattern": "tvm.relay.op.tensor.round({{data}})",
    "torch_pattern": "torch.round({{input}})",
    "arg_mapping": {
      "data": "input"
    },
    "example_pairs": [
      {
        "tvm": "y = tvm.relay.op.tensor.round(x)",
        "torch": "y = torch.round(x)"
      }
    ],
    "constraints": "PyTorch's `torch.round` also has a `decimals` argument, which TVM's `round` does not specify in the signature, implying rounding to the nearest integer.",
    "notes": "Direct element-wise rounding to the nearest integer (default behavior for both).",
    "confidence": 0.98
  },
  {
    "tvm_api": "tvm.relay.op.tensor.abs",
    "torch_api": "torch.abs",
    "mapping_type": "direct",
    "direction": "tvm_to_torch",
    "tvm_pattern": "tvm.relay.op.tensor.abs({{data}})",
    "torch_pattern": "torch.abs({{input}})",
    "arg_mapping": {
      "data": "input"
    },
    "example_pairs": [
      {
        "tvm": "y = tvm.relay.op.tensor.abs(x)",
        "torch": "y = torch.abs(x)"
      }
    ],
    "constraints": "",
    "notes": "Direct element-wise absolute value function.",
    "confidence": 0.99
  },
  {
    "tvm_api": "tvm.relay.op.tensor.tanh",
    "torch_api": "torch.tanh",
    "mapping_type": "direct",
    "direction": "tvm_to_torch",
    "tvm_pattern": "tvm.relay.op.tensor.tanh({{data}})",
    "torch_pattern": "torch.tanh({{input}})",
    "arg_mapping": {
      "data": "input"
    },
    "example_pairs": [
      {
        "tvm": "y = tvm.relay.op.tensor.tanh(x)",
        "torch": "y = torch.tanh(x)"
      }
    ],
    "constraints": "",
    "notes": "Direct element-wise hyperbolic tangent function.",
    "confidence": 0.99
  },
  {
    "tvm_api": "tvm.relay.op.tensor.add",
    "torch_api": "torch.add",
    "mapping_type": "direct",
    "direction": "tvm_to_torch",
    "tvm_pattern": "tvm.relay.op.tensor.add({{lhs}}, {{rhs}})",
    "torch_pattern": "torch.add({{input}}, {{other}})",
    "arg_mapping": {
      "lhs": "input",
      "rhs": "other"
    },
    "example_pairs": [
      {
        "tvm": "z = tvm.relay.op.tensor.add(x, y)",
        "torch": "z = torch.add(x, y)"
      },
      {
        "tvm": "z = tvm.relay.op.tensor.add(x, 5)",
        "torch": "z = torch.add(x, 5)"
      },
      {
        "tvm": "z = x + y",
        "torch": "z = x + y"
      }
    ],
    "constraints": "Supports broadcasting as described by NumPy-style broadcasting.",
    "notes": "Direct element-wise addition. Can also be represented by the `+` operator.",
    "confidence": 0.99
  },
  {
    "tvm_api": "tvm.relay.op.tensor.logical_or",
    "torch_api": "torch.logical_or",
    "mapping_type": "direct",
    "direction": "tvm_to_torch",
    "tvm_pattern": "tvm.relay.op.tensor.logical_or({{lhs}}, {{rhs}})",
    "torch_pattern": "torch.logical_or({{input}}, {{other}})",
    "arg_mapping": {
      "lhs": "input",
      "rhs": "other"
    },
    "example_pairs": [
      {
        "tvm": "z = tvm.relay.op.tensor.logical_or(x, y)",
        "torch": "z = torch.logical_or(x, y)"
      }
    ],
    "constraints": "Input tensors are treated as booleans (non-zero is True, zero is False). Supports broadcasting.",
    "notes": "Direct element-wise logical OR function.",
    "confidence": 0.99
  },
  {
    "tvm_api": "tvm.relay.op.tensor.equal",
    "torch_api": "torch.eq",
    "mapping_type": "direct",
    "direction": "tvm_to_torch",
    "tvm_pattern": "tvm.relay.op.tensor.equal({{lhs}}, {{rhs}})",
    "torch_pattern": "torch.eq({{input}}, {{other}})",
    "arg_mapping": {
      "lhs": "input",
      "rhs": "other"
    },
    "example_pairs": [
      {
        "tvm": "z = tvm.relay.op.tensor.equal(x, y)",
        "torch": "z = torch.eq(x, y)"
      },
      {
        "tvm": "z = x == y",
        "torch": "z = x == y"
      }
    ],
    "constraints": "Performs element-wise comparison. Supports broadcasting.",
    "notes": "TVM's description 'Broadcasted elementwise test for (lhs == rhs)' directly matches `torch.eq` (or the `==` operator for tensors) which returns a boolean tensor. `torch.equal` is generally used for a single boolean check of tensor *identity* (shape and content are exactly the same), not element-wise.",
    "confidence": 0.98
  },
  {
    "tvm_api": "tvm.relay.op.tensor.maximum",
    "torch_api": "torch.maximum",
    "mapping_type": "direct",
    "direction": "tvm_to_torch",
    "tvm_pattern": "tvm.relay.op.tensor.maximum({{lhs}}, {{rhs}})",
    "torch_pattern": "torch.maximum({{input}}, {{other}})",
    "arg_mapping": {
      "lhs": "input",
      "rhs": "other"
    },
    "example_pairs": [
      {
        "tvm": "z = tvm.relay.op.tensor.maximum(x, y)",
        "torch": "z = torch.maximum(x, y)"
      }
    ],
    "constraints": "Supports broadcasting.",
    "notes": "Direct element-wise maximum function.",
    "confidence": 0.99
  },
  {
    "tvm_api": "tvm.relay.op.tensor.minimum",
    "torch_api": "torch.minimum",
    "mapping_type": "direct",
    "direction": "tvm_to_torch",
    "tvm_pattern": "tvm.relay.op.tensor.minimum({{lhs}}, {{rhs}})",
    "torch_pattern": "torch.minimum({{input}}, {{other}})",
    "arg_mapping": {
      "lhs": "input",
      "rhs": "other"
    },
    "example_pairs": [
      {
        "tvm": "z = tvm.relay.op.tensor.minimum(x, y)",
        "torch": "z = torch.minimum(x, y)"
      }
    ],
    "constraints": "Supports broadcasting.",
    "notes": "Direct element-wise minimum function.",
    "confidence": 0.99
  },
  {
    "tvm_api": "tvm.relay.op.tensor.zeros",
    "torch_api": "torch.zeros",
    "mapping_type": "direct",
    "direction": "tvm_to_torch",
    "tvm_pattern": "tvm.relay.op.tensor.zeros({{shape}}, {{dtype}})",
    "torch_pattern": "torch.zeros({{shape}}, dtype={{dtype}})",
    "arg_mapping": {
      "shape": "size",
      "dtype": "dtype"
    },
    "example_pairs": [
      {
        "tvm": "z = tvm.relay.op.tensor.zeros((2, 3), 'float32')",
        "torch": "z = torch.zeros((2, 3), dtype=torch.float32)"
      }
    ],
    "constraints": "Assumes `shape` is a tuple/list of integers, and `dtype` is a string convertible to a PyTorch dtype (e.g., 'float32' to `torch.float32`). If `shape` is a symbolic Relay Expr, a pre-processing step to resolve it to a concrete tuple might be needed.",
    "notes": "Direct tensor creation function. `shape` in TVM maps to `size` in PyTorch. TVM `dtype` needs conversion from string to `torch.dtype` object.",
    "confidence": 0.95
  },
  {
    "tvm_api": "tvm.relay.op.tensor.zeros_like",
    "torch_api": "torch.zeros_like",
    "mapping_type": "direct",
    "direction": "tvm_to_torch",
    "tvm_pattern": "tvm.relay.op.tensor.zeros_like({{data}})",
    "torch_pattern": "torch.zeros_like({{input}})",
    "arg_mapping": {
      "data": "input"
    },
    "example_pairs": [
      {
        "tvm": "z = tvm.relay.op.tensor.zeros_like(x)",
        "torch": "z = torch.zeros_like(x)"
      }
    ],
    "constraints": "",
    "notes": "Direct function to create a zero tensor with the same shape and dtype as input.",
    "confidence": 0.99
  },
  {
    "tvm_api": "tvm.relay.op.tensor.ones",
    "torch_api": "torch.ones",
    "mapping_type": "direct",
    "direction": "tvm_to_torch",
    "tvm_pattern": "tvm.relay.op.tensor.ones({{shape}}, {{dtype}})",
    "torch_pattern": "torch.ones({{shape}}, dtype={{dtype}})",
    "arg_mapping": {
      "shape": "size",
      "dtype": "dtype"
    },
    "example_pairs": [
      {
        "tvm": "o = tvm.relay.op.tensor.ones((2, 3), 'float32')",
        "torch": "o = torch.ones((2, 3), dtype=torch.float32)"
      }
    ],
    "constraints": "Assumes `shape` is a tuple/list of integers, and `dtype` is a string convertible to a PyTorch dtype (e.g., 'float32' to `torch.float32`). If `shape` is a symbolic Relay Expr, a pre-processing step to resolve it to a concrete tuple might be needed.",
    "notes": "Direct tensor creation function. `shape` in TVM maps to `size` in PyTorch. TVM `dtype` needs conversion from string to `torch.dtype` object.",
    "confidence": 0.95
  },
  {
    "tvm_api": "tvm.relay.op.tensor.ones_like",
    "torch_api": "torch.ones_like",
    "mapping_type": "direct",
    "direction": "tvm_to_torch",
    "tvm_pattern": "tvm.relay.op.tensor.ones_like({{data}})",
    "torch_pattern": "torch.ones_like({{input}})",
    "arg_mapping": {
      "data": "input"
    },
    "example_pairs": [
      {
        "tvm": "o = tvm.relay.op.tensor.ones_like(x)",
        "torch": "o = torch.ones_like(x)"
      }
    ],
    "constraints": "",
    "notes": "Direct function to create a ones tensor with the same shape and dtype as input.",
    "confidence": 0.99
  },
  {
    "tvm_api": "tvm.relay.op.tensor.clip",
    "torch_api": "torch.clamp",
    "mapping_type": "direct",
    "direction": "tvm_to_torch",
    "tvm_pattern": "tvm.relay.op.tensor.clip({{a}}, {{a_min}}, {{a_max}})",
    "torch_pattern": "torch.clamp({{input}}, min={{min}}, max={{max}})",
    "arg_mapping": {
      "a": "input",
      "a_min": "min",
      "a_max": "max"
    },
    "example_pairs": [
      {
        "tvm": "clipped_x = tvm.relay.op.tensor.clip(x, 0.0, 1.0)",
        "torch": "clipped_x = torch.clamp(x, min=0.0, max=1.0)"
      }
    ],
    "constraints": "PyTorch's `clamp` also supports `min` and `max` as tensors, matching TVM's behavior of casting `a_min` and `a_max` to `a`'s dtype. If `a_min` or `a_max` are omitted, PyTorch's `clamp` can be called with only one bound (e.g., `clamp(min=...)`). TVM's `clip` implies both bounds are present.",
    "notes": "Direct mapping to `torch.clamp`. `a_min` maps to `min` and `a_max` maps to `max`.",
    "confidence": 0.99
  },
  {
    "tvm_api": "tvm.relay.op.tensor.concatenate",
    "torch_api": "torch.cat",
    "mapping_type": "direct",
    "direction": "tvm_to_torch",
    "tvm_pattern": "tvm.relay.op.tensor.concatenate({{data}}, axis={{axis}})",
    "torch_pattern": "torch.cat({{tensors}}, dim={{axis}})",
    "arg_mapping": {
      "data": "tensors",
      "axis": "dim"
    },
    "example_pairs": [
      {
        "tvm": "combined = tvm.relay.op.tensor.concatenate([a, b], axis=0)",
        "torch": "combined = torch.cat([a, b], dim=0)"
      }
    ],
    "constraints": "TVM's `data` is a list/tuple of tensors, which maps directly to PyTorch's `tensors` argument. TVM's `axis` must be an integer, matching PyTorch's `dim`.",
    "notes": "Direct mapping. The function names and argument semantics are equivalent.",
    "confidence": 0.99
  },
  {
    "tvm_api": "tvm.relay.op.tensor.einsum",
    "torch_api": "torch.einsum",
    "mapping_type": "direct",
    "direction": "tvm_to_torch",
    "tvm_pattern": "tvm.relay.op.tensor.einsum({{data}}, {{equation}})",
    "torch_pattern": "torch.einsum({{equation}}, *{{operands}})",
    "arg_mapping": {
      "data": "operands",
      "equation": "equation"
    },
    "example_pairs": [
      {
        "tvm": "result = tvm.relay.op.tensor.einsum([A, B], 'ij,jk->ik')",
        "torch": "result = torch.einsum('ij,jk->ik', A, B)"
      }
    ],
    "constraints": "TVM's `data` (list of tensors) maps to PyTorch's variadic `*operands` argument. The equation string syntax is identical.",
    "notes": "Direct mapping. Both TVM and PyTorch implement Einstein summation convention with identical string-based equation syntax.",
    "confidence": 0.99
  },
  {
    "tvm_api": "tvm.relay.op.tensor.stack",
    "torch_api": "torch.stack",
    "mapping_type": "direct",
    "direction": "tvm_to_torch",
    "tvm_pattern": "tvm.relay.op.tensor.stack({{data}}, axis={{axis}})",
    "torch_pattern": "torch.stack({{tensors}}, dim={{axis}})",
    "arg_mapping": {
      "data": "tensors",
      "axis": "dim"
    },
    "example_pairs": [
      {
        "tvm": "stacked = tvm.relay.op.tensor.stack([a, b, c], axis=0)",
        "torch": "stacked = torch.stack([a, b, c], dim=0)"
      }
    ],
    "constraints": "TVM's `data` (list or tuple of tensors) maps directly to PyTorch's `tensors` argument. TVM's `axis` must be an integer, matching PyTorch's `dim`.",
    "notes": "Direct mapping. The function names and argument semantics are equivalent.",
    "confidence": 0.99
  },
  {
    "tvm_api": "tvm.relay.op.tensor.copy",
    "torch_api": "torch.clone",
    "mapping_type": "direct",
    "direction": "tvm_to_torch",
    "tvm_pattern": "tvm.relay.op.tensor.copy({{data}})",
    "torch_pattern": "torch.clone({{input}})",
    "arg_mapping": {
      "data": "input"
    },
    "example_pairs": [
      {
        "tvm": "copied_x = tvm.relay.op.tensor.copy(x)",
        "torch": "copied_x = torch.clone(x)"
      }
    ],
    "constraints": "Creates a new tensor with the same data. PyTorch's `.detach().clone()` might be used if gradient tracking needs to be explicitly managed, but `torch.clone()` is the direct equivalent for data copying.",
    "notes": "Directly maps to `torch.clone()` which creates a new tensor (a copy) with the same data, shape, and dtype as the input. The PyTorch candidate `copy` in `torch._inductor.lowering.py` uses `clone` internally for a similar purpose.",
    "confidence": 0.98
  },
  {
    "tvm_api": "tvm.relay.op.tensor.isnan",
    "torch_api": "torch.isnan",
    "mapping_type": "direct",
    "direction": "tvm_to_torch",
    "tvm_pattern": "tvm.relay.op.tensor.isnan({{data}})",
    "torch_pattern": "torch.isnan({{input}})",
    "arg_mapping": {
      "data": "input"
    },
    "example_pairs": [
      {
        "tvm": "is_nan_mask = tvm.relay.op.tensor.isnan(x)",
        "torch": "is_nan_mask = torch.isnan(x)"
      }
    ],
    "constraints": "",
    "notes": "Direct element-wise NaN check function.",
    "confidence": 0.99
  },
  {
    "tvm_api": "tvm.relay.op.transform.expand_dims",
    "torch_api": "torch.unsqueeze",
    "mapping_type": "direct",
    "direction": "tvm_to_torch",
    "tvm_pattern": "tvm.relay.op.transform.expand_dims({{data}}, axis={{axis}}, num_newaxis={{num_newaxis}})",
    "torch_pattern": "torch.unsqueeze({{input}}, dim={{axis}})",
    "arg_mapping": {
      "data": "input",
      "axis": "dim"
    },
    "example_pairs": [
      {
        "tvm": "expanded = tvm.relay.op.transform.expand_dims(x, axis=0, num_newaxis=1)",
        "torch": "expanded = torch.unsqueeze(x, dim=0)"
      },
      {
        "tvm": "expanded = tvm.relay.op.transform.expand_dims(x, axis=-1, num_newaxis=1)",
        "torch": "expanded = torch.unsqueeze(x, dim=-1)"
      }
    ],
    "constraints": "This mapping is for `num_newaxis=1`. If `num_newaxis > 1`, a composite mapping with multiple `torch.unsqueeze` calls or `torch.reshape` would be needed. `axis` in TVM and `dim` in PyTorch can handle negative indices for relative positioning.",
    "notes": "Directly maps to `torch.unsqueeze` when `num_newaxis=1`. The `torch._numpy._funcs_impl.py::expand_dims` implementation suggests `view`ing, which is conceptually similar but `unsqueeze` is a more direct, dedicated API for this specific transformation.",
    "confidence": 0.9
  },
  {
    "tvm_api": "tvm.relay.op.transform.transpose",
    "torch_api": "torch.permute",
    "mapping_type": "direct",
    "direction": "tvm_to_torch",
    "tvm_pattern": "tvm.relay.op.transform.transpose({{data}}, axes={{axes}})",
    "torch_pattern": "torch.permute({{input}}, dims={{dims}})",
    "arg_mapping": {
      "data": "input",
      "axes": "dims"
    },
    "example_pairs": [
      {
        "tvm": "transposed_x = tvm.relay.op.transform.transpose(x)",
        "torch": "transposed_x = torch.permute(x, dims=tuple(reversed(range(x.ndim))))"
      },
      {
        "tvm": "transposed_x = tvm.relay.op.transform.transpose(x, axes=[0, 2, 1])",
        "torch": "transposed_x = torch.permute(x, dims=[0, 2, 1])"
      }
    ],
    "constraints": "If TVM's `axes` is `None`, it implies reversing the dimensions. This needs to be explicitly converted to `tuple(reversed(range(input.ndim)))` for `torch.permute`. If only two dimensions are swapped, `torch.transpose(input, dim0, dim1)` could also be used, but `permute` is more general.",
    "notes": "Directly maps to `torch.permute`. TVM's `axes` parameter directly corresponds to PyTorch's `dims`. The special case of `axes=None` in TVM (reverse dimensions) needs to be handled by constructing the `dims` tuple.",
    "confidence": 0.95
  },
  {
    "tvm_api": "tvm.relay.op.transform.squeeze",
    "torch_api": "torch.squeeze",
    "mapping_type": "direct",
    "direction": "tvm_to_torch",
    "tvm_pattern": "tvm.relay.op.transform.squeeze({{data}}, axis={{axis}})",
    "torch_pattern": "torch.squeeze({{data}}, dim={{axis}})",
    "arg_mapping": {
      "data": "data",
      "axis": "dim"
    },
    "example_pairs": [
      {
        "tvm": "x_squeezed = tvm.relay.op.transform.squeeze(x, axis=0)",
        "torch": "x_squeezed = torch.squeeze(x, dim=0)"
      },
      {
        "tvm": "x_squeezed = tvm.relay.op.transform.squeeze(x)",
        "torch": "x_squeezed = torch.squeeze(x)"
      }
    ],
    "constraints": "PyTorch's `dim` is equivalent to TVM's `axis`. If specified axis does not have dimension 1, an error is raised in both.",
    "notes": "Direct mapping to torch.squeeze, which removes dimensions of size 1. 'axis=None' in TVM means removing all dimensions of size 1, which is also the default behavior of torch.squeeze when `dim` is not provided.",
    "confidence": 0.98
  },
  {
    "tvm_api": "tvm.relay.op.transform.reshape",
    "torch_api": "torch.reshape",
    "mapping_type": "direct",
    "direction": "tvm_to_torch",
    "tvm_pattern": "tvm.relay.op.transform.reshape({{data}}, newshape={{newshape}}, allowzero={{allowzero}})",
    "torch_pattern": "torch.reshape({{data}}, {{newshape}})",
    "arg_mapping": {
      "data": "data",
      "newshape": "newshape"
    },
    "example_pairs": [
      {
        "tvm": "y = tvm.relay.op.transform.reshape(x, newshape=(4, 3, 2))",
        "torch": "y = torch.reshape(x, (4, 3, 2))"
      },
      {
        "tvm": "y = tvm.relay.op.transform.reshape(x, newshape=(2, -1))",
        "torch": "y = torch.reshape(x, (2, -1))"
      }
    ],
    "constraints": "TVM's `newshape` allows `0` to copy a dimension from the input. PyTorch's `reshape` does not support this and treats `0` as a literal dimension size, which would typically be an error unless the input has a 0-sized dimension. The `allowzero` parameter is not directly supported in PyTorch's `torch.reshape` and would require custom handling for true empty tensor semantics.",
    "notes": "Directly maps for common use cases, especially with `-1` for inferred dimensions. The behavior for `0` in `newshape` and the `allowzero` parameter in TVM differ from PyTorch's native `reshape`.",
    "confidence": 0.85
  },
  {
    "tvm_api": "tvm.relay.op.transform.argwhere",
    "torch_api": "torch.argwhere",
    "mapping_type": "direct",
    "direction": "tvm_to_torch",
    "tvm_pattern": "tvm.relay.op.transform.argwhere({{condition}})",
    "torch_pattern": "torch.argwhere({{condition}})",
    "arg_mapping": {
      "condition": "condition"
    },
    "example_pairs": [
      {
        "tvm": "indices = tvm.relay.op.transform.argwhere(cond_tensor)",
        "torch": "indices = torch.argwhere(cond_tensor)"
      }
    ],
    "constraints": "Functionality is identical: returns the indices of non-zero elements.",
    "notes": "Directly corresponds to `torch.argwhere`, which is a NumPy-compatible alias for `torch.nonzero(as_tuple=False)`.",
    "confidence": 0.99
  },
  {
    "tvm_api": "tvm.relay.op.transform.scatter",
    "torch_api": "torch.scatter",
    "mapping_type": "direct",
    "direction": "tvm_to_torch",
    "tvm_pattern": "tvm.relay.op.transform.scatter({{data}}, {{indices}}, {{updates}}, axis={{axis}})",
    "torch_pattern": "torch.scatter({{data}}, dim={{axis}}, index={{indices}}, src={{updates}})",
    "arg_mapping": {
      "data": "data",
      "indices": "index",
      "updates": "src",
      "axis": "dim"
    },
    "example_pairs": [
      {
        "tvm": "output = tvm.relay.op.transform.scatter(data, indices, updates, axis=0)",
        "torch": "output = torch.scatter(data, dim=0, index=indices, src=updates)"
      }
    ],
    "constraints": "TVM's `scatter` does not explicitly have a `reduce` argument like PyTorch's. PyTorch's default behavior for `scatter` when elements overlap is 'update' (last write wins), which aligns with the typical scatter operation. If reduction is required, `scatter_add` or `scatter_reduce` should be used.",
    "notes": "Directly maps to `torch.scatter`. The arguments are functionally equivalent.",
    "confidence": 0.97
  },
  {
    "tvm_api": "tvm.relay.op.transform.scatter_add",
    "torch_api": "torch.scatter_add",
    "mapping_type": "direct",
    "direction": "tvm_to_torch",
    "tvm_pattern": "tvm.relay.op.transform.scatter_add({{data}}, {{indices}}, {{updates}}, axis={{axis}})",
    "torch_pattern": "torch.scatter_add({{data}}, dim={{axis}}, index={{indices}}, src={{updates}})",
    "arg_mapping": {
      "data": "data",
      "indices": "index",
      "updates": "src",
      "axis": "dim"
    },
    "example_pairs": [
      {
        "tvm": "output = tvm.relay.op.transform.scatter_add(data, indices, updates, axis=0)",
        "torch": "output = torch.scatter_add(data, dim=0, index=indices, src=updates)"
      }
    ],
    "constraints": "Functionality is identical: adds values from `updates` to `data` at specified `indices` along `axis`.",
    "notes": "Directly maps to `torch.scatter_add`. The arguments are functionally equivalent.",
    "confidence": 0.99
  },
  {
    "tvm_api": "tvm.relay.op.transform.take",
    "torch_api": "torch.take",
    "mapping_type": "direct",
    "direction": "tvm_to_torch",
    "tvm_pattern": "tvm.relay.op.transform.take({{data}}, {{indices}}, axis={{axis}}, batch_dims={{batch_dims}}, mode='{{mode}}')",
    "torch_pattern": "torch.take({{data}}, {{indices}})",
    "arg_mapping": {
      "data": "data",
      "indices": "indices"
    },
    "example_pairs": [
      {
        "tvm": "output = tvm.relay.op.transform.take(data, indices)",
        "torch": "output = torch.take(data, indices)"
      }
    ],
    "constraints": "PyTorch's `torch.take` by default flattens the input `data` before indexing, which matches TVM's `axis=None` behavior. However, PyTorch's `torch.take` does not directly support the `axis`, `batch_dims`, or `mode` arguments. For non-flattened `axis` behavior, `torch.take_along_dim` would be more appropriate but requires reshaping `indices` and `data` to match semantics. For this direct mapping, we assume `axis=None` for TVM. `mode` ('clip', 'wrap', 'fast') is not directly supported by `torch.take`.",
    "notes": "Matches the default behavior of TVM's `take` where the input array is flattened. For more complex `axis` or `mode` scenarios, a composite mapping using `torch.take_along_dim` or explicit indexing might be needed.",
    "confidence": 0.8
  },
  {
    "tvm_api": "tvm.relay.op.transform.full",
    "torch_api": "torch.full",
    "mapping_type": "direct",
    "direction": "tvm_to_torch",
    "tvm_pattern": "tvm.relay.op.transform.full(fill_value={{fill_value}}, shape={{shape}}, dtype='{{dtype}}')",
    "torch_pattern": "torch.full(size={{shape}}, fill_value={{fill_value}}, dtype=torch.{{dtype}})",
    "arg_mapping": {
      "fill_value": "fill_value",
      "shape": "size",
      "dtype": "dtype"
    },
    "example_pairs": [
      {
        "tvm": "tensor = tvm.relay.op.transform.full(fill_value=1.0, shape=(2, 3), dtype='float32')",
        "torch": "tensor = torch.full(size=(2, 3), fill_value=1.0, dtype=torch.float32)"
      }
    ],
    "constraints": "PyTorch's `dtype` is specified using `torch.float32` etc., not as a string. TVM's `shape` maps to PyTorch's `size`.",
    "notes": "Directly maps to `torch.full`, creating a tensor of specified shape and filling it with a scalar value.",
    "confidence": 0.99
  },
  {
    "tvm_api": "tvm.relay.op.transform.full_like",
    "torch_api": "torch.full_like",
    "mapping_type": "direct",
    "direction": "tvm_to_torch",
    "tvm_pattern": "tvm.relay.op.transform.full_like({{data}}, fill_value={{fill_value}})",
    "torch_pattern": "torch.full_like({{data}}, fill_value={{fill_value}})",
    "arg_mapping": {
      "data": "data",
      "fill_value": "fill_value"
    },
    "example_pairs": [
      {
        "tvm": "tensor = tvm.relay.op.transform.full_like(input_tensor, fill_value=0.0)",
        "torch": "tensor = torch.full_like(input_tensor, fill_value=0.0)"
      }
    ],
    "constraints": "The `dtype`, `layout`, `device`, `pin_memory`, `requires_grad`, `memory_format` parameters are implicitly taken from the `data` tensor in PyTorch unless explicitly overridden, which aligns with TVM's 'same shape and type as input array'.",
    "notes": "Directly maps to `torch.full_like`, creating a tensor with the same shape and properties as `data`, filled with `fill_value`.",
    "confidence": 0.99
  },
  {
    "tvm_api": "tvm.relay.op.transform.arange",
    "torch_api": "torch.arange",
    "mapping_type": "direct",
    "direction": "tvm_to_torch",
    "tvm_pattern": "tvm.relay.op.transform.arange(start={{start}}, stop={{stop}}, step={{step}}, dtype='{{dtype}}')",
    "torch_pattern": "torch.arange(start={{start}}, end={{stop}}, step={{step}}, dtype=torch.{{dtype}})",
    "arg_mapping": {
      "start": "start",
      "stop": "end",
      "step": "step",
      "dtype": "dtype"
    },
    "example_pairs": [
      {
        "tvm": "seq = tvm.relay.op.transform.arange(start=0, stop=10, step=2, dtype='int32')",
        "torch": "seq = torch.arange(start=0, end=10, step=2, dtype=torch.int32)"
      }
    ],
    "constraints": "PyTorch uses `end` for `stop`. `dtype` is specified as `torch.float32` etc. in PyTorch. Both handle the single-argument case as `stop`.",
    "notes": "Directly maps to `torch.arange`, generating evenly spaced values within an interval.",
    "confidence": 0.98
  },
  {
    "tvm_api": "tvm.relay.op.transform.meshgrid",
    "torch_api": "torch.meshgrid",
    "mapping_type": "direct",
    "direction": "tvm_to_torch",
    "tvm_pattern": "tvm.relay.op.transform.meshgrid(data={{data}}, indexing='{{indexing}}')",
    "torch_pattern": "torch.meshgrid(*{{data}}, indexing='{{indexing}}')",
    "arg_mapping": {
      "data": "data",
      "indexing": "indexing"
    },
    "example_pairs": [
      {
        "tvm": "grid_x, grid_y = tvm.relay.op.transform.meshgrid(data=[x_coords, y_coords], indexing='ij')",
        "torch": "grid_x, grid_y = torch.meshgrid(x_coords, y_coords, indexing='ij')"
      }
    ],
    "constraints": "TVM defaults `indexing` to 'ij', while PyTorch defaults to 'xy'. The example uses 'ij' for consistency. PyTorch takes individual tensors as `*args` instead of a list/tuple for `data`.",
    "notes": "Directly maps to `torch.meshgrid`. Requires careful handling of the `indexing` argument if TVM's default 'ij' is used, as PyTorch's default is 'xy'.",
    "confidence": 0.95
  },
  {
    "tvm_api": "tvm.relay.op.transform.repeat",
    "torch_api": "torch.repeat_interleave",
    "mapping_type": "direct",
    "direction": "tvm_to_torch",
    "tvm_pattern": "tvm.relay.op.transform.repeat({{data}}, repeats={{repeats}}, axis={{axis}})",
    "torch_pattern": "torch.repeat_interleave({{data}}, repeats={{repeats}}, dim={{axis}})",
    "arg_mapping": {
      "data": "data",
      "repeats": "repeats",
      "axis": "dim"
    },
    "example_pairs": [
      {
        "tvm": "output = tvm.relay.op.transform.repeat(x, repeats=3, axis=0)",
        "torch": "output = torch.repeat_interleave(x, repeats=3, dim=0)"
      },
      {
        "tvm": "output = tvm.relay.op.transform.repeat(x, repeats=3, axis=None)",
        "torch": "output = torch.repeat_interleave(x.flatten(), repeats=3, dim=0)"
      }
    ],
    "constraints": "PyTorch's `torch.repeat` (tensor method) repeats the *entire tensor* along given dimensions (like `numpy.tile`), while TVM's `repeat` and PyTorch's `torch.repeat_interleave` repeat *elements*. When `axis=None`, TVM flattens the input, which requires `x.flatten()` in PyTorch for `repeat_interleave`.",
    "notes": "The TVM description 'Repeats elements of an array' aligns perfectly with `torch.repeat_interleave`, not `torch.repeat` (which duplicates the tensor along new/existing dimensions).",
    "confidence": 0.95
  },
  {
    "tvm_api": "tvm.relay.op.transform.tile",
    "torch_api": "torch.tile",
    "mapping_type": "direct",
    "direction": "tvm_to_torch",
    "tvm_pattern": "tvm.relay.op.transform.tile({{data}}, reps={{reps}})",
    "torch_pattern": "torch.tile({{data}}, dims={{reps}})",
    "arg_mapping": {
      "data": "data",
      "reps": "dims"
    },
    "example_pairs": [
      {
        "tvm": "output = tvm.relay.op.transform.tile(x, reps=(2, 3))",
        "torch": "output = torch.tile(x, dims=(2, 3))"
      }
    ],
    "constraints": "TVM's `reps` is a tuple of ints; PyTorch's `dims` is also a tuple of ints.",
    "notes": "Directly maps to `torch.tile`, which repeats the input tensor along each dimension according to `reps`.",
    "confidence": 0.99
  },
  {
    "tvm_api": "tvm.relay.op.transform.reverse",
    "torch_api": "torch.flip",
    "mapping_type": "composite",
    "direction": "tvm_to_torch",
    "tvm_pattern": "tvm.relay.op.transform.reverse({{data}}, axis={{axis}})",
    "torch_pattern": "torch.flip({{data}}, dims=[{{axis}}])",
    "arg_mapping": {
      "data": "data",
      "axis": "dims_list_element"
    },
    "example_pairs": [
      {
        "tvm": "output = tvm.relay.op.transform.reverse(x, axis=0)",
        "torch": "output = torch.flip(x, dims=[0])"
      }
    ],
    "constraints": "PyTorch's `flip` expects a list of dimensions to flip, even for a single axis.",
    "notes": "TVM's `reverse` operation, which reverses elements along a given axis, is functionally equivalent to PyTorch's `torch.flip` where the `dims` argument specifies the axes to flip.",
    "confidence": 0.95
  },
  {
    "tvm_api": "tvm.relay.op.transform.where",
    "torch_api": "torch.where",
    "mapping_type": "direct",
    "direction": "tvm_to_torch",
    "tvm_pattern": "tvm.relay.op.transform.where({{condition}}, {{x}}, {{y}})",
    "torch_pattern": "torch.where({{condition}}, {{x}}, {{y}})",
    "arg_mapping": {
      "condition": "condition",
      "x": "x",
      "y": "y"
    },
    "example_pairs": [
      {
        "tvm": "result = tvm.relay.op.transform.where(cond, val1, val2)",
        "torch": "result = torch.where(cond, val1, val2)"
      }
    ],
    "constraints": "Shapes of condition, x, and y must be broadcastable to a common shape in both frameworks.",
    "notes": "Directly maps to `torch.where`, which selects elements from `x` or `y` based on `condition`.",
    "confidence": 0.99
  },
  {
    "tvm_api": "tvm.relay.op.transform.broadcast_to",
    "torch_api": "torch.broadcast_to",
    "mapping_type": "direct",
    "direction": "tvm_to_torch",
    "tvm_pattern": "tvm.relay.op.transform.broadcast_to({{data}}, shape={{shape}})",
    "torch_pattern": "torch.broadcast_to({{data}}, size={{shape}})",
    "arg_mapping": {
      "data": "data",
      "shape": "size"
    },
    "example_pairs": [
      {
        "tvm": "output = tvm.relay.op.transform.broadcast_to(x, shape=(3, 4, 5))",
        "torch": "output = torch.broadcast_to(x, size=(3, 4, 5))"
      }
    ],
    "constraints": "TVM's `shape` maps to PyTorch's `size`.",
    "notes": "Directly maps to `torch.broadcast_to`, which expands the input tensor to a new shape by broadcasting.",
    "confidence": 0.99
  },
  {
    "tvm_api": "tvm.relay.op.transform.split",
    "torch_api": "torch.split",
    "mapping_type": "direct",
    "direction": "tvm_to_torch",
    "tvm_pattern": "tvm.relay.op.transform.split({{data}}, indices_or_sections={{indices_or_sections}}, axis={{axis}})",
    "torch_pattern": "torch.split({{data}}, split_size_or_sections={{indices_or_sections}}, dim={{axis}})",
    "arg_mapping": {
      "data": "data",
      "indices_or_sections": "split_size_or_sections",
      "axis": "dim"
    },
    "example_pairs": [
      {
        "tvm": "t1, t2, t3 = tvm.relay.op.transform.split(x, indices_or_sections=3, axis=1)",
        "torch": "t1, t2, t3 = torch.split(x, split_size_or_sections=3, dim=1)"
      },
      {
        "tvm": "t1, t2 = tvm.relay.op.transform.split(x, indices_or_sections=(2, 4), axis=1)",
        "torch": "t1, t2 = torch.split(x, split_size_or_sections=(2, 4), dim=1)"
      }
    ],
    "constraints": "Arguments and behavior align perfectly.",
    "notes": "Directly maps to `torch.split`. TVM's `indices_or_sections` corresponds to PyTorch's `split_size_or_sections`, and `axis` to `dim`.",
    "confidence": 0.99
  },
  {
    "tvm_api": "tvm.relay.op.transform.gather",
    "torch_api": "torch.gather",
    "mapping_type": "direct",
    "direction": "tvm_to_torch",
    "tvm_pattern": "tvm.relay.op.transform.gather({{data}}, axis={{axis}}, indices={{indices}})",
    "torch_pattern": "torch.gather({{data}}, dim={{axis}}, index={{indices}})",
    "arg_mapping": {
      "data": "data",
      "axis": "dim",
      "indices": "index"
    },
    "example_pairs": [
      {
        "tvm": "output = tvm.relay.op.transform.gather(data_tensor, axis=1, indices=idx_tensor)",
        "torch": "output = torch.gather(data_tensor, dim=1, index=idx_tensor)"
      }
    ],
    "constraints": "PyTorch's `gather` has an optional `sparse_grad` argument which TVM's does not. Otherwise, arguments and functionality are identical.",
    "notes": "Directly maps to `torch.gather`. Arguments are functionally equivalent.",
    "confidence": 0.98
  },
  {
    "tvm_api": "tvm.relay.op.transform.one_hot",
    "torch_api": "torch.nn.functional.one_hot",
    "mapping_type": "composite",
    "direction": "tvm_to_torch",
    "tvm_pattern": "tvm.relay.op.transform.one_hot(indices={{indices}}, on_value={{on_value}}, off_value={{off_value}}, depth={{depth}}, axis={{axis}}, dtype='{{dtype}}')",
    "torch_pattern": "(torch.nn.functional.one_hot({{indices}}, num_classes={{depth}}).to(torch.{{dtype}}) * ({{on_value}} - {{off_value}})) + {{off_value}}",
    "arg_mapping": {
      "indices": "indices",
      "on_value": "on_value",
      "off_value": "off_value",
      "depth": "num_classes",
      "dtype": "dtype"
    },
    "example_pairs": [
      {
        "tvm": "onehot_tensor = tvm.relay.op.transform.one_hot(indices_in, on_value=1.0, off_value=0.0, depth=10, axis=-1, dtype='float32')",
        "torch": "onehot_tensor = (torch.nn.functional.one_hot(indices_in, num_classes=10).to(torch.float32) * (1.0 - 0.0)) + 0.0"
      }
    ],
    "constraints": "PyTorch's `F.one_hot` only produces tensors of 0s and 1s. To achieve `on_value` and `off_value`, a linear scaling and shift operation is required. PyTorch's `F.one_hot` implicitly adds the one-hot dimension at the end of the input's shape, so if `axis` is not -1 in TVM, additional `permute` or `transpose` operations might be needed to place the dimension correctly.",
    "notes": "Composite mapping. PyTorch's `F.one_hot` is combined with arithmetic operations to match the TVM `on_value` and `off_value` semantics. The `axis` parameter would implicitly be the last dimension in PyTorch, requiring permutation if different.",
    "confidence": 0.85
  },
  {
    "tvm_api": "tvm.relay.op.transform.unravel_index",
    "torch_api": "torch.unravel_index",
    "mapping_type": "direct",
    "direction": "tvm_to_torch",
    "tvm_pattern": "tvm.relay.op.transform.unravel_index(indices={{indices}}, shape={{shape}})",
    "torch_pattern": "torch.unravel_index(indices={{indices}}, shape={{shape}})",
    "arg_mapping": {
      "indices": "indices",
      "shape": "shape"
    },
    "example_pairs": [
      {
        "tvm": "coords = tvm.relay.op.transform.unravel_index(flat_indices, (7, 6))",
        "torch": "coords = torch.unravel_index(flat_indices, (7, 6))"
      }
    ],
    "constraints": "Arguments and functionality are identical. Both return a tuple of coordinate tensors.",
    "notes": "Directly maps to `torch.unravel_index`, converting flat indices to coordinate arrays.",
    "confidence": 0.99
  },
  {
    "tvm_api": "tvm.relay.op.transform.cumsum",
    "torch_api": "torch.cumsum",
    "mapping_type": "direct",
    "direction": "tvm_to_torch",
    "tvm_pattern": "tvm.relay.op.transform.cumsum({{data}}, axis={{axis}}, dtype='{{dtype}}', exclusive={{exclusive}})",
    "torch_pattern": "torch.cumsum({{data}}, dim={{axis}}, dtype=torch.{{dtype}})",
    "arg_mapping": {
      "data": "data",
      "axis": "dim",
      "dtype": "dtype"
    },
    "example_pairs": [
      {
        "tvm": "output = tvm.relay.op.transform.cumsum(x, axis=0, dtype='float32')",
        "torch": "output = torch.cumsum(x, dim=0, dtype=torch.float32)"
      },
      {
        "tvm": "output = tvm.relay.op.transform.cumsum(x, axis=None)",
        "torch": "output = torch.cumsum(x.flatten(), dim=0)"
      }
    ],
    "constraints": "PyTorch's `torch.cumsum` does not have an `exclusive` parameter. Implementing an exclusive cumulative sum would require additional operations (e.g., `torch.cat([torch.zeros_like(data.narrow(dim=axis, start=0, length=1)), data.cumsum(dim=axis)], dim=axis)[:, :-1])`). If TVM's `axis` is `None`, PyTorch requires flattening the input before `cumsum` (and then potentially reshaping back).",
    "notes": "Directly maps for the inclusive cumulative sum. The `exclusive` parameter requires a composite operation in PyTorch. For `axis=None`, `data.flatten()` is needed.",
    "confidence": 0.8
  },
  {
    "tvm_api": "tvm.relay.op.transform.unique",
    "torch_api": "torch.unique",
    "mapping_type": "direct",
    "direction": "tvm_to_torch",
    "tvm_pattern": "tvm.relay.op.transform.unique({{data}}, is_sorted={{is_sorted}}, return_counts={{return_counts}})",
    "torch_pattern": "torch.unique({{data}}, return_counts={{return_counts}}, sorted={{is_sorted}})",
    "arg_mapping": {
      "data": "data",
      "is_sorted": "sorted",
      "return_counts": "return_counts"
    },
    "example_pairs": [
      {
        "tvm": "u, c = tvm.relay.op.transform.unique(x, return_counts=True)",
        "torch": "u, c = torch.unique(x, return_counts=True)"
      }
    ],
    "constraints": "TVM specifies `data` as a 1-D tensor of integers, while PyTorch's `torch.unique` can operate on higher-dimensional tensors and different dtypes. The `dim` argument in `torch.unique` is not explicitly present in TVM, implying a flattened unique if not 1D. Both have `sorted` and `return_counts` parameters.",
    "notes": "Directly maps to `torch.unique`. Assumes the typical use case for 1-D or flattened tensors.",
    "confidence": 0.95
  },
  {
    "tvm_api": "tvm.relay.op.transform.stft",
    "torch_api": "torch.stft",
    "mapping_type": "direct",
    "direction": "tvm_to_torch",
    "tvm_pattern": "tvm.relay.op.transform.stft(data={{data}}, n_fft={{n_fft}}, hop_length={{hop_length}}, win_length={{win_length}}, window={{window}}, normalized={{normalized}}, onesided={{onesided}})",
    "torch_pattern": "torch.stft(input={{data}}, n_fft={{n_fft}}, hop_length={{hop_length}}, win_length={{win_length}}, window={{window}}, normalized={{normalized}}, onesided={{onesided}}, return_complex=True)",
    "arg_mapping": {
      "data": "input",
      "n_fft": "n_fft",
      "hop_length": "hop_length",
      "win_length": "win_length",
      "window": "window",
      "normalized": "normalized",
      "onesided": "onesided"
    },
    "example_pairs": [
      {
        "tvm": "stft_out = tvm.relay.op.transform.stft(audio_data, n_fft=400, hop_length=160, window=torch.hann_window(400))",
        "torch": "stft_out = torch.stft(audio_data, n_fft=400, hop_length=160, window=torch.hann_window(400), return_complex=True)"
      }
    ],
    "constraints": "PyTorch's `stft` has additional parameters like `center`, `pad_mode`, `return_complex`, `align_to_window`. For real inputs, `return_complex=True` is strongly preferred in PyTorch versions 1.8.0+, which is assumed here. TVM's arguments are a subset of PyTorch's.",
    "notes": "Directly maps to `torch.stft`. The core parameters are the same.",
    "confidence": 0.98
  },
  {
    "tvm_api": "tvm.relay.op.annotation.annotation.checkpoint",
    "torch_api": "torch.utils.checkpoint.checkpoint",
    "mapping_type": "direct",
    "direction": "tvm_to_torch",
    "tvm_pattern": "tvm.relay.op.annotation.checkpoint({{data}})",
    "torch_pattern": "torch.utils.checkpoint.checkpoint(lambda data: data, {{data}})",
    "arg_mapping": {
      "data": "data"
    },
    "example_pairs": [
      {
        "tvm": "out = tvm.relay.op.annotation.checkpoint(expensive_op(x))",
        "torch": "out = torch.utils.checkpoint.checkpoint(lambda x: expensive_op(x), x)"
      }
    ],
    "constraints": "TVM's `checkpoint` annotates an expression, implying a functional transformation. PyTorch's `checkpoint` wraps a function that takes tensors as input and returns tensors. The example assumes `expensive_op(x)` is the expression to be checkpointed, which is then wrapped in a lambda for PyTorch.",
    "notes": "Direct conceptual mapping. Both serve to enable activation checkpointing for memory optimization. PyTorch's API expects a callable, so the TVM expression needs to be wrapped.",
    "confidence": 0.9
  },
  {
    "tvm_api": "tvm.relay.op.image.image.affine_grid",
    "torch_api": "torch.nn.functional.affine_grid",
    "mapping_type": "direct",
    "direction": "tvm_to_torch",
    "tvm_pattern": "tvm.relay.op.image.affine_grid(data={{data}}, target_shape={{target_shape}})",
    "torch_pattern": "torch.nn.functional.affine_grid(theta={{data}}, size=[1, 1, *{{target_shape}}], align_corners=False)",
    "arg_mapping": {
      "data": "theta",
      "target_shape": "size_h_w"
    },
    "example_pairs": [
      {
        "tvm": "grid = tvm.relay.op.image.affine_grid(theta_matrix, target_shape=(64, 64))",
        "torch": "grid = torch.nn.functional.affine_grid(theta_matrix, size=[1, 1, 64, 64], align_corners=False)"
      }
    ],
    "constraints": "PyTorch's `size` argument expects a 4-D (for 2D) or 5-D (for 3D) shape `(N, C, H, W)` or `(N, C, D, H, W)`. TVM's `target_shape` is typically `(H, W)`. So PyTorch's `size` needs to be constructed, e.g., `[batch_size, channels, *target_shape]`. The example assumes a batch size of 1 and 1 channel, and `align_corners` is a new PyTorch parameter, defaulted to `False` for safety.",
    "notes": "Direct mapping for generating affine transformation grids. The `target_shape` handling requires constructing the full output tensor shape for PyTorch.",
    "confidence": 0.9
  },
  {
    "tvm_api": "tvm.relay.op.image.image.grid_sample",
    "torch_api": "torch.nn.functional.grid_sample",
    "mapping_type": "direct",
    "direction": "tvm_to_torch",
    "tvm_pattern": "tvm.relay.op.image.grid_sample(data={{data}}, grid={{grid}}, method='{{method}}', layout='{{layout}}', padding_mode='{{padding_mode}}', align_corners={{align_corners}})",
    "torch_pattern": "torch.nn.functional.grid_sample(input={{data}}, grid={{grid}}, mode='{{method}}', padding_mode='{{padding_mode}}', align_corners={{align_corners}})",
    "arg_mapping": {
      "data": "input",
      "grid": "grid",
      "method": "mode",
      "padding_mode": "padding_mode",
      "align_corners": "align_corners"
    },
    "example_pairs": [
      {
        "tvm": "sampled_img = tvm.relay.op.image.grid_sample(input_image, sampling_grid, method='bilinear', padding_mode='zeros')",
        "torch": "sampled_img = torch.nn.functional.grid_sample(input_image, sampling_grid, mode='bilinear', padding_mode='zeros')"
      }
    ],
    "constraints": "TVM's `layout` parameter is not present in PyTorch's `F.grid_sample`, as PyTorch operates on NCHW/NCDHW layout natively. TVM's `method` corresponds to PyTorch's `mode`.",
    "notes": "Directly maps to `torch.nn.functional.grid_sample`. Parameters align well.",
    "confidence": 0.98
  },
  {
    "tvm_api": "tvm.relay.op.nn.nn.conv1d",
    "torch_api": "torch.nn.functional.conv1d",
    "mapping_type": "direct",
    "direction": "tvm_to_torch",
    "tvm_pattern": "tvm.relay.op.nn.conv1d(data={{data}}, weight={{weight}}, strides={{strides}}, padding={{padding}}, dilation={{dilation}}, groups={{groups}}, channels={{channels}}, kernel_size={{kernel_size}}, data_layout='{{data_layout}}', kernel_layout='{{kernel_layout}}', out_layout='{{out_layout}}', out_dtype='{{out_dtype}}')",
    "torch_pattern": "torch.nn.functional.conv1d(input={{data}}, weight={{weight}}, bias=None, stride={{strides}}, padding={{padding}}, dilation={{dilation}}, groups={{groups}})",
    "arg_mapping": {
      "data": "input",
      "weight": "weight",
      "strides": "stride",
      "padding": "padding",
      "dilation": "dilation",
      "groups": "groups"
    },
    "example_pairs": [
      {
        "tvm": "output = tvm.relay.op.nn.conv1d(input_data, kernel_weight, strides=1, padding=0)",
        "torch": "output = torch.nn.functional.conv1d(input_data, kernel_weight, bias=None, stride=1, padding=0)"
      }
    ],
    "constraints": "PyTorch's `F.conv1d` requires a `bias` argument (can be `None`), which TVM's `conv1d` does not explicitly show but often includes as a separate op. TVM's `channels`, `kernel_size` are usually inferred from `weight` shape in PyTorch. TVM's `data_layout`, `kernel_layout`, `out_layout`, `out_dtype` are typically handled by PyTorch's internal tensor formats or implicit conversions.",
    "notes": "Direct mapping to `torch.nn.functional.conv1d`. Assumes no bias is used, or it's handled separately. Layout and dtype parameters are implicitly managed by PyTorch.",
    "confidence": 0.9
  },
  {
    "tvm_api": "tvm.relay.op.nn.nn.conv2d",
    "torch_api": "torch.nn.functional.conv2d",
    "mapping_type": "direct",
    "direction": "tvm_to_torch",
    "tvm_pattern": "tvm.relay.op.nn.conv2d(data={{data}}, weight={{weight}}, strides={{strides}}, padding={{padding}}, dilation={{dilation}}, groups={{groups}}, channels={{channels}}, kernel_size={{kernel_size}}, data_layout='{{data_layout}}', kernel_layout='{{kernel_layout}}', out_layout='{{out_layout}}', out_dtype='{{out_dtype}}')",
    "torch_pattern": "torch.nn.functional.conv2d(input={{data}}, weight={{weight}}, bias=None, stride={{strides}}, padding={{padding}}, dilation={{dilation}}, groups={{groups}})",
    "arg_mapping": {
      "data": "input",
      "weight": "weight",
      "strides": "stride",
      "padding": "padding",
      "dilation": "dilation",
      "groups": "groups"
    },
    "example_pairs": [
      {
        "tvm": "output = tvm.relay.op.nn.conv2d(input_data, kernel_weight, strides=(1, 1), padding=(0, 0))",
        "torch": "output = torch.nn.functional.conv2d(input_data, kernel_weight, bias=None, stride=(1, 1), padding=(0, 0))"
      }
    ],
    "constraints": "Same constraints as `conv1d`.",
    "notes": "Direct mapping to `torch.nn.functional.conv2d`. Assumes no bias is used, or it's handled separately. Layout and dtype parameters are implicitly managed by PyTorch.",
    "confidence": 0.9
  },
  {
    "tvm_api": "tvm.relay.op.nn.nn.conv3d",
    "torch_api": "torch.nn.functional.conv3d",
    "mapping_type": "direct",
    "direction": "tvm_to_torch",
    "tvm_pattern": "tvm.relay.op.nn.conv3d(data={{data}}, weight={{weight}}, strides={{strides}}, padding={{padding}}, dilation={{dilation}}, groups={{groups}}, channels={{channels}}, kernel_size={{kernel_size}}, data_layout='{{data_layout}}', kernel_layout='{{kernel_layout}}', out_layout='{{out_layout}}', out_dtype='{{out_dtype}}')",
    "torch_pattern": "torch.nn.functional.conv3d(input={{data}}, weight={{weight}}, bias=None, stride={{strides}}, padding={{padding}}, dilation={{dilation}}, groups={{groups}})",
    "arg_mapping": {
      "data": "input",
      "weight": "weight",
      "strides": "stride",
      "padding": "padding",
      "dilation": "dilation",
      "groups": "groups"
    },
    "example_pairs": [
      {
        "tvm": "output = tvm.relay.op.nn.conv3d(input_data, kernel_weight, strides=(1, 1, 1), padding=(0, 0, 0))",
        "torch": "output = torch.nn.functional.conv3d(input_data, kernel_weight, bias=None, stride=(1, 1, 1), padding=(0, 0, 0))"
      }
    ],
    "constraints": "Same constraints as `conv1d`.",
    "notes": "Direct mapping to `torch.nn.functional.conv3d`. Assumes no bias is used, or it's handled separately. Layout and dtype parameters are implicitly managed by PyTorch.",
    "confidence": 0.9
  },
  {
    "tvm_api": "tvm.relay.op.nn.nn.softmax",
    "torch_api": "torch.nn.functional.softmax",
    "mapping_type": "direct",
    "direction": "tvm_to_torch",
    "tvm_pattern": "tvm.relay.op.nn.softmax(data={{data}}, axis={{axis}})",
    "torch_pattern": "torch.nn.functional.softmax(input={{data}}, dim={{axis}})",
    "arg_mapping": {
      "data": "input",
      "axis": "dim"
    },
    "example_pairs": [
      {
        "tvm": "output = tvm.relay.op.nn.softmax(input_tensor, axis=1)",
        "torch": "output = torch.nn.functional.softmax(input_tensor, dim=1)"
      }
    ],
    "constraints": "PyTorch's `softmax` also has an optional `dtype` argument not present in TVM. `axis` maps to `dim`.",
    "notes": "Directly maps to `torch.nn.functional.softmax`. Arguments are functionally equivalent.",
    "confidence": 0.99
  },
  {
    "tvm_api": "tvm.relay.op.nn.nn.log_softmax",
    "torch_api": "torch.nn.functional.log_softmax",
    "mapping_type": "direct",
    "direction": "tvm_to_torch",
    "tvm_pattern": "tvm.relay.op.nn.log_softmax(data={{data}}, axis={{axis}})",
    "torch_pattern": "torch.nn.functional.log_softmax(input={{data}}, dim={{axis}})",
    "arg_mapping": {
      "data": "input",
      "axis": "dim"
    },
    "example_pairs": [
      {
        "tvm": "output = tvm.relay.op.nn.log_softmax(input_tensor, axis=1)",
        "torch": "output = torch.nn.functional.log_softmax(input_tensor, dim=1)"
      }
    ],
    "constraints": "PyTorch's `log_softmax` also has an optional `dtype` argument not present in TVM. `axis` maps to `dim`.",
    "notes": "Directly maps to `torch.nn.functional.log_softmax`. Arguments are functionally equivalent.",
    "confidence": 0.99
  },
  {
    "tvm_api": "tvm.relay.op.nn.nn.max_pool1d",
    "torch_api": "torch.nn.functional.max_pool1d",
    "mapping_type": "direct",
    "direction": "tvm_to_torch",
    "tvm_pattern": "tvm.relay.op.nn.max_pool1d(data={{data}}, pool_size={{pool_size}}, strides={{strides}}, dilation={{dilation}}, padding={{padding}}, layout='{{layout}}', out_layout='{{out_layout}}', ceil_mode={{ceil_mode}})",
    "torch_pattern": "torch.nn.functional.max_pool1d(input={{data}}, kernel_size={{pool_size}}, stride={{strides}}, padding={{padding}}, dilation={{dilation}}, ceil_mode={{ceil_mode}})",
    "arg_mapping": {
      "data": "input",
      "pool_size": "kernel_size",
      "strides": "stride",
      "dilation": "dilation",
      "padding": "padding",
      "ceil_mode": "ceil_mode"
    },
    "example_pairs": [
      {
        "tvm": "output = tvm.relay.op.nn.max_pool1d(input_data, pool_size=(2,), strides=(2,), padding=(0,))",
        "torch": "output = torch.nn.functional.max_pool1d(input_data, kernel_size=(2,), stride=(2,), padding=(0,))"
      }
    ],
    "constraints": "TVM's `pool_size` maps to PyTorch's `kernel_size`, and `strides` to `stride`. PyTorch's `max_pool1d` has an optional `return_indices` argument not in TVM. TVM's `layout` and `out_layout` are implicitly handled by PyTorch's tensor format (typically NCL).",
    "notes": "Directly maps to `torch.nn.functional.max_pool1d`. Core parameters are aligned.",
    "confidence": 0.98
  },
  {
    "tvm_api": "tvm.relay.op.nn.nn.max_pool2d",
    "torch_api": "torch.nn.functional.max_pool2d",
    "mapping_type": "direct",
    "direction": "tvm_to_torch",
    "tvm_pattern": "tvm.relay.op.nn.max_pool2d(data={{data}}, pool_size={{pool_size}}, strides={{strides}}, dilation={{dilation}}, padding={{padding}}, layout='{{layout}}', out_layout='{{out_layout}}', ceil_mode={{ceil_mode}})",
    "torch_pattern": "torch.nn.functional.max_pool2d(input={{data}}, kernel_size={{pool_size}}, stride={{strides}}, padding={{padding}}, dilation={{dilation}}, ceil_mode={{ceil_mode}})",
    "arg_mapping": {
      "data": "input",
      "pool_size": "kernel_size",
      "strides": "stride",
      "dilation": "dilation",
      "padding": "padding",
      "ceil_mode": "ceil_mode"
    },
    "example_pairs": [
      {
        "tvm": "output = tvm.relay.op.nn.max_pool2d(input_data, pool_size=(2, 2), strides=(2, 2), padding=(0, 0))",
        "torch": "output = torch.nn.functional.max_pool2d(input_data, kernel_size=(2, 2), stride=(2, 2), padding=(0, 0))"
      }
    ],
    "constraints": "Same constraints as `max_pool1d`.",
    "notes": "Directly maps to `torch.nn.functional.max_pool2d`. Core parameters are aligned.",
    "confidence": 0.98
  },
  {
    "tvm_api": "tvm.relay.op.nn.nn.avg_pool2d",
    "torch_api": "torch.nn.functional.avg_pool2d",
    "mapping_type": "direct",
    "direction": "tvm_to_torch",
    "tvm_pattern": "tvm.relay.op.nn.avg_pool2d(data={{data}}, pool_size={{pool_size}}, strides={{strides}}, dilation={{dilation}}, padding={{padding}}, layout='{{layout}}', out_layout='{{out_layout}}', ceil_mode={{ceil_mode}}, count_include_pad={{count_include_pad}})",
    "torch_pattern": "torch.nn.functional.avg_pool2d(input={{data}}, kernel_size={{pool_size}}, stride={{strides}}, padding={{padding}}, ceil_mode={{ceil_mode}}, count_include_pad={{count_include_pad}})",
    "arg_mapping": {
      "data": "input",
      "pool_size": "kernel_size",
      "strides": "stride",
      "dilation": "dilation",
      "padding": "padding",
      "ceil_mode": "ceil_mode",
      "count_include_pad": "count_include_pad"
    },
    "example_pairs": [
      {
        "tvm": "output = tvm.relay.op.nn.avg_pool2d(input_data, pool_size=(2, 2), strides=(2, 2), padding=(0, 0), count_include_pad=False)",
        "torch": "output = torch.nn.functional.avg_pool2d(input_data, kernel_size=(2, 2), stride=(2, 2), padding=(0, 0), count_include_pad=False)"
      }
    ],
    "constraints": "TVM's `pool_size` maps to PyTorch's `kernel_size`, and `strides` to `stride`. PyTorch's `avg_pool2d` has an optional `divisor_override` argument not in TVM. TVM's `layout` and `out_layout` are implicitly handled by PyTorch's tensor format (typically NCHW).",
    "notes": "Directly maps to `torch.nn.functional.avg_pool2d`. Core parameters are aligned.",
    "confidence": 0.98
  },
  {
    "tvm_api": "tvm.relay.op.nn.nn.matmul",
    "torch_api": "torch.matmul",
    "mapping_type": "composite",
    "direction": "tvm_to_torch",
    "tvm_pattern": "tvm.relay.op.nn.matmul(tensor_a={{tensor_a}}, tensor_b={{tensor_b}}, units={{units}}, out_dtype='{{out_dtype}}', transpose_a={{transpose_a}}, transpose_b={{transpose_b}})",
    "torch_pattern": "torch.matmul({{tensor_a_transformed}}, {{tensor_b_transformed}})",
    "arg_mapping": {
      "tensor_a": "tensor_a_input",
      "tensor_b": "tensor_b_input",
      "transpose_a": "transpose_a_flag",
      "transpose_b": "transpose_b_flag"
    },
    "example_pairs": [
      {
        "tvm": "output = tvm.relay.op.nn.matmul(A, B, transpose_a=True)",
        "torch": "tensor_a_transformed = A.mT if True else A\ntensor_b_transformed = B.mT if False else B\noutput = torch.matmul(tensor_a_transformed, tensor_b_transformed)"
      }
    ],
    "constraints": "TVM's `transpose_a` and `transpose_b` parameters require explicitly applying `.mT` (matrix transpose) to the input tensors in PyTorch *before* calling `torch.matmul`. TVM's `units` and `out_dtype` are not direct parameters for `torch.matmul`; output dtype is usually inferred or explicitly cast after the operation.",
    "notes": "Composite mapping due to explicit `transpose_a` and `transpose_b` flags in TVM, which are handled by tensor methods like `.mT` in PyTorch. The `units` and `out_dtype` parameters are not direct arguments to `torch.matmul`.",
    "confidence": 0.85
  },
  {
    "tvm_api": "tvm.relay.op.nn.nn.relu",
    "torch_api": "torch.nn.functional.relu",
    "mapping_type": "direct",
    "direction": "tvm_to_torch",
    "tvm_pattern": "tvm.relay.op.nn.relu(data={{data}})",
    "torch_pattern": "torch.nn.functional.relu(input={{data}})",
    "arg_mapping": {
      "data": "input"
    },
    "example_pairs": [
      {
        "tvm": "output = tvm.relay.op.nn.relu(input_tensor)",
        "torch": "output = torch.nn.functional.relu(input_tensor)"
      }
    ],
    "constraints": "PyTorch's `F.relu` has an optional `inplace` argument not present in TVM. Otherwise, functionality is identical.",
    "notes": "Directly maps to `torch.nn.functional.relu` or `tensor.relu()`.",
    "confidence": 0.99
  },
  {
    "tvm_api": "tvm.relay.op.nn.nn.leaky_relu",
    "torch_api": "torch.nn.functional.leaky_relu",
    "mapping_type": "direct",
    "direction": "tvm_to_torch",
    "tvm_pattern": "tvm.relay.op.nn.leaky_relu(data={{data}}, alpha={{alpha}})",
    "torch_pattern": "torch.nn.functional.leaky_relu(input={{data}}, negative_slope={{alpha}})",
    "arg_mapping": {
      "data": "input",
      "alpha": "negative_slope"
    },
    "example_pairs": [
      {
        "tvm": "output = tvm.relay.op.nn.leaky_relu(input_tensor, alpha=0.1)",
        "torch": "output = torch.nn.functional.leaky_relu(input_tensor, negative_slope=0.1)"
      }
    ],
    "constraints": "TVM's `alpha` maps to PyTorch's `negative_slope`. PyTorch's `F.leaky_relu` has an optional `inplace` argument not present in TVM. Otherwise, functionality is identical.",
    "notes": "Directly maps to `torch.nn.functional.leaky_relu`.",
    "confidence": 0.99
  },
  {
    "tvm_api": "tvm.relay.op.nn.nn.prelu",
    "torch_api": "torch.nn.functional.prelu",
    "mapping_type": "direct",
    "direction": "tvm_to_torch",
    "tvm_pattern": "tvm.relay.op.nn.prelu(data={{data}}, alpha={{alpha}}, axis={{axis}})",
    "torch_pattern": "torch.nn.functional.prelu(input={{data}}, weight={{alpha}})",
    "arg_mapping": {
      "data": "input",
      "alpha": "weight"
    },
    "example_pairs": [
      {
        "tvm": "output = tvm.relay.op.nn.prelu(input_tensor, alpha_param)",
        "torch": "output = torch.nn.functional.prelu(input_tensor, alpha_param)"
      }
    ],
    "constraints": "TVM's `alpha` (slope coefficient) corresponds to PyTorch's `weight`. The `axis` parameter in TVM is handled by PyTorch's broadcasting rules for `weight`. If `weight` has `numel() == 1`, it's broadcast to all channels; otherwise, `weight.numel()` should match the channel size (usually `input.shape[1]`).",
    "notes": "Directly maps to `torch.nn.functional.prelu`. The `axis` parameter is implicitly handled by PyTorch's broadcasting of the `weight` tensor.",
    "confidence": 0.95
  },
  {
    "tvm_api": "tvm.relay.op.nn.nn.pad",
    "torch_api": "torch.nn.functional.pad",
    "mapping_type": "composite",
    "direction": "tvm_to_torch",
    "tvm_pattern": "tvm.relay.op.nn.pad(data={{data}}, pad_width={{pad_width}}, pad_value={{pad_value}}, pad_mode='{{pad_mode}}')",
    "torch_pattern": "torch.nn.functional.pad(input={{data}}, pad={{torch_pad_tuple}}, mode='{{pad_mode}}', value={{pad_value}})",
    "arg_mapping": {
      "data": "input",
      "pad_width": "pad_width_tvm",
      "pad_value": "value",
      "pad_mode": "mode"
    },
    "example_pairs": [
      {
        "tvm": "output = tvm.relay.op.nn.pad(input_data, pad_width=((0, 0), (1, 1), (2, 2)), pad_value=0.0, pad_mode='constant')",
        "torch": "torch_pad_tuple = (2, 2, 1, 1, 0, 0)\noutput = torch.nn.functional.pad(input=input_data, pad=torch_pad_tuple, mode='constant', value=0.0)"
      }
    ],
    "constraints": "TVM's `pad_width` is a tuple of tuples `((before_1, after_1), ..., (before_N, after_N))` applying to dimensions from 0 to N-1. PyTorch's `pad` is a flat tuple `(pad_left, pad_right, pad_top, pad_bottom, ...)` applying to dimensions in *reverse* order (last dimension first). This requires reversing and flattening `pad_width` for the PyTorch `pad` argument. `pad_mode` 'edge' maps to 'replicate' in PyTorch, 'reflect' is the same, 'constant' is the same.",
    "notes": "Composite mapping due to the difference in `pad_width` specification format and order. Requires a transformation of the `pad_width` argument.",
    "confidence": 0.8
  },
  {
    "tvm_api": "tvm.relay.op.nn.nn.dropout",
    "torch_api": "torch.nn.functional.dropout",
    "mapping_type": "direct",
    "direction": "tvm_to_torch",
    "tvm_pattern": "tvm.relay.op.nn.dropout(data={{data}}, rate={{rate}})",
    "torch_pattern": "torch.nn.functional.dropout(input={{data}}, p={{rate}}, training=True)",
    "arg_mapping": {
      "data": "input",
      "rate": "p"
    },
    "example_pairs": [
      {
        "tvm": "output = tvm.relay.op.nn.dropout(input_tensor, rate=0.5)",
        "torch": "output = torch.nn.functional.dropout(input_tensor, p=0.5, training=True)"
      }
    ],
    "constraints": "TVM's `rate` corresponds to PyTorch's `p`. PyTorch's `F.dropout` has `training` and `inplace` arguments. TVM's `dropout` is typically applied during training, so `training=True` is assumed for PyTorch.",
    "notes": "Directly maps to `torch.nn.functional.dropout`.",
    "confidence": 0.99
  },
  {
    "tvm_api": "tvm.relay.op.nn.nn.batch_norm",
    "torch_api": "torch.nn.functional.batch_norm",
    "mapping_type": "direct",
    "direction": "tvm_to_torch",
    "tvm_pattern": "tvm.relay.op.nn.batch_norm(data={{data}}, gamma={{gamma}}, beta={{beta}}, moving_mean={{moving_mean}}, moving_var={{moving_var}}, axis={{axis}}, epsilon={{epsilon}}, center={{center}}, scale={{scale}})",
    "torch_pattern": "torch.nn.functional.batch_norm(input={{data}}, running_mean={{moving_mean}}, running_var={{moving_var}}, weight={{gamma_if_scaled}}, bias={{beta_if_centered}}, training=False, momentum=0.1, eps={{epsilon}})",
    "arg_mapping": {
      "data": "input",
      "gamma": "weight",
      "beta": "bias",
      "moving_mean": "running_mean",
      "moving_var": "running_var",
      "epsilon": "eps",
      "scale": "scale_flag",
      "center": "center_flag"
    },
    "example_pairs": [
      {
        "tvm": "output, _, _ = tvm.relay.op.nn.batch_norm(input_data, gamma_tensor, beta_tensor, mean_tensor, var_tensor, epsilon=1e-5)",
        "torch": "gamma_if_scaled = gamma_tensor if True else None\nbeta_if_centered = beta_tensor if True else None\noutput = torch.nn.functional.batch_norm(input_data, mean_tensor, var_tensor, gamma_if_scaled, beta_if_centered, training=False, momentum=0.1, eps=1e-5)"
      }
    ],
    "constraints": "TVM's `gamma` maps to PyTorch's `weight`, `beta` to `bias`. TVM's `center=True` implies `bias` should be used; `scale=True` implies `weight` should be used. If `center` or `scale` are `False`, the corresponding PyTorch `weight` or `bias` should be `None`. TVM's `batch_norm` is usually used in inference graphs, so `training=False` is a safe assumption for PyTorch functional calls. `momentum` is not in TVM, using default PyTorch value. TVM's `axis` is usually implicit in PyTorch (channel dimension).",
    "notes": "Direct mapping to `torch.nn.functional.batch_norm`. Handling `center` and `scale` requires conditional assignment of `gamma` and `beta` to PyTorch's `weight` and `bias`.",
    "confidence": 0.9
  },
  {
    "tvm_api": "tvm.relay.op.nn.nn.instance_norm",
    "torch_api": "torch.nn.functional.instance_norm",
    "mapping_type": "direct",
    "direction": "tvm_to_torch",
    "tvm_pattern": "tvm.relay.op.nn.instance_norm(data={{data}}, gamma={{gamma}}, beta={{beta}}, axis={{axis}}, epsilon={{epsilon}}, center={{center}}, scale={{scale}})",
    "torch_pattern": "torch.nn.functional.instance_norm(input={{data}}, running_mean=None, running_var=None, weight={{gamma_if_scaled}}, bias={{beta_if_centered}}, use_input_stats=True, momentum=0.1, eps={{epsilon}})",
    "arg_mapping": {
      "data": "input",
      "gamma": "weight",
      "beta": "bias",
      "epsilon": "eps",
      "scale": "scale_flag",
      "center": "center_flag"
    },
    "example_pairs": [
      {
        "tvm": "output = tvm.relay.op.nn.instance_norm(input_data, gamma_tensor, beta_tensor, epsilon=1e-5)",
        "torch": "gamma_if_scaled = gamma_tensor if True else None\nbeta_if_centered = beta_tensor if True else None\noutput = torch.nn.functional.instance_norm(input_data, None, None, gamma_if_scaled, beta_if_centered, use_input_stats=True, momentum=0.1, eps=1e-5)"
      }
    ],
    "constraints": "TVM's `gamma` maps to PyTorch's `weight`, `beta` to `bias`. `center=True` implies `bias` should be used; `scale=True` implies `weight` should be used. PyTorch's `F.instance_norm` has `running_mean` and `running_var` as optional arguments, but for instance normalization, they are typically `None` or ignored (`use_input_stats=True`). TVM's `axis` is usually implicit in PyTorch (channel dimension). `momentum` and `use_input_stats` are PyTorch specific, using defaults.",
    "notes": "Direct mapping to `torch.nn.functional.instance_norm`. Similar to `batch_norm`, handling `center` and `scale` involves conditional assignment of `gamma` and `beta`.",
    "confidence": 0.9
  },
  {
    "tvm_api": "tvm.relay.op.nn.nn.layer_norm",
    "torch_api": "torch.nn.functional.layer_norm",
    "mapping_type": "composite",
    "direction": "tvm_to_torch",
    "tvm_pattern": "tvm.relay.op.nn.layer_norm(data={{data}}, gamma={{gamma}}, beta={{beta}}, axis={{axis}}, epsilon={{epsilon}}, center={{center}}, scale={{scale}})",
    "torch_pattern": "torch.nn.functional.layer_norm(input={{data}}, normalized_shape={{normalized_shape}}, weight={{gamma_if_scaled}}, bias={{beta_if_centered}}, eps={{epsilon}})",
    "arg_mapping": {
      "data": "input",
      "gamma": "weight",
      "beta": "bias",
      "axis": "axis_val",
      "epsilon": "eps",
      "scale": "scale_flag",
      "center": "center_flag"
    },
    "example_pairs": [
      {
        "tvm": "output = tvm.relay.op.nn.layer_norm(input_data, gamma_tensor, beta_tensor, axis=-1, epsilon=1e-5)",
        "torch": "gamma_if_scaled = gamma_tensor if True else None\nbeta_if_centered = beta_tensor if True else None\nnormalized_shape_val = input_data.shape[len(input_data.shape) - 1:]\noutput = torch.nn.functional.layer_norm(input_data, normalized_shape_val, gamma_if_scaled, beta_if_centered, eps=1e-5)"
      }
    ],
    "constraints": "TVM uses `axis` to specify the dimension(s) for normalization. PyTorch requires `normalized_shape`, which is a tuple defining the last N dimensions over which to normalize. If TVM's `axis` is a single integer, then `normalized_shape` in PyTorch would be `input.shape[axis:]`. Handling `center` and `scale` is similar to `batch_norm`.",
    "notes": "Composite mapping due to the `axis` vs `normalized_shape` difference. Requires computing `normalized_shape` from the input tensor's shape and the `axis` argument.",
    "confidence": 0.85
  },
  {
    "tvm_api": "tvm.relay.op.nn.nn.cross_entropy",
    "torch_api": null,
    "mapping_type": "no_mapping",
    "direction": "tvm_to_torch",
    "tvm_pattern": null,
    "torch_pattern": null,
    "arg_mapping": {},
    "example_pairs": [],
    "constraints": "Not convertible without assumption.",
    "notes": "NO_MAPPING: TVM's `cross_entropy` is described as 'without logits', suggesting it expects probabilities. PyTorch's `torch.nn.functional.cross_entropy` expects *logits* and combines `log_softmax` and `nll_loss`. If TVM's `predictions` are probabilities, a direct `F.cross_entropy` mapping is incorrect. A composite `torch.sum(-targets * torch.log(predictions))` would be required, but `torch.nn.functional.cross_entropy` is a specific and optimized op. Given the 'without logits' phrasing, direct mapping is unsafe.",
    "confidence": 0.3
  },
  {
    "tvm_api": "tvm.relay.op.nn.nn.nll_loss",
    "torch_api": "torch.nn.functional.nll_loss",
    "mapping_type": "direct",
    "direction": "tvm_to_torch",
    "tvm_pattern": "tvm.relay.op.nn.nll_loss(predictions={{predictions}}, targets={{targets}}, weights={{weights}}, reduction='{{reduction}}', ignore_index={{ignore_index}})",
    "torch_pattern": "torch.nn.functional.nll_loss(input={{predictions}}, target={{targets}}, weight={{weights}}, reduction='{{reduction}}', ignore_index={{ignore_index}})",
    "arg_mapping": {
      "predictions": "input",
      "targets": "target",
      "weights": "weight",
      "reduction": "reduction",
      "ignore_index": "ignore_index"
    },
    "example_pairs": [
      {
        "tvm": "loss = tvm.relay.op.nn.nll_loss(log_probs, target_indices, weight_tensor)",
        "torch": "loss = torch.nn.functional.nll_loss(log_probs, target_indices, weight_tensor)"
      }
    ],
    "constraints": "Assumes TVM's `predictions` are log-probabilities, as required by PyTorch's `nll_loss`. Arguments `weights` and `targets` map to `weight` and `target` respectively.",
    "notes": "Directly maps to `torch.nn.functional.nll_loss`. Functionality and arguments align.",
    "confidence": 0.98
  },
  {
    "tvm_api": "tvm.relay.op.nn.nn.adaptive_avg_pool2d",
    "torch_api": "torch.nn.functional.adaptive_avg_pool2d",
    "mapping_type": "direct",
    "direction": "tvm_to_torch",
    "tvm_pattern": "tvm.relay.op.nn.adaptive_avg_pool2d(data={{data}}, output_size={{output_size}}, layout='{{layout}}', out_layout='{{out_layout}}')",
    "torch_pattern": "torch.nn.functional.adaptive_avg_pool2d(input={{data}}, output_size={{output_size}})",
    "arg_mapping": {
      "data": "input",
      "output_size": "output_size"
    },
    "example_pairs": [
      {
        "tvm": "output = tvm.relay.op.nn.adaptive_avg_pool2d(input_data, output_size=(8, 8))",
        "torch": "output = torch.nn.functional.adaptive_avg_pool2d(input_data, output_size=(8, 8))"
      }
    ],
    "constraints": "PyTorch's `F.adaptive_avg_pool2d` expects `output_size` to be explicitly provided (can be `None` to use input size for height/width only if it's a tuple of 1 int, or 2 ints). TVM's `output_size=None` default implies using input height and width, which would require dynamically getting `input_data.shape[-2:]` for PyTorch. TVM's `layout` parameters are implicitly handled by PyTorch.",
    "notes": "Directly maps to `torch.nn.functional.adaptive_avg_pool2d`. PyTorch's functional version expects `output_size` directly.",
    "confidence": 0.97
  },
  {
    "tvm_api": "tvm.relay.op.random.kernel.uniform",
    "torch_api": "torch.rand",
    "mapping_type": "composite",
    "direction": "tvm_to_torch",
    "tvm_pattern": "tvm.relay.op.random.kernel.uniform(key={{key}}, shape={{shape}}, dtype='{{dtype}}', low={{low}}, high={{high}})",
    "torch_pattern": "({{high}} - {{low}}) * torch.rand({{shape}}, dtype=torch.{{dtype}}) + {{low}}",
    "arg_mapping": {
      "shape": "shape",
      "dtype": "dtype",
      "low": "low",
      "high": "high"
    },
    "example_pairs": [
      {
        "tvm": "key, values = tvm.relay.op.random.kernel.uniform(current_key, (100,), low=0.0, high=10.0)",
        "torch": "values = (10.0 - 0.0) * torch.rand((100,), dtype=torch.float32) + 0.0"
      }
    ],
    "constraints": "TVM's `key` parameter for managing RNG state has no direct functional equivalent in PyTorch, which typically uses a global RNG or an explicit `torch.Generator` object. The `key` input/output structure implies a functional PRNG that updates its state, which is not standard in PyTorch's tensor-level random functions. The example shows how to achieve the *distribution* of uniform, not state management. PyTorch's `torch.rand` generates numbers in `[0,1)`, requiring scaling and shifting for `[low, high)`.",
    "notes": "Composite mapping. TVM's functional RNG with explicit `key` passing is not directly supported by PyTorch's default `torch.rand`. Scaling and shifting are required to match the `low` and `high` bounds. `key` management is not directly translatable.",
    "confidence": 0.7
  },
  {
    "tvm_api": "tvm.relay.op.random.kernel.normal",
    "torch_api": "torch.normal",
    "mapping_type": "composite",
    "direction": "tvm_to_torch",
    "tvm_pattern": "tvm.relay.op.random.kernel.normal(key={{key}}, shape={{shape}}, dtype='{{dtype}}', mean={{mean}}, scale={{scale}})",
    "torch_pattern": "torch.normal(mean={{mean}}, std={{scale}}, size={{shape}}, dtype=torch.{{dtype}})",
    "arg_mapping": {
      "shape": "size",
      "dtype": "dtype",
      "mean": "mean",
      "scale": "std"
    },
    "example_pairs": [
      {
        "tvm": "key, values = tvm.relay.op.random.kernel.normal(current_key, (100,), mean=0.0, scale=1.0)",
        "torch": "values = torch.normal(mean=0.0, std=1.0, size=(100,), dtype=torch.float32)"
      }
    ],
    "constraints": "Similar to `uniform`, TVM's `key` for managing RNG state has no direct functional equivalent in PyTorch. PyTorch uses a global RNG or `torch.Generator`. TVM's `scale` maps to PyTorch's `std`. PyTorch's `normal` can take `mean` and `std` as tensors or scalars, and `size` for the output shape. If `mean` or `std` are tensors, `size` must be compatible or omitted.",
    "notes": "Composite mapping. TVM's functional RNG with explicit `key` passing is not directly supported by PyTorch. The statistical distribution is directly matched by `torch.normal`.",
    "confidence": 0.7
  },
  {
    "tvm_api": "tvm.relay.op.random.kernel.multinomial",
    "torch_api": "torch.multinomial",
    "mapping_type": "composite",
    "direction": "tvm_to_torch",
    "tvm_pattern": "tvm.relay.op.random.kernel.multinomial(key={{key}}, probs={{probs}}, num_samples={{num_samples}})",
    "torch_pattern": "torch.multinomial(input={{probs}}, num_samples={{num_samples}}, replacement=True)",
    "arg_mapping": {
      "probs": "input",
      "num_samples": "num_samples"
    },
    "example_pairs": [
      {
        "tvm": "key, indices = tvm.relay.op.random.kernel.multinomial(current_key, probabilities, num_samples=5)",
        "torch": "indices = torch.multinomial(probabilities, num_samples=5, replacement=True)"
      }
    ],
    "constraints": "Similar to other random operations, TVM's `key` for RNG state is not directly supported by PyTorch. PyTorch's `multinomial` has an optional `replacement` parameter (default `False`) which is not explicit in TVM's `multinomial` description (though typically multinomial implies replacement). We assume `replacement=True` for this mapping.",
    "notes": "Composite mapping due to TVM's `key` parameter. The core multinomial sampling functionality is matched by `torch.multinomial`.",
    "confidence": 0.7
  },
  {
    "tvm_api": "tvm.relay.qnn.op.qnn.quantize",
    "torch_api": "torch.quantize_per_tensor",
    "mapping_type": "direct",
    "direction": "tvm_to_torch",
    "tvm_pattern": "tvm.relay.qnn.op.qnn.quantize(data={{data}}, output_scale={{output_scale}}, output_zero_point={{output_zero_point}}, axis={{axis}}, out_dtype='{{out_dtype}}')",
    "torch_pattern": "torch.quantize_per_tensor({{data}}, scale={{output_scale}}, zero_point={{output_zero_point}}, dtype=torch.{{out_dtype}})",
    "arg_mapping": {
      "data": "data",
      "output_scale": "scale",
      "output_zero_point": "zero_point",
      "out_dtype": "dtype"
    },
    "example_pairs": [
      {
        "tvm": "q_tensor = tvm.relay.qnn.op.qnn.quantize(float_tensor, 0.1, 128, out_dtype='int8')",
        "torch": "q_tensor = torch.quantize_per_tensor(float_tensor, 0.1, 128, torch.qint8)"
      }
    ],
    "constraints": "This mapping assumes `output_scale` and `output_zero_point` are scalar, leading to `quantize_per_tensor`. If they are tensors per channel, `torch.quantize_per_channel` would be used, which takes a `ch_axis` parameter similar to TVM's `axis`. If `axis` is not -1 and scale/zero_point are per-channel, this would need to map to `quantize_per_channel`.",
    "notes": "Maps to `torch.quantize_per_tensor` for general quantization. The `axis` parameter is for per-channel quantization, which would necessitate `torch.quantize_per_channel` if `output_scale` or `output_zero_point` are tensors (one value per channel). For scalar scale/zero_point, `axis` is often ignored or assumed as `per_tensor`.",
    "confidence": 0.85
  },
  {
    "tvm_api": "tvm.relay.qnn.op.qnn.dequantize",
    "torch_api": "torch.dequantize",
    "mapping_type": "direct",
    "direction": "tvm_to_torch",
    "tvm_pattern": "tvm.relay.qnn.op.qnn.dequantize(data={{data}}, input_scale={{input_scale}}, input_zero_point={{input_zero_point}}, axis={{axis}})",
    "torch_pattern": "torch.dequantize({{data}})",
    "arg_mapping": {
      "data": "data"
    },
    "example_pairs": [
      {
        "tvm": "float_tensor = tvm.relay.qnn.op.qnn.dequantize(q_tensor, 0.1, 128)",
        "torch": "float_tensor = torch.dequantize(q_tensor)"
      }
    ],
    "constraints": "In PyTorch, a quantized tensor object inherently stores its `scale` and `zero_point`. Therefore, `torch.dequantize` takes only the quantized tensor as input; `input_scale`, `input_zero_point`, and `axis` are not explicit arguments in the function call, as they are attributes of the input quantized tensor.",
    "notes": "Directly maps to `torch.dequantize`. The quantization parameters are assumed to be part of the `data` tensor in PyTorch.",
    "confidence": 0.95
  },
  {
    "tvm_api": "tvm.relay.qnn.op.qnn.concatenate",
    "torch_api": "torch.cat",
    "mapping_type": "composite",
    "direction": "tvm_to_torch",
    "tvm_pattern": "tvm.relay.qnn.op.qnn.concatenate(data={{data}}, input_scales={{input_scales}}, input_zero_points={{input_zero_points}}, output_scale={{output_scale}}, output_zero_point={{output_zero_point}}, axis={{axis}})",
    "torch_pattern": "float_tensors = [torch.dequantize(t) for t in {{data}}]\nfloat_concat = torch.cat(float_tensors, dim={{axis}})\nquantized_output = torch.quantize_per_tensor(float_concat, scale={{output_scale}}, zero_point={{output_zero_point}}, dtype=torch.qint8)",
    "arg_mapping": {
      "data": "data_tensors",
      "axis": "dim",
      "output_scale": "scale_out",
      "output_zero_point": "zero_point_out"
    },
    "example_pairs": [
      {
        "tvm": "q_out = tvm.relay.qnn.op.qnn.concatenate([q_a, q_b], [scale_a, scale_b], [zp_a, zp_b], out_scale, out_zp, axis=1)",
        "torch": "float_tensors = [torch.dequantize(q_a), torch.dequantize(q_b)]\nfloat_concat = torch.cat(float_tensors, dim=1)\nquantized_output = torch.quantize_per_tensor(float_concat, scale=out_scale, zero_point=out_zp, dtype=torch.qint8)"
      }
    ],
    "constraints": "PyTorch's `torch.cat` operates on (float or quantized) tensors. When concatenating *quantized* tensors, PyTorch implicitly determines the output quantization parameters. TVM explicitly takes `input_scales`, `input_zero_points`, `output_scale`, `output_zero_point`. This necessitates a dequantize-float_op-quantize sequence to match TVM's explicit control over quantization parameters.",
    "notes": "Composite mapping. Involves dequantizing all input tensors, performing `torch.cat` on the float tensors, and then requantizing the result using the specified `output_scale` and `output_zero_point`.",
    "confidence": 0.8
  },
  {
    "tvm_api": "tvm.relay.qnn.op.qnn.conv2d",
    "torch_api": "torch.ao.nn.quantized.functional.conv2d",
    "mapping_type": "direct",
    "direction": "tvm_to_torch",
    "tvm_pattern": "tvm.relay.qnn.op.qnn.conv2d(data={{data}}, kernel={{kernel}}, input_zero_point={{input_zero_point}}, kernel_zero_point={{kernel_zero_point}}, input_scale={{input_scale}}, kernel_scale={{kernel_scale}}, kernel_size={{kernel_size}}, channels={{channels}}, strides={{strides}}, padding={{padding}}, dilation={{dilation}}, groups={{groups}}, data_layout='{{data_layout}}', kernel_layout='{{kernel_layout}}', out_layout='{{out_layout}}', out_dtype='{{out_dtype}}')",
    "torch_pattern": "torch.ao.nn.quantized.functional.conv2d(input={{data}}, weight={{kernel}}, bias=None, stride={{strides}}, padding={{padding}}, dilation={{dilation}}, groups={{groups}}, scale={{output_scale}}, zero_point={{output_zero_point}}, dtype=torch.{{out_dtype}})",
    "arg_mapping": {
      "data": "input",
      "kernel": "weight",
      "strides": "stride",
      "padding": "padding",
      "dilation": "dilation",
      "groups": "groups",
      "out_dtype": "dtype"
    },
    "example_pairs": [
      {
        "tvm": "q_out = tvm.relay.qnn.op.qnn.conv2d(q_input, q_weight, input_zp, kernel_zp, input_scale, kernel_scale, kernel_size=(3,3), strides=(1,1), padding=(1,1), out_dtype='int32')",
        "torch": "q_out = torch.ao.nn.quantized.functional.conv2d(q_input, q_weight, bias=None, stride=(1,1), padding=(1,1), dilation=(1,1), groups=1, scale=input_scale * kernel_scale, zero_point=0, dtype=torch.qint32)"
      }
    ],
    "constraints": "PyTorch's `torch.ao.nn.quantized.functional.conv2d` expects `input` and `weight` to be already quantized tensors. It takes explicit `scale` and `zero_point` for the *output* quantized tensor, but not for input/kernel. TVM's `input_zero_point`, `kernel_zero_point`, `input_scale`, `kernel_scale` would be properties of the `data` and `kernel` quantized tensors in PyTorch. The `output_scale` and `output_zero_point` must be derived from the input scales/zero-points and target `out_dtype`.",
    "notes": "Direct mapping to PyTorch's quantized functional `conv2d`. PyTorch's API expects inputs to be quantized tensors, and specifies the output quantization parameters. The TVM explicit input scales/zero-points are implicit in PyTorch's quantized tensor objects. The output scale for QNN conv2d is often `input_scale * kernel_scale`, and zero_point is typically 0 for the accumulator type.",
    "confidence": 0.8
  },
  {
    "tvm_api": "tvm.relay.qnn.op.qnn.add",
    "torch_api": [
      "torch.dequantize",
      "torch.add",
      "torch.quantize_per_tensor"
    ],
    "mapping_type": "composite",
    "direction": "tvm_to_torch",
    "tvm_pattern": "tvm.relay.qnn.op.qnn.add(lhs={{lhs}}, rhs={{rhs}}, lhs_scale={{lhs_scale}}, lhs_zero_point={{lhs_zero_point}}, rhs_scale={{rhs_scale}}, rhs_zero_point={{rhs_zero_point}}, output_scale={{output_scale}}, output_zero_point={{output_zero_point}}, lhs_axis={{lhs_axis}}, rhs_axis={{rhs_axis}})",
    "torch_pattern": "float_lhs = torch.dequantize({{lhs}})\nfloat_rhs = torch.dequantize({{rhs}})\nfloat_output = torch.add(float_lhs, float_rhs)\nquantized_output = torch.quantize_per_tensor(float_output, scale={{output_scale}}, zero_point={{output_zero_point}}, dtype=torch.qint8)",
    "arg_mapping": {
      "lhs": "lhs_q_tensor",
      "rhs": "rhs_q_tensor",
      "output_scale": "output_scale",
      "output_zero_point": "output_zero_point"
    },
    "example_pairs": [
      {
        "tvm": "q_out = tvm.relay.qnn.op.qnn.add(q_a, q_b, scale_a, zp_a, scale_b, zp_b, out_scale, out_zp)",
        "torch": "float_lhs = torch.dequantize(q_a)\nfloat_rhs = torch.dequantize(q_b)\nfloat_output = torch.add(float_lhs, float_rhs)\nquantized_output = torch.quantize_per_tensor(float_output, scale=out_scale, zero_point=out_zp, dtype=torch.qint8)"
      }
    ],
    "constraints": "PyTorch's `torch.add` operates on float tensors or internally handles addition of quantized tensors with compatible parameters. TVM explicitly provides all input and output quantization parameters. This requires a dequantize-float_op-quantize sequence to maintain explicit control over quantization.",
    "notes": "Composite mapping. Involves dequantizing inputs, performing float addition (`torch.add`), and then quantizing the result using the specified `output_scale` and `output_zero_point`.",
    "confidence": 0.8
  },
  {
    "tvm_api": "tvm.relay.qnn.op.qnn.mul",
    "torch_api": [
      "torch.dequantize",
      "torch.mul",
      "torch.quantize_per_tensor"
    ],
    "mapping_type": "composite",
    "direction": "tvm_to_torch",
    "tvm_pattern": "tvm.relay.qnn.op.qnn.mul(lhs={{lhs}}, rhs={{rhs}}, lhs_scale={{lhs_scale}}, lhs_zero_point={{lhs_zero_point}}, rhs_scale={{rhs_scale}}, rhs_zero_point={{rhs_zero_point}}, output_scale={{output_scale}}, output_zero_point={{output_zero_point}}, lhs_axis={{lhs_axis}}, rhs_axis={{rhs_axis}})",
    "torch_pattern": "float_lhs = torch.dequantize({{lhs}})\nfloat_rhs = torch.dequantize({{rhs}})\nfloat_output = torch.mul(float_lhs, float_rhs)\nquantized_output = torch.quantize_per_tensor(float_output, scale={{output_scale}}, zero_point={{output_zero_point}}, dtype=torch.qint8)",
    "arg_mapping": {
      "lhs": "lhs_q_tensor",
      "rhs": "rhs_q_tensor",
      "output_scale": "output_scale",
      "output_zero_point": "output_zero_point"
    },
    "example_pairs": [
      {
        "tvm": "q_out = tvm.relay.qnn.op.qnn.mul(q_a, q_b, scale_a, zp_a, scale_b, zp_b, out_scale, out_zp)",
        "torch": "float_lhs = torch.dequantize(q_a)\nfloat_rhs = torch.dequantize(q_b)\nfloat_output = torch.mul(float_lhs, float_rhs)\nquantized_output = torch.quantize_per_tensor(float_output, scale=out_scale, zero_point=out_zp, dtype=torch.qint8)"
      }
    ],
    "constraints": "Similar to `qnn.add`, requires dequantize-float_op-quantize sequence due to explicit quantization parameters in TVM.",
    "notes": "Composite mapping. Involves dequantizing inputs, performing float multiplication (`torch.mul`), and then quantizing the result.",
    "confidence": 0.8
  },
  {
    "tvm_api": "tvm.relay.qnn.op.qnn.tanh",
    "torch_api": [
      "torch.dequantize",
      "torch.tanh",
      "torch.quantize_per_tensor"
    ],
    "mapping_type": "composite",
    "direction": "tvm_to_torch",
    "tvm_pattern": "tvm.relay.qnn.op.qnn.tanh(x={{x}}, scale={{scale}}, zero_point={{zero_point}}, output_scale={{output_scale}}, output_zero_point={{output_zero_point}})",
    "torch_pattern": "float_input = torch.dequantize({{x}})\nfloat_output = torch.tanh(float_input)\nquantized_output = torch.quantize_per_tensor(float_output, scale={{output_scale}}, zero_point={{output_zero_point}}, dtype=torch.qint8)",
    "arg_mapping": {
      "x": "x_q_tensor",
      "output_scale": "output_scale",
      "output_zero_point": "output_zero_point"
    },
    "example_pairs": [
      {
        "tvm": "q_out = tvm.relay.qnn.op.qnn.tanh(q_input, input_scale, input_zp, out_scale, out_zp)",
        "torch": "float_input = torch.dequantize(q_input)\nfloat_output = torch.tanh(float_input)\nquantized_output = torch.quantize_per_tensor(float_output, scale=out_scale, zero_point=out_zp, dtype=torch.qint8)"
      }
    ],
    "constraints": "Requires dequantize-float_op-quantize sequence due to TVM explicitly providing input and output quantization parameters, which is not how `torch.tanh` directly operates on quantized tensors.",
    "notes": "Composite mapping. Involves dequantizing input, applying `torch.tanh` to the float tensor, and then quantizing the result.",
    "confidence": 0.8
  },
  {
    "tvm_api": "tvm.relay.qnn.op.qnn.exp",
    "torch_api": [
      "torch.dequantize",
      "torch.exp",
      "torch.quantize_per_tensor"
    ],
    "mapping_type": "composite",
    "direction": "tvm_to_torch",
    "tvm_pattern": "tvm.relay.qnn.op.qnn.exp(x={{x}}, scale={{scale}}, zero_point={{zero_point}}, output_scale={{output_scale}}, output_zero_point={{output_zero_point}})",
    "torch_pattern": "float_input = torch.dequantize({{x}})\nfloat_output = torch.exp(float_input)\nquantized_output = torch.quantize_per_tensor(float_output, scale={{output_scale}}, zero_point={{output_zero_point}}, dtype=torch.qint8)",
    "arg_mapping": {
      "x": "x_q_tensor",
      "output_scale": "output_scale",
      "output_zero_point": "output_zero_point"
    },
    "example_pairs": [
      {
        "tvm": "q_out = tvm.relay.qnn.op.qnn.exp(q_input, input_scale, input_zp, out_scale, out_zp)",
        "torch": "float_input = torch.dequantize(q_input)\nfloat_output = torch.exp(float_input)\nquantized_output = torch.quantize_per_tensor(float_output, scale=out_scale, zero_point=out_zp, dtype=torch.qint8)"
      }
    ],
    "constraints": "Requires dequantize-float_op-quantize sequence due to TVM explicitly providing input and output quantization parameters.",
    "notes": "Composite mapping. Involves dequantizing input, applying `torch.exp` to the float tensor, and then quantizing the result.",
    "confidence": 0.8
  },
  {
    "tvm_api": "tvm.relay.qnn.op.qnn.sqrt",
    "torch_api": [
      "torch.dequantize",
      "torch.sqrt",
      "torch.quantize_per_tensor"
    ],
    "mapping_type": "composite",
    "direction": "tvm_to_torch",
    "tvm_pattern": "tvm.relay.qnn.op.qnn.sqrt(x={{x}}, scale={{scale}}, zero_point={{zero_point}}, output_scale={{output_scale}}, output_zero_point={{output_zero_point}})",
    "torch_pattern": "float_input = torch.dequantize({{x}})\nfloat_output = torch.sqrt(float_input)\nquantized_output = torch.quantize_per_tensor(float_output, scale={{output_scale}}, zero_point={{output_zero_point}}, dtype=torch.qint8)",
    "arg_mapping": {
      "x": "x_q_tensor",
      "output_scale": "output_scale",
      "output_zero_point": "output_zero_point"
    },
    "example_pairs": [
      {
        "tvm": "q_out = tvm.relay.qnn.op.qnn.sqrt(q_input, input_scale, input_zp, out_scale, out_zp)",
        "torch": "float_input = torch.dequantize(q_input)\nfloat_output = torch.sqrt(float_input)\nquantized_output = torch.quantize_per_tensor(float_output, scale=out_scale, zero_point=out_zp, dtype=torch.qint8)"
      }
    ],
    "constraints": "Requires dequantize-float_op-quantize sequence due to TVM explicitly providing input and output quantization parameters.",
    "notes": "Composite mapping. Involves dequantizing input, applying `torch.sqrt` to the float tensor, and then quantizing the result.",
    "confidence": 0.8
  },
  {
    "tvm_api": "tvm.relay.qnn.op.qnn.rsqrt",
    "torch_api": [
      "torch.dequantize",
      "torch.rsqrt",
      "torch.quantize_per_tensor"
    ],
    "mapping_type": "composite",
    "direction": "tvm_to_torch",
    "tvm_pattern": "tvm.relay.qnn.op.qnn.rsqrt(x={{x}}, scale={{scale}}, zero_point={{zero_point}}, output_scale={{output_scale}}, output_zero_point={{output_zero_point}})",
    "torch_pattern": "float_input = torch.dequantize({{x}})\nfloat_output = torch.rsqrt(float_input)\nquantized_output = torch.quantize_per_tensor(float_output, scale={{output_scale}}, zero_point={{output_zero_point}}, dtype=torch.qint8)",
    "arg_mapping": {
      "x": "x_q_tensor",
      "output_scale": "output_scale",
      "output_zero_point": "output_zero_point"
    },
    "example_pairs": [
      {
        "tvm": "q_out = tvm.relay.qnn.op.qnn.rsqrt(q_input, input_scale, input_zp, out_scale, out_zp)",
        "torch": "float_input = torch.dequantize(q_input)\nfloat_output = torch.rsqrt(float_input)\nquantized_output = torch.quantize_per_tensor(float_output, scale=out_scale, zero_point=out_zp, dtype=torch.qint8)"
      }
    ],
    "constraints": "Requires dequantize-float_op-quantize sequence due to TVM explicitly providing input and output quantization parameters.",
    "notes": "Composite mapping. Involves dequantizing input, applying `torch.rsqrt` to the float tensor, and then quantizing the result.",
    "confidence": 0.8
  },
  {
    "tvm_api": "tvm.relay.qnn.op.qnn.erf",
    "torch_api": [
      "torch.dequantize",
      "torch.erf",
      "torch.quantize_per_tensor"
    ],
    "mapping_type": "composite",
    "direction": "tvm_to_torch",
    "tvm_pattern": "tvm.relay.qnn.op.qnn.erf(x={{x}}, scale={{scale}}, zero_point={{zero_point}}, output_scale={{output_scale}}, output_zero_point={{output_zero_point}})",
    "torch_pattern": "float_input = torch.dequantize({{x}})\nfloat_output = torch.erf(float_input)\nquantized_output = torch.quantize_per_tensor(float_output, scale={{output_scale}}, zero_point={{output_zero_point}}, dtype=torch.qint8)",
    "arg_mapping": {
      "x": "x_q_tensor",
      "output_scale": "output_scale",
      "output_zero_point": "output_zero_point"
    },
    "example_pairs": [
      {
        "tvm": "q_out = tvm.relay.qnn.op.qnn.erf(q_input, input_scale, input_zp, out_scale, out_zp)",
        "torch": "float_input = torch.dequantize(q_input)\nfloat_output = torch.erf(float_input)\nquantized_output = torch.quantize_per_tensor(float_output, scale=out_scale, zero_point=out_zp, dtype=torch.qint8)"
      }
    ],
    "constraints": "Requires dequantize-float_op-quantize sequence due to TVM explicitly providing input and output quantization parameters.",
    "notes": "Composite mapping. Involves dequantizing input, applying `torch.erf` to the float tensor, and then quantizing the result.",
    "confidence": 0.8
  },
  {
    "tvm_api": "tvm.relay.qnn.op.qnn.abs",
    "torch_api": [
      "torch.dequantize",
      "torch.abs",
      "torch.quantize_per_tensor"
    ],
    "mapping_type": "composite",
    "direction": "tvm_to_torch",
    "tvm_pattern": "tvm.relay.qnn.op.qnn.abs(x={{x}}, scale={{scale}}, zero_point={{zero_point}}, output_scale={{output_scale}}, output_zero_point={{output_zero_point}})",
    "torch_pattern": "float_input = torch.dequantize({{x}})\nfloat_output = torch.abs(float_input)\nquantized_output = torch.quantize_per_tensor(float_output, scale={{output_scale}}, zero_point={{output_zero_point}}, dtype=torch.qint8)",
    "arg_mapping": {
      "x": "x_q_tensor",
      "output_scale": "output_scale",
      "output_zero_point": "output_zero_point"
    },
    "example_pairs": [
      {
        "tvm": "q_out = tvm.relay.qnn.op.qnn.abs(q_input, input_scale, input_zp, out_scale, out_zp)",
        "torch": "float_input = torch.dequantize(q_input)\nfloat_output = torch.abs(float_input)\nquantized_output = torch.quantize_per_tensor(float_output, scale=out_scale, zero_point=out_zp, dtype=torch.qint8)"
      }
    ],
    "constraints": "Requires dequantize-float_op-quantize sequence due to TVM explicitly providing input and output quantization parameters.",
    "notes": "Composite mapping. Involves dequantizing input, applying `torch.abs` to the float tensor, and then quantizing the result.",
    "confidence": 0.8
  },
  {
    "tvm_api": "tvm.relay.qnn.op.qnn.sigmoid",
    "torch_api": [
      "torch.dequantize",
      "torch.sigmoid",
      "torch.quantize_per_tensor"
    ],
    "mapping_type": "composite",
    "direction": "tvm_to_torch",
    "tvm_pattern": "tvm.relay.qnn.op.qnn.sigmoid(x={{x}}, scale={{scale}}, zero_point={{zero_point}}, output_scale={{output_scale}}, output_zero_point={{output_zero_point}})",
    "torch_pattern": "float_input = torch.dequantize({{x}})\nfloat_output = torch.sigmoid(float_input)\nquantized_output = torch.quantize_per_tensor(float_output, scale={{output_scale}}, zero_point={{output_zero_point}}, dtype=torch.qint8)",
    "arg_mapping": {
      "x": "x_q_tensor",
      "output_scale": "output_scale",
      "output_zero_point": "output_zero_point"
    },
    "example_pairs": [
      {
        "tvm": "q_out = tvm.relay.qnn.op.qnn.sigmoid(q_input, input_scale, input_zp, out_scale, out_zp)",
        "torch": "float_input = torch.dequantize(q_input)\nfloat_output = torch.sigmoid(float_input)\nquantized_output = torch.quantize_per_tensor(float_output, scale=out_scale, zero_point=out_zp, dtype=torch.qint8)"
      }
    ],
    "constraints": "Requires dequantize-float_op-quantize sequence due to TVM explicitly providing input and output quantization parameters.",
    "notes": "Composite mapping. Involves dequantizing input, applying `torch.sigmoid` to the float tensor, and then quantizing the result.",
    "confidence": 0.8
  },
  {
    "tvm_api": "tvm.relay.qnn.op.qnn.log",
    "torch_api": [
      "torch.dequantize",
      "torch.log",
      "torch.quantize_per_tensor"
    ],
    "mapping_type": "composite",
    "direction": "tvm_to_torch",
    "tvm_pattern": "tvm.relay.qnn.op.qnn.log(x={{x}}, scale={{scale}}, zero_point={{zero_point}}, output_scale={{output_scale}}, output_zero_point={{output_zero_point}})",
    "torch_pattern": "float_input = torch.dequantize({{x}})\nfloat_output = torch.log(float_input)\nquantized_output = torch.quantize_per_tensor(float_output, scale={{output_scale}}, zero_point={{output_zero_point}}, dtype=torch.qint8)",
    "arg_mapping": {
      "x": "x_q_tensor",
      "output_scale": "output_scale",
      "output_zero_point": "output_zero_point"
    },
    "example_pairs": [
      {
        "tvm": "q_out = tvm.relay.qnn.op.qnn.log(q_input, input_scale, input_zp, out_scale, out_zp)",
        "torch": "float_input = torch.dequantize(q_input)\nfloat_output = torch.log(float_input)\nquantized_output = torch.quantize_per_tensor(float_output, scale=out_scale, zero_point=out_zp, dtype=torch.qint8)"
      }
    ],
    "constraints": "Requires dequantize-float_op-quantize sequence due to TVM explicitly providing input and output quantization parameters.",
    "notes": "Composite mapping. Involves dequantizing input, applying `torch.log` to the float tensor, and then quantizing the result.",
    "confidence": 0.8
  },
  {
    "tvm_api": "tvm.relay.qnn.op.qnn.leaky_relu",
    "torch_api": [
      "torch.dequantize",
      "torch.nn.functional.leaky_relu",
      "torch.quantize_per_tensor"
    ],
    "mapping_type": "composite",
    "direction": "tvm_to_torch",
    "tvm_pattern": "tvm.relay.qnn.op.qnn.leaky_relu(x={{x}}, alpha={{alpha}}, input_scale={{input_scale}}, input_zero_point={{input_zero_point}}, output_scale={{output_scale}}, output_zero_point={{output_zero_point}})",
    "torch_pattern": "float_input = torch.dequantize({{x}})\nfloat_output = torch.nn.functional.leaky_relu(float_input, negative_slope={{alpha}})\nquantized_output = torch.quantize_per_tensor(float_output, scale={{output_scale}}, zero_point={{output_zero_point}}, dtype=torch.qint8)",
    "arg_mapping": {
      "x": "x_q_tensor",
      "alpha": "alpha",
      "output_scale": "output_scale",
      "output_zero_point": "output_zero_point"
    },
    "example_pairs": [
      {
        "tvm": "q_out = tvm.relay.qnn.op.qnn.leaky_relu(q_input, 0.1, input_scale, input_zp, out_scale, out_zp)",
        "torch": "float_input = torch.dequantize(q_input)\nfloat_output = torch.nn.functional.leaky_relu(float_input, negative_slope=0.1)\nquantized_output = torch.quantize_per_tensor(float_output, scale=out_scale, zero_point=out_zp, dtype=torch.qint8)"
      }
    ],
    "constraints": "Requires dequantize-float_op-quantize sequence due to TVM explicitly providing input and output quantization parameters. TVM's `alpha` maps to PyTorch's `negative_slope`.",
    "notes": "Composite mapping. Involves dequantizing input, applying `F.leaky_relu` to the float tensor, and then quantizing the result.",
    "confidence": 0.8
  },
  {
    "tvm_api": "tvm.relay.quantize.quantize.realize",
    "torch_api": null,
    "mapping_type": "no_mapping",
    "direction": "tvm_to_torch",
    "tvm_pattern": null,
    "torch_pattern": null,
    "arg_mapping": {},
    "example_pairs": [],
    "constraints": "Not convertible",
    "notes": "NO_MAPPING: `realize` in TVM is a graph transformation pass that converts a simulated quantized graph (float32 computation) into a real low-bit integer graph. This is a compiler-specific IR transformation. PyTorch's quantization framework (e.g., `torch.ao.quantization`) manages this conversion internally as part of its quantization workflow, but there isn't a direct user-facing API or function named `realize` for this purpose.",
    "confidence": 0.2
  },
  {
    "tvm_api": "tvm.relay.quantize.quantize.quantize",
    "torch_api": "torch.ao.quantization.quantize",
    "mapping_type": "direct",
    "direction": "tvm_to_torch",
    "tvm_pattern": "tvm.relay.quantize.quantize(mod={{mod}}, params={{params}}, dataset={{dataset}})",
    "torch_pattern": "torch.ao.quantization.quantize(model={{mod}}, run_fn={{run_fn_for_calibration}}, run_args={{run_args_for_calibration}})",
    "arg_mapping": {
      "mod": "model",
      "dataset": "run_args_for_calibration"
    },
    "example_pairs": [
      {
        "tvm": "quantized_mod = tvm.relay.quantize.quantize(relay_mod, params=model_params, dataset=calib_dataset)",
        "torch": "def run_fn_for_calibration(model, data_loader):\n    for input_batch in data_loader:\n        model(input_batch)\nquantized_model = torch.ao.quantization.quantize(model=torch_model, run_fn=run_fn_for_calibration, run_args=[calib_data_loader])"
      }
    ],
    "constraints": "Both are high-level APIs for the entire post-training quantization process. TVM uses `mod`, `params`, `dataset`. PyTorch uses `model`, `run_fn`, `run_args`. `run_fn` in PyTorch provides the calibration mechanism. The `params` in TVM would be loaded into the PyTorch `model` beforehand.",
    "notes": "Direct conceptual mapping. Both functions orchestrate the end-to-end quantization process for a given model.",
    "confidence": 0.9
  },
  {
    "tvm_api": "tvm.relay.testing.__init__.rand",
    "torch_api": "torch.rand",
    "mapping_type": "direct",
    "direction": "tvm_to_torch",
    "tvm_pattern": "tvm.relay.testing.rand(dtype='{{dtype}}', *shape={{shape}})",
    "torch_pattern": "torch.rand(*{{shape}}, dtype=torch.{{dtype}})",
    "arg_mapping": {
      "dtype": "dtype",
      "shape": "shape"
    },
    "example_pairs": [
      {
        "tvm": "random_tensor = tvm.relay.testing.rand('float32', 2, 3)",
        "torch": "random_tensor = torch.rand(2, 3, dtype=torch.float32)"
      }
    ],
    "constraints": "PyTorch's `rand` takes `*shape` as positional arguments and `dtype` as a keyword argument. TVM takes `dtype` as the first positional argument. PyTorch's `rand` generates values in `[0,1)`.",
    "notes": "Directly maps to `torch.rand`. The argument order for `dtype` differs, but the core functionality is the same.",
    "confidence": 0.98
  },
  {
    "tvm_api": "tvm.relay.testing.layers.conv2d",
    "torch_api": null,
    "mapping_type": "no_mapping",
    "direction": "tvm_to_torch",
    "tvm_pattern": null,
    "torch_pattern": null,
    "arg_mapping": {},
    "example_pairs": [],
    "constraints": "Not convertible",
    "notes": "NO_MAPPING: This is a TVM testing utility function that automatically creates weights if not given and then calls `relay.nn.conv2d`. It's a helper for building Relay graphs in tests, not a fundamental functional operation. In PyTorch, users would typically either create an `torch.nn.Conv2d` module and manage weights, or call `torch.nn.functional.conv2d` with explicitly provided weight and bias tensors.",
    "confidence": 0.2
  },
  {
    "tvm_api": "tvm.relay.testing.layers.conv3d",
    "torch_api": null,
    "mapping_type": "no_mapping",
    "direction": "tvm_to_torch",
    "tvm_pattern": null,
    "torch_pattern": null,
    "arg_mapping": {},
    "example_pairs": [],
    "constraints": "Not convertible",
    "notes": "NO_MAPPING: Similar to `tvm.relay.testing.layers.conv2d`, this is a TVM testing utility for easy model construction, not a core functional operation. There is no direct PyTorch equivalent for a wrapper function that conditionally creates weights.",
    "confidence": 0.2
  },
  {
    "tvm_api": "tvm.relay.testing.nat.count",
    "torch_api": null,
    "mapping_type": "no_mapping",
    "direction": "tvm_to_torch",
    "tvm_pattern": null,
    "torch_pattern": null,
    "arg_mapping": {},
    "example_pairs": [],
    "constraints": "Not convertible",
    "notes": "NO_MAPPING: This TVM API is specific to converting a Relay ADT (Algebraic Data Type) `ConstructorValue` representing a natural number into a Python integer. This concept is internal to TVM's Relay type system and has no direct equivalent in PyTorch's tensor-based operations or high-level APIs.",
    "confidence": 0.2
  },
  {
    "tvm_api": "tvm.relay.transform.fake_quantization_to_integer.dequantize",
    "torch_api": null,
    "mapping_type": "no_mapping",
    "direction": "tvm_to_torch",
    "tvm_pattern": null,
    "torch_pattern": null,
    "arg_mapping": {},
    "example_pairs": [],
    "constraints": "Not convertible",
    "notes": "NO_MAPPING: This function is a *rewrite rule* used internally by TVM's `fake_quantization_to_integer` pass. It's part of the Relay graph transformation, not a user-facing tensor operation like `torch.dequantize`. Its purpose is to modify the graph IR during a compilation stage.",
    "confidence": 0.2
  },
  {
    "tvm_api": "tvm.relay.transform.fake_quantization_to_integer.quantize",
    "torch_api": null,
    "mapping_type": "no_mapping",
    "direction": "tvm_to_torch",
    "tvm_pattern": null,
    "torch_pattern": null,
    "arg_mapping": {},
    "example_pairs": [],
    "constraints": "Not convertible",
    "notes": "NO_MAPPING: Similar to `dequantize` in this context, this is a *rewrite rule* within TVM's `fake_quantization_to_integer` pass. It's an internal graph transformation function, not a direct PyTorch tensor operation or high-level quantization API.",
    "confidence": 0.2
  },
  {
    "tvm_api": "tvm.relay.transform.fake_quantization_to_integer.broadcast_to",
    "torch_api": null,
    "mapping_type": "no_mapping",
    "direction": "tvm_to_torch",
    "tvm_pattern": null,
    "torch_pattern": null,
    "arg_mapping": {},
    "example_pairs": [],
    "constraints": "Not convertible",
    "notes": "NO_MAPPING: This is an internal *rewrite rule* for the `broadcast_to` operator within TVM's `fake_quantization_to_integer` pass. It describes how to transform the IR for this specific op during quantization, not a user-callable function corresponding to `torch.broadcast_to`.",
    "confidence": 0.2
  },
  {
    "tvm_api": "tvm.relay.transform.fake_quantization_to_integer.conv2d",
    "torch_api": null,
    "mapping_type": "no_mapping",
    "direction": "tvm_to_torch",
    "tvm_pattern": null,
    "torch_pattern": null,
    "arg_mapping": {},
    "example_pairs": [],
    "constraints": "Not convertible",
    "notes": "NO_MAPPING: This is an internal *rewrite rule* for the `nn.conv2d` operator within TVM's `fake_quantization_to_integer` pass. It describes how to transform the IR for this specific op during quantization, not a user-callable function corresponding to `torch.nn.functional.conv2d`.",
    "confidence": 0.2
  },
  {
    "tvm_api": "tvm.relay.transform.fake_quantization_to_integer.topk",
    "torch_api": null,
    "mapping_type": "no_mapping",
    "direction": "tvm_to_torch",
    "tvm_pattern": null,
    "torch_pattern": null,
    "arg_mapping": {},
    "example_pairs": [],
    "constraints": "Not convertible",
    "notes": "NO_MAPPING: This is an internal *rewrite rule* for the `topk` operator within TVM's `fake_quantization_to_integer` pass. It describes how to transform the IR for this specific op during quantization, not a user-callable function corresponding to `torch.topk`.",
    "confidence": 0.2
  },
  {
    "tvm_api": "tvm.relay.transform.fake_quantization_to_integer.split",
    "torch_api": null,
    "mapping_type": "no_mapping",
    "direction": "tvm_to_torch",
    "tvm_pattern": null,
    "torch_pattern": null,
    "arg_mapping": {},
    "example_pairs": [],
    "constraints": "Not convertible",
    "notes": "NO_MAPPING: This is an internal *rewrite rule* for the `split` operator within TVM's `fake_quantization_to_integer` pass. It describes how to transform the IR for this specific op during quantization, not a user-callable function corresponding to `torch.split`.",
    "confidence": 0.2
  },
  {
    "tvm_api": "tvm.relay.transform.fake_quantization_to_integer.clip",
    "torch_api": null,
    "mapping_type": "no_mapping",
    "direction": "tvm_to_torch",
    "tvm_pattern": null,
    "torch_pattern": null,
    "arg_mapping": {},
    "example_pairs": [],
    "constraints": "Not convertible",
    "notes": "NO_MAPPING: This is an internal *rewrite rule* for the `clip` operator within TVM's `fake_quantization_to_integer` pass. It describes how to transform the IR for this specific op during quantization, not a user-callable function corresponding to `torch.clamp` (PyTorch's equivalent for clip).",
    "confidence": 0.2
  },
  {
    "tvm_api": "tvm.relay.transform.fake_quantization_to_integer.relu",
    "torch_api": null,
    "mapping_type": "no_mapping",
    "direction": "tvm_to_torch",
    "tvm_pattern": null,
    "torch_pattern": null,
    "arg_mapping": {},
    "example_pairs": [],
    "constraints": "Not convertible",
    "notes": "NO_MAPPING: This is an internal *rewrite rule* for the `nn.relu` operator within TVM's `fake_quantization_to_integer` pass. It describes how to transform the IR for this specific op during quantization, not a user-callable function corresponding to `torch.nn.functional.relu`.",
    "confidence": 0.2
  },
  {
    "tvm_api": "tvm.relay.transform.fake_quantization_to_integer.leaky_relu",
    "torch_api": null,
    "mapping_type": "no_mapping",
    "direction": "tvm_to_torch",
    "tvm_pattern": null,
    "torch_pattern": null,
    "arg_mapping": {},
    "example_pairs": [],
    "constraints": "Not convertible",
    "notes": "NO_MAPPING: This is an internal *rewrite rule* for the `nn.leaky_relu` operator within TVM's `fake_quantization_to_integer` pass. It describes how to transform the IR for this specific op during quantization, not a user-callable function corresponding to `torch.nn.functional.leaky_relu`.",
    "confidence": 0.2
  },
  {
    "tvm_api": "tvm.relay.transform.fake_quantization_to_integer.pad",
    "torch_api": null,
    "mapping_type": "no_mapping",
    "direction": "tvm_to_torch",
    "tvm_pattern": null,
    "torch_pattern": null,
    "arg_mapping": {},
    "example_pairs": [],
    "constraints": "Not convertible",
    "notes": "NO_MAPPING: This is an internal *rewrite rule* for the `nn.pad` operator within TVM's `fake_quantization_to_integer` pass. It describes how to transform the IR for this specific op during quantization, not a user-callable function corresponding to `torch.nn.functional.pad`.",
    "confidence": 0.2
  },
  {
    "tvm_api": "tvm.relay.transform.fake_quantization_to_integer.mean",
    "torch_api": null,
    "mapping_type": "no_mapping",
    "direction": "tvm_to_torch",
    "tvm_pattern": null,
    "torch_pattern": null,
    "arg_mapping": {},
    "example_pairs": [],
    "constraints": "Not convertible",
    "notes": "NO_MAPPING: This is an internal *rewrite rule* for the `mean` operator within TVM's `fake_quantization_to_integer` pass. It describes how to transform the IR for this specific op during quantization, not a user-callable function corresponding to `torch.mean`.",
    "confidence": 0.2
  },
  {
    "tvm_api": "tvm.relay.transform.transform.gradient",
    "torch_api": null,
    "mapping_type": "no_mapping",
    "direction": "tvm_to_torch",
    "tvm_pattern": null,
    "torch_pattern": null,
    "arg_mapping": {},
    "example_pairs": [],
    "constraints": "Not convertible",
    "notes": "NO_MAPPING: TVM's `gradient` performs symbolic automatic differentiation of Relay expressions. PyTorch's candidate `_numpy.gradient` calculates numerical gradients of tensors (like numpy.gradient), which is a different functionality. For symbolic differentiation, PyTorch uses `torch.autograd.grad` or `.backward()` which operate on a computational graph.",
    "confidence": 0.2
  },
  {
    "tvm_api": "tvm.runtime.name_transforms.sanitize_name",
    "torch_api": null,
    "mapping_type": "no_mapping",
    "direction": "tvm_to_torch",
    "tvm_pattern": null,
    "torch_pattern": null,
    "arg_mapping": {},
    "example_pairs": [],
    "constraints": "Not convertible",
    "notes": "NO_MAPPING: TVM's `sanitize_name` is for preparing names for compiler artifacts (e.g., valid identifiers). The PyTorch candidate `sanitize_name` is an internal utility for handling folder names and keywords in a testing context, with different sanitization logic and purpose.",
    "confidence": 0.3
  },
  {
    "tvm_api": "tvm.runtime.ndarray.empty",
    "torch_api": "torch.empty",
    "mapping_type": "direct",
    "direction": "tvm_to_torch",
    "tvm_pattern": "tvm.runtime.ndarray.empty({{shape}}, dtype=\"{{dtype}}\", device={{device}}, mem_scope={{mem_scope}})",
    "torch_pattern": "torch.empty({{shape}}, dtype={{dtype}}, device={{device}})",
    "arg_mapping": {
      "shape": "shape",
      "dtype": "dtype",
      "device": "device",
      "mem_scope": null
    },
    "example_pairs": [
      {
        "tvm": "x = tvm.runtime.ndarray.empty((10, 20), dtype=\"float32\", device=tvm.cpu(0))",
        "torch": "x = torch.empty((10, 20), dtype=torch.float32, device='cpu')"
      }
    ],
    "constraints": "Memory scope `mem_scope` has no direct PyTorch equivalent and should be omitted.",
    "notes": "Creates an uninitialized tensor of a specified shape, dtype, and device.",
    "confidence": 0.95
  },
  {
    "tvm_api": "tvm.runtime.ndarray.from_dlpack",
    "torch_api": "torch.utils.dlpack.from_dlpack",
    "mapping_type": "direct",
    "direction": "tvm_to_torch",
    "tvm_pattern": "tvm.runtime.ndarray.from_dlpack({{dltensor}})",
    "torch_pattern": "torch.utils.dlpack.from_dlpack({{ext_tensor}})",
    "arg_mapping": {
      "dltensor": "ext_tensor"
    },
    "example_pairs": [
      {
        "tvm": "arr = tvm.runtime.ndarray.from_dlpack(dl_capsule)",
        "torch": "tensor = torch.utils.dlpack.from_dlpack(dl_capsule)"
      }
    ],
    "constraints": "Requires the input `ext_tensor` to implement the DLPack protocol (`__dlpack__` method or be a DLPack capsule).",
    "notes": "Converts a DLPack tensor/object into a PyTorch tensor, sharing memory.",
    "confidence": 0.98
  },
  {
    "tvm_api": "tvm.runtime.ndarray.array",
    "torch_api": "torch.tensor",
    "mapping_type": "direct",
    "direction": "tvm_to_torch",
    "tvm_pattern": "tvm.runtime.ndarray.array({{arr}}, device={{device}}, mem_scope={{mem_scope}})",
    "torch_pattern": "torch.tensor({{data}}, device={{device}})",
    "arg_mapping": {
      "arr": "data",
      "device": "device",
      "mem_scope": null
    },
    "example_pairs": [
      {
        "tvm": "x = tvm.runtime.ndarray.array(numpy_array, device=tvm.cpu(0))",
        "torch": "x = torch.tensor(numpy_array, device='cpu')"
      }
    ],
    "constraints": "Memory scope `mem_scope` has no direct PyTorch equivalent and should be omitted. `arr` is typically a NumPy array or list/tuple.",
    "notes": "Creates a PyTorch tensor from host data (e.g., NumPy array) on a specified device.",
    "confidence": 0.95
  },
  {
    "tvm_api": "tvm.runtime.object_generic.convert",
    "torch_api": null,
    "mapping_type": "no_mapping",
    "direction": "tvm_to_torch",
    "tvm_pattern": null,
    "torch_pattern": null,
    "arg_mapping": {},
    "example_pairs": [],
    "constraints": "Not convertible",
    "notes": "NO_MAPPING: TVM's `convert` is an internal type conversion utility for TVM's own object system (e.g., Python values to TVM expressions/objects). The PyTorch candidates are for model quantization and graph transformation, serving entirely different purposes.",
    "confidence": 0.2
  },
  {
    "tvm_api": "tvm.runtime.vm.convert",
    "torch_api": null,
    "mapping_type": "no_mapping",
    "direction": "tvm_to_torch",
    "tvm_pattern": null,
    "torch_pattern": null,
    "arg_mapping": {},
    "example_pairs": [],
    "constraints": "Not convertible",
    "notes": "NO_MAPPING: TVM's `convert` is specific to converting arguments for the Relay VM to its internal representations. The PyTorch candidates are for model quantization and graph transformation, serving entirely different purposes.",
    "confidence": 0.2
  },
  {
    "tvm_api": "tvm.runtime.profiling.__init__.profile_function",
    "torch_api": null,
    "mapping_type": "no_mapping",
    "direction": "tvm_to_torch",
    "tvm_pattern": null,
    "torch_pattern": null,
    "arg_mapping": {},
    "example_pairs": [],
    "constraints": "Not convertible",
    "notes": "NO_MAPPING: TVM's `profile_function` collects low-level hardware performance counters for compiled `PrimFunc`s. The PyTorch candidate `functorch.benchmarks.cse.profile_function` is an internal benchmark utility for timing specific operations. The general PyTorch equivalent for profiling execution would be `torch.profiler.profile`.",
    "confidence": 0.3
  },
  {
    "tvm_api": "tvm.script.ir_builder.tir.ir.init",
    "torch_api": null,
    "mapping_type": "no_mapping",
    "direction": "tvm_to_torch",
    "tvm_pattern": null,
    "torch_pattern": null,
    "arg_mapping": {},
    "example_pairs": [],
    "constraints": "Not convertible",
    "notes": "NO_MAPPING: TVM's `tir.ir.init` is an IR builder construct for block initialization statements. The PyTorch `init` functions are for system-level initialization of CUDA, profilers, or backends, which are unrelated to IR building.",
    "confidence": 0.2
  },
  {
    "tvm_api": "tvm.script.ir_builder.tir.ir.where",
    "torch_api": null,
    "mapping_type": "no_mapping",
    "direction": "tvm_to_torch",
    "tvm_pattern": null,
    "torch_pattern": null,
    "arg_mapping": {},
    "example_pairs": [],
    "constraints": "Not convertible",
    "notes": "NO_MAPPING: TVM's `tir.ir.where` is an IR-level control flow construct (block predicate statement) for conditional execution. PyTorch's `torch.where` is an element-wise tensor operation for selecting values based on a condition, which is a functional difference in scope.",
    "confidence": 0.4
  },
  {
    "tvm_api": "tvm.script.ir_builder.tir.ir.unroll",
    "torch_api": null,
    "mapping_type": "no_mapping",
    "direction": "tvm_to_torch",
    "tvm_pattern": null,
    "torch_pattern": null,
    "arg_mapping": {},
    "example_pairs": [],
    "constraints": "Not convertible",
    "notes": "NO_MAPPING: TVM's `unroll` is an IR builder construct for specifying loop unrolling as an optimization directive. The PyTorch candidates are internal code generation helpers, not general user-facing APIs for defining program logic or IR.",
    "confidence": 0.3
  },
  {
    "tvm_api": "tvm.script.ir_builder.tir.ir.realize",
    "torch_api": null,
    "mapping_type": "no_mapping",
    "direction": "tvm_to_torch",
    "tvm_pattern": null,
    "torch_pattern": null,
    "arg_mapping": {},
    "example_pairs": [],
    "constraints": "Not convertible",
    "notes": "NO_MAPPING: TVM's `realize` is an IR-level memory management construct, binding a buffer region to a storage scope. The PyTorch candidate is an internal testing utility. There is no direct PyTorch API for this low-level IR concept.",
    "confidence": 0.3
  },
  {
    "tvm_api": "tvm.script.ir_builder.tir.ir.var",
    "torch_api": null,
    "mapping_type": "no_mapping",
    "direction": "tvm_to_torch",
    "tvm_pattern": null,
    "torch_pattern": null,
    "arg_mapping": {},
    "example_pairs": [],
    "constraints": "Not convertible",
    "notes": "NO_MAPPING: TVM's `tir.ir.var` creates a symbolic variable (e.g., for loop iterators) within its IR. The PyTorch `var` functions are for calculating statistical variance of tensors or internal symbolic representation unrelated to TVM's TIR variable definition.",
    "confidence": 0.2
  },
  {
    "tvm_api": "tvm.script.ir_builder.tir.ir.min",
    "torch_api": "torch.min",
    "mapping_type": "direct",
    "direction": "tvm_to_torch",
    "tvm_pattern": "tvm.script.ir_builder.tir.ir.min({{a}}, {{b}})",
    "torch_pattern": "torch.min({{input}}, {{other}})",
    "arg_mapping": {
      "a": "input",
      "b": "other"
    },
    "example_pairs": [
      {
        "tvm": "result = tvm.script.ir_builder.tir.ir.min(x, y)",
        "torch": "result = torch.min(x, y)"
      }
    ],
    "constraints": "Assumes `a` and `b` are PyTorch tensors representing `PrimExpr`.",
    "notes": "Performs element-wise minimum of two tensors. PyTorch's `torch.min(input, other)` is the direct functional equivalent.",
    "confidence": 0.95
  },
  {
    "tvm_api": "tvm.script.ir_builder.tir.ir.max",
    "torch_api": "torch.max",
    "mapping_type": "direct",
    "direction": "tvm_to_torch",
    "tvm_pattern": "tvm.script.ir_builder.tir.ir.max({{a}}, {{b}})",
    "torch_pattern": "torch.max({{input}}, {{other}})",
    "arg_mapping": {
      "a": "input",
      "b": "other"
    },
    "example_pairs": [
      {
        "tvm": "result = tvm.script.ir_builder.tir.ir.max(x, y)",
        "torch": "result = torch.max(x, y)"
      }
    ],
    "constraints": "Assumes `a` and `b` are PyTorch tensors representing `PrimExpr`.",
    "notes": "Performs element-wise maximum of two tensors. PyTorch's `torch.max(input, other)` is the direct functional equivalent.",
    "confidence": 0.95
  },
  {
    "tvm_api": "tvm.script.parser.core.doc.parse",
    "torch_api": null,
    "mapping_type": "no_mapping",
    "direction": "tvm_to_torch",
    "tvm_pattern": null,
    "torch_pattern": null,
    "arg_mapping": {},
    "example_pairs": [],
    "constraints": "Not convertible",
    "notes": "NO_MAPPING: TVM's `parse` is specific to parsing TVMScript source code into its internal AST representation. The PyTorch `parse` candidates are for parsing version strings or graph visualization formats, which are unrelated.",
    "confidence": 0.2
  },
  {
    "tvm_api": "tvm.script.parser.core.entry.parse",
    "torch_api": null,
    "mapping_type": "no_mapping",
    "direction": "tvm_to_torch",
    "tvm_pattern": null,
    "torch_pattern": null,
    "arg_mapping": {},
    "example_pairs": [],
    "constraints": "Not convertible",
    "notes": "NO_MAPPING: TVM's `parse` is the main entry point for parsing TVMScript code into its internal IR. The PyTorch `parse` candidates are for parsing version strings or graph visualization formats, which are unrelated.",
    "confidence": 0.2
  },
  {
    "tvm_api": "tvm.script.parser_v1.tir.intrin.floordiv",
    "torch_api": "torch.floor_divide",
    "mapping_type": "direct",
    "direction": "tvm_to_torch",
    "tvm_pattern": "tvm.script.parser_v1.tir.intrin.floordiv({{x}}, {{y}}, {{span}})",
    "torch_pattern": "torch.floor_divide({{input}}, {{other}})",
    "arg_mapping": {
      "x": "input",
      "y": "other",
      "span": null
    },
    "example_pairs": [
      {
        "tvm": "result = tvm.script.parser_v1.tir.intrin.floordiv(a, b)",
        "torch": "result = torch.floor_divide(a, b)"
      }
    ],
    "constraints": "`span` argument has no direct PyTorch equivalent. Inputs are assumed to be tensors.",
    "notes": "Performs element-wise floor division (division that rounds down to the nearest integer).",
    "confidence": 0.95
  },
  {
    "tvm_api": "tvm.script.parser_v1.tir.intrin.truncdiv",
    "torch_api": "torch.div",
    "mapping_type": "direct",
    "direction": "tvm_to_torch",
    "tvm_pattern": "tvm.script.parser_v1.tir.intrin.truncdiv({{x}}, {{y}}, {{span}})",
    "torch_pattern": "torch.div({{input}}, {{other}}, rounding_mode='trunc')",
    "arg_mapping": {
      "x": "input",
      "y": "other",
      "span": null
    },
    "example_pairs": [
      {
        "tvm": "result = tvm.script.parser_v1.tir.intrin.truncdiv(a, b)",
        "torch": "result = torch.div(a, b, rounding_mode='trunc')"
      }
    ],
    "constraints": "`span` argument has no direct PyTorch equivalent. Inputs are assumed to be tensors.",
    "notes": "Performs element-wise truncated division (division that rounds towards zero).",
    "confidence": 0.95
  },
  {
    "tvm_api": "tvm.script.parser_v1.tir.intrin.ceildiv",
    "torch_api": [
      "torch.ceil",
      "torch.div"
    ],
    "mapping_type": "composite",
    "direction": "tvm_to_torch",
    "tvm_pattern": "tvm.script.parser_v1.tir.intrin.ceildiv({{x}}, {{y}}, {{span}})",
    "torch_pattern": "torch.ceil(torch.div({{input}}, {{other}}))",
    "arg_mapping": {
      "x": "input",
      "y": "other",
      "span": null
    },
    "example_pairs": [
      {
        "tvm": "result = tvm.script.parser_v1.tir.intrin.ceildiv(a, b)",
        "torch": "result = torch.ceil(torch.div(a, b))"
      }
    ],
    "constraints": "`span` argument has no direct PyTorch equivalent. Inputs are assumed to be tensors.",
    "notes": "Performs element-wise ceiling division using a combination of `torch.div` and `torch.ceil`.",
    "confidence": 0.9
  },
  {
    "tvm_api": "tvm.script.parser_v1.tir.intrin.abs",
    "torch_api": "torch.abs",
    "mapping_type": "direct",
    "direction": "tvm_to_torch",
    "tvm_pattern": "tvm.script.parser_v1.tir.intrin.abs({{x}}, {{span}})",
    "torch_pattern": "torch.abs({{input}})",
    "arg_mapping": {
      "x": "input",
      "span": null
    },
    "example_pairs": [
      {
        "tvm": "result = tvm.script.parser_v1.tir.intrin.abs(x)",
        "torch": "result = torch.abs(x)"
      }
    ],
    "constraints": "`span` argument has no direct PyTorch equivalent. Input is assumed to be a tensor.",
    "notes": "Performs element-wise absolute value.",
    "confidence": 0.98
  },
  {
    "tvm_api": "tvm.script.parser_v1.tir.intrin.load",
    "torch_api": null,
    "mapping_type": "no_mapping",
    "direction": "tvm_to_torch",
    "tvm_pattern": null,
    "torch_pattern": null,
    "arg_mapping": {},
    "example_pairs": [],
    "constraints": "Not convertible",
    "notes": "NO_MAPPING: TVM's `load` is a low-level IR instruction for accessing data from a buffer. The PyTorch candidates are for deserialization or model loading, which are different concepts.",
    "confidence": 0.2
  },
  {
    "tvm_api": "tvm.script.parser_v1.tir.intrin.broadcast",
    "torch_api": "torch.full",
    "mapping_type": "direct",
    "direction": "tvm_to_torch",
    "tvm_pattern": "tvm.script.parser_v1.tir.intrin.broadcast({{value}}, {{lanes}}, {{span}})",
    "torch_pattern": "torch.full((({{lanes}},)), {{fill_value}})",
    "arg_mapping": {
      "value": "fill_value",
      "lanes": "lanes",
      "span": null
    },
    "example_pairs": [
      {
        "tvm": "vec = tvm.script.parser_v1.tir.intrin.broadcast(scalar_val, 16)",
        "torch": "vec = torch.full((16,), scalar_val)"
      }
    ],
    "constraints": "`span` argument has no direct PyTorch equivalent. Assumes `lanes` is an integer value.",
    "notes": "Creates a new tensor of a specified size filled with a scalar value. In TVM, `lanes` typically refers to the vector length for broadcasting a scalar.",
    "confidence": 0.9
  },
  {
    "tvm_api": "tvm.script.parser_v1.tir.intrin.max",
    "torch_api": "torch.max",
    "mapping_type": "direct",
    "direction": "tvm_to_torch",
    "tvm_pattern": "tvm.script.parser_v1.tir.intrin.max({{a}}, {{b}}, {{span}})",
    "torch_pattern": "torch.max({{input}}, {{other}})",
    "arg_mapping": {
      "a": "input",
      "b": "other",
      "span": null
    },
    "example_pairs": [
      {
        "tvm": "result = tvm.script.parser_v1.tir.intrin.max(x, y)",
        "torch": "result = torch.max(x, y)"
      }
    ],
    "constraints": "`span` argument has no direct PyTorch equivalent. Inputs are assumed to be tensors.",
    "notes": "Performs element-wise maximum of two tensors.",
    "confidence": 0.95
  },
  {
    "tvm_api": "tvm.script.parser_v1.tir.intrin.min",
    "torch_api": "torch.min",
    "mapping_type": "direct",
    "direction": "tvm_to_torch",
    "tvm_pattern": "tvm.script.parser_v1.tir.intrin.min({{a}}, {{b}}, {{span}})",
    "torch_pattern": "torch.min({{input}}, {{other}})",
    "arg_mapping": {
      "a": "input",
      "b": "other",
      "span": null
    },
    "example_pairs": [
      {
        "tvm": "result = tvm.script.parser_v1.tir.intrin.min(x, y)",
        "torch": "result = torch.min(x, y)"
      }
    ],
    "constraints": "`span` argument has no direct PyTorch equivalent. Inputs are assumed to be tensors.",
    "notes": "Performs element-wise minimum of two tensors.",
    "confidence": 0.95
  },
  {
    "tvm_api": "tvm.script.printer.entry.script",
    "torch_api": null,
    "mapping_type": "no_mapping",
    "direction": "tvm_to_torch",
    "tvm_pattern": null,
    "torch_pattern": null,
    "arg_mapping": {},
    "example_pairs": [],
    "constraints": "Not convertible",
    "notes": "NO_MAPPING: TVM's `script` function is used for pretty-printing an IR graph as TVMScript code. PyTorch's `torch.jit.script` is for compiling Python code to TorchScript, which is a different functionality.",
    "confidence": 0.3
  },
  {
    "tvm_api": "tvm.te.autodiff.gradient",
    "torch_api": "torch.autograd.grad",
    "mapping_type": "direct",
    "direction": "tvm_to_torch",
    "tvm_pattern": "tvm.te.autodiff.gradient({{output}}, {{inputs}}, head={{head}})",
    "torch_pattern": "torch.autograd.grad(outputs={{outputs}}, inputs={{inputs}}, grad_outputs={{grad_outputs}})",
    "arg_mapping": {
      "output": "outputs",
      "inputs": "inputs",
      "head": "grad_outputs"
    },
    "example_pairs": [
      {
        "tvm": "grads = tvm.te.autodiff.gradient(out_tensor, [input1, input2], head=head_tensor)",
        "torch": "grads = torch.autograd.grad(outputs=out_tensor, inputs=[input1, input2], grad_outputs=head_tensor)"
      }
    ],
    "constraints": "The `output` tensor must be a scalar or requires `head` (grad_outputs) for non-scalar outputs. Input tensors must have `requires_grad=True`.",
    "notes": "Performs reverse-mode automatic differentiation.",
    "confidence": 0.95
  },
  {
    "tvm_api": "tvm.te.operation.scan",
    "torch_api": "torch.scan",
    "mapping_type": "direct",
    "direction": "tvm_to_torch",
    "tvm_pattern": "tvm.te.operation.scan(init={{init}}, update={{update}}, state_placeholder={{state_placeholder}}, inputs={{inputs}}, name=\"{{name}}\", tag=\"{{tag}}\", attrs={{attrs}})",
    "torch_pattern": "torch.scan(combine_fn={{combine_fn}}, init={{init_state}}, xs={{scanned_inputs}})",
    "arg_mapping": {
      "init": "init_state",
      "update": "combine_fn",
      "state_placeholder": null,
      "inputs": "scanned_inputs",
      "name": null,
      "tag": null,
      "attrs": null
    },
    "example_pairs": [
      {
        "tvm": "outputs = tvm.te.operation.scan(init=initial_state, update=update_fn, state_placeholder=state_var, inputs=input_sequence)",
        "torch": "final_state, outputs = torch.scan(combine_fn=update_fn, init=initial_state, xs=input_sequence)"
      }
    ],
    "constraints": "The `state_placeholder` in TVM typically refers to the symbolic state variable used in the `update` function. In PyTorch `torch.scan`, the `init` argument defines the initial state, and the `combine_fn` handles the state update. TVM's `update` function must be refactored into PyTorch's `combine_fn`. Returns a tuple of (final_state, outputs_sequence) in PyTorch.",
    "notes": "Performs an inclusive scan operation, iterating over a sequence with an initial state and an update function.",
    "confidence": 0.85
  },
  {
    "tvm_api": "tvm.te.operation.var",
    "torch_api": null,
    "mapping_type": "no_mapping",
    "direction": "tvm_to_torch",
    "tvm_pattern": null,
    "torch_pattern": null,
    "arg_mapping": {},
    "example_pairs": [],
    "constraints": "Not convertible",
    "notes": "NO_MAPPING: TVM's `var` creates a symbolic variable (`tvm.tir.Var`) for use in Tensor Expression. PyTorch's `var` functions are for calculating statistical variance of tensors or internal symbolic representations unrelated to TVM's `tir.Var` for computation definition.",
    "confidence": 0.2
  },
  {
    "tvm_api": "tvm.te.hybrid.__init__.script",
    "torch_api": null,
    "mapping_type": "no_mapping",
    "direction": "tvm_to_torch",
    "tvm_pattern": null,
    "torch_pattern": null,
    "arg_mapping": {},
    "example_pairs": [],
    "constraints": "Not convertible",
    "notes": "NO_MAPPING: TVM's `hybrid.script` is a decorator for defining functions in TVM's hybrid script, which compiles to TVM IR. PyTorch's `torch.jit.script` compiles Python functions to TorchScript. While both 'script' functions to an IR, the target IRs and compilation mechanisms are distinct.",
    "confidence": 0.3
  },
  {
    "tvm_api": "tvm.te.hybrid.calls.bind",
    "torch_api": null,
    "mapping_type": "no_mapping",
    "direction": "tvm_to_torch",
    "tvm_pattern": null,
    "torch_pattern": null,
    "arg_mapping": {},
    "example_pairs": [],
    "constraints": "Not convertible",
    "notes": "NO_MAPPING: TVM's `bind` is an internal function for thread binding within TVM's hybrid script, an IR-level optimization directive. PyTorch's candidate `bind` is a utility for functional programming with Optional types, which is unrelated.",
    "confidence": 0.3
  },
  {
    "tvm_api": "tvm.te.hybrid.runtime.rsqrt",
    "torch_api": "torch.rsqrt",
    "mapping_type": "direct",
    "direction": "tvm_to_torch",
    "tvm_pattern": "tvm.te.hybrid.runtime.rsqrt({{x}})",
    "torch_pattern": "torch.rsqrt({{input}})",
    "arg_mapping": {
      "x": "input"
    },
    "example_pairs": [
      {
        "tvm": "result = tvm.te.hybrid.runtime.rsqrt(x)",
        "torch": "result = torch.rsqrt(x)"
      }
    ],
    "constraints": "Input is assumed to be a tensor.",
    "notes": "Computes the reciprocal of the square root element-wise.",
    "confidence": 0.98
  },
  {
    "tvm_api": "tvm.te.hybrid.runtime.sigmoid",
    "torch_api": "torch.sigmoid",
    "mapping_type": "direct",
    "direction": "tvm_to_torch",
    "tvm_pattern": "tvm.te.hybrid.runtime.sigmoid({{x}})",
    "torch_pattern": "torch.sigmoid({{input}})",
    "arg_mapping": {
      "x": "input"
    },
    "example_pairs": [
      {
        "tvm": "result = tvm.te.hybrid.runtime.sigmoid(x)",
        "torch": "result = torch.sigmoid(x)"
      }
    ],
    "constraints": "Input is assumed to be a tensor.",
    "notes": "Computes the element-wise sigmoid function.",
    "confidence": 0.98
  },
  {
    "tvm_api": "tvm.testing.autotvm.matmul",
    "torch_api": "torch.matmul",
    "mapping_type": "direct",
    "direction": "tvm_to_torch",
    "tvm_pattern": "tvm.testing.autotvm.matmul({{N}}, {{L}}, {{M}}, {{dtype}})",
    "torch_pattern": "torch.matmul({{input}}, {{other}})",
    "arg_mapping": {
      "N": null,
      "L": null,
      "M": null,
      "dtype": null,
      "A": "input",
      "B": "other"
    },
    "example_pairs": [
      {
        "tvm": "C = tvm.testing.autotvm.matmul(N, L, M, 'float32')",
        "torch": "C = torch.matmul(A, B)"
      }
    ],
    "constraints": "TVM's `matmul` defines the computation in Tensor Expression. The PyTorch equivalent `torch.matmul` performs the operation on actual tensors `A` and `B` (which would be the placeholders in TVM's definition). Dimensions N, L, M and dtype are part of the *definition* in TVM, but *implicit* in the PyTorch execution.",
    "notes": "Performs matrix multiplication. TVM's function defines the computation, while PyTorch's performs it directly on tensors.",
    "confidence": 0.9
  },
  {
    "tvm_api": "tvm.testing.utils.assert_allclose",
    "torch_api": "torch.testing.assert_allclose",
    "mapping_type": "direct",
    "direction": "tvm_to_torch",
    "tvm_pattern": "tvm.testing.utils.assert_allclose({{actual}}, {{desired}}, rtol={{rtol}}, atol={{atol}})",
    "torch_pattern": "torch.testing.assert_allclose({{actual}}, {{expected}}, rtol={{rtol}}, atol={{atol}})",
    "arg_mapping": {
      "actual": "actual",
      "desired": "expected",
      "rtol": "rtol",
      "atol": "atol"
    },
    "example_pairs": [
      {
        "tvm": "tvm.testing.utils.assert_allclose(actual_val, desired_val, rtol=1e-5, atol=1e-5)",
        "torch": "torch.testing.assert_allclose(actual_val, desired_val, rtol=1e-5, atol=1e-5)"
      }
    ],
    "constraints": "Note that `torch.testing.assert_allclose` is deprecated in favor of `torch.testing.assert_close`.",
    "notes": "Asserts that two tensors or array-like objects are element-wise equal within a tolerance.",
    "confidence": 0.98
  },
  {
    "tvm_api": "tvm.testing.utils.main",
    "torch_api": null,
    "mapping_type": "no_mapping",
    "direction": "tvm_to_torch",
    "tvm_pattern": null,
    "torch_pattern": null,
    "arg_mapping": {},
    "example_pairs": [],
    "constraints": "Not convertible",
    "notes": "NO_MAPPING: TVM's `main` is an entry point for its Pytest-based testing framework. The PyTorch `main` functions are various entry points for internal scripts and are not functionally equivalent to launching a test suite.",
    "confidence": 0.2
  },
  {
    "tvm_api": "tvm.tir.data_layout.layout",
    "torch_api": null,
    "mapping_type": "no_mapping",
    "direction": "tvm_to_torch",
    "tvm_pattern": null,
    "torch_pattern": null,
    "arg_mapping": {},
    "example_pairs": [],
    "constraints": "Not convertible",
    "notes": "NO_MAPPING: TVM's `layout` constructs a symbolic layout object from a string format specific to TVM's IR. PyTorch uses a fixed set of `torch.layout` objects (e.g., `torch.strided`, `torch.sparse_coo`) and does not support arbitrary string-based layout definitions from a user-facing API.",
    "confidence": 0.3
  },
  {
    "tvm_api": "tvm.tir.generic.add",
    "torch_api": "torch.add",
    "mapping_type": "direct",
    "direction": "tvm_to_torch",
    "tvm_pattern": "tvm.tir.generic.add({{lhs}}, {{rhs}}, {{span}})",
    "torch_pattern": "torch.add({{input}}, {{other}})",
    "arg_mapping": {
      "lhs": "input",
      "rhs": "other",
      "span": null
    },
    "example_pairs": [
      {
        "tvm": "result = tvm.tir.generic.add(x, y)",
        "torch": "result = torch.add(x, y)"
      }
    ],
    "constraints": "`span` argument has no direct PyTorch equivalent. Inputs are assumed to be tensors.",
    "notes": "Performs element-wise addition. PyTorch's `torch.add` supports broadcasting.",
    "confidence": 0.98
  },
  {
    "tvm_api": "tvm.tir.generic.floordiv",
    "torch_api": "torch.floor_divide",
    "mapping_type": "direct",
    "direction": "tvm_to_torch",
    "tvm_pattern": "tvm.tir.generic.floordiv({{lhs}}, {{rhs}}, {{span}})",
    "torch_pattern": "torch.floor_divide({{input}}, {{other}})",
    "arg_mapping": {
      "lhs": "input",
      "rhs": "other",
      "span": null
    },
    "example_pairs": [
      {
        "tvm": "result = tvm.tir.generic.floordiv(a, b)",
        "torch": "result = torch.floor_divide(a, b)"
      }
    ],
    "constraints": "`span` argument has no direct PyTorch equivalent. Inputs are assumed to be tensors.",
    "notes": "Performs element-wise floor division.",
    "confidence": 0.95
  },
  {
    "tvm_api": "tvm.tir.op.any",
    "torch_api": "torch.logical_or",
    "mapping_type": "composite",
    "direction": "tvm_to_torch",
    "tvm_pattern": "tvm.tir.op.any({{args_list}}, span={{span}})",
    "torch_pattern": "functools.reduce(torch.logical_or, {{args_list}})",
    "arg_mapping": {
      "args_list": "args_list",
      "span": null
    },
    "example_pairs": [
      {
        "tvm": "result = tvm.tir.op.any(cond1, cond2, cond3)",
        "torch": "import functools\nresult = functools.reduce(torch.logical_or, [cond1, cond2, cond3])"
      }
    ],
    "constraints": "`span` argument has no direct PyTorch equivalent. Assumes `args` are boolean tensors. For a single argument, `torch.any(arg)` would reduce the tensor to a scalar boolean.",
    "notes": "TVM's `any(*args)` creates a new expression representing the logical OR of all argument expressions. In PyTorch, this is achieved by iteratively applying `torch.logical_or` to multiple boolean tensors.",
    "confidence": 0.85
  },
  {
    "tvm_api": "tvm.tir.op.all",
    "torch_api": "torch.logical_and",
    "mapping_type": "composite",
    "direction": "tvm_to_torch",
    "tvm_pattern": "tvm.tir.op.all({{args_list}}, span={{span}})",
    "torch_pattern": "functools.reduce(torch.logical_and, {{args_list}})",
    "arg_mapping": {
      "args_list": "args_list",
      "span": null
    },
    "example_pairs": [
      {
        "tvm": "result = tvm.tir.op.all(cond1, cond2)",
        "torch": "import functools\nresult = functools.reduce(torch.logical_and, [cond1, cond2])"
      }
    ],
    "constraints": "`span` argument has no direct PyTorch equivalent. Assumes `args` are boolean tensors. For a single argument, `torch.all(arg)` would reduce the tensor to a scalar boolean.",
    "notes": "TVM's `all(*args)` creates a new expression representing the logical AND of all argument expressions. In PyTorch, this is achieved by iteratively applying `torch.logical_and` to multiple boolean tensors.",
    "confidence": 0.85
  },
  {
    "tvm_api": "tvm.tir.op.trace",
    "torch_api": null,
    "mapping_type": "no_mapping",
    "direction": "tvm_to_torch",
    "tvm_pattern": null,
    "torch_pattern": null,
    "arg_mapping": {},
    "example_pairs": [],
    "constraints": "Not convertible",
    "notes": "NO_MAPPING: TVM's `trace` is for runtime observation/debugging of tensor data. PyTorch's `trace` functions calculate the mathematical trace of a matrix (sum of diagonal elements), which is a different functionality.",
    "confidence": 0.2
  },
  {
    "tvm_api": "tvm.tir.op.exp",
    "torch_api": "torch.exp",
    "mapping_type": "direct",
    "direction": "tvm_to_torch",
    "tvm_pattern": "tvm.tir.op.exp({{x}})",
    "torch_pattern": "torch.exp({{input}})",
    "arg_mapping": {
      "x": "input"
    },
    "example_pairs": [
      {
        "tvm": "result = tvm.tir.op.exp(x)",
        "torch": "result = torch.exp(x)"
      }
    ],
    "constraints": "Input is assumed to be a tensor.",
    "notes": "Computes the element-wise exponential function.",
    "confidence": 0.98
  },
  {
    "tvm_api": "tvm.tir.op.erf",
    "torch_api": "torch.special.erf",
    "mapping_type": "direct",
    "direction": "tvm_to_torch",
    "tvm_pattern": "tvm.tir.op.erf({{x}})",
    "torch_pattern": "torch.special.erf({{input}})",
    "arg_mapping": {
      "x": "input"
    },
    "example_pairs": [
      {
        "tvm": "result = tvm.tir.op.erf(x)",
        "torch": "result = torch.special.erf(x)"
      }
    ],
    "constraints": "Input is assumed to be a tensor.",
    "notes": "Computes the element-wise Gauss error function.",
    "confidence": 0.98
  },
  {
    "tvm_api": "tvm.tir.op.tanh",
    "torch_api": "torch.tanh",
    "mapping_type": "direct",
    "direction": "tvm_to_torch",
    "tvm_pattern": "tvm.tir.op.tanh({{x}})",
    "torch_pattern": "torch.tanh({{input}})",
    "arg_mapping": {
      "x": "input"
    },
    "example_pairs": [
      {
        "tvm": "result = tvm.tir.op.tanh(x)",
        "torch": "result = torch.tanh(x)"
      }
    ],
    "constraints": "Input is assumed to be a tensor.",
    "notes": "Computes the element-wise hyperbolic tangent function.",
    "confidence": 0.98
  },
  {
    "tvm_api": "tvm.tir.op.sigmoid",
    "torch_api": "torch.sigmoid",
    "mapping_type": "direct",
    "direction": "tvm_to_torch",
    "tvm_pattern": "tvm.tir.op.sigmoid({{x}})",
    "torch_pattern": "torch.sigmoid({{input}})",
    "arg_mapping": {
      "x": "input"
    },
    "example_pairs": [
      {
        "tvm": "result = tvm.tir.op.sigmoid(x)",
        "torch": "result = torch.sigmoid(x)"
      }
    ],
    "constraints": "Input is assumed to be a tensor.",
    "notes": "Computes the element-wise sigmoid function.",
    "confidence": 0.98
  },
  {
    "tvm_api": "tvm.tir.op.log",
    "torch_api": "torch.log",
    "mapping_type": "direct",
    "direction": "tvm_to_torch",
    "tvm_pattern": "tvm.tir.op.log({{x}})",
    "torch_pattern": "torch.log({{input}})",
    "arg_mapping": {
      "x": "input"
    },
    "example_pairs": [
      {
        "tvm": "result = tvm.tir.op.log(x)",
        "torch": "result = torch.log(x)"
      }
    ],
    "constraints": "Input is assumed to be a tensor.",
    "notes": "Computes the element-wise natural logarithm.",
    "confidence": 0.98
  },
  {
    "tvm_api": "tvm.tir.op.log2",
    "torch_api": "torch.log2",
    "mapping_type": "direct",
    "direction": "tvm_to_torch",
    "tvm_pattern": "tvm.tir.op.log2({{x}})",
    "torch_pattern": "torch.log2({{input}})",
    "arg_mapping": {
      "x": "input"
    },
    "example_pairs": [
      {
        "tvm": "result = tvm.tir.op.log2(x)",
        "torch": "result = torch.log2(x)"
      }
    ],
    "constraints": "Input is assumed to be a tensor.",
    "notes": "Computes the element-wise base-2 logarithm.",
    "confidence": 0.98
  },
  {
    "tvm_api": "tvm.tir.op.sqrt",
    "torch_api": "torch.sqrt",
    "mapping_type": "direct",
    "direction": "tvm_to_torch",
    "tvm_pattern": "tvm.tir.op.sqrt({{x}})",
    "torch_pattern": "torch.sqrt({{input}})",
    "arg_mapping": {
      "x": "input"
    },
    "example_pairs": [
      {
        "tvm": "result = tvm.tir.op.sqrt(x)",
        "torch": "result = torch.sqrt(x)"
      }
    ],
    "constraints": "Input is assumed to be a tensor.",
    "notes": "Computes the element-wise square root.",
    "confidence": 0.98
  },
  {
    "tvm_api": "tvm.tir.op.rsqrt",
    "torch_api": "torch.rsqrt",
    "mapping_type": "direct",
    "direction": "tvm_to_torch",
    "tvm_pattern": "tvm.tir.op.rsqrt({{x}})",
    "torch_pattern": "torch.rsqrt({{input}})",
    "arg_mapping": {
      "x": "input"
    },
    "example_pairs": [
      {
        "tvm": "result = tvm.tir.op.rsqrt(x)",
        "torch": "result = torch.rsqrt(x)"
      }
    ],
    "constraints": "Input is assumed to be a tensor.",
    "notes": "Computes the element-wise reciprocal of the square root.",
    "confidence": 0.98
  },
  {
    "tvm_api": "tvm.tir.op.floor",
    "torch_api": "torch.floor",
    "mapping_type": "direct",
    "direction": "tvm_to_torch",
    "tvm_pattern": "tvm.tir.op.floor({{x}}, span={{span}})",
    "torch_pattern": "torch.floor({{input}})",
    "arg_mapping": {
      "x": "input",
      "span": null
    },
    "example_pairs": [
      {
        "tvm": "result = tvm.tir.op.floor(x)",
        "torch": "result = torch.floor(x)"
      }
    ],
    "constraints": "`span` argument has no direct PyTorch equivalent. Input is assumed to be a tensor.",
    "notes": "Computes the element-wise floor of the input.",
    "confidence": 0.98
  },
  {
    "tvm_api": "tvm.tir.op.ceil",
    "torch_api": "torch.ceil",
    "mapping_type": "direct",
    "direction": "tvm_to_torch",
    "tvm_pattern": "tvm.tir.op.ceil({{x}}, span={{span}})",
    "torch_pattern": "torch.ceil({{input}})",
    "arg_mapping": {
      "x": "input",
      "span": null
    },
    "example_pairs": [
      {
        "tvm": "result = tvm.tir.op.ceil(x)",
        "torch": "result = torch.ceil(x)"
      }
    ],
    "constraints": "`span` argument has no direct PyTorch equivalent. Input is assumed to be a tensor.",
    "notes": "Computes the element-wise ceiling of the input.",
    "confidence": 0.98
  },
  {
    "tvm_api": "tvm.tir.op.trunc",
    "torch_api": "torch.trunc",
    "mapping_type": "direct",
    "direction": "tvm_to_torch",
    "tvm_pattern": "tvm.tir.op.trunc({{x}}, span={{span}})",
    "torch_pattern": "torch.trunc({{input}})",
    "arg_mapping": {
      "x": "input",
      "span": null
    },
    "example_pairs": [
      {
        "tvm": "result = tvm.tir.op.trunc(x)",
        "torch": "result = torch.trunc(x)"
      }
    ],
    "constraints": "`span` argument has no direct PyTorch equivalent. Input is assumed to be a tensor.",
    "notes": "Computes the element-wise truncated value of the input (rounds towards zero).",
    "confidence": 0.98
  },
  {
    "tvm_api": "tvm.tir.op.abs",
    "torch_api": "torch.abs",
    "mapping_type": "direct",
    "direction": "tvm_to_torch",
    "tvm_pattern": "tvm.tir.op.abs({{x}}, span={{span}})",
    "torch_pattern": "torch.abs({{input}})",
    "arg_mapping": {
      "x": "input",
      "span": null
    },
    "example_pairs": [
      {
        "tvm": "result = tvm.tir.op.abs(x)",
        "torch": "result = torch.abs(x)"
      }
    ],
    "constraints": "`span` argument has no direct PyTorch equivalent. Input is assumed to be a tensor.",
    "notes": "Computes the element-wise absolute value.",
    "confidence": 0.98
  },
  {
    "tvm_api": "tvm.tir.op.round",
    "torch_api": "torch.round",
    "mapping_type": "direct",
    "direction": "tvm_to_torch",
    "tvm_pattern": "tvm.tir.op.round({{x}}, span={{span}})",
    "torch_pattern": "torch.round({{input}})",
    "arg_mapping": {
      "x": "input",
      "span": null
    },
    "example_pairs": [
      {
        "tvm": "result = tvm.tir.op.round(x)",
        "torch": "result = torch.round(x)"
      }
    ],
    "constraints": "`span` argument has no direct PyTorch equivalent. Input is assumed to be a tensor.",
    "notes": "Computes the element-wise rounded value of the input (to the nearest integer).",
    "confidence": 0.98
  },
  {
    "tvm_api": "tvm.tir.op.ldexp",
    "torch_api": "torch.ldexp",
    "mapping_type": "direct",
    "direction": "tvm_to_torch",
    "tvm_pattern": "tvm.tir.op.ldexp({{x1}}, {{x2}})",
    "torch_pattern": "torch.ldexp({{input}}, {{other}})",
    "arg_mapping": {
      "x1": "input",
      "x2": "other"
    },
    "example_pairs": [
      {
        "tvm": "result = tvm.tir.op.ldexp(x, y)",
        "torch": "result = torch.ldexp(x, y)"
      }
    ],
    "constraints": "Inputs are assumed to be tensors.",
    "notes": "Computes element-wise `input * (2 ** other)`.",
    "confidence": 0.98
  },
  {
    "tvm_api": "tvm.tir.op.isnan",
    "torch_api": "torch.isnan",
    "mapping_type": "direct",
    "direction": "tvm_to_torch",
    "tvm_pattern": "tvm.tir.op.isnan({{x}}, span={{span}})",
    "torch_pattern": "torch.isnan({{input}})",
    "arg_mapping": {
      "x": "input",
      "span": null
    },
    "example_pairs": [
      {
        "tvm": "result = tvm.tir.op.isnan(x)",
        "torch": "result = torch.isnan(x)"
      }
    ],
    "constraints": "`span` argument has no direct PyTorch equivalent. Input is assumed to be a tensor.",
    "notes": "Checks element-wise if values are NaN.",
    "confidence": 0.98
  },
  {
    "tvm_api": "tvm.tir.op.fmod",
    "torch_api": "torch.fmod",
    "mapping_type": "direct",
    "direction": "tvm_to_torch",
    "tvm_pattern": "tvm.tir.op.fmod({{x}}, {{y}})",
    "torch_pattern": "torch.fmod({{input}}, {{other}})",
    "arg_mapping": {
      "x": "input",
      "y": "other"
    },
    "example_pairs": [
      {
        "tvm": "result = tvm.tir.op.fmod(x, y)",
        "torch": "result = torch.fmod(x, y)"
      }
    ],
    "constraints": "Inputs are assumed to be tensors.",
    "notes": "Computes the element-wise remainder of division, with the same sign as the dividend `x`.",
    "confidence": 0.98
  },
  {
    "tvm_api": "tvm.tir.op.div",
    "torch_api": "torch.div",
    "mapping_type": "direct",
    "direction": "tvm_to_torch",
    "tvm_pattern": "tvm.tir.op.div({{a}}, {{b}}, span={{span}})",
    "torch_pattern": "torch.div({{input}}, {{other}}, rounding_mode='trunc')",
    "arg_mapping": {
      "a": "input",
      "b": "other",
      "span": null
    },
    "example_pairs": [
      {
        "tvm": "result = tvm.tir.op.div(x, y)",
        "torch": "result = torch.div(x, y, rounding_mode='trunc')"
      }
    ],
    "constraints": "`span` argument has no direct PyTorch equivalent. Inputs are assumed to be tensors. PyTorch's `div` with `rounding_mode='trunc'` emulates C/C++ integer division semantics.",
    "notes": "Performs element-wise division with truncation towards zero for integer inputs.",
    "confidence": 0.95
  },
  {
    "tvm_api": "tvm.tir.op.truncdiv",
    "torch_api": "torch.div",
    "mapping_type": "direct",
    "direction": "tvm_to_torch",
    "tvm_pattern": "tvm.tir.op.truncdiv({{a}}, {{b}}, span={{span}})",
    "torch_pattern": "torch.div({{input}}, {{other}}, rounding_mode='trunc')",
    "arg_mapping": {
      "a": "input",
      "b": "other",
      "span": null
    },
    "example_pairs": [
      {
        "tvm": "result = tvm.tir.op.truncdiv(x, y)",
        "torch": "result = torch.div(x, y, rounding_mode='trunc')"
      }
    ],
    "constraints": "`span` argument has no direct PyTorch equivalent. Inputs are assumed to be tensors.",
    "notes": "Performs element-wise truncated division (division that rounds towards zero). Identical to `tvm.tir.op.div` with C/C++ semantics.",
    "confidence": 0.95
  },
  {
    "tvm_api": "tvm.tir.op.floordiv",
    "torch_api": "torch.floor_divide",
    "mapping_type": "direct",
    "direction": "tvm_to_torch",
    "tvm_pattern": "tvm.tir.op.floordiv({{a}}, {{b}}, span={{span}})",
    "torch_pattern": "torch.floor_divide({{input}}, {{other}})",
    "arg_mapping": {
      "a": "input",
      "b": "other",
      "span": null
    },
    "example_pairs": [
      {
        "tvm": "result = tvm.tir.op.floordiv(x, y)",
        "torch": "result = torch.floor_divide(x, y)"
      }
    ],
    "constraints": "`span` argument has no direct PyTorch equivalent. Inputs are assumed to be tensors.",
    "notes": "Performs element-wise floor division (division that rounds down to the nearest integer).",
    "confidence": 0.95
  },
  {
    "tvm_api": "tvm.tir.op.ceildiv",
    "torch_api": [
      "torch.ceil",
      "torch.div"
    ],
    "mapping_type": "composite",
    "direction": "tvm_to_torch",
    "tvm_pattern": "tvm.tir.op.ceildiv({{lhs}}, {{rhs}}, span={{span}})",
    "torch_pattern": "torch.ceil(torch.div({{input}}, {{other}}))",
    "arg_mapping": {
      "lhs": "input",
      "rhs": "other",
      "span": null
    },
    "example_pairs": [
      {
        "tvm": "result = tvm.tir.op.ceildiv(a, b)",
        "torch": "result = torch.ceil(torch.div(a, b))"
      }
    ],
    "constraints": "`span` argument has no direct PyTorch equivalent. Inputs are assumed to be tensors.",
    "notes": "Performs element-wise ceiling division using a combination of `torch.div` and `torch.ceil`.",
    "confidence": 0.9
  },
  {
    "tvm_api": "tvm.topi.argwhere.argwhere",
    "torch_api": "torch.argwhere",
    "mapping_type": "direct",
    "direction": "tvm_to_torch",
    "tvm_pattern": "tvm.topi.argwhere.argwhere({{output_shape}}, {{condition}})",
    "torch_pattern": "torch.argwhere({{input}})",
    "arg_mapping": {
      "output_shape": null,
      "condition": "input"
    },
    "example_pairs": [
      {
        "tvm": "indices = tvm.topi.argwhere(output_shape, boolean_tensor)",
        "torch": "indices = torch.argwhere(boolean_tensor)"
      }
    ],
    "constraints": "`output_shape` in TVM is for the shape of the result indices; `torch.argwhere` directly computes and returns the indices, so `output_shape` is not directly mapped as an argument.",
    "notes": "Finds the indices of elements that are non-zero (or True) in a tensor. The result shape is implicitly determined by the input in PyTorch.",
    "confidence": 0.95
  },
  {
    "tvm_api": "tvm.topi.broadcast.broadcast_to",
    "torch_api": "torch.broadcast_to",
    "mapping_type": "direct",
    "direction": "tvm_to_torch",
    "tvm_pattern": "tvm.topi.broadcast.broadcast_to({{data}}, {{shape}})",
    "torch_pattern": "torch.broadcast_to({{input}}, {{size}})",
    "arg_mapping": {
      "data": "input",
      "shape": "size"
    },
    "example_pairs": [
      {
        "tvm": "b_tensor = tvm.topi.broadcast.broadcast_to(original_tensor, new_shape)",
        "torch": "b_tensor = torch.broadcast_to(original_tensor, new_shape)"
      }
    ],
    "constraints": "Input `data` must be broadcastable to `shape` according to NumPy-like broadcasting rules.",
    "notes": "Broadcasts an input tensor to a specified target shape.",
    "confidence": 0.98
  },
  {
    "tvm_api": "tvm.topi.broadcast.add",
    "torch_api": "torch.add",
    "mapping_type": "direct",
    "direction": "tvm_to_torch",
    "tvm_pattern": "tvm.topi.broadcast.add({{lhs}}, {{rhs}})",
    "torch_pattern": "torch.add({{input}}, {{other}})",
    "arg_mapping": {
      "lhs": "input",
      "rhs": "other"
    },
    "example_pairs": [
      {
        "tvm": "result = tvm.topi.broadcast.add(x, y)",
        "torch": "result = torch.add(x, y)"
      }
    ],
    "constraints": "Inputs are assumed to be tensors.",
    "notes": "Performs element-wise addition with broadcasting.",
    "confidence": 0.98
  },
  {
    "tvm_api": "tvm.topi.broadcast.maximum",
    "torch_api": "torch.maximum",
    "mapping_type": "direct",
    "direction": "tvm_to_torch",
    "tvm_pattern": "tvm.topi.broadcast.maximum({{lhs}}, {{rhs}})",
    "torch_pattern": "torch.maximum({{input}}, {{other}})",
    "arg_mapping": {
      "lhs": "input",
      "rhs": "other"
    },
    "example_pairs": [
      {
        "tvm": "result = tvm.topi.broadcast.maximum(x, y)",
        "torch": "result = torch.maximum(x, y)"
      }
    ],
    "constraints": "Inputs are assumed to be tensors.",
    "notes": "Performs element-wise maximum of two tensors with broadcasting.",
    "confidence": 0.98
  },
  {
    "tvm_api": "tvm.topi.broadcast.minimum",
    "torch_api": "torch.minimum",
    "mapping_type": "direct",
    "direction": "tvm_to_torch",
    "tvm_pattern": "tvm.topi.broadcast.minimum({{lhs}}, {{rhs}})",
    "torch_pattern": "torch.minimum({{input}}, {{other}})",
    "arg_mapping": {
      "lhs": "input",
      "rhs": "other"
    },
    "example_pairs": [
      {
        "tvm": "result = tvm.topi.broadcast.minimum(x, y)",
        "torch": "result = torch.minimum(x, y)"
      }
    ],
    "constraints": "Inputs are assumed to be tensors.",
    "notes": "Performs element-wise minimum of two tensors with broadcasting.",
    "confidence": 0.98
  },
  {
    "tvm_api": "tvm.topi.broadcast.equal",
    "torch_api": "torch.eq",
    "mapping_type": "direct",
    "direction": "tvm_to_torch",
    "tvm_pattern": "tvm.topi.broadcast.equal({{lhs}}, {{rhs}})",
    "torch_pattern": "torch.eq({{input}}, {{other}})",
    "arg_mapping": {
      "lhs": "input",
      "rhs": "other"
    },
    "example_pairs": [
      {
        "tvm": "result = tvm.topi.broadcast.equal(x, y)",
        "torch": "result = torch.eq(x, y)"
      }
    ],
    "constraints": "Inputs are assumed to be tensors. `torch.eq` performs element-wise comparison, returning a boolean tensor, which aligns with 'compute (lhs==rhs) with auto-broadcasting'. Note this is different from `torch.equal` which returns a single boolean.",
    "notes": "Performs element-wise equality comparison with broadcasting.",
    "confidence": 0.98
  },
  {
    "tvm_api": "tvm.topi.broadcast.logical_or",
    "torch_api": "torch.logical_or",
    "mapping_type": "direct",
    "direction": "tvm_to_torch",
    "tvm_pattern": "tvm.topi.broadcast.logical_or({{lhs}}, {{rhs}})",
    "torch_pattern": "torch.logical_or({{input}}, {{other}})",
    "arg_mapping": {
      "lhs": "input",
      "rhs": "other"
    },
    "example_pairs": [
      {
        "tvm": "result = tvm.topi.broadcast.logical_or(x, y)",
        "torch": "result = torch.logical_or(x, y)"
      }
    ],
    "constraints": "Inputs are assumed to be boolean tensors or tensors that can be cast to boolean.",
    "notes": "Performs element-wise logical OR with broadcasting.",
    "confidence": 0.98
  },
  {
    "tvm_api": "tvm.topi.einsum.einsum",
    "torch_api": "torch.einsum",
    "mapping_type": "direct",
    "direction": "tvm_to_torch",
    "tvm_pattern": "tvm.topi.einsum.einsum(\"{{subscripts}}\", ({{operands_tuple}}))",
    "torch_pattern": "torch.einsum(\"{{equation}}\", {{operands_varargs}})",
    "arg_mapping": {
      "subscripts": "equation",
      "operands_tuple": "operands_varargs"
    },
    "example_pairs": [
      {
        "tvm": "result = tvm.topi.einsum(\"ij,jk->ik\", (A, B))",
        "torch": "result = torch.einsum(\"ij,jk->ik\", A, B)"
      }
    ],
    "constraints": "TVM expects operands as a tuple `(A, B)`, while PyTorch takes them as variadic arguments `A, B`. This difference is handled in `torch_pattern` and `arg_mapping`.",
    "notes": "Evaluates the Einstein summation convention on the operands.",
    "confidence": 0.98
  },
  {
    "tvm_api": "tvm.topi.math.identity",
    "torch_api": null,
    "mapping_type": "no_mapping",
    "direction": "tvm_to_torch",
    "tvm_pattern": null,
    "torch_pattern": null,
    "arg_mapping": {},
    "example_pairs": [],
    "constraints": "Not convertible",
    "notes": "NO_MAPPING: TVM's `identity` is a computation that simply returns its input, effectively a no-op at the tensor level. PyTorch typically handles this by directly using the tensor variable (e.g., `y = x`). The PyTorch candidates are for creating identity matrices or internal utilities, not a general tensor 'identity' computation.",
    "confidence": 0.3
  },
  {
    "tvm_api": "tvm.topi.math.exp",
    "torch_api": "torch.exp",
    "mapping_type": "direct",
    "direction": "tvm_to_torch",
    "tvm_pattern": "tvm.topi.math.exp({{x}})",
    "torch_pattern": "torch.exp({{input}})",
    "arg_mapping": {
      "x": "input"
    },
    "example_pairs": [
      {
        "tvm": "result = tvm.topi.math.exp(x)",
        "torch": "result = torch.exp(x)"
      }
    ],
    "constraints": "Input is assumed to be a tensor.",
    "notes": "Computes the element-wise exponential function.",
    "confidence": 0.98
  },
  {
    "tvm_api": "tvm.topi.math.erf",
    "torch_api": "torch.special.erf",
    "mapping_type": "direct",
    "direction": "tvm_to_torch",
    "tvm_pattern": "tvm.topi.math.erf({{x}})",
    "torch_pattern": "torch.special.erf({{input}})",
    "arg_mapping": {
      "x": "input"
    },
    "example_pairs": [
      {
        "tvm": "result = tvm.topi.math.erf(x)",
        "torch": "result = torch.special.erf(x)"
      }
    ],
    "constraints": "Input is assumed to be a tensor.",
    "notes": "Computes the element-wise Gauss error function.",
    "confidence": 0.98
  },
  {
    "tvm_api": "tvm.topi.math.tanh",
    "torch_api": "torch.tanh",
    "mapping_type": "direct",
    "direction": "tvm_to_torch",
    "tvm_pattern": "tvm.topi.math.tanh({{x}})",
    "torch_pattern": "torch.tanh({{input}})",
    "arg_mapping": {
      "x": "input"
    },
    "example_pairs": [
      {
        "tvm": "result = tvm.topi.math.tanh(x)",
        "torch": "result = torch.tanh(x)"
      }
    ],
    "constraints": "Input is assumed to be a tensor.",
    "notes": "Computes the element-wise hyperbolic tangent function.",
    "confidence": 0.98
  },
  {
    "tvm_api": "tvm.topi.math.floor",
    "torch_api": "torch.floor",
    "mapping_type": "direct",
    "direction": "tvm_to_torch",
    "tvm_pattern": "tvm.topi.math.floor({{x}})",
    "torch_pattern": "torch.floor({{input}})",
    "arg_mapping": {
      "x": "input"
    },
    "example_pairs": [
      {
        "tvm": "result = tvm.topi.math.floor(x)",
        "torch": "result = torch.floor(x)"
      }
    ],
    "constraints": "Input is assumed to be a tensor.",
    "notes": "Computes the element-wise floor of the input.",
    "confidence": 0.98
  },
  {
    "tvm_api": "tvm.topi.math.ceil",
    "torch_api": "torch.ceil",
    "mapping_type": "direct",
    "direction": "tvm_to_torch",
    "tvm_pattern": "tvm.topi.math.ceil({{x}})",
    "torch_pattern": "torch.ceil({{input}})",
    "arg_mapping": {
      "x": "input"
    },
    "example_pairs": [
      {
        "tvm": "result = tvm.topi.math.ceil(x)",
        "torch": "result = torch.ceil(x)"
      }
    ],
    "constraints": "Input is assumed to be a tensor.",
    "notes": "Computes the element-wise ceiling of the input.",
    "confidence": 0.98
  },
  {
    "tvm_api": "tvm.topi.math.trunc",
    "torch_api": "torch.trunc",
    "mapping_type": "direct",
    "direction": "tvm_to_torch",
    "tvm_pattern": "tvm.topi.math.trunc({{x}})",
    "torch_pattern": "torch.trunc({{input}})",
    "arg_mapping": {
      "x": "input"
    },
    "example_pairs": [
      {
        "tvm": "result = tvm.topi.math.trunc(x)",
        "torch": "result = torch.trunc(x)"
      }
    ],
    "constraints": "Input is assumed to be a tensor.",
    "notes": "Computes the element-wise truncated value of the input (rounds towards zero).",
    "confidence": 0.98
  },
  {
    "tvm_api": "tvm.topi.math.abs",
    "torch_api": "torch.abs",
    "mapping_type": "direct",
    "direction": "tvm_to_torch",
    "tvm_pattern": "tvm.topi.math.abs({{x}})",
    "torch_pattern": "torch.abs({{input}})",
    "arg_mapping": {
      "x": "input"
    },
    "example_pairs": [
      {
        "tvm": "result = tvm.topi.math.abs(x)",
        "torch": "result = torch.abs(x)"
      }
    ],
    "constraints": "Input is assumed to be a tensor.",
    "notes": "Computes the element-wise absolute value.",
    "confidence": 0.98
  },
  {
    "tvm_api": "tvm.topi.math.isnan",
    "torch_api": "torch.isnan",
    "mapping_type": "direct",
    "direction": "tvm_to_torch",
    "tvm_pattern": "tvm.topi.math.isnan({{x}})",
    "torch_pattern": "torch.isnan({{input}})",
    "arg_mapping": {
      "x": "input"
    },
    "example_pairs": [
      {
        "tvm": "result = tvm.topi.math.isnan(x)",
        "torch": "result = torch.isnan(x)"
      }
    ],
    "constraints": "Input is assumed to be a tensor.",
    "notes": "Checks element-wise if values are NaN.",
    "confidence": 0.98
  },
  {
    "tvm_api": "tvm.topi.math.round",
    "torch_api": "torch.round",
    "mapping_type": "direct",
    "direction": "tvm_to_torch",
    "tvm_pattern": "tvm.topi.math.round({{x}})",
    "torch_pattern": "torch.round({{input}})",
    "arg_mapping": {
      "x": "input"
    },
    "example_pairs": [
      {
        "tvm": "result = tvm.topi.math.round(x)",
        "torch": "result = torch.round(x)"
      }
    ],
    "constraints": "Input is assumed to be a tensor.",
    "notes": "Computes the element-wise rounded value of the input (to the nearest integer).",
    "confidence": 0.98
  },
  {
    "tvm_api": "tvm.topi.math.log",
    "torch_api": "torch.log",
    "mapping_type": "direct",
    "direction": "tvm_to_torch",
    "tvm_pattern": "tvm.topi.math.log({{x}})",
    "torch_pattern": "torch.log({{x}})",
    "arg_mapping": {
      "x": "x"
    },
    "example_pairs": [
      {
        "tvm": "y = tvm.topi.math.log(x)",
        "torch": "y = torch.log(x)"
      }
    ],
    "constraints": "Applies element-wise logarithm to the input tensor. Similar to `x.log()` method.",
    "notes": "Direct element-wise logarithm. PyTorch's `torch.log` operates similarly to NumPy's `np.log`.",
    "confidence": 0.98
  },
  {
    "tvm_api": "tvm.topi.math.log2",
    "torch_api": "torch.log2",
    "mapping_type": "direct",
    "direction": "tvm_to_torch",
    "tvm_pattern": "tvm.topi.math.log2({{x}})",
    "torch_pattern": "torch.log2({{x}})",
    "arg_mapping": {
      "x": "x"
    },
    "example_pairs": [
      {
        "tvm": "y = tvm.topi.math.log2(x)",
        "torch": "y = torch.log2(x)"
      }
    ],
    "constraints": "Applies element-wise base-2 logarithm to the input tensor. Similar to `x.log2()` method.",
    "notes": "Direct element-wise base-2 logarithm. PyTorch's `torch.log2` operates similarly to NumPy's `np.log2`.",
    "confidence": 0.98
  },
  {
    "tvm_api": "tvm.topi.math.sqrt",
    "torch_api": "torch.sqrt",
    "mapping_type": "direct",
    "direction": "tvm_to_torch",
    "tvm_pattern": "tvm.topi.math.sqrt({{x}})",
    "torch_pattern": "torch.sqrt({{x}})",
    "arg_mapping": {
      "x": "x"
    },
    "example_pairs": [
      {
        "tvm": "y = tvm.topi.math.sqrt(x)",
        "torch": "y = torch.sqrt(x)"
      }
    ],
    "constraints": "Applies element-wise square root to the input tensor. Similar to `x.sqrt()` method.",
    "notes": "Direct element-wise square root. PyTorch's `torch.sqrt` operates similarly to NumPy's `np.sqrt`.",
    "confidence": 0.98
  },
  {
    "tvm_api": "tvm.topi.math.rsqrt",
    "torch_api": "torch.rsqrt",
    "mapping_type": "direct",
    "direction": "tvm_to_torch",
    "tvm_pattern": "tvm.topi.math.rsqrt({{x}})",
    "torch_pattern": "torch.rsqrt({{x}})",
    "arg_mapping": {
      "x": "x"
    },
    "example_pairs": [
      {
        "tvm": "y = tvm.topi.math.rsqrt(x)",
        "torch": "y = torch.rsqrt(x)"
      }
    ],
    "constraints": "Applies element-wise reciprocal square root to the input tensor. Similar to `x.rsqrt()` method.",
    "notes": "Direct element-wise reciprocal square root. PyTorch's `torch.rsqrt` operates similarly to NumPy's `np.rsqrt`.",
    "confidence": 0.98
  },
  {
    "tvm_api": "tvm.topi.math.sigmoid",
    "torch_api": "torch.sigmoid",
    "mapping_type": "direct",
    "direction": "tvm_to_torch",
    "tvm_pattern": "tvm.topi.math.sigmoid({{x}})",
    "torch_pattern": "torch.sigmoid({{x}})",
    "arg_mapping": {
      "x": "x"
    },
    "example_pairs": [
      {
        "tvm": "y = tvm.topi.math.sigmoid(x)",
        "torch": "y = torch.sigmoid(x)"
      }
    ],
    "constraints": "Applies element-wise sigmoid function to the input tensor. Similar to `x.sigmoid()` method.",
    "notes": "Direct element-wise sigmoid. PyTorch's `torch.sigmoid` operates similarly to NumPy's `expit`.",
    "confidence": 0.98
  },
  {
    "tvm_api": "tvm.topi.math.clip",
    "torch_api": "torch.clamp",
    "mapping_type": "direct",
    "direction": "tvm_to_torch",
    "tvm_pattern": "tvm.topi.math.clip({{x}}, {{a_min}}, {{a_max}})",
    "torch_pattern": "torch.clamp({{x}}, min={{a_min}}, max={{a_max}})",
    "arg_mapping": {
      "x": "x",
      "a_min": "a_min",
      "a_max": "a_max"
    },
    "example_pairs": [
      {
        "tvm": "y = tvm.topi.math.clip(x, 0.0, 1.0)",
        "torch": "y = torch.clamp(x, min=0.0, max=1.0)"
      }
    ],
    "constraints": "Maps to `torch.clamp` which performs clipping. Arguments `min` and `max` must be provided.",
    "notes": "PyTorch's `torch.clamp` directly implements the clipping functionality.",
    "confidence": 0.98
  },
  {
    "tvm_api": "tvm.topi.reduction.sum",
    "torch_api": "torch.sum",
    "mapping_type": "direct",
    "direction": "tvm_to_torch",
    "tvm_pattern": "tvm.topi.reduction.sum({{data}}, axis={{axis}}, keepdims={{keepdims}})",
    "torch_pattern": "torch.sum({{data}}, dim={{axis}}, keepdim={{keepdims}})",
    "arg_mapping": {
      "data": "data",
      "axis": "axis",
      "keepdims": "keepdims"
    },
    "example_pairs": [
      {
        "tvm": "y = tvm.topi.reduction.sum(data, axis=0, keepdims=True)",
        "torch": "y = torch.sum(data, dim=0, keepdim=True)"
      },
      {
        "tvm": "y = tvm.topi.reduction.sum(data, axis=None, keepdims=False)",
        "torch": "y = torch.sum(data)"
      }
    ],
    "constraints": "When `axis=None`, TVM sums all elements. PyTorch `torch.sum(data)` also sums all elements.",
    "notes": "Direct mapping to `torch.sum`. The `axis` parameter in TVM corresponds to `dim` in PyTorch.",
    "confidence": 0.95
  },
  {
    "tvm_api": "tvm.topi.reduction.all",
    "torch_api": "torch.all",
    "mapping_type": "direct",
    "direction": "tvm_to_torch",
    "tvm_pattern": "tvm.topi.reduction.all({{data}}, axis={{axis}}, keepdims={{keepdims}})",
    "torch_pattern": "torch.all({{data}}, dim={{axis}}, keepdim={{keepdims}})",
    "arg_mapping": {
      "data": "data",
      "axis": "axis",
      "keepdims": "keepdims"
    },
    "example_pairs": [
      {
        "tvm": "y = tvm.topi.reduction.all(data, axis=0, keepdims=True)",
        "torch": "y = torch.all(data, dim=0, keepdim=True)"
      },
      {
        "tvm": "y = tvm.topi.reduction.all(data, axis=None, keepdims=False)",
        "torch": "y = torch.all(data)"
      }
    ],
    "constraints": "When `axis=None`, TVM performs logical AND over all elements. PyTorch `torch.all(data)` also performs logical AND over all elements.",
    "notes": "Direct mapping to `torch.all`. The `axis` parameter in TVM corresponds to `dim` in PyTorch. Input tensor is expected to be boolean.",
    "confidence": 0.95
  },
  {
    "tvm_api": "tvm.topi.reduction.any",
    "torch_api": "torch.any",
    "mapping_type": "direct",
    "direction": "tvm_to_torch",
    "tvm_pattern": "tvm.topi.reduction.any({{data}}, axis={{axis}}, keepdims={{keepdims}})",
    "torch_pattern": "torch.any({{data}}, dim={{axis}}, keepdim={{keepdims}})",
    "arg_mapping": {
      "data": "data",
      "axis": "axis",
      "keepdims": "keepdims"
    },
    "example_pairs": [
      {
        "tvm": "y = tvm.topi.reduction.any(data, axis=0, keepdims=True)",
        "torch": "y = torch.any(data, dim=0, keepdim=True)"
      },
      {
        "tvm": "y = tvm.topi.reduction.any(data, axis=None, keepdims=False)",
        "torch": "y = torch.any(data)"
      }
    ],
    "constraints": "When `axis=None`, TVM performs logical OR over all elements. PyTorch `torch.any(data)` also performs logical OR over all elements.",
    "notes": "Direct mapping to `torch.any`. The `axis` parameter in TVM corresponds to `dim` in PyTorch. Input tensor is expected to be boolean.",
    "confidence": 0.95
  },
  {
    "tvm_api": "tvm.topi.reduction.max",
    "torch_api": "torch.max",
    "mapping_type": "direct",
    "direction": "tvm_to_torch",
    "tvm_pattern": "tvm.topi.reduction.max({{data}}, axis={{axis}}, keepdims={{keepdims}})",
    "torch_pattern": "torch.max({{data}}, dim={{axis}}, keepdim={{keepdims}}).values",
    "arg_mapping": {
      "data": "data",
      "axis": "axis",
      "keepdims": "keepdims"
    },
    "example_pairs": [
      {
        "tvm": "y = tvm.topi.reduction.max(data, axis=0, keepdims=True)",
        "torch": "y = torch.max(data, dim=0, keepdim=True).values"
      },
      {
        "tvm": "y = tvm.topi.reduction.max(data, axis=None, keepdims=False)",
        "torch": "y = torch.max(data)"
      }
    ],
    "constraints": "When `axis` is specified, `torch.max` returns a tuple of (values, indices), so `.values` must be appended. When `axis=None`, `torch.max(data)` returns a single value.",
    "notes": "Direct mapping to `torch.max`. The `axis` parameter in TVM corresponds to `dim` in PyTorch.",
    "confidence": 0.95
  },
  {
    "tvm_api": "tvm.topi.reduction.min",
    "torch_api": "torch.min",
    "mapping_type": "direct",
    "direction": "tvm_to_torch",
    "tvm_pattern": "tvm.topi.reduction.min({{data}}, axis={{axis}}, keepdims={{keepdims}})",
    "torch_pattern": "torch.min({{data}}, dim={{axis}}, keepdim={{keepdims}}).values",
    "arg_mapping": {
      "data": "data",
      "axis": "axis",
      "keepdims": "keepdims"
    },
    "example_pairs": [
      {
        "tvm": "y = tvm.topi.reduction.min(data, axis=0, keepdims=True)",
        "torch": "y = torch.min(data, dim=0, keepdim=True).values"
      },
      {
        "tvm": "y = tvm.topi.reduction.min(data, axis=None, keepdims=False)",
        "torch": "y = torch.min(data)"
      }
    ],
    "constraints": "When `axis` is specified, `torch.min` returns a tuple of (values, indices), so `.values` must be appended. When `axis=None`, `torch.min(data)` returns a single value.",
    "notes": "Direct mapping to `torch.min`. The `axis` parameter in TVM corresponds to `dim` in PyTorch.",
    "confidence": 0.95
  },
  {
    "tvm_api": "tvm.topi.reduction.argmax",
    "torch_api": "torch.argmax",
    "mapping_type": "direct",
    "direction": "tvm_to_torch",
    "tvm_pattern": "tvm.topi.reduction.argmax({{data}}, axis={{axis}}, keepdims={{keepdims}})",
    "torch_pattern": "torch.argmax({{data}}, dim={{axis}}, keepdim={{keepdims}})",
    "arg_mapping": {
      "data": "data",
      "axis": "axis",
      "keepdims": "keepdims"
    },
    "example_pairs": [
      {
        "tvm": "y = tvm.topi.reduction.argmax(data, axis=0, keepdims=True)",
        "torch": "y = torch.argmax(data, dim=0, keepdim=True)"
      },
      {
        "tvm": "y = tvm.topi.reduction.argmax(data, axis=None, keepdims=False)",
        "torch": "y = torch.argmax(data)"
      }
    ],
    "constraints": "TVM's `select_last_index` parameter is not directly available in `torch.argmax`. PyTorch's `argmax` returns the *first* occurrence of the maximum value. If `axis=None`, PyTorch `torch.argmax(data)` flattens the input.",
    "notes": "Direct mapping to `torch.argmax`. The `axis` parameter in TVM corresponds to `dim` in PyTorch.",
    "confidence": 0.9
  },
  {
    "tvm_api": "tvm.topi.reduction.argmin",
    "torch_api": "torch.argmin",
    "mapping_type": "direct",
    "direction": "tvm_to_torch",
    "tvm_pattern": "tvm.topi.reduction.argmin({{data}}, axis={{axis}}, keepdims={{keepdims}})",
    "torch_pattern": "torch.argmin({{data}}, dim={{axis}}, keepdim={{keepdims}})",
    "arg_mapping": {
      "data": "data",
      "axis": "axis",
      "keepdims": "keepdims"
    },
    "example_pairs": [
      {
        "tvm": "y = tvm.topi.reduction.argmin(data, axis=0, keepdims=True)",
        "torch": "y = torch.argmin(data, dim=0, keepdim=True)"
      },
      {
        "tvm": "y = tvm.topi.reduction.argmin(data, axis=None, keepdims=False)",
        "torch": "y = torch.argmin(data)"
      }
    ],
    "constraints": "TVM's `select_last_index` parameter is not directly available in `torch.argmin`. PyTorch's `argmin` returns the *first* occurrence of the minimum value. If `axis=None`, PyTorch `torch.argmin(data)` flattens the input.",
    "notes": "Direct mapping to `torch.argmin`. The `axis` parameter in TVM corresponds to `dim` in PyTorch.",
    "confidence": 0.9
  },
  {
    "tvm_api": "tvm.topi.scan.cumsum",
    "torch_api": "torch.cumsum",
    "mapping_type": "direct",
    "direction": "tvm_to_torch",
    "tvm_pattern": "tvm.topi.scan.cumsum({{data}}, axis={{axis}}, dtype={{dtype}}, exclusive={{exclusive}})",
    "torch_pattern": "torch.cumsum({{data}}, dim={{axis}}, dtype={{dtype}})",
    "arg_mapping": {
      "data": "data",
      "axis": "axis",
      "dtype": "dtype",
      "exclusive": "null"
    },
    "example_pairs": [
      {
        "tvm": "y = tvm.topi.scan.cumsum(data, axis=0, dtype='float32')",
        "torch": "y = torch.cumsum(data, dim=0, dtype=torch.float32)"
      },
      {
        "tvm": "y = tvm.topi.scan.cumsum(data, axis=1)",
        "torch": "y = torch.cumsum(data, dim=1)"
      }
    ],
    "constraints": "TVM's `exclusive` parameter is not directly supported by `torch.cumsum`. If `exclusive` is required, a composite operation involving `roll` and `pad` would be needed. When `axis=None`, TVM flattens the array, while PyTorch `cumsum` requires `dim` to be specified.",
    "notes": "Direct mapping for `data`, `axis`, and `dtype`. The `exclusive` parameter is a known difference.",
    "confidence": 0.8
  },
  {
    "tvm_api": "tvm.topi.scatter.scatter",
    "torch_api": "torch.scatter",
    "mapping_type": "direct",
    "direction": "tvm_to_torch",
    "tvm_pattern": "tvm.topi.scatter.scatter({{data}}, {{indices}}, {{updates}}, axis={{axis}})",
    "torch_pattern": "torch.scatter({{data}}, dim={{axis}}, index={{indices}}, src={{updates}})",
    "arg_mapping": {
      "data": "data",
      "indices": "indices",
      "updates": "updates",
      "axis": "axis"
    },
    "example_pairs": [
      {
        "tvm": "y = tvm.topi.scatter.scatter(data, indices, updates, axis=0)",
        "torch": "y = torch.scatter(data, dim=0, index=indices, src=updates)"
      }
    ],
    "constraints": "PyTorch `scatter` copies `data` if not in-place. `torch.scatter_` is the in-place version.",
    "notes": "Direct mapping to `torch.scatter`. TVM's `axis` maps to PyTorch's `dim`, `updates` maps to `src`.",
    "confidence": 0.95
  },
  {
    "tvm_api": "tvm.topi.scatter_add.scatter_add",
    "torch_api": "torch.scatter_add",
    "mapping_type": "direct",
    "direction": "tvm_to_torch",
    "tvm_pattern": "tvm.topi.scatter_add.scatter_add({{data}}, {{indices}}, {{updates}}, axis={{axis}})",
    "torch_pattern": "torch.scatter_add({{data}}, dim={{axis}}, index={{indices}}, src={{updates}})",
    "arg_mapping": {
      "data": "data",
      "indices": "indices",
      "updates": "updates",
      "axis": "axis"
    },
    "example_pairs": [
      {
        "tvm": "y = tvm.topi.scatter_add.scatter_add(data, indices, updates, axis=0)",
        "torch": "y = torch.scatter_add(data, dim=0, index=indices, src=updates)"
      }
    ],
    "constraints": "PyTorch `scatter_add` is an in-place operation by default, but there is also a functional version. The TVM `scatter_add` seems to imply a functional return.",
    "notes": "Direct mapping to `torch.scatter_add`. TVM's `axis` maps to PyTorch's `dim`, `updates` maps to `src`.",
    "confidence": 0.95
  },
  {
    "tvm_api": "tvm.topi.searchsorted.searchsorted",
    "torch_api": "torch.searchsorted",
    "mapping_type": "direct",
    "direction": "tvm_to_torch",
    "tvm_pattern": "tvm.topi.searchsorted.searchsorted({{sorted_sequence}}, {{values}}, right={{right}}, out_dtype={{out_dtype}})",
    "torch_pattern": "torch.searchsorted({{sorted_sequence}}, {{values}}, right={{right}}, out_int32={{out_int32}})",
    "arg_mapping": {
      "sorted_sequence": "sorted_sequence",
      "values": "values",
      "right": "right",
      "out_dtype": "null"
    },
    "example_pairs": [
      {
        "tvm": "y = tvm.topi.searchsorted(seq, val, right=True, out_dtype='int64')",
        "torch": "y = torch.searchsorted(seq, val, right=True, out_int32=False)"
      }
    ],
    "constraints": "TVM's `out_dtype` is typically an 'int64' or 'int32' string. PyTorch uses `out_int32=True/False` to control output dtype. `torch.searchsorted` does not support complex dtypes.",
    "notes": "Direct mapping for the core functionality. Need to translate `out_dtype` to `out_int32` boolean.",
    "confidence": 0.9
  },
  {
    "tvm_api": "tvm.topi.sort.sort",
    "torch_api": "torch.sort",
    "mapping_type": "direct",
    "direction": "tvm_to_torch",
    "tvm_pattern": "tvm.topi.sort.sort({{data}}, axis={{axis}}, is_ascend={{is_ascend}})",
    "torch_pattern": "torch.sort({{data}}, dim={{axis}}, descending={{descending}}).values",
    "arg_mapping": {
      "data": "data",
      "axis": "axis",
      "is_ascend": "descending_from_is_ascend"
    },
    "example_pairs": [
      {
        "tvm": "values = tvm.topi.sort.sort(data, axis=-1, is_ascend=True)",
        "torch": "values = torch.sort(data, dim=-1, descending=False).values"
      },
      {
        "tvm": "values = tvm.topi.sort.sort(data, axis=0, is_ascend=False)",
        "torch": "values = torch.sort(data, dim=0, descending=True).values"
      }
    ],
    "constraints": "PyTorch `torch.sort` returns a tuple of (values, indices), so `.values` must be appended if only values are desired. `is_ascend=True` in TVM means `descending=False` in PyTorch, and vice-versa.",
    "notes": "Direct mapping. The `axis` parameter in TVM corresponds to `dim` in PyTorch, and `is_ascend` needs inversion for `descending`.",
    "confidence": 0.95
  },
  {
    "tvm_api": "tvm.topi.sort.argsort",
    "torch_api": "torch.argsort",
    "mapping_type": "direct",
    "direction": "tvm_to_torch",
    "tvm_pattern": "tvm.topi.sort.argsort({{data}}, axis={{axis}}, is_ascend={{is_ascend}})",
    "torch_pattern": "torch.argsort({{data}}, dim={{axis}}, descending={{descending}})",
    "arg_mapping": {
      "data": "data",
      "axis": "axis",
      "is_ascend": "descending_from_is_ascend"
    },
    "example_pairs": [
      {
        "tvm": "indices = tvm.topi.sort.argsort(data, axis=-1, is_ascend=True)",
        "torch": "indices = torch.argsort(data, dim=-1, descending=False)"
      },
      {
        "tvm": "indices = tvm.topi.sort.argsort(data, axis=0, is_ascend=False)",
        "torch": "indices = torch.argsort(data, dim=0, descending=True)"
      }
    ],
    "constraints": "`is_ascend=True` in TVM means `descending=False` in PyTorch, and vice-versa. TVM `valid_count` parameter has no direct equivalent in PyTorch's `argsort`.",
    "notes": "Direct mapping. The `axis` parameter in TVM corresponds to `dim` in PyTorch, and `is_ascend` needs inversion for `descending`.",
    "confidence": 0.9
  },
  {
    "tvm_api": "tvm.topi.sort.topk",
    "torch_api": "torch.topk",
    "mapping_type": "direct",
    "direction": "tvm_to_torch",
    "tvm_pattern": "tvm.topi.sort.topk({{data}}, k={{k}}, axis={{axis}}, ret_type={{ret_type}}, is_ascend={{is_ascend}})",
    "torch_pattern": "torch.topk({{data}}, k={{k}}, dim={{axis}}, largest={{largest_from_is_ascend}}, sorted=True)",
    "arg_mapping": {
      "data": "data",
      "k": "k",
      "axis": "axis",
      "ret_type": "null",
      "is_ascend": "largest_from_is_ascend"
    },
    "example_pairs": [
      {
        "tvm": "values, indices = tvm.topi.sort.topk(data, k=3, axis=-1, ret_type='both', is_ascend=False)",
        "torch": "values, indices = torch.topk(data, k=3, dim=-1, largest=True, sorted=True)"
      },
      {
        "tvm": "values = tvm.topi.sort.topk(data, k=5, axis=0, ret_type='values', is_ascend=True)",
        "torch": "values, _ = torch.topk(data, k=5, dim=0, largest=False, sorted=True)"
      }
    ],
    "constraints": "TVM `ret_type` needs to be handled by selecting the appropriate return value(s) from `torch.topk` (which always returns `(values, indices)`). `is_ascend=True` in TVM means `largest=False` in PyTorch, and vice-versa. PyTorch's `topk` implies `sorted=True` by default, matching TVM.",
    "notes": "Direct mapping for core parameters. `ret_type` requires post-processing of `torch.topk` output. `is_ascend` needs inversion for `largest`.",
    "confidence": 0.9
  },
  {
    "tvm_api": "tvm.topi.stft.stft",
    "torch_api": "torch.stft",
    "mapping_type": "direct",
    "direction": "tvm_to_torch",
    "tvm_pattern": "tvm.topi.stft.stft({{data}}, {{n_fft}}, {{hop_length}}, {{win_length}}, {{window}}, normalized={{normalized}}, onesided={{onesided}}, output_shape={{output_shape}})",
    "torch_pattern": "torch.stft(input={{data}}, n_fft={{n_fft}}, hop_length={{hop_length}}, win_length={{win_length}}, window={{window}}, center=True, pad_mode='reflect', normalized={{normalized}}, onesided={{onesided}}, return_complex=True)",
    "arg_mapping": {
      "data": "input",
      "n_fft": "n_fft",
      "hop_length": "hop_length",
      "win_length": "win_length",
      "window": "window",
      "normalized": "normalized",
      "onesided": "onesided",
      "output_shape": "null"
    },
    "example_pairs": [
      {
        "tvm": "spec = tvm.topi.stft.stft(data, 2048, 512, 2048, window_tensor, normalized=False, onesided=True, output_shape=(1025, 100))",
        "torch": "spec = torch.stft(input=data, n_fft=2048, hop_length=512, win_length=2048, window=window_tensor, center=True, pad_mode='reflect', normalized=False, onesided=True, return_complex=True)"
      }
    ],
    "constraints": "PyTorch `stft` has `center`, `pad_mode`, and `return_complex` parameters not explicitly in TVM's signature but typically assumed. `output_shape` in TVM is for inference but not a direct input to PyTorch's `stft` function for computation. `return_complex=True` is strongly preferred in modern PyTorch for real inputs.",
    "notes": "Generally a direct mapping. Default PyTorch `center=True` and `pad_mode='reflect'` (or 'zeros') often match common STFT usage. `return_complex` is a crucial PyTorch parameter.",
    "confidence": 0.9
  },
  {
    "tvm_api": "tvm.topi.tensor.full",
    "torch_api": "torch.full",
    "mapping_type": "direct",
    "direction": "tvm_to_torch",
    "tvm_pattern": "tvm.topi.tensor.full({{shape}}, {{dtype}}, {{fill_value}})",
    "torch_pattern": "torch.full({{size}}, {{fill_value}}, dtype={{dtype}})",
    "arg_mapping": {
      "shape": "size",
      "dtype": "dtype",
      "fill_value": "fill_value"
    },
    "example_pairs": [
      {
        "tvm": "y = tvm.topi.tensor.full((2, 3), 'float32', 1.0)",
        "torch": "y = torch.full((2, 3), 1.0, dtype=torch.float32)"
      }
    ],
    "constraints": "PyTorch uses `size` instead of `shape` and expects PyTorch `dtype` objects (e.g., `torch.float32`) instead of string representations.",
    "notes": "Direct mapping for functionality. Argument names and dtype representation need conversion.",
    "confidence": 0.98
  },
  {
    "tvm_api": "tvm.topi.tensor.full_like",
    "torch_api": "torch.full_like",
    "mapping_type": "direct",
    "direction": "tvm_to_torch",
    "tvm_pattern": "tvm.topi.tensor.full_like({{x}}, {{fill_value}})",
    "torch_pattern": "torch.full_like({{input}}, {{fill_value}})",
    "arg_mapping": {
      "x": "input",
      "fill_value": "fill_value"
    },
    "example_pairs": [
      {
        "tvm": "y = tvm.topi.tensor.full_like(x, 1.0)",
        "torch": "y = torch.full_like(x, 1.0)"
      }
    ],
    "constraints": "PyTorch `full_like` also allows specifying `dtype`, `layout`, `device`, etc., which are not in the TVM signature here but might be implicitly determined.",
    "notes": "Direct mapping for creating a tensor with the same shape and dtype as an input tensor, filled with a scalar value.",
    "confidence": 0.98
  },
  {
    "tvm_api": "tvm.topi.transform.expand_dims",
    "torch_api": "torch.unsqueeze",
    "mapping_type": "direct",
    "direction": "tvm_to_torch",
    "tvm_pattern": "tvm.topi.transform.expand_dims({{a}}, {{axis}}, num_newaxis={{num_newaxis}})",
    "torch_pattern": "torch.unsqueeze({{input}}, dim={{axis}})",
    "arg_mapping": {
      "a": "input",
      "axis": "dim",
      "num_newaxis": "null"
    },
    "example_pairs": [
      {
        "tvm": "y = tvm.topi.transform.expand_dims(x, 0, num_newaxis=1)",
        "torch": "y = torch.unsqueeze(x, dim=0)"
      },
      {
        "tvm": "y = tvm.topi.transform.expand_dims(x, 2, num_newaxis=1)",
        "torch": "y = torch.unsqueeze(x, dim=2)"
      }
    ],
    "constraints": "PyTorch `torch.unsqueeze` can only add one dimension at a time, meaning `num_newaxis` in TVM must be 1. If `num_newaxis` is greater than 1, a composite operation (multiple `unsqueeze` calls) would be needed.",
    "notes": "Direct mapping when `num_newaxis` is 1. `expand_dims` in NumPy/TVM is equivalent to `unsqueeze` in PyTorch when adding a single dimension.",
    "confidence": 0.9
  },
  {
    "tvm_api": "tvm.topi.transform.transpose",
    "torch_api": "torch.permute",
    "mapping_type": "direct",
    "direction": "tvm_to_torch",
    "tvm_pattern": "tvm.topi.transform.transpose({{a}}, axes={{axes}})",
    "torch_pattern": "torch.permute({{input}}, dims={{axes}})",
    "arg_mapping": {
      "a": "input",
      "axes": "dims"
    },
    "example_pairs": [
      {
        "tvm": "y = tvm.topi.transform.transpose(x, axes=(1, 0, 2))",
        "torch": "y = torch.permute(x, dims=(1, 0, 2))"
      },
      {
        "tvm": "y = tvm.topi.transform.transpose(x)",
        "torch": "y = torch.permute(x, dims=tuple(reversed(range(x.ndim))))"
      }
    ],
    "constraints": "If `axes=None` in TVM, it reverses dimensions. This behavior needs to be explicitly implemented for PyTorch `permute` using `tuple(reversed(range(x.ndim)))`.",
    "notes": "While `torch.transpose` exists, it only swaps two dimensions. `torch.permute` is the more general equivalent of NumPy/TVM `transpose` for arbitrary axis permutations.",
    "confidence": 0.95
  },
  {
    "tvm_api": "tvm.topi.transform.flip",
    "torch_api": "torch.flip",
    "mapping_type": "direct",
    "direction": "tvm_to_torch",
    "tvm_pattern": "tvm.topi.transform.flip({{a}}, axis={{axis}})",
    "torch_pattern": "torch.flip({{input}}, dims=({{axis}},))",
    "arg_mapping": {
      "a": "input",
      "axis": "axis"
    },
    "example_pairs": [
      {
        "tvm": "y = tvm.topi.transform.flip(x, axis=0)",
        "torch": "y = torch.flip(x, dims=(0,))"
      },
      {
        "tvm": "y = tvm.topi.transform.flip(x, axis=-1)",
        "torch": "y = torch.flip(x, dims=(-1,))"
      }
    ],
    "constraints": "PyTorch `torch.flip` expects `dims` as a tuple of integers, even for a single axis.",
    "notes": "Direct mapping. `axis` in TVM corresponds to `dims` in PyTorch, requiring conversion to a tuple.",
    "confidence": 0.98
  },
  {
    "tvm_api": "tvm.topi.transform.reshape",
    "torch_api": "torch.reshape",
    "mapping_type": "direct",
    "direction": "tvm_to_torch",
    "tvm_pattern": "tvm.topi.transform.reshape({{a}}, {{newshape}})",
    "torch_pattern": "torch.reshape({{input}}, {{shape}})",
    "arg_mapping": {
      "a": "input",
      "newshape": "shape"
    },
    "example_pairs": [
      {
        "tvm": "y = tvm.topi.transform.reshape(x, (2, 5))",
        "torch": "y = torch.reshape(x, (2, 5))"
      },
      {
        "tvm": "y = tvm.topi.transform.reshape(x, (-1, 10))",
        "torch": "y = torch.reshape(x, (-1, 10))"
      }
    ],
    "constraints": "PyTorch `reshape` can infer one dimension if specified as -1, similar to TVM/NumPy. New shape must be compatible with the number of elements in the input tensor.",
    "notes": "Direct mapping for the core reshape functionality.",
    "confidence": 0.98
  },
  {
    "tvm_api": "tvm.topi.transform.squeeze",
    "torch_api": "torch.squeeze",
    "mapping_type": "direct",
    "direction": "tvm_to_torch",
    "tvm_pattern": "tvm.topi.transform.squeeze({{a}}, axis={{axis}})",
    "torch_pattern": "torch.squeeze({{input}}, dim={{axis}})",
    "arg_mapping": {
      "a": "input",
      "axis": "dim"
    },
    "example_pairs": [
      {
        "tvm": "y = tvm.topi.transform.squeeze(x, axis=0)",
        "torch": "y = torch.squeeze(x, dim=0)"
      },
      {
        "tvm": "y = tvm.topi.transform.squeeze(x)",
        "torch": "y = torch.squeeze(x)"
      }
    ],
    "constraints": "If `axis` is a tuple of ints in TVM, multiple `torch.squeeze` calls or a custom implementation would be needed, as `torch.squeeze` only accepts a single `dim` or `None` to remove all singleton dimensions.",
    "notes": "Direct mapping when `axis` is a single integer or `None`. `axis` in TVM corresponds to `dim` in PyTorch.",
    "confidence": 0.95
  },
  {
    "tvm_api": "tvm.topi.transform.concatenate",
    "torch_api": "torch.cat",
    "mapping_type": "direct",
    "direction": "tvm_to_torch",
    "tvm_pattern": "tvm.topi.transform.concatenate({{a_tuple}}, axis={{axis}})",
    "torch_pattern": "torch.cat({{tensors}}, dim={{axis}})",
    "arg_mapping": {
      "a_tuple": "tensors",
      "axis": "dim"
    },
    "example_pairs": [
      {
        "tvm": "y = tvm.topi.transform.concatenate((x1, x2), axis=0)",
        "torch": "y = torch.cat((x1, x2), dim=0)"
      }
    ],
    "constraints": "All input tensors must have the same shape except in the dimension `axis`.",
    "notes": "Direct mapping. TVM's `a_tuple` maps to PyTorch's `tensors`, and `axis` maps to `dim`.",
    "confidence": 0.98
  },
  {
    "tvm_api": "tvm.topi.transform.stack",
    "torch_api": "torch.stack",
    "mapping_type": "direct",
    "direction": "tvm_to_torch",
    "tvm_pattern": "tvm.topi.transform.stack({{a}}, axis={{axis}})",
    "torch_pattern": "torch.stack({{tensors}}, dim={{axis}})",
    "arg_mapping": {
      "a": "tensors",
      "axis": "dim"
    },
    "example_pairs": [
      {
        "tvm": "y = tvm.topi.transform.stack([x1, x2], axis=0)",
        "torch": "y = torch.stack([x1, x2], dim=0)"
      }
    ],
    "constraints": "All input tensors must have the same shape. The `axis` parameter is the dimension along which to stack.",
    "notes": "Direct mapping. TVM's `a` (a sequence of tensors) maps to PyTorch's `tensors`, and `axis` maps to `dim`.",
    "confidence": 0.98
  },
  {
    "tvm_api": "tvm.topi.transform.split",
    "torch_api": "torch.split",
    "mapping_type": "direct",
    "direction": "tvm_to_torch",
    "tvm_pattern": "tvm.topi.transform.split({{ary}}, {{indices_or_sections}}, axis={{axis}})",
    "torch_pattern": "torch.split({{tensor}}, {{split_size_or_sections}}, dim={{axis}})",
    "arg_mapping": {
      "ary": "tensor",
      "indices_or_sections": "split_size_or_sections",
      "axis": "dim"
    },
    "example_pairs": [
      {
        "tvm": "y = tvm.topi.transform.split(x, 2, axis=0)",
        "torch": "y = torch.split(x, 2, dim=0)"
      },
      {
        "tvm": "y = tvm.topi.transform.split(x, [1, 3], axis=1)",
        "torch": "y = torch.split(x, [1, 3], dim=1)"
      }
    ],
    "constraints": "PyTorch `split` takes `split_size_or_sections` which can be an integer (for equal-sized chunks) or a list of integers (for specific chunk sizes). This matches TVM's `indices_or_sections` behavior.",
    "notes": "Direct mapping. TVM's `ary` maps to PyTorch's `tensor`, `indices_or_sections` maps to `split_size_or_sections`, and `axis` maps to `dim`.",
    "confidence": 0.98
  },
  {
    "tvm_api": "tvm.topi.transform.take",
    "torch_api": "torch.take",
    "mapping_type": "direct",
    "direction": "tvm_to_torch",
    "tvm_pattern": "tvm.topi.transform.take({{a}}, {{indices}}, axis={{axis}}, batch_dims={{batch_dims}}, mode={{mode}})",
    "torch_pattern": "torch.take({{input}}, {{indices}})",
    "arg_mapping": {
      "a": "input",
      "indices": "indices",
      "axis": "null",
      "batch_dims": "null",
      "mode": "null"
    },
    "example_pairs": [
      {
        "tvm": "y = tvm.topi.transform.take(x, idx_tensor, axis=None)",
        "torch": "y = torch.take(x, idx_tensor)"
      }
    ],
    "constraints": "PyTorch `torch.take` only operates on the flattened input `a` and takes a 1D `indices` tensor. It does not have `axis`, `batch_dims`, or `mode` parameters. If `axis` is specified in TVM, `torch.take_along_dim` might be a better fit, but its semantics differ for `indices`.",
    "notes": "Direct mapping only when TVM `axis` is `None` (flattened input). If `axis` is used, this is not a direct mapping and would require a more complex PyTorch expression.",
    "confidence": 0.7
  },
  {
    "tvm_api": "tvm.topi.transform.gather",
    "torch_api": "torch.gather",
    "mapping_type": "direct",
    "direction": "tvm_to_torch",
    "tvm_pattern": "tvm.topi.transform.gather({{data}}, axis={{axis}}, indices={{indices}})",
    "torch_pattern": "torch.gather({{input}}, dim={{axis}}, index={{indices}})",
    "arg_mapping": {
      "data": "input",
      "axis": "dim",
      "indices": "index"
    },
    "example_pairs": [
      {
        "tvm": "y = tvm.topi.transform.gather(data_tensor, axis=0, indices=idx_tensor)",
        "torch": "y = torch.gather(data_tensor, dim=0, index=idx_tensor)"
      }
    ],
    "constraints": "`indices` tensor must have the same number of dimensions as `input` tensor, and its size must be 1 in all dimensions except for `dim`.",
    "notes": "Direct mapping. TVM `data` maps to `input`, `axis` to `dim`, and `indices` to `index`.",
    "confidence": 0.98
  },
  {
    "tvm_api": "tvm.topi.transform.matmul",
    "torch_api": "torch.matmul",
    "mapping_type": "direct",
    "direction": "tvm_to_torch",
    "tvm_pattern": "tvm.topi.transform.matmul({{a}}, {{b}}, transp_a={{transp_a}}, transp_b={{transp_b}})",
    "torch_pattern": "torch.matmul({{a_processed}}, {{b_processed}})",
    "arg_mapping": {
      "a": "a_original",
      "b": "b_original",
      "transp_a": "transp_a",
      "transp_b": "transp_b"
    },
    "example_pairs": [
      {
        "tvm": "C = tvm.topi.transform.matmul(A, B, transp_a=False, transp_b=False)",
        "torch": "C = torch.matmul(A, B)"
      },
      {
        "tvm": "C = tvm.topi.transform.matmul(A, B, transp_a=True, transp_b=False)",
        "torch": "C = torch.matmul(A.T, B)"
      },
      {
        "tvm": "C = tvm.topi.transform.matmul(A, B, transp_a=False, transp_b=True)",
        "torch": "C = torch.matmul(A, B.T)"
      }
    ],
    "constraints": "PyTorch `torch.matmul` expects the inputs to be already transposed if needed. This means `transp_a` and `transp_b` need to be applied to `a` and `b` before calling `torch.matmul` (e.g., `A.T`).",
    "notes": "Requires pre-processing of inputs based on `transp_a` and `transp_b` flags. `torch.matmul` is a general matrix multiplication that supports broadcasting.",
    "confidence": 0.9
  },
  {
    "tvm_api": "tvm.topi.transform.tensordot",
    "torch_api": "torch.tensordot",
    "mapping_type": "direct",
    "direction": "tvm_to_torch",
    "tvm_pattern": "tvm.topi.transform.tensordot({{a}}, {{b}}, axes={{axes}})",
    "torch_pattern": "torch.tensordot({{a}}, {{b}}, dims={{axes_torch}})",
    "arg_mapping": {
      "a": "a",
      "b": "b",
      "axes": "axes_tvm"
    },
    "example_pairs": [
      {
        "tvm": "y = tvm.topi.transform.tensordot(A, B, 2)",
        "torch": "y = torch.tensordot(A, B, dims=2)"
      },
      {
        "tvm": "y = tvm.topi.transform.tensordot(A, B, axes=([1,3], [0,2]))",
        "torch": "y = torch.tensordot(A, B, dims=([1,3], [0,2]))"
      },
      {
        "tvm": "y = tvm.topi.transform.tensordot(A, B, (1, 0))",
        "torch": "y = torch.tensordot(A, B, dims=([1], [0]))"
      }
    ],
    "constraints": "TVM's `axes` parameter has multiple forms: int, (int, int), or (list, list). PyTorch's `dims` parameter handles int or (list, list). The (int, int) form in TVM needs to be converted to ([int], [int]) for PyTorch.",
    "notes": "Direct mapping, but `axes` parameter might require slight restructuring for PyTorch's `dims` argument to handle single int vs. tuple of lists.",
    "confidence": 0.95
  },
  {
    "tvm_api": "tvm.topi.transform.arange",
    "torch_api": "torch.arange",
    "mapping_type": "direct",
    "direction": "tvm_to_torch",
    "tvm_pattern": "tvm.topi.transform.arange(start={{start}}, stop={{stop}}, step={{step}}, dtype={{dtype}})",
    "torch_pattern": "torch.arange(start={{start}}, end={{stop}}, step={{step}}, dtype={{dtype}})",
    "arg_mapping": {
      "start": "start",
      "stop": "end",
      "step": "step",
      "dtype": "dtype"
    },
    "example_pairs": [
      {
        "tvm": "y = tvm.topi.transform.arange(0, 10, 1, dtype='int32')",
        "torch": "y = torch.arange(start=0, end=10, step=1, dtype=torch.int32)"
      },
      {
        "tvm": "y = tvm.topi.transform.arange(5)",
        "torch": "y = torch.arange(end=5)"
      }
    ],
    "constraints": "PyTorch uses `end` instead of `stop`. TVM `start` can be optional (defaults to 0), but PyTorch `arange` has a few overloads; typically, if only one argument is given, it's `end`. Dtype string in TVM needs conversion to `torch.dtype` object.",
    "notes": "Direct mapping for the sequence generation. Argument name difference for `stop`/`end` and dtype representation.",
    "confidence": 0.98
  },
  {
    "tvm_api": "tvm.topi.transform.meshgrid",
    "torch_api": "torch.meshgrid",
    "mapping_type": "direct",
    "direction": "tvm_to_torch",
    "tvm_pattern": "tvm.topi.transform.meshgrid({{a_tuple}}, indexing={{indexing}})",
    "torch_pattern": "torch.meshgrid(*{{tensors}}, indexing={{indexing}})",
    "arg_mapping": {
      "a_tuple": "tensors",
      "indexing": "indexing"
    },
    "example_pairs": [
      {
        "tvm": "X, Y = tvm.topi.transform.meshgrid((x_coords, y_coords), indexing='xy')",
        "torch": "X, Y = torch.meshgrid(x_coords, y_coords, indexing='xy')"
      }
    ],
    "constraints": "PyTorch `meshgrid` expects arguments to be unpacked (`*tensors`) if `tensors` is a sequence. TVM's `a_tuple` is directly a tuple of tensors.",
    "notes": "Direct mapping. The `indexing` parameter is identical.",
    "confidence": 0.98
  },
  {
    "tvm_api": "tvm.topi.transform.repeat",
    "torch_api": "torch.repeat_interleave",
    "mapping_type": "direct",
    "direction": "tvm_to_torch",
    "tvm_pattern": "tvm.topi.transform.repeat({{a}}, repeats={{repeats}}, axis={{axis}})",
    "torch_pattern": "torch.repeat_interleave({{input}}, repeats={{repeats}}, dim={{axis}})",
    "arg_mapping": {
      "a": "input",
      "repeats": "repeats",
      "axis": "dim"
    },
    "example_pairs": [
      {
        "tvm": "y = tvm.topi.transform.repeat(x, repeats=3, axis=0)",
        "torch": "y = torch.repeat_interleave(x, repeats=3, dim=0)"
      },
      {
        "tvm": "y = tvm.topi.transform.repeat(x, repeats=torch.tensor([1,2,3]), axis=0)",
        "torch": "y = torch.repeat_interleave(x, repeats=torch.tensor([1,2,3]), dim=0)"
      }
    ],
    "constraints": "PyTorch `torch.repeat_interleave` allows `repeats` to be an int or a tensor. TVM's definition implies `repeats` is an int, but the example in `_numpy` uses `torch.repeat_interleave` which supports both. Assuming `repeats` can be a scalar or a 1D tensor compatible with the dimension size.",
    "notes": "Direct mapping to `torch.repeat_interleave`, which is conceptually similar to NumPy's `repeat`.",
    "confidence": 0.95
  },
  {
    "tvm_api": "tvm.topi.transform.tile",
    "torch_api": "torch.tile",
    "mapping_type": "direct",
    "direction": "tvm_to_torch",
    "tvm_pattern": "tvm.topi.transform.tile({{a}}, reps={{reps}})",
    "torch_pattern": "torch.tile({{input}}, dims={{reps}})",
    "arg_mapping": {
      "a": "input",
      "reps": "dims"
    },
    "example_pairs": [
      {
        "tvm": "y = tvm.topi.transform.tile(x, reps=(2, 3))",
        "torch": "y = torch.tile(x, dims=(2, 3))"
      }
    ],
    "constraints": "PyTorch `torch.tile` expects `dims` as a tuple, which maps directly from TVM `reps`.",
    "notes": "Direct mapping to `torch.tile`, which is equivalent to NumPy's `tile`.",
    "confidence": 0.98
  },
  {
    "tvm_api": "tvm.topi.transform.shape",
    "torch_api": "torch.Tensor.shape",
    "mapping_type": "direct",
    "direction": "tvm_to_torch",
    "tvm_pattern": "tvm.topi.transform.shape({{array}}, dtype={{dtype}})",
    "torch_pattern": "{{tensor}}.shape",
    "arg_mapping": {
      "array": "tensor",
      "dtype": "null"
    },
    "example_pairs": [
      {
        "tvm": "s = tvm.topi.transform.shape(x, dtype='int32')",
        "torch": "s = x.shape"
      }
    ],
    "constraints": "PyTorch `tensor.shape` returns a `torch.Size` object (tuple-like) which defaults to `int64` for its elements internally. The `dtype` parameter in TVM is for the resulting tensor, while `tensor.shape` in PyTorch directly gives the shape as a tuple of Python integers.",
    "notes": "PyTorch tensors have a `.shape` attribute that directly returns their dimensions. If a tensor of shape values is strictly required, additional steps would be needed.",
    "confidence": 0.9
  },
  {
    "tvm_api": "tvm.topi.transform.where",
    "torch_api": "torch.where",
    "mapping_type": "direct",
    "direction": "tvm_to_torch",
    "tvm_pattern": "tvm.topi.transform.where({{condition}}, {{x}}, {{y}})",
    "torch_pattern": "torch.where({{condition}}, {{input}}, {{other}})",
    "arg_mapping": {
      "condition": "condition",
      "x": "input",
      "y": "other"
    },
    "example_pairs": [
      {
        "tvm": "result = tvm.topi.transform.where(cond, x_val, y_val)",
        "torch": "result = torch.where(cond, x_val, y_val)"
      }
    ],
    "constraints": "Inputs `condition`, `x`, and `y` must be broadcastable to a common shape.",
    "notes": "Direct mapping for the element-wise selection based on a condition.",
    "confidence": 0.98
  },
  {
    "tvm_api": "tvm.topi.transform.one_hot",
    "torch_api": "torch.nn.functional.one_hot",
    "mapping_type": "direct",
    "direction": "tvm_to_torch",
    "tvm_pattern": "tvm.topi.transform.one_hot({{indices}}, {{on_value}}, {{off_value}}, {{depth}}, {{axis}}, {{dtype}})",
    "torch_pattern": "torch.nn.functional.one_hot({{input}}, num_classes={{depth}}).to(dtype={{dtype}}) * ({{on_value}} - {{off_value}}) + {{off_value}}",
    "arg_mapping": {
      "indices": "input",
      "on_value": "on_value",
      "off_value": "off_value",
      "depth": "depth",
      "axis": "null",
      "dtype": "dtype"
    },
    "example_pairs": [
      {
        "tvm": "one_hot_tensor = tvm.topi.transform.one_hot(idx, 1.0, 0.0, 10, -1, 'float32')",
        "torch": "one_hot_tensor = torch.nn.functional.one_hot(idx, num_classes=10).to(dtype=torch.float32) * (1.0 - 0.0) + 0.0"
      },
      {
        "tvm": "one_hot_tensor = tvm.topi.transform.one_hot(idx, 5, 2, 10, -1, 'int32')",
        "torch": "one_hot_tensor = torch.nn.functional.one_hot(idx, num_classes=10).to(dtype=torch.int32) * (5 - 2) + 2"
      }
    ],
    "constraints": "PyTorch `torch.nn.functional.one_hot` by default generates 0/1 values and places the one-hot dimension at the *end*. The TVM `axis` parameter would require `torch.movedim` or `torch.permute` after the `one_hot` call. The `on_value`/`off_value` logic needs to be manually applied through arithmetic operations.",
    "notes": "This is a composite mapping because `on_value` and `off_value` are not direct parameters of `torch.nn.functional.one_hot`. The default behavior of PyTorch's `one_hot` is to put the new dimension at the end (`axis=-1`). If `axis` is different, further manipulation is needed.",
    "confidence": 0.8
  },
  {
    "tvm_api": "tvm.topi.transform.unravel_index",
    "torch_api": "torch.unravel_index",
    "mapping_type": "direct",
    "direction": "tvm_to_torch",
    "tvm_pattern": "tvm.topi.transform.unravel_index({{indices}}, {{shape}})",
    "torch_pattern": "torch.unravel_index({{indices}}, {{shape}})",
    "arg_mapping": {
      "indices": "indices",
      "shape": "shape"
    },
    "example_pairs": [
      {
        "tvm": "coords = tvm.topi.transform.unravel_index(flat_indices, (7, 6))",
        "torch": "coords = torch.unravel_index(flat_indices, (7, 6))"
      }
    ],
    "constraints": "Input `indices` must be an integer tensor. `shape` can be an int or sequence of ints.",
    "notes": "Direct mapping. PyTorch's `torch.unravel_index` is designed to be compatible with NumPy's `unravel_index`.",
    "confidence": 0.98
  },
  {
    "tvm_api": "tvm.topi.unique.unique",
    "torch_api": "torch.unique",
    "mapping_type": "direct",
    "direction": "tvm_to_torch",
    "tvm_pattern": "tvm.topi.unique.unique({{data}}, is_sorted={{is_sorted}}, return_counts={{return_counts}})",
    "torch_pattern": "torch.unique({{input}}, sorted={{is_sorted}}, return_counts={{return_counts}})",
    "arg_mapping": {
      "data": "input",
      "is_sorted": "is_sorted",
      "return_counts": "return_counts"
    },
    "example_pairs": [
      {
        "tvm": "unique_vals, counts = tvm.topi.unique(data, is_sorted=True, return_counts=True)",
        "torch": "unique_vals, counts = torch.unique(data, sorted=True, return_counts=True)"
      },
      {
        "tvm": "unique_vals = tvm.topi.unique(data, is_sorted=False)",
        "torch": "unique_vals = torch.unique(data, sorted=False)"
      }
    ],
    "constraints": "TVM notes that `output` and `counts` are padded to have the same length as `data`, and elements with index >= num_unique[0] have undefined value. PyTorch's `torch.unique` returns tensors with actual unique elements and counts, which might be shorter. If padding is explicitly required, a composite operation would be needed.",
    "notes": "Direct mapping for the core functionality. TVM's `is_sorted` maps to PyTorch's `sorted`. PyTorch `unique` also has `return_inverse` and `dim` options not present in the TVM signature shown.",
    "confidence": 0.9
  },
  {
    "tvm_api": "tvm.topi.utils.unravel_index",
    "torch_api": "torch.unravel_index",
    "mapping_type": "direct",
    "direction": "tvm_to_torch",
    "tvm_pattern": "tvm.topi.utils.unravel_index({{idx}}, {{shape}})",
    "torch_pattern": "torch.unravel_index({{indices}}, {{shape}})",
    "arg_mapping": {
      "idx": "indices",
      "shape": "shape"
    },
    "example_pairs": [
      {
        "tvm": "coords = tvm.topi.utils.unravel_index(flat_idx, (7, 6))",
        "torch": "coords = torch.unravel_index(flat_idx, (7, 6))"
      }
    ],
    "constraints": "Input `indices` must be an integer tensor or scalar. `shape` can be an int or sequence of ints.",
    "notes": "This appears to be the same functionality as `tvm.topi.transform.unravel_index`, directly mapping to `torch.unravel_index`.",
    "confidence": 0.98
  },
  {
    "tvm_api": "tvm.topi.utils.get_shape",
    "torch_api": "torch.Tensor.shape",
    "mapping_type": "direct",
    "direction": "tvm_to_torch",
    "tvm_pattern": "tvm.topi.utils.get_shape({{src_shape}}, {{src_layout}}, {{dst_layout}})",
    "torch_pattern": "{{input_tensor}}.shape",
    "arg_mapping": {
      "src_shape": "null",
      "src_layout": "null",
      "dst_layout": "null"
    },
    "example_pairs": [
      {
        "tvm": "shape = tvm.topi.utils.get_shape(input_tensor.shape, 'NCHW', 'NHWC')",
        "torch": "shape = input_tensor.shape"
      }
    ],
    "constraints": "The TVM function `get_shape` is used for inferring destination shape based on source shape and layout transformations. PyTorch's `tensor.shape` directly provides the current shape of a tensor. For layout transformations and shape inference, more complex logic using `torch.Tensor.permute` or manual shape calculations would be necessary.",
    "notes": "The primary role of this TVM function as presented is shape inference based on layout. A direct PyTorch equivalent for *inference* using `src_layout` and `dst_layout` isn't available as a single function call; PyTorch operates on concrete tensor shapes and layouts (contiguous, channels_last, etc.) directly. `tensor.shape` is the closest to 'getting the shape'.",
    "confidence": 0.6
  },
  {
    "tvm_api": "tvm.topi.bifrost.transforms.transpose",
    "torch_api": "torch.permute",
    "mapping_type": "direct",
    "direction": "tvm_to_torch",
    "tvm_pattern": "tvm.topi.bifrost.transforms.transpose({{s}}, {{tensor}}, {{y_index}}, {{x_index}}, {{readers}})",
    "torch_pattern": "torch.permute({{input_tensor}}, dims={{permutation_tuple}})",
    "arg_mapping": {
      "s": "null",
      "tensor": "input_tensor",
      "y_index": "dim0",
      "x_index": "dim1",
      "readers": "null"
    },
    "example_pairs": [
      {
        "tvm": "output = tvm.topi.bifrost.transforms.transpose(s, tensor_a, 0, 1, readers)",
        "torch": "output = torch.permute(tensor_a, dims=(1, 0, *range(2, tensor_a.ndim)))"
      }
    ],
    "constraints": "This TVM API appears to be a schedule-specific function for transposing two specific axes (`y_index`, `x_index`) within a tensor. PyTorch `torch.transpose` can swap two axes, and `torch.permute` can do arbitrary permutations. The `s` and `readers` parameters are related to TVM's scheduling/lowering and have no direct PyTorch equivalent. For a simple 2D transpose (like `X[n, m] -> X[m, n]`), `torch.transpose` or `tensor.T` is sufficient. For arbitrary axes swap, `torch.permute` is needed with a constructed permutation tuple.",
    "notes": "Given the description 'Do transform X[n, m] -> X[m, n]', it implies swapping two specific dimensions. `torch.permute` is more general than `torch.transpose` and can achieve this by constructing the correct `dims` tuple. The TVM scheduling parameters are ignored.",
    "confidence": 0.75
  },
  {
    "tvm_api": "tvm.topi.cuda.argwhere.argwhere",
    "torch_api": "torch.argwhere",
    "mapping_type": "direct",
    "direction": "tvm_to_torch",
    "tvm_pattern": "tvm.topi.cuda.argwhere.argwhere({{output_shape}}, {{condition}})",
    "torch_pattern": "torch.argwhere({{input}})",
    "arg_mapping": {
      "output_shape": "null",
      "condition": "input"
    },
    "example_pairs": [
      {
        "tvm": "indices = tvm.topi.cuda.argwhere.argwhere(out_shape, cond_tensor)",
        "torch": "indices = torch.argwhere(cond_tensor)"
      }
    ],
    "constraints": "PyTorch `torch.argwhere` (or `torch.nonzero(as_tuple=False)`) returns the coordinates of non-zero elements. The `output_shape` parameter in TVM is likely for pre-allocation or shape inference, which is not a direct input to PyTorch's `argwhere` function.",
    "notes": "Direct mapping of `condition` to `input`. PyTorch handles the output shape automatically. `torch.argwhere` is equivalent to `np.argwhere`.",
    "confidence": 0.9
  },
  {
    "tvm_api": "tvm.topi.cuda.scan.cumsum",
    "torch_api": "torch.cumsum",
    "mapping_type": "direct",
    "direction": "tvm_to_torch",
    "tvm_pattern": "tvm.topi.cuda.scan.cumsum({{data}}, axis={{axis}}, dtype={{dtype}}, exclusive={{exclusive}})",
    "torch_pattern": "torch.cumsum({{input}}, dim={{axis}}, dtype={{dtype}})",
    "arg_mapping": {
      "data": "input",
      "axis": "axis",
      "dtype": "dtype",
      "exclusive": "null"
    },
    "example_pairs": [
      {
        "tvm": "y = tvm.topi.cuda.scan.cumsum(data, axis=0, dtype='float32')",
        "torch": "y = torch.cumsum(data, dim=0, dtype=torch.float32)"
      }
    ],
    "constraints": "Same as `tvm.topi.scan.cumsum`. TVM's `exclusive` parameter is not directly supported by `torch.cumsum`. If `exclusive` is required, a composite operation involving `roll` and `pad` would be needed. When `axis=None`, TVM flattens the array, while PyTorch `cumsum` requires `dim` to be specified.",
    "notes": "This is essentially the same as `tvm.topi.scan.cumsum`, just specific to CUDA. The mapping constraints remain the same.",
    "confidence": 0.8
  },
  {
    "tvm_api": "tvm.topi.cuda.scatter.scatter",
    "torch_api": "torch.scatter",
    "mapping_type": "direct",
    "direction": "tvm_to_torch",
    "tvm_pattern": "tvm.topi.cuda.scatter.scatter({{data}}, {{indices}}, {{updates}}, axis={{axis}})",
    "torch_pattern": "torch.scatter({{input}}, dim={{axis}}, index={{indices}}, src={{updates}})",
    "arg_mapping": {
      "data": "input",
      "indices": "indices",
      "updates": "updates",
      "axis": "axis"
    },
    "example_pairs": [
      {
        "tvm": "y = tvm.topi.cuda.scatter.scatter(data, indices, updates, axis=0)",
        "torch": "y = torch.scatter(data, dim=0, index=indices, src=updates)"
      }
    ],
    "constraints": "Same as `tvm.topi.scatter.scatter`. PyTorch `scatter` copies `data` if not in-place. `torch.scatter_` is the in-place version.",
    "notes": "This is essentially the same as `tvm.topi.scatter.scatter`, just specific to CUDA. The mapping constraints remain the same.",
    "confidence": 0.95
  },
  {
    "tvm_api": "tvm.topi.cuda.scatter.scatter_add",
    "torch_api": "torch.scatter_add",
    "mapping_type": "direct",
    "direction": "tvm_to_torch",
    "tvm_pattern": "tvm.topi.cuda.scatter.scatter_add({{data}}, {{indices}}, {{updates}}, axis={{axis}})",
    "torch_pattern": "torch.scatter_add({{input}}, dim={{axis}}, index={{indices}}, src={{updates}})",
    "arg_mapping": {
      "data": "input",
      "indices": "indices",
      "updates": "updates",
      "axis": "axis"
    },
    "example_pairs": [
      {
        "tvm": "y = tvm.topi.cuda.scatter.scatter_add(data, indices, updates, axis=0)",
        "torch": "y = torch.scatter_add(data, dim=0, index=indices, src=updates)"
      }
    ],
    "constraints": "Same as `tvm.topi.scatter_add.scatter_add`. PyTorch `scatter_add` is an in-place operation by default, but there is also a functional version. The TVM `scatter_add` seems to imply a functional return.",
    "notes": "This is essentially the same as `tvm.topi.scatter_add.scatter_add`, just specific to CUDA. The mapping constraints remain the same.",
    "confidence": 0.95
  },
  {
    "tvm_api": "tvm.topi.cuda.searchsorted.searchsorted",
    "torch_api": "torch.searchsorted",
    "mapping_type": "direct",
    "direction": "tvm_to_torch",
    "tvm_pattern": "tvm.topi.cuda.searchsorted.searchsorted({{sorted_sequence}}, {{values}}, right={{right}}, out_dtype={{out_dtype}})",
    "torch_pattern": "torch.searchsorted({{sorted_sequence}}, {{values}}, right={{right}}, out_int32={{out_int32}})",
    "arg_mapping": {
      "sorted_sequence": "sorted_sequence",
      "values": "values",
      "right": "right",
      "out_dtype": "null"
    },
    "example_pairs": [
      {
        "tvm": "y = tvm.topi.cuda.searchsorted(seq, val, right=True, out_dtype='int64')",
        "torch": "y = torch.searchsorted(seq, val, right=True, out_int32=False)"
      }
    ],
    "constraints": "Same as `tvm.topi.searchsorted.searchsorted`. TVM's `out_dtype` is typically an 'int64' or 'int32' string. PyTorch uses `out_int32=True/False` to control output dtype. `torch.searchsorted` does not support complex dtypes.",
    "notes": "This is essentially the same as `tvm.topi.searchsorted.searchsorted`, just specific to CUDA. The mapping constraints remain the same.",
    "confidence": 0.9
  },
  {
    "tvm_api": "tvm.topi.cuda.sort.sort",
    "torch_api": "torch.sort",
    "mapping_type": "direct",
    "direction": "tvm_to_torch",
    "tvm_pattern": "tvm.topi.cuda.sort.sort({{data}}, axis={{axis}}, is_ascend={{is_ascend}})",
    "torch_pattern": "torch.sort({{input}}, dim={{axis}}, descending={{descending}}).values",
    "arg_mapping": {
      "data": "input",
      "axis": "axis",
      "is_ascend": "descending_from_is_ascend"
    },
    "example_pairs": [
      {
        "tvm": "values = tvm.topi.cuda.sort.sort(data, axis=-1, is_ascend=True)",
        "torch": "values = torch.sort(data, dim=-1, descending=False).values"
      }
    ],
    "constraints": "Same as `tvm.topi.sort.sort`. PyTorch `torch.sort` returns a tuple of (values, indices), so `.values` must be appended if only values are desired. `is_ascend=True` in TVM means `descending=False` in PyTorch, and vice-versa.",
    "notes": "This is essentially the same as `tvm.topi.sort.sort`, just specific to CUDA. The mapping constraints remain the same.",
    "confidence": 0.95
  },
  {
    "tvm_api": "tvm.topi.cuda.sort.argsort",
    "torch_api": "torch.argsort",
    "mapping_type": "direct",
    "direction": "tvm_to_torch",
    "tvm_pattern": "tvm.topi.cuda.sort.argsort({{data}}, axis={{axis}}, is_ascend={{is_ascend}})",
    "torch_pattern": "torch.argsort({{input}}, dim={{axis}}, descending={{descending}})",
    "arg_mapping": {
      "data": "input",
      "axis": "axis",
      "is_ascend": "descending_from_is_ascend"
    },
    "example_pairs": [
      {
        "tvm": "indices = tvm.topi.cuda.sort.argsort(data, axis=-1, is_ascend=True)",
        "torch": "indices = torch.argsort(data, dim=-1, descending=False)"
      }
    ],
    "constraints": "Same as `tvm.topi.sort.argsort`. `is_ascend=True` in TVM means `descending=False` in PyTorch, and vice-versa. TVM `valid_count` parameter has no direct equivalent in PyTorch's `argsort`.",
    "notes": "This is essentially the same as `tvm.topi.sort.argsort`, just specific to CUDA. The mapping constraints remain the same.",
    "confidence": 0.9
  },
  {
    "tvm_api": "tvm.topi.cuda.sort.topk",
    "torch_api": "torch.topk",
    "mapping_type": "direct",
    "direction": "tvm_to_torch",
    "tvm_pattern": "tvm.topi.cuda.sort.topk({{data}}, k={{k}}, axis={{axis}}, ret_type={{ret_type}}, is_ascend={{is_ascend}})",
    "torch_pattern": "torch.topk({{input}}, k={{k}}, dim={{axis}}, largest={{largest_from_is_ascend}}, sorted=True)",
    "arg_mapping": {
      "data": "input",
      "k": "k",
      "axis": "axis",
      "ret_type": "null",
      "is_ascend": "largest_from_is_ascend"
    },
    "example_pairs": [
      {
        "tvm": "values, indices = tvm.topi.cuda.sort.topk(data, k=3, axis=-1, ret_type='both', is_ascend=False)",
        "torch": "values, indices = torch.topk(data, k=3, dim=-1, largest=True, sorted=True)"
      }
    ],
    "constraints": "Same as `tvm.topi.sort.topk`. TVM `ret_type` needs to be handled by selecting the appropriate return value(s) from `torch.topk` (which always returns `(values, indices)`). `is_ascend=True` in TVM means `largest=False` in PyTorch, and vice-versa. PyTorch's `topk` implies `sorted=True` by default, matching TVM.",
    "notes": "This is essentially the same as `tvm.topi.sort.topk`, just specific to CUDA. The mapping constraints remain the same.",
    "confidence": 0.9
  },
  {
    "tvm_api": "tvm.topi.cuda.stft.stft",
    "torch_api": "torch.stft",
    "mapping_type": "direct",
    "direction": "tvm_to_torch",
    "tvm_pattern": "tvm.topi.cuda.stft.stft({{data}}, {{n_fft}}, {{hop_length}}, {{win_length}}, {{window}}, normalized={{normalized}}, onesided={{onesided}}, output_shape={{output_shape}})",
    "torch_pattern": "torch.stft(input={{data}}, n_fft={{n_fft}}, hop_length={{hop_length}}, win_length={{win_length}}, window={{window}}, center=True, pad_mode='reflect', normalized={{normalized}}, onesided={{onesided}}, return_complex=True)",
    "arg_mapping": {
      "data": "input",
      "n_fft": "n_fft",
      "hop_length": "hop_length",
      "win_length": "win_length",
      "window": "window",
      "normalized": "normalized",
      "onesided": "onesided",
      "output_shape": "null"
    },
    "example_pairs": [
      {
        "tvm": "spec = tvm.topi.cuda.stft.stft(data, 2048, 512, 2048, window_tensor, normalized=False, onesided=True, output_shape=(1025, 100))",
        "torch": "spec = torch.stft(input=data, n_fft=2048, hop_length=512, win_length=2048, window=window_tensor, center=True, pad_mode='reflect', normalized=False, onesided=True, return_complex=True)"
      }
    ],
    "constraints": "Same as `tvm.topi.stft.stft`. PyTorch `stft` has `center`, `pad_mode`, and `return_complex` parameters not explicitly in TVM's signature but typically assumed. `output_shape` in TVM is for inference but not a direct input to PyTorch's `stft` function for computation. `return_complex=True` is strongly preferred in modern PyTorch for real inputs.",
    "notes": "This is essentially the same as `tvm.topi.stft.stft`, just specific to CUDA. The mapping constraints remain the same.",
    "confidence": 0.9
  },
  {
    "tvm_api": "tvm.topi.cuda.unique.unique",
    "torch_api": "torch.unique",
    "mapping_type": "direct",
    "direction": "tvm_to_torch",
    "tvm_pattern": "tvm.topi.cuda.unique.unique({{data}}, is_sorted={{is_sorted}}, return_counts={{return_counts}})",
    "torch_pattern": "torch.unique({{input}}, sorted={{is_sorted}}, return_counts={{return_counts}})",
    "arg_mapping": {
      "data": "input",
      "is_sorted": "is_sorted",
      "return_counts": "return_counts"
    },
    "example_pairs": [
      {
        "tvm": "unique_vals, counts = tvm.topi.cuda.unique(data, is_sorted=True, return_counts=True)",
        "torch": "unique_vals, counts = torch.unique(data, sorted=True, return_counts=True)"
      }
    ],
    "constraints": "Same as `tvm.topi.unique.unique`. TVM notes that `output` and `counts` are padded to have the same length as `data`, and elements with index >= num_unique[0] have undefined value. PyTorch's `torch.unique` returns tensors with actual unique elements and counts, which might be shorter. If padding is explicitly required, a composite operation would be needed.",
    "notes": "This is essentially the same as `tvm.topi.unique.unique`, just specific to CUDA. The mapping constraints remain the same.",
    "confidence": 0.9
  },
  {
    "tvm_api": "tvm.topi.image.grid_sample.affine_grid",
    "torch_api": "torch.nn.functional.affine_grid",
    "mapping_type": "direct",
    "direction": "tvm_to_torch",
    "tvm_pattern": "tvm.topi.image.grid_sample.affine_grid({{data}}, {{target_shape}})",
    "torch_pattern": "torch.nn.functional.affine_grid(theta={{theta}}, size={{size}}, align_corners=True)",
    "arg_mapping": {
      "data": "theta",
      "target_shape": "size"
    },
    "example_pairs": [
      {
        "tvm": "grid = tvm.topi.image.grid_sample.affine_grid(theta_matrix, (224, 224))",
        "torch": "grid = torch.nn.functional.affine_grid(theta=theta_matrix, size=[N, C, 224, 224], align_corners=True)"
      }
    ],
    "constraints": "PyTorch `affine_grid`'s `size` parameter expects the full output tensor size including batch and channel dimensions (e.g., `[N, C, H, W]`), whereas TVM's `target_shape` is just `(H, W)`. Also, PyTorch has an `align_corners` parameter (defaulting to `False` in PyTorch 1.x, but often `True` in image processing contexts) that needs careful consideration. TVM's `affine_grid` doesn't explicitly expose `align_corners` in the signature but typically implies a specific behavior.",
    "notes": "Partial direct mapping. `target_shape` needs to be extended to the full output tensor size for PyTorch. `align_corners` parameter is a key difference.",
    "confidence": 0.8
  },
  {
    "tvm_api": "tvm.topi.image.grid_sample.grid_sample",
    "torch_api": "torch.nn.functional.grid_sample",
    "mapping_type": "direct",
    "direction": "tvm_to_torch",
    "tvm_pattern": "tvm.topi.image.grid_sample.grid_sample({{data}}, {{grid}}, method={{method}}, layout={{layout}}, padding_mode={{padding_mode}}, align_corners={{align_corners}})",
    "torch_pattern": "torch.nn.functional.grid_sample(input={{input}}, grid={{grid}}, mode={{mode}}, padding_mode={{padding_mode}}, align_corners={{align_corners}})",
    "arg_mapping": {
      "data": "input",
      "grid": "grid",
      "method": "mode",
      "layout": "null",
      "padding_mode": "padding_mode",
      "align_corners": "align_corners"
    },
    "example_pairs": [
      {
        "tvm": "sampled_features = tvm.topi.image.grid_sample(data_tensor, grid_tensor, method='bilinear', layout='NCHW', padding_mode='zeros', align_corners=True)",
        "torch": "sampled_features = torch.nn.functional.grid_sample(input=data_tensor, grid=grid_tensor, mode='bilinear', padding_mode='zeros', align_corners=True)"
      }
    ],
    "constraints": "TVM `method` maps to PyTorch `mode`. TVM `layout` is not a direct parameter in PyTorch's `grid_sample` as PyTorch's `NCHW` layout is typically assumed for image ops or handled by input tensor format. Ensure consistency in `align_corners` and `padding_mode` values.",
    "notes": "Direct mapping. The `layout` parameter in TVM relates to internal data representation, while PyTorch's `grid_sample` implicitly handles data based on standard tensor layouts (like NCHW).",
    "confidence": 0.95
  },
  {
    "tvm_api": "tvm.topi.nn.batch_norm.batch_norm",
    "torch_api": "torch.nn.functional.batch_norm",
    "mapping_type": "direct",
    "direction": "tvm_to_torch",
    "tvm_pattern": "tvm.topi.nn.batch_norm.batch_norm({{data}}, {{gamma}}, {{beta}}, {{moving_mean}}, {{moving_var}}, axis={{axis}}, epsilon={{epsilon}}, center={{center}}, scale={{scale}})",
    "torch_pattern": "torch.nn.functional.batch_norm(input={{input}}, running_mean={{running_mean}}, running_var={{running_var}}, weight={{weight}}, bias={{bias}}, training={{training}}, momentum={{momentum}}, eps={{eps}})",
    "arg_mapping": {
      "data": "input",
      "gamma": "weight",
      "beta": "bias",
      "moving_mean": "running_mean",
      "moving_var": "running_var",
      "axis": "null",
      "epsilon": "eps",
      "center": "null",
      "scale": "null"
    },
    "example_pairs": [
      {
        "tvm": "out_tensors = tvm.topi.nn.batch_norm(data, gamma, beta, mean, variance, axis=1, epsilon=1e-5, center=True, scale=True)",
        "torch": "output = torch.nn.functional.batch_norm(input=data, running_mean=mean, running_var=variance, weight=gamma, bias=beta, training=True, momentum=0.1, eps=1e-5)"
      }
    ],
    "constraints": "PyTorch `batch_norm` includes `training` (bool) and `momentum` (float) parameters which are not explicitly in the TVM signature provided but are crucial. TVM `axis` specifies the channel dimension, which is implicitly handled by PyTorch's function (typically the second dimension for NCHW). TVM `center` and `scale` parameters are implicit in PyTorch (if `bias` and `weight` tensors are provided, they are applied). This mapping assumes `training=True` and a default `momentum=0.1` for PyTorch, or these must be inferred/set. For `center=False` or `scale=False` in TVM, the corresponding `bias` or `weight` tensors should be `None` in PyTorch.",
    "notes": "The mapping requires careful handling of implicit parameters and the interpretation of TVM's `center` and `scale` flags, which determine if `beta` and `gamma` are used.",
    "confidence": 0.85
  },
  {
    "tvm_api": "tvm.topi.nn.conv1d.conv1d",
    "torch_api": "torch.nn.functional.conv1d",
    "mapping_type": "direct",
    "direction": "tvm_to_torch",
    "tvm_pattern": "tvm.topi.nn.conv1d.conv1d({{data}}, {{kernel}}, strides={{strides}}, padding={{padding}}, dilation={{dilation}}, data_layout={{data_layout}}, kernel_layout={{kernel_layout}}, out_dtype={{out_dtype}})",
    "torch_pattern": "torch.nn.functional.conv1d(input={{input}}, weight={{weight}}, bias=None, stride={{stride}}, padding={{padding}}, dilation={{dilation}}, groups=1)",
    "arg_mapping": {
      "data": "input",
      "kernel": "weight",
      "strides": "stride",
      "padding": "padding",
      "dilation": "dilation",
      "data_layout": "null",
      "kernel_layout": "null",
      "out_dtype": "null"
    },
    "example_pairs": [
      {
        "tvm": "output = tvm.topi.nn.conv1d(input_data, kernel_data, strides=1, padding=0, dilation=1, data_layout='NCW')",
        "torch": "output = torch.nn.functional.conv1d(input=input_data, weight=kernel_data, stride=1, padding=0, dilation=1)"
      }
    ],
    "constraints": "PyTorch `conv1d` defaults to `bias=None` and `groups=1`. If these are non-default in TVM, they need to be specified in PyTorch. TVM `data_layout` and `kernel_layout` indicate expected input/kernel formats, while PyTorch implicitly handles these (typically `NCW` for input, `OIW` for kernel). `out_dtype` is not directly exposed as a parameter in `torch.nn.functional.conv1d`.",
    "notes": "Mostly direct mapping, but TVM's layout parameters might require pre-transposition of data/kernel if PyTorch's default assumptions differ from TVM's. Assumes PyTorch's default `groups=1` and `bias=None` behavior.",
    "confidence": 0.9
  },
  {
    "tvm_api": "tvm.topi.nn.conv2d.conv2d",
    "torch_api": "torch.nn.functional.conv2d",
    "mapping_type": "direct",
    "direction": "tvm_to_torch",
    "tvm_pattern": "tvm.topi.nn.conv2d.conv2d({{input}}, {{filter}}, strides={{strides}}, padding={{padding}}, dilation={{dilation}}, data_layout={{data_layout}}, kernel_layout={{kernel_layout}}, out_dtype={{out_dtype}})",
    "torch_pattern": "torch.nn.functional.conv2d(input={{input}}, weight={{weight}}, bias=None, stride={{stride}}, padding={{padding}}, dilation={{dilation}}, groups=1)",
    "arg_mapping": {
      "input": "input",
      "filter": "weight",
      "strides": "stride",
      "padding": "padding",
      "dilation": "dilation",
      "data_layout": "null",
      "kernel_layout": "null",
      "out_dtype": "null"
    },
    "example_pairs": [
      {
        "tvm": "output = tvm.topi.nn.conv2d(input_data, filter_data, strides=1, padding=0, dilation=1, data_layout='NCHW')",
        "torch": "output = torch.nn.functional.conv2d(input=input_data, weight=filter_data, stride=1, padding=0, dilation=1)"
      }
    ],
    "constraints": "PyTorch `conv2d` defaults to `bias=None` and `groups=1`. If these are non-default in TVM, they need to be specified in PyTorch. TVM `data_layout` and `kernel_layout` indicate expected input/kernel formats, while PyTorch implicitly handles these (typically `NCHW` for input, `OIHW` for kernel). `out_dtype` is not directly exposed as a parameter in `torch.nn.functional.conv2d`.",
    "notes": "Mostly direct mapping, but TVM's layout parameters might require pre-transposition of data/kernel if PyTorch's default assumptions differ from TVM's. Assumes PyTorch's default `groups=1` and `bias=None` behavior.",
    "confidence": 0.9
  },
  {
    "tvm_api": "tvm.topi.nn.dense.matmul",
    "torch_api": "torch.matmul",
    "mapping_type": "direct",
    "direction": "tvm_to_torch",
    "tvm_pattern": "tvm.topi.nn.dense.matmul(tensor_a={{tensor_a}}, tensor_b={{tensor_b}}, bias={{bias}}, out_dtype={{out_dtype}}, transpose_a={{transpose_a}}, transpose_b={{transpose_b}})",
    "torch_pattern": "torch.matmul({{a_processed}}, {{b_processed}}) + ({{bias}} if {{bias}} is not None else 0)",
    "arg_mapping": {
      "tensor_a": "a_original",
      "tensor_b": "b_original",
      "bias": "bias",
      "out_dtype": "null",
      "transpose_a": "transpose_a",
      "transpose_b": "transpose_b"
    },
    "example_pairs": [
      {
        "tvm": "output = tvm.topi.nn.dense.matmul(A, B, bias=C, transpose_a=False, transpose_b=False)",
        "torch": "output = torch.matmul(A, B) + C"
      },
      {
        "tvm": "output = tvm.topi.nn.dense.matmul(A, B, bias=None, transpose_a=True, transpose_b=False)",
        "torch": "output = torch.matmul(A.T, B)"
      }
    ],
    "constraints": "PyTorch `torch.matmul` does not have `bias` as a direct argument; it needs to be added separately. Also, `transpose_a` and `transpose_b` need to be applied to the input tensors using `.T` or `torch.transpose` before the `matmul` call. `out_dtype` is not directly supported as a `matmul` argument in PyTorch and would require an explicit `.to(dtype)` call on the result.",
    "notes": "Composite mapping due to `bias` and `transpose` handling. TVM `dense.matmul` is essentially `linear` without activation, where `bias` is optional and transpositions are flags.",
    "confidence": 0.85
  },
  {
    "tvm_api": "tvm.topi.nn.elemwise.relu",
    "torch_api": "torch.relu",
    "mapping_type": "direct",
    "direction": "tvm_to_torch",
    "tvm_pattern": "tvm.topi.nn.elemwise.relu({{x}})",
    "torch_pattern": "torch.relu({{input}})",
    "arg_mapping": {
      "x": "input"
    },
    "example_pairs": [
      {
        "tvm": "y = tvm.topi.nn.elemwise.relu(x)",
        "torch": "y = torch.relu(x)"
      }
    ],
    "constraints": "Applies element-wise ReLU activation. Similar to `x.relu()` method.",
    "notes": "Direct element-wise ReLU. PyTorch `torch.relu` is an alias for `torch.nn.functional.relu`.",
    "confidence": 0.98
  },
  {
    "tvm_api": "tvm.topi.nn.elemwise.leaky_relu",
    "torch_api": "torch.nn.functional.leaky_relu",
    "mapping_type": "direct",
    "direction": "tvm_to_torch",
    "tvm_pattern": "tvm.topi.nn.elemwise.leaky_relu({{x}}, {{alpha}})",
    "torch_pattern": "torch.nn.functional.leaky_relu(input={{input}}, negative_slope={{alpha}})",
    "arg_mapping": {
      "x": "input",
      "alpha": "negative_slope"
    },
    "example_pairs": [
      {
        "tvm": "y = tvm.topi.nn.elemwise.leaky_relu(x, 0.1)",
        "torch": "y = torch.nn.functional.leaky_relu(input=x, negative_slope=0.1)"
      }
    ],
    "constraints": "Applies element-wise Leaky ReLU activation. PyTorch uses `negative_slope` for `alpha`.",
    "notes": "Direct mapping. Argument name change from `alpha` to `negative_slope`.",
    "confidence": 0.98
  },
  {
    "tvm_api": "tvm.topi.nn.elemwise.prelu",
    "torch_api": "torch.nn.functional.prelu",
    "mapping_type": "direct",
    "direction": "tvm_to_torch",
    "tvm_pattern": "tvm.topi.nn.elemwise.prelu({{x}}, {{slope}}, axis={{axis}})",
    "torch_pattern": "torch.nn.functional.prelu(input={{input}}, weight={{weight}})",
    "arg_mapping": {
      "x": "input",
      "slope": "weight",
      "axis": "null"
    },
    "example_pairs": [
      {
        "tvm": "y = tvm.topi.nn.elemwise.prelu(x, slope_tensor, axis=1)",
        "torch": "y = torch.nn.functional.prelu(input=x, weight=slope_tensor)"
      }
    ],
    "constraints": "PyTorch `prelu` handles the `axis` parameter implicitly based on `weight`'s shape. If `weight` has `numel == 1`, it's a scalar PReLU. Otherwise, `weight`'s `numel` must match the channel size (usually `input.shape[1]`). TVM `axis` specifies this channel axis.",
    "notes": "Direct mapping. The `axis` parameter in TVM is inferred by PyTorch from the `weight` tensor's shape. `slope` in TVM maps to `weight` in PyTorch.",
    "confidence": 0.95
  },
  {
    "tvm_api": "tvm.topi.nn.layer_norm.layer_norm",
    "torch_api": "torch.nn.functional.layer_norm",
    "mapping_type": "direct",
    "direction": "tvm_to_torch",
    "tvm_pattern": "tvm.topi.nn.layer_norm.layer_norm({{data}}, {{gamma}}, {{beta}}, {{axis}}, epsilon={{epsilon}})",
    "torch_pattern": "torch.nn.functional.layer_norm(input={{input}}, normalized_shape={{normalized_shape}}, weight={{weight}}, bias={{bias}}, eps={{eps}})",
    "arg_mapping": {
      "data": "input",
      "gamma": "weight",
      "beta": "bias",
      "axis": "null",
      "epsilon": "eps"
    },
    "example_pairs": [
      {
        "tvm": "normed = tvm.topi.nn.layer_norm(data, gamma, beta, axis=[1,2,3], epsilon=1e-5)",
        "torch": "normed = torch.nn.functional.layer_norm(input=data, normalized_shape=data.shape[1:], weight=gamma, bias=beta, eps=1e-5)"
      }
    ],
    "constraints": "PyTorch `layer_norm`'s `normalized_shape` parameter expects the *tuple* of dimensions over which to normalize (e.g., `input.shape[axis:]` if `axis` is the first dim to normalize), not just a single `axis` integer or list of integers. If `axis` in TVM is a list of dimensions to normalize, then `normalized_shape` should be `[data.shape[d] for d in axis]`. If `gamma` or `beta` are `None` in TVM, they should also be `None` in PyTorch.",
    "notes": "Direct mapping for the core functionality. `axis` from TVM needs to be converted to `normalized_shape` for PyTorch. `gamma` maps to `weight`, `beta` maps to `bias`.",
    "confidence": 0.9
  },
  {
    "tvm_api": "tvm.topi.nn.loss.nll_loss",
    "torch_api": "torch.nn.functional.nll_loss",
    "mapping_type": "direct",
    "direction": "tvm_to_torch",
    "tvm_pattern": "tvm.topi.nn.loss.nll_loss({{predictions}}, {{targets}}, {{weights}}, reduction={{reduction}}, ignore_index={{ignore_index}})",
    "torch_pattern": "torch.nn.functional.nll_loss(input={{input}}, target={{target}}, weight={{weight}}, reduction={{reduction}}, ignore_index={{ignore_index}})",
    "arg_mapping": {
      "predictions": "input",
      "targets": "target",
      "weights": "weight",
      "reduction": "reduction",
      "ignore_index": "ignore_index"
    },
    "example_pairs": [
      {
        "tvm": "loss = tvm.topi.nn.loss.nll_loss(preds, true_labels, weights_tensor, reduction='mean', ignore_index=-1)",
        "torch": "loss = torch.nn.functional.nll_loss(input=preds, target=true_labels, weight=weights_tensor, reduction='mean', ignore_index=-1)"
      }
    ],
    "constraints": "Parameters like `size_average` and `reduce` are deprecated in PyTorch in favor of `reduction`, which should be consistent. The shapes and types of `predictions`, `targets`, and `weights` must conform to PyTorch's `nll_loss` expectations.",
    "notes": "Direct mapping. TVM arguments correspond directly to PyTorch's `nll_loss` arguments.",
    "confidence": 0.98
  },
  {
    "tvm_api": "tvm.topi.nn.lstm.lstm",
    "torch_api": "torch.nn.LSTM",
    "mapping_type": "no_mapping",
    "direction": "tvm_to_torch",
    "tvm_pattern": null,
    "torch_pattern": null,
    "arg_mapping": {},
    "example_pairs": [],
    "constraints": "Not convertible",
    "notes": "NO_MAPPING: TVM's `lstm` is a low-level TE scan implementation with many internal parameters (e.g., `Wi`, `Wh`, `Bi`, `Bh`, `p_i`, `p_f`, `p_o`, activation functions, `weight_layout`). PyTorch's `torch.nn.LSTM` is a high-level module, and `torch.nn.functional.lstm` is a functional interface that takes concatenated weight/bias tensors. A direct, general mapping is not feasible without significant re-architecture of the TVM definition into PyTorch's tensor conventions for LSTM weights and state, which typically involve combining all internal weights and biases into fewer larger tensors.",
    "confidence": 0.3
  },
  {
    "tvm_api": "tvm.topi.nn.pad.pad",
    "torch_api": "torch.nn.functional.pad",
    "mapping_type": "direct",
    "direction": "tvm_to_torch",
    "tvm_pattern": "tvm.topi.nn.pad.pad({{data}}, {{pad_before}}, pad_after={{pad_after}}, pad_value={{pad_value}})",
    "torch_pattern": "torch.nn.functional.pad(input={{input}}, pad={{pad_list}}, mode='constant', value={{value}})",
    "arg_mapping": {
      "data": "input",
      "pad_before": "pad_before",
      "pad_after": "pad_after",
      "pad_value": "value"
    },
    "example_pairs": [
      {
        "tvm": "padded_tensor = tvm.topi.nn.pad(input_data, [1, 1], [0, 0], pad_value=0.0)",
        "torch": "padded_tensor = torch.nn.functional.pad(input=input_data, pad=[0, 0, 1, 1], mode='constant', value=0.0)"
      },
      {
        "tvm": "padded_tensor = tvm.topi.nn.pad(input_data, [1, 2], [3, 4], pad_value=5.0)",
        "torch": "padded_tensor = torch.nn.functional.pad(input=input_data, pad=[4, 3, 2, 1], mode='constant', value=5.0)"
      }
    ],
    "constraints": "PyTorch `torch.nn.functional.pad` `pad` argument is a tuple/list of (padding_left, padding_right, padding_top, padding_bottom, ...) for the last N dimensions, *in reverse order of dimensions*. TVM's `pad_before` and `pad_after` are lists of padding amounts for each dimension, in order. This requires transforming TVM's `pad_before` and `pad_after` into PyTorch's `pad_list` format. TVM `pad_after` defaults to `pad_before` if `None`, which PyTorch doesn't do implicitly.",
    "notes": "Composite mapping due to the difference in `pad` argument format. PyTorch `pad_list` should be constructed by zipping and reversing `pad_before` and `pad_after` values.",
    "confidence": 0.85
  },
  {
    "tvm_api": "tvm.topi.nn.softmax.softmax",
    "torch_api": "torch.softmax",
    "mapping_type": "direct",
    "direction": "tvm_to_torch",
    "tvm_pattern": "tvm.topi.nn.softmax.softmax({{x}}, axis={{axis}})",
    "torch_pattern": "torch.softmax(input={{input}}, dim={{axis}})",
    "arg_mapping": {
      "x": "input",
      "axis": "dim"
    },
    "example_pairs": [
      {
        "tvm": "y = tvm.topi.nn.softmax.softmax(x, axis=-1)",
        "torch": "y = torch.softmax(input=x, dim=-1)"
      },
      {
        "tvm": "y = tvm.topi.nn.softmax.softmax(x, axis=1)",
        "torch": "y = torch.softmax(input=x, dim=1)"
      }
    ],
    "constraints": "Input `x` should be a tensor. TVM `axis` maps to PyTorch `dim`. PyTorch `softmax` can also take an optional `dtype` argument.",
    "notes": "Direct mapping.",
    "confidence": 0.98
  },
  {
    "tvm_api": "tvm.topi.nn.softmax.log_softmax",
    "torch_api": "torch.log_softmax",
    "mapping_type": "direct",
    "direction": "tvm_to_torch",
    "tvm_pattern": "tvm.topi.nn.softmax.log_softmax({{x}}, axis={{axis}})",
    "torch_pattern": "torch.log_softmax(input={{input}}, dim={{axis}})",
    "arg_mapping": {
      "x": "input",
      "axis": "dim"
    },
    "example_pairs": [
      {
        "tvm": "y = tvm.topi.nn.softmax.log_softmax(x, axis=-1)",
        "torch": "y = torch.log_softmax(input=x, dim=-1)"
      },
      {
        "tvm": "y = tvm.topi.nn.softmax.log_softmax(x, axis=1)",
        "torch": "y = torch.log_softmax(input=x, dim=1)"
      }
    ],
    "constraints": "Input `x` should be a tensor. TVM `axis` maps to PyTorch `dim`. PyTorch `log_softmax` can also take an optional `dtype` argument.",
    "notes": "Direct mapping.",
    "confidence": 0.98
  },
  {
    "tvm_api": "tvm.topi.random.kernel.uniform",
    "torch_api": "torch.rand",
    "mapping_type": "composite",
    "direction": "tvm_to_torch",
    "tvm_pattern": "tvm.topi.random.kernel.uniform({{gen}}, {{low}}, {{high}}, {{out_shape}}, {{out_dtype}})",
    "torch_pattern": "({{high}} - {{low}}) * torch.rand({{out_shape}}, dtype={{out_dtype}}) + {{low}}",
    "arg_mapping": {
      "gen": "null",
      "low": "low",
      "high": "high",
      "out_shape": "out_shape",
      "out_dtype": "out_dtype"
    },
    "example_pairs": [
      {
        "tvm": "random_tensor = tvm.topi.random.kernel.uniform(gen_key, 0.0, 1.0, (10, 20), 'float32')",
        "torch": "random_tensor = (1.0 - 0.0) * torch.rand((10, 20), dtype=torch.float32) + 0.0"
      },
      {
        "tvm": "random_tensor = tvm.topi.random.kernel.uniform(gen_key, -5, 5, (5,), 'int64')",
        "torch": "random_tensor = (5 - (-5)) * torch.rand((5,), dtype=torch.int64) + (-5)"
      }
    ],
    "constraints": "PyTorch `torch.rand` generates numbers in `[0, 1)`. To scale to `[low, high)`, a linear transformation `(high - low) * rand + low` is needed. TVM `gen` (ThreefryKey) is for deterministic random number generation and has no direct functional equivalent in PyTorch's `rand` function which uses global/thread-local generators.",
    "notes": "Composite mapping. PyTorch offers `torch.rand` (uniform [0,1)) and `Tensor.uniform_` (in-place uniform). The TVM `gen` parameter is a significant difference as PyTorch's random operations typically rely on global or `torch.Generator` instances.",
    "confidence": 0.8
  },
  {
    "tvm_api": "tvm.topi.random.kernel.normal",
    "torch_api": "torch.randn",
    "mapping_type": "composite",
    "direction": "tvm_to_torch",
    "tvm_pattern": "tvm.topi.random.kernel.normal({{gen}}, {{mean}}, {{scale}}, {{out_shape}}, {{out_dtype}})",
    "torch_pattern": "{{scale}} * torch.randn({{out_shape}}, dtype={{out_dtype}}) + {{mean}}",
    "arg_mapping": {
      "gen": "null",
      "mean": "mean",
      "scale": "scale",
      "out_shape": "out_shape",
      "out_dtype": "out_dtype"
    },
    "example_pairs": [
      {
        "tvm": "random_tensor = tvm.topi.random.kernel.normal(gen_key, 0.0, 1.0, (10, 20), 'float32')",
        "torch": "random_tensor = 1.0 * torch.randn((10, 20), dtype=torch.float32) + 0.0"
      },
      {
        "tvm": "random_tensor = tvm.topi.random.kernel.normal(gen_key, 10, 2, (5,), 'float32')",
        "torch": "random_tensor = 2 * torch.randn((5,), dtype=torch.float32) + 10"
      }
    ],
    "constraints": "PyTorch `torch.randn` generates numbers from a standard normal distribution (mean 0, std 1). To scale to `mean` and `scale`, a transformation `scale * randn + mean` is needed. TVM `gen` (ThreefryKey) is for deterministic random number generation and has no direct functional equivalent in PyTorch's `randn` function which uses global/thread-local generators.",
    "notes": "Composite mapping. PyTorch offers `torch.randn` (standard normal) and `Tensor.normal_` (in-place normal). The TVM `gen` parameter is a significant difference as PyTorch's random operations typically rely on global or `torch.Generator` instances.",
    "confidence": 0.8
  },
  {
    "tvm_api": "tvm.topi.random.kernel.multinomial",
    "torch_api": "torch.multinomial",
    "mapping_type": "direct",
    "direction": "tvm_to_torch",
    "tvm_pattern": "tvm.topi.random.kernel.multinomial({{gen}}, {{probs}}, {{num_samples}})",
    "torch_pattern": "torch.multinomial(input={{input}}, num_samples={{num_samples}}, replacement=True)",
    "arg_mapping": {
      "gen": "null",
      "probs": "input",
      "num_samples": "num_samples"
    },
    "example_pairs": [
      {
        "tvm": "samples = tvm.topi.random.kernel.multinomial(gen_key, probs_tensor, 5)",
        "torch": "samples = torch.multinomial(input=probs_tensor, num_samples=5, replacement=True)"
      }
    ],
    "constraints": "PyTorch `multinomial` has a `replacement` parameter, which defaults to `False`. TVM's behavior isn't specified in the snippet but typically multinomial sampling can be with or without replacement. Assuming sampling *with* replacement, so `replacement=True` is needed in PyTorch. TVM `gen` parameter (ThreefryKey) is for deterministic random generation and has no direct equivalent in PyTorch's `multinomial` functional API.",
    "notes": "Direct mapping for the core multinomial sampling. The `gen` parameter is a difference, and `replacement` needs explicit consideration.",
    "confidence": 0.85
  },
  {
    "tvm_api": "tvm.topi.testing.batch_norm.batch_norm",
    "torch_api": "torch.nn.functional.batch_norm",
    "mapping_type": "direct",
    "direction": "tvm_to_torch",
    "tvm_pattern": "tvm.topi.testing.batch_norm.batch_norm({{x}}, {{gamma}}, {{beta}}, {{moving_mean}}, {{moving_var}}, axis={{axis}}, epsilon={{epsilon}}, center={{center}}, scale={{scale}})",
    "torch_pattern": "torch.nn.functional.batch_norm(input={{input}}, running_mean={{running_mean}}, running_var={{running_var}}, weight={{weight}}, bias={{bias}}, training={{training}}, momentum={{momentum}}, eps={{eps}})",
    "arg_mapping": {
      "x": "input",
      "gamma": "weight",
      "beta": "bias",
      "moving_mean": "running_mean",
      "moving_var": "running_var",
      "axis": "null",
      "epsilon": "eps",
      "center": "null",
      "scale": "null"
    },
    "example_pairs": [
      {
        "tvm": "output = tvm.topi.testing.batch_norm.batch_norm(x, gamma, beta, mean, variance, axis=1, epsilon=1e-5, center=True, scale=True)",
        "torch": "output = torch.nn.functional.batch_norm(input=x, running_mean=mean, running_var=variance, weight=gamma, bias=beta, training=True, momentum=0.1, eps=1e-5)"
      }
    ],
    "constraints": "This is a NumPy-based TVM testing utility. Its parameters match the `tvm.topi.nn.batch_norm.batch_norm` and thus the same mapping constraints apply, specifically regarding `training`, `momentum`, and the implicit handling of `axis`, `center`, and `scale` by PyTorch.",
    "notes": "Same as `tvm.topi.nn.batch_norm.batch_norm`, but for testing. The mapping logic is identical.",
    "confidence": 0.85
  },
  {
    "tvm_api": "tvm.topi.testing.common.dispatch",
    "torch_api": null,
    "mapping_type": "no_mapping",
    "direction": "tvm_to_torch",
    "tvm_pattern": null,
    "torch_pattern": null,
    "arg_mapping": {},
    "example_pairs": [],
    "constraints": "Not convertible",
    "notes": "NO_MAPPING: This TVM function is a utility for dispatching to different schedules based on the `tvm.target.Target`. This is a TVM-specific infrastructure concept for hardware backend compilation and optimization, which has no direct equivalent in PyTorch's user-facing API. PyTorch handles backend dispatch (CPU/CUDA) internally.",
    "confidence": 0.1
  },
  {
    "tvm_api": "tvm.topi.testing.nll_loss.nll_loss",
    "torch_api": "torch.nn.functional.nll_loss",
    "mapping_type": "direct",
    "direction": "tvm_to_torch",
    "tvm_pattern": "tvm.topi.testing.nll_loss.nll_loss({{predictions}}, {{targets}}, {{weights}}, reduction={{reduction}}, ignore_index={{ignore_index}})",
    "torch_pattern": "torch.nn.functional.nll_loss(input={{input}}, target={{target}}, weight={{weight}}, reduction={{reduction}}, ignore_index={{ignore_index}})",
    "arg_mapping": {
      "predictions": "input",
      "targets": "target",
      "weights": "weight",
      "reduction": "reduction",
      "ignore_index": "ignore_index"
    },
    "example_pairs": [
      {
        "tvm": "loss = tvm.topi.testing.nll_loss.nll_loss(preds, true_labels, weights_tensor, reduction='mean', ignore_index=-1)",
        "torch": "loss = torch.nn.functional.nll_loss(input=preds, target=true_labels, weight=weights_tensor, reduction='mean', ignore_index=-1)"
      }
    ],
    "constraints": "This is a NumPy-based TVM testing utility. Its parameters match the `tvm.topi.nn.loss.nll_loss` and thus the same direct mapping applies.",
    "notes": "Same as `tvm.topi.nn.loss.nll_loss`, but for testing. The mapping logic is identical.",
    "confidence": 0.98
  },
  {
    "tvm_api": "tvm.topi.testing.one_hot.one_hot",
    "torch_api": "torch.nn.functional.one_hot",
    "mapping_type": "composite",
    "direction": "tvm_to_torch",
    "tvm_pattern": "tvm.topi.testing.one_hot.one_hot({{indices}}, {{on_value}}, {{off_value}}, {{depth}}, {{axis}}, {{dtype}})",
    "torch_pattern": "torch.nn.functional.one_hot({{input}}, num_classes={{depth}}).to(dtype={{dtype}}) * ({{on_value}} - {{off_value}}) + {{off_value}}",
    "arg_mapping": {
      "indices": "input",
      "on_value": "on_value",
      "off_value": "off_value",
      "depth": "depth",
      "axis": "null",
      "dtype": "dtype"
    },
    "example_pairs": [
      {
        "tvm": "one_hot_tensor = tvm.topi.testing.one_hot.one_hot(idx, 1.0, 0.0, 10, -1, 'float32')",
        "torch": "one_hot_tensor = torch.nn.functional.one_hot(idx, num_classes=10).to(dtype=torch.float32) * (1.0 - 0.0) + 0.0"
      }
    ],
    "constraints": "This is a NumPy-based TVM testing utility. Its parameters match the `tvm.topi.transform.one_hot` and thus the same composite mapping applies, regarding the handling of `on_value`, `off_value`, and the `axis` parameter.",
    "notes": "Same as `tvm.topi.transform.one_hot`, but for testing. The mapping logic is identical.",
    "confidence": 0.8
  },
  {
    "tvm_api": "tvm.topi.x86.concat.concatenate",
    "torch_api": "torch.cat",
    "mapping_type": "direct",
    "direction": "tvm_to_torch",
    "tvm_pattern": "tvm.topi.x86.concat.concatenate({{data}}, axis={{axis}})",
    "torch_pattern": "torch.cat({{tensors}}, dim={{axis}})",
    "arg_mapping": {
      "data": "tensors",
      "axis": "dim"
    },
    "example_pairs": [
      {
        "tvm": "y = tvm.topi.x86.concat.concatenate((x1, x2), axis=0)",
        "torch": "y = torch.cat((x1, x2), dim=0)"
      }
    ],
    "constraints": "This is an x86-specific optimized implementation, but the core functionality is standard concatenation. PyTorch `torch.cat` is optimized for various backends. All input tensors must have the same shape except in the dimension `axis`.",
    "notes": "Direct mapping to `torch.cat`. The `data` parameter (tuple of tensors) maps to `tensors`, and `axis` maps to `dim`. The x86 specific optimization is handled by PyTorch's internal dispatch.",
    "confidence": 0.98
  }
]