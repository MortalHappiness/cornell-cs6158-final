[
  {
    "torch_api": "torch.__init__.compile",
    "tvm_api": null,
    "mapping_type": "no_mapping",
    "direction": "torch_to_tvm",
    "torch_pattern": null,
    "tvm_pattern": null,
    "arg_mapping": {},
    "example_pairs": [],
    "constraints": "Not convertible",
    "notes": "NO_MAPPING: torch.compile is a high-level API to optimize PyTorch models, often using TorchInductor as a backend. tvm.relay.backend.vm.compile is used to compile a TVM Relay IRModule. The input types and overall compilation ecosystems are fundamentally different, requiring significant graph conversion not covered by a direct API mapping.",
    "confidence": 0.3
  },
  {
    "torch_api": "torch.__init__.compile",
    "tvm_api": null,
    "mapping_type": "no_mapping",
    "direction": "torch_to_tvm",
    "torch_pattern": null,
    "tvm_pattern": null,
    "arg_mapping": {},
    "example_pairs": [],
    "constraints": "Not convertible",
    "notes": "NO_MAPPING: See API 1. Same reasoning. torch.compile is a high-level API to optimize PyTorch models, often using TorchInductor as a backend. tvm.relay.backend.vm.compile is used to compile a TVM Relay IRModule. The input types and overall compilation ecosystems are fundamentally different, requiring significant graph conversion not covered by a direct API mapping.",
    "confidence": 0.3
  },
  {
    "torch_api": "torch.__init__.compile",
    "tvm_api": null,
    "mapping_type": "no_mapping",
    "direction": "torch_to_tvm",
    "torch_pattern": null,
    "tvm_pattern": null,
    "arg_mapping": {},
    "example_pairs": [],
    "constraints": "Not convertible",
    "notes": "NO_MAPPING: See API 1. Same reasoning. torch.compile is a high-level API to optimize PyTorch models, often using TorchInductor as a backend. tvm.relay.backend.vm.compile is used to compile a TVM Relay IRModule. The input types and overall compilation ecosystems are fundamentally different, requiring significant graph conversion not covered by a direct API mapping.",
    "confidence": 0.3
  },
  {
    "torch_api": "torch._linalg_utils.matmul",
    "tvm_api": "tvm.relay.op.nn.nn.matmul",
    "mapping_type": "direct",
    "direction": "torch_to_tvm",
    "torch_pattern": "torch._linalg_utils.matmul({{A}}, {{B}})",
    "tvm_pattern": "tvm.relay.op.nn.nn.matmul({{A_tvm}}, {{B_tvm}})",
    "arg_mapping": {
      "A": "A_tvm",
      "B": "B_tvm"
    },
    "example_pairs": [
      {
        "torch": "result = torch._linalg_utils.matmul(tensor_a, tensor_b)",
        "tvm": "result = tvm.relay.op.nn.nn.matmul(tensor_a_tvm, tensor_b_tvm)"
      }
    ],
    "constraints": "Maps to dense matrix multiplication. PyTorch's utility function also handles None, sparse tensors, and dispatches to other matmul variants, which would require composite TVM operations.",
    "notes": "Maps the core dense matrix multiplication aspect. TVM's Relay matmul provides options for transpose and output dtype.",
    "confidence": 0.8
  },
  {
    "torch_api": "torch._meta_registrations.full",
    "tvm_api": "tvm.relay.op.transform.full",
    "mapping_type": "direct",
    "direction": "torch_to_tvm",
    "torch_pattern": "torch.full({{size}}, {{fill_value}}, **kwargs)",
    "tvm_pattern": "tvm.relay.op.transform.full({{fill_value_tvm}}, shape={{size_tvm}}, dtype={{dtype_tvm}})",
    "arg_mapping": {
      "size": "size_tvm",
      "fill_value": "fill_value_tvm",
      "dtype": "dtype_tvm"
    },
    "example_pairs": [
      {
        "torch": "x = torch.full([2, 3], 5.0, dtype=torch.float32)",
        "tvm": "x = tvm.relay.op.transform.full(tvm.tir.FloatImm('float32', 5.0), shape=[2, 3], dtype='float32')"
      }
    ],
    "constraints": "TVM's fill_value parameter is first, then shape. Dtype should be explicitly provided or inferred.",
    "notes": "This is a direct functional mapping for creating a tensor filled with a scalar value. The parameter order is different.",
    "confidence": 0.9
  },
  {
    "torch_api": "torch._meta_registrations.zeros_like",
    "tvm_api": "tvm.relay.op.tensor.zeros_like",
    "mapping_type": "direct",
    "direction": "torch_to_tvm",
    "torch_pattern": "torch.zeros_like({{self}})",
    "tvm_pattern": "tvm.relay.op.tensor.zeros_like({{data}})",
    "arg_mapping": {
      "self": "data"
    },
    "example_pairs": [
      {
        "torch": "z = torch.zeros_like(x)",
        "tvm": "z = tvm.relay.op.tensor.zeros_like(x_tvm)"
      }
    ],
    "constraints": "Assumes default dtype and layout matching the input tensor for TVM. PyTorch's API allows overriding dtype/layout/device, which would require explicit conversion ops in TVM if desired.",
    "notes": "Direct functional mapping to create a tensor of zeros with the same shape and type as the input.",
    "confidence": 0.95
  },
  {
    "torch_api": "torch._meta_registrations.sigmoid",
    "tvm_api": "tvm.relay.op.tensor.sigmoid",
    "mapping_type": "direct",
    "direction": "torch_to_tvm",
    "torch_pattern": "torch.sigmoid({{self}})",
    "tvm_pattern": "tvm.relay.op.tensor.sigmoid({{data}})",
    "arg_mapping": {
      "self": "data"
    },
    "example_pairs": [
      {
        "torch": "output = torch.sigmoid(input_tensor)",
        "tvm": "output_tvm = tvm.relay.op.tensor.sigmoid(input_tensor_tvm)"
      }
    ],
    "constraints": "TVM's sigmoid does not have explicit type promotion kind parameters like PyTorch; it operates on the input's dtype. If explicit type promotion is needed, it must be handled prior to the TVM sigmoid call.",
    "notes": "Direct element-wise sigmoid function mapping.",
    "confidence": 0.95
  },
  {
    "torch_api": "torch._meta_registrations.softmax",
    "tvm_api": "tvm.relay.op.nn.nn.softmax",
    "mapping_type": "direct",
    "direction": "torch_to_tvm",
    "torch_pattern": "torch.softmax({{x}}, dim={{dim}}, half_to_float={{half_to_float}})",
    "tvm_pattern": "tvm.relay.op.nn.nn.softmax({{data}}, axis={{axis}})",
    "arg_mapping": {
      "x": "data",
      "dim": "axis"
    },
    "example_pairs": [
      {
        "torch": "output = torch.softmax(input_tensor, dim=1, half_to_float=False)",
        "tvm": "output_tvm = tvm.relay.op.nn.nn.softmax(input_tensor_tvm, axis=1)"
      }
    ],
    "constraints": "PyTorch's `half_to_float` parameter for specific type promotion is not directly available in TVM's softmax. Type casting would need to be applied explicitly before the softmax operation in TVM if such promotion is required.",
    "notes": "Direct functional mapping for softmax along a given dimension/axis.",
    "confidence": 0.9
  },
  {
    "torch_api": "torch._utils.annotate",
    "tvm_api": null,
    "mapping_type": "no_mapping",
    "direction": "torch_to_tvm",
    "torch_pattern": null,
    "tvm_pattern": null,
    "arg_mapping": {},
    "example_pairs": [],
    "constraints": "Not convertible",
    "notes": "NO_MAPPING: PyTorch's `annotate` is a Python decorator used for type annotations, a language-level utility. TVM's `annotate` (`tvm.relay.quantize.quantize.annotate`) is a graph transformation pass for quantization simulation. Their functionalities are entirely unrelated.",
    "confidence": 0.2
  },
  {
    "torch_api": "torch._weights_only_unpickler.load",
    "tvm_api": null,
    "mapping_type": "no_mapping",
    "direction": "torch_to_tvm",
    "torch_pattern": null,
    "tvm_pattern": null,
    "arg_mapping": {},
    "example_pairs": [],
    "constraints": "Not convertible",
    "notes": "NO_MAPPING: PyTorch's `load` is part of its serialization mechanism for loading pickled objects. TVM's `load` (`tvm.script.parser_v1.tir.intrin.load`) is a low-level intrinsic in TIR for reading from memory. These are completely different operations.",
    "confidence": 0.2
  },
  {
    "torch_api": "torch.functional.split",
    "tvm_api": "tvm.relay.op.transform.split",
    "mapping_type": "direct",
    "direction": "torch_to_tvm",
    "torch_pattern": "torch.functional.split({{tensor}}, {{split_size_or_sections}}, dim={{dim}})",
    "tvm_pattern": "tvm.relay.op.transform.split({{data}}, indices_or_sections={{indices_or_sections}}, axis={{axis}})",
    "arg_mapping": {
      "tensor": "data",
      "split_size_or_sections": "indices_or_sections",
      "dim": "axis"
    },
    "example_pairs": [
      {
        "torch": "a, b = torch.functional.split(x, 2, dim=0)",
        "tvm": "a_tvm, b_tvm = tvm.relay.op.transform.split(x_tvm, 2, axis=0)"
      },
      {
        "torch": "a, b, c = torch.functional.split(x, [1, 2, 3], dim=1)",
        "tvm": "a_tvm, b_tvm, c_tvm = tvm.relay.op.transform.split(x_tvm, (1, 2, 3), axis=1)"
      }
    ],
    "constraints": "The `split_size_or_sections` list in PyTorch maps to a tuple in TVM for `indices_or_sections`.",
    "notes": "Direct functional mapping for splitting a tensor along a dimension.",
    "confidence": 0.95
  },
  {
    "torch_api": "torch.functional.einsum",
    "tvm_api": "tvm.relay.op.tensor.einsum",
    "mapping_type": "direct",
    "direction": "torch_to_tvm",
    "torch_pattern": "torch.functional.einsum({{equation}}, *{{operands}})",
    "tvm_pattern": "tvm.relay.op.tensor.einsum({{data}}, {{equation_tvm}})",
    "arg_mapping": {
      "equation": "equation_tvm",
      "operands": "data"
    },
    "example_pairs": [
      {
        "torch": "result = torch.einsum('ij,jk->ik', A, B)",
        "tvm": "result_tvm = tvm.relay.op.tensor.einsum([A_tvm, B_tvm], 'ij,jk->ik')"
      }
    ],
    "constraints": "PyTorch takes equation and operands as variadic args; TVM takes a list/tuple of data tensors and then the equation string.",
    "notes": "Direct functional mapping for Einstein summation.",
    "confidence": 0.9
  },
  {
    "torch_api": "torch.functional.stft",
    "tvm_api": "tvm.relay.op.transform.stft",
    "mapping_type": "direct",
    "direction": "torch_to_tvm",
    "torch_pattern": "torch.functional.stft({{input}}, {{n_fft}}, hop_length={{hop_length}}, win_length={{win_length}}, window={{window}}, normalized={{normalized}}, onesided={{onesided}})",
    "tvm_pattern": "tvm.relay.op.transform.stft({{data}}, {{n_fft_tvm}}, hop_length={{hop_length_tvm}}, win_length={{win_length_tvm}}, window={{window_tvm}}, normalized={{normalized_tvm}}, onesided={{onesided_tvm}})",
    "arg_mapping": {
      "input": "data",
      "n_fft": "n_fft_tvm",
      "hop_length": "hop_length_tvm",
      "win_length": "win_length_tvm",
      "window": "window_tvm",
      "normalized": "normalized_tvm",
      "onesided": "onesided_tvm"
    },
    "example_pairs": [
      {
        "torch": "spec = torch.functional.stft(x, n_fft=400, hop_length=160)",
        "tvm": "spec_tvm = tvm.relay.op.transform.stft(x_tvm, n_fft_tvm=400, hop_length_tvm=160)"
      }
    ],
    "constraints": "TVM Relay's STFT function does not explicitly expose all parameters present in PyTorch's `stft` (e.g., `center`, `pad_mode`, `return_complex`, `align_to_window`). These would be assumed default or handled by preceding/succeeding operations in TVM.",
    "notes": "Direct functional mapping for Short-time Fourier Transform with common parameters.",
    "confidence": 0.85
  },
  {
    "torch_api": "torch.functional.tensordot",
    "tvm_api": "tvm.topi.transform.tensordot",
    "mapping_type": "direct",
    "direction": "torch_to_tvm",
    "torch_pattern": "torch.functional.tensordot({{a}}, {{b}}, dims={{dims}})",
    "tvm_pattern": "tvm.topi.transform.tensordot({{a_tvm}}, {{b_tvm}}, axes={{axes_tvm}})",
    "arg_mapping": {
      "a": "a_tvm",
      "b": "b_tvm",
      "dims": "axes_tvm"
    },
    "example_pairs": [
      {
        "torch": "result = torch.functional.tensordot(A, B, dims=2)",
        "tvm": "result_tvm = tvm.topi.transform.tensordot(A_tvm, B_tvm, axes=2)"
      },
      {
        "torch": "result = torch.functional.tensordot(A, B, dims=([2,3],[0,1]))",
        "tvm": "result_tvm = tvm.topi.transform.tensordot(A_tvm, B_tvm, axes=([2,3],[0,1]))"
      }
    ],
    "constraints": "PyTorch's `out` parameter is not directly supported by TVM's `tensordot` and would need to be handled separately if in-place updates are required.",
    "notes": "Direct functional mapping for tensor dot product.",
    "confidence": 0.95
  },
  {
    "torch_api": "torch.functional.unravel_index",
    "tvm_api": "tvm.relay.op.transform.unravel_index",
    "mapping_type": "direct",
    "direction": "torch_to_tvm",
    "torch_pattern": "torch.functional.unravel_index({{indices}}, {{shape}})",
    "tvm_pattern": "tvm.relay.op.transform.unravel_index({{indices_tvm}}, {{shape_tvm}})",
    "arg_mapping": {
      "indices": "indices_tvm",
      "shape": "shape_tvm"
    },
    "example_pairs": [
      {
        "torch": "coords = torch.functional.unravel_index(torch.tensor([22, 41, 37]), (7, 6))",
        "tvm": "coords_tvm = tvm.relay.op.transform.unravel_index(tvm.relay.Constant(tvm.nd.array(np.array([22, 41, 37]))), tvm.relay.Constant(tvm.nd.array(np.array([7, 6]))))"
      }
    ],
    "constraints": "PyTorch's `shape` can be int, sequence of ints, or torch.Size. TVM's `shape` is expected as a Relay expression representing the shape.",
    "notes": "Direct functional mapping to convert flat indices to coordinate tensors.",
    "confidence": 0.9
  },
  {
    "torch_api": "torch.hub.load",
    "tvm_api": null,
    "mapping_type": "no_mapping",
    "direction": "torch_to_tvm",
    "torch_pattern": null,
    "tvm_pattern": null,
    "arg_mapping": {},
    "example_pairs": [],
    "constraints": "Not convertible",
    "notes": "NO_MAPPING: PyTorch's `torch.hub.load` is a high-level utility for loading models/resources from repositories (e.g., GitHub). TVM's `tvm.script.parser_v1.tir.intrin.load` is a low-level TIR intrinsic for memory access. These functionalities are entirely unrelated.",
    "confidence": 0.2
  },
  {
    "torch_api": "torch.serialization.load",
    "tvm_api": null,
    "mapping_type": "no_mapping",
    "direction": "torch_to_tvm",
    "torch_pattern": null,
    "tvm_pattern": null,
    "arg_mapping": {},
    "example_pairs": [],
    "constraints": "Not convertible",
    "notes": "NO_MAPPING: PyTorch's `torch.serialization.load` is a utility for deserializing PyTorch objects (models, tensors) from files. TVM's `tvm.script.parser_v1.tir.intrin.load` is a low-level TIR intrinsic for memory access. These functionalities are entirely unrelated.",
    "confidence": 0.2
  },
  {
    "torch_api": "torch._custom_op.impl.get_op",
    "tvm_api": null,
    "mapping_type": "no_mapping",
    "direction": "torch_to_tvm",
    "torch_pattern": null,
    "tvm_pattern": null,
    "arg_mapping": {},
    "example_pairs": [],
    "constraints": "Not convertible",
    "notes": "NO_MAPPING: PyTorch's `get_op` is an internal utility for retrieving custom operators by name. TVM's `tvm.script.parser.core.dispatch.get_op` is for registering internal dispatch methods for AST operator nodes. While both involve 'ops', their purpose and context within their respective frameworks are entirely different.",
    "confidence": 0.2
  },
  {
    "torch_api": "torch._decomp.decompositions.hardswish",
    "tvm_api": null,
    "mapping_type": "no_mapping",
    "direction": "torch_to_tvm",
    "torch_pattern": null,
    "tvm_pattern": null,
    "arg_mapping": {},
    "example_pairs": [],
    "constraints": "Not convertible",
    "notes": "NO_MAPPING: PyTorch's `hardswish` decomposition is for float tensors. The TVM candidate `tvm.relay.qnn.op.qnn.hardswish` is specifically for *quantized* tensors, requiring explicit scale and zero-point parameters. A direct mapping for the float hardswish is not available among the candidates, and would typically be a composite operation in TVM Relay.",
    "confidence": 0.4
  },
  {
    "torch_api": "torch._decomp.decompositions.dropout",
    "tvm_api": "tvm.relay.op.nn.nn.dropout",
    "mapping_type": "direct",
    "direction": "torch_to_tvm",
    "torch_pattern": "torch.dropout({{input}}, p={{p}}, train={{train}})",
    "tvm_pattern": "tvm.relay.op.nn.nn.dropout({{data}}, rate={{rate}})",
    "arg_mapping": {
      "input": "data",
      "p": "rate"
    },
    "example_pairs": [
      {
        "torch": "output = torch.dropout(input_tensor, p=0.5, train=True)",
        "tvm": "output_tvm = tvm.relay.op.nn.nn.dropout(input_tensor_tvm, rate=0.5)"
      }
    ],
    "constraints": "PyTorch's `train` parameter dictates if dropout is active. In TVM Relay, the dropout op generally operates based on `rate`, and for inference, optimizers can remove dropout layers. The `train` parameter's conditional logic in PyTorch's decomposition needs to be handled external to the TVM op itself.",
    "notes": "Direct functional mapping for dropout. PyTorch's decomposition explicitly handles `train=False` by returning input.clone(). TVM's dropout is typically optimized out during inference.",
    "confidence": 0.9
  },
  {
    "torch_api": "torch._decomp.decompositions.prod",
    "tvm_api": "tvm.topi.utils.prod",
    "mapping_type": "direct",
    "direction": "torch_to_tvm",
    "torch_pattern": "prod({{x}})",
    "tvm_pattern": "tvm.topi.utils.prod({{x_tvm}})",
    "arg_mapping": {
      "x": "x_tvm"
    },
    "example_pairs": [
      {
        "torch": "val = prod([1, 2, 3])",
        "tvm": "val_tvm = tvm.topi.utils.prod((1, 2, 3))"
      }
    ],
    "constraints": "PyTorch's `prod` takes a `list[int]`. TVM's `prod` takes a tuple of expressions (can be Python numbers or `tvm.tir.IntImm`). The functionality is a scalar utility, not a tensor reduction.",
    "notes": "Maps to a utility function for calculating the product of a sequence of numbers, rather than a tensor reduction operator.",
    "confidence": 0.8
  },
  {
    "torch_api": "torch._decomp.decompositions.split",
    "tvm_api": "tvm.relay.op.transform.split",
    "mapping_type": "direct",
    "direction": "torch_to_tvm",
    "torch_pattern": "torch.split({{self}}, {{split_size}}, dim={{dim}})",
    "tvm_pattern": "tvm.relay.op.transform.split({{data}}, indices_or_sections={{indices_or_sections}}, axis={{axis}})",
    "arg_mapping": {
      "self": "data",
      "split_size": "indices_or_sections",
      "dim": "axis"
    },
    "example_pairs": [
      {
        "torch": "t1, t2 = torch.split(my_tensor, 5, dim=0)",
        "tvm": "t1_tvm, t2_tvm = tvm.relay.op.transform.split(my_tensor_tvm, 5, axis=0)"
      }
    ],
    "constraints": "Handles the case where `split_size` is an integer, leading to equally sized chunks (or a smaller last chunk). If `split_size` is a list, PyTorch's decomposition converts it internally, which maps to TVM's `indices_or_sections` as a tuple.",
    "notes": "Direct functional mapping for splitting a tensor into equally sized chunks. This covers the integer `split_size` case.",
    "confidence": 0.95
  },
  {
    "torch_api": "torch._decomp.decompositions.adaptive_avg_pool2d",
    "tvm_api": "tvm.relay.op.nn.nn.adaptive_avg_pool2d",
    "mapping_type": "direct",
    "direction": "torch_to_tvm",
    "torch_pattern": "torch.adaptive_avg_pool2d({{input}}, {{output_size}})",
    "tvm_pattern": "tvm.relay.op.nn.nn.adaptive_avg_pool2d({{data}}, output_size={{output_size_tvm}})",
    "arg_mapping": {
      "input": "data",
      "output_size": "output_size_tvm"
    },
    "example_pairs": [
      {
        "torch": "output = torch.adaptive_avg_pool2d(input_tensor, (7, 7))",
        "tvm": "output_tvm = tvm.relay.op.nn.nn.adaptive_avg_pool2d(input_tensor_tvm, output_size=(7, 7))"
      }
    ],
    "constraints": "Assumes default layout 'NCHW' for TVM if not specified. PyTorch's API includes internal checks for tensor dimensions and non-zero sizes.",
    "notes": "Direct functional mapping for 2D adaptive average pooling.",
    "confidence": 0.95
  },
  {
    "torch_api": "torch._decomp.decompositions.uniform",
    "tvm_api": "tvm.relay.op.random.kernel.uniform",
    "mapping_type": "direct",
    "direction": "torch_to_tvm",
    "torch_pattern": "torch.uniform({{x_shape}}, low={{low}}, high={{high}}, dtype={{dtype}}, device={{device}}, generator={{generator}})",
    "tvm_pattern": "tvm.relay.op.random.kernel.uniform({{key}}, shape={{shape_tvm}}, dtype={{dtype_tvm}}, low={{low_tvm}}, high={{high_tvm}})",
    "arg_mapping": {
      "x_shape": "shape_tvm",
      "low": "low_tvm",
      "high": "high_tvm",
      "dtype": "dtype_tvm",
      "generator": "key"
    },
    "example_pairs": [
      {
        "torch": "out = torch.uniform(x.shape, low=0.0, high=1.0, dtype=x.dtype, device=x.device)",
        "tvm": "key = tvm.relay.op.random.kernel.threefry_key(0); out_tvm = tvm.relay.op.random.kernel.uniform(key, shape=x_tvm.shape, dtype=x_tvm.dtype, low=0.0, high=1.0)"
      }
    ],
    "constraints": "PyTorch's `uniform` uses an optional `torch.Generator`. TVM's `uniform` requires an explicit `key` (e.g., from `threefry_key`) for deterministic random number generation within the Relay graph. PyTorch uses `x` for shape/dtype inference; TVM requires explicit `shape` and `dtype` arguments.",
    "notes": "Maps the random number generation functionality from a uniform distribution. Requires explicit management of random state (`key`) and shape/dtype in TVM.",
    "confidence": 0.85
  },
  {
    "torch_api": "torch._decomp.decompositions.matmul",
    "tvm_api": "tvm.relay.op.nn.nn.matmul",
    "mapping_type": "direct",
    "direction": "torch_to_tvm",
    "torch_pattern": "torch.matmul({{tensor1}}, {{tensor2}})",
    "tvm_pattern": "tvm.relay.op.nn.nn.matmul({{tensor_a_tvm}}, {{tensor_b_tvm}})",
    "arg_mapping": {
      "tensor1": "tensor_a_tvm",
      "tensor2": "tensor_b_tvm"
    },
    "example_pairs": [
      {
        "torch": "result = torch.matmul(A, B)",
        "tvm": "result_tvm = tvm.relay.op.nn.nn.matmul(A_tvm, B_tvm)"
      }
    ],
    "constraints": "PyTorch's `matmul` handles various tensor dimensions (vectors, matrices, batches) by dispatching to specialized ops (dot, mv, mm, bmm). TVM's `relay.op.nn.nn.matmul` is a general matrix multiplication. For complex PyTorch `matmul` behavior, a composite TVM strategy might be needed to explicitly handle batching or vector ops, though TVM's `matmul` might implicitly handle batching if inputs are compatible.",
    "notes": "Maps the core matrix multiplication operation. TVM's matmul offers additional transpose options not explicitly shown in PyTorch's `matmul` call signature.",
    "confidence": 0.8
  },
  {
    "torch_api": "torch._decomp.decompositions.floor_divide",
    "tvm_api": "tvm.relay.op.tensor.floor_divide",
    "mapping_type": "direct",
    "direction": "torch_to_tvm",
    "torch_pattern": "torch.floor_divide({{self}}, {{other}})",
    "tvm_pattern": "tvm.relay.op.tensor.floor_divide({{lhs}}, {{rhs}})",
    "arg_mapping": {
      "self": "lhs",
      "other": "rhs"
    },
    "example_pairs": [
      {
        "torch": "output = torch.floor_divide(x, y)",
        "tvm": "output_tvm = tvm.relay.op.tensor.floor_divide(x_tvm, y_tvm)"
      }
    ],
    "constraints": "None.",
    "notes": "Direct element-wise floor division mapping with broadcasting support.",
    "confidence": 0.95
  },
  {
    "torch_api": "torch._decomp.decompositions.take",
    "tvm_api": "tvm.relay.op.transform.take",
    "mapping_type": "direct",
    "direction": "torch_to_tvm",
    "torch_pattern": "torch.take({{self}}, {{index}})",
    "tvm_pattern": "tvm.relay.op.transform.take({{data}}, {{indices}}, axis=None)",
    "arg_mapping": {
      "self": "data",
      "index": "indices"
    },
    "example_pairs": [
      {
        "torch": "output = torch.take(input_tensor, index_tensor)",
        "tvm": "output_tvm = tvm.relay.op.transform.take(input_tensor_tvm, index_tensor_tvm, axis=None)"
      }
    ],
    "constraints": "PyTorch's `take` operates on a flattened input tensor. This behavior is matched in TVM by setting `axis=None`.",
    "notes": "Direct functional mapping for taking elements from a tensor using indices.",
    "confidence": 0.95
  },
  {
    "torch_api": "torch._decomp.decompositions_for_jvp.trace",
    "tvm_api": null,
    "mapping_type": "no_mapping",
    "direction": "torch_to_tvm",
    "torch_pattern": null,
    "tvm_pattern": null,
    "arg_mapping": {},
    "example_pairs": [],
    "constraints": "Not convertible",
    "notes": "NO_MAPPING: PyTorch's `trace` calculates the sum of diagonal elements of a matrix (matrix trace). TVM's `tvm.tir.op.trace` is a runtime debugging/profiling utility to trace tensor data. These are entirely different concepts.",
    "confidence": 0.2
  },
  {
    "torch_api": "torch._decomp.decompositions_for_jvp.prod",
    "tvm_api": "tvm.topi.utils.prod",
    "mapping_type": "direct",
    "direction": "torch_to_tvm",
    "torch_pattern": "prod({{x}})",
    "tvm_pattern": "tvm.topi.utils.prod({{x_tvm}})",
    "arg_mapping": {
      "x": "x_tvm"
    },
    "example_pairs": [
      {
        "torch": "val = prod([1, 2, 3])",
        "tvm": "val_tvm = tvm.topi.utils.prod((1, 2, 3))"
      }
    ],
    "constraints": "PyTorch's `prod` takes a `list[int]`. TVM's `prod` takes a tuple of expressions (can be Python numbers or `tvm.tir.IntImm`). The functionality is a scalar utility, not a tensor reduction.",
    "notes": "Maps to a utility function for calculating the product of a sequence of numbers, rather than a tensor reduction operator. Same as API 21.",
    "confidence": 0.8
  },
  {
    "torch_api": "torch._decomp.decompositions_for_rng.rand",
    "tvm_api": null,
    "mapping_type": "no_mapping",
    "direction": "torch_to_tvm",
    "torch_pattern": null,
    "tvm_pattern": null,
    "arg_mapping": {},
    "example_pairs": [],
    "constraints": "Not convertible",
    "notes": "NO_MAPPING: PyTorch's `rand` (`aten.rand`) generates random numbers as a graph operation for execution on a device. The TVM candidate `tvm.relay.testing.__init__.rand` is a testing utility that creates a pre-filled NumPy array and wraps it into a `tvm.nd.array` on the host, not a graph-level random number generation operator.",
    "confidence": 0.3
  },
  {
    "torch_api": "torch._dynamo.eval_frame.optimize",
    "tvm_api": null,
    "mapping_type": "no_mapping",
    "direction": "torch_to_tvm",
    "torch_pattern": null,
    "tvm_pattern": null,
    "arg_mapping": {},
    "example_pairs": [],
    "constraints": "Not convertible",
    "notes": "NO_MAPPING: PyTorch's `optimize` is a high-level API to optimize PyTorch models/functions, part of the TorchDynamo framework for Python-level graph capture and optimization. TVM's `optimize` (`tvm.relay.build_module.optimize`) optimizes an existing `tvm.IRModule`. The input types and contexts are different; `torch.optimize` operates on Python functions/modules, while TVM's `optimize` operates on an IRModule.",
    "confidence": 0.3
  },
  {
    "torch_api": "torch._dynamo.guards.unique",
    "tvm_api": null,
    "mapping_type": "no_mapping",
    "direction": "torch_to_tvm",
    "torch_pattern": null,
    "tvm_pattern": null,
    "arg_mapping": {},
    "example_pairs": [],
    "constraints": "Not convertible",
    "notes": "NO_MAPPING: PyTorch's `unique` is a Python utility function operating on generic sequences to yield unique elements. The TVM candidates (`tvm.relay.op.transform.unique`, `tvm.topi.unique.unique`) are tensor operations that find unique elements within a 1-D tensor. The input types and domain of operation are different.",
    "confidence": 0.2
  },
  {
    "torch_api": "torch._dynamo.trace_rules.add",
    "tvm_api": null,
    "mapping_type": "no_mapping",
    "direction": "torch_to_tvm",
    "torch_pattern": null,
    "tvm_pattern": null,
    "arg_mapping": {},
    "example_pairs": [],
    "constraints": "Not convertible",
    "notes": "NO_MAPPING: PyTorch's `add` is an internal utility for adding an integer ID to a set, part of TorchDynamo's tracing mechanism. The TVM candidates (`tvm.relay.op.tensor.add`, `tvm.relay.qnn.op.qnn.add`, `tvm.tir.generic.add`) are all arithmetic addition operations on tensors or IR expressions. Their functionalities are entirely unrelated.",
    "confidence": 0.2
  },
  {
    "torch_api": "torch._dynamo.polyfills.builtins.all",
    "tvm_api": null,
    "mapping_type": "no_mapping",
    "direction": "torch_to_tvm",
    "torch_pattern": null,
    "tvm_pattern": null,
    "arg_mapping": {},
    "example_pairs": [],
    "constraints": "Not convertible",
    "notes": "NO_MAPPING: PyTorch's `all` refers to the Python built-in function for checking if all elements in an iterable are true. The TVM candidates (`tvm.relay.op.reduce.all`, `tvm.tir.op.all`, `tvm.topi.reduction.all`) are all tensor or IR expression operations for logical AND reduction. The input types and domain of operation are different.",
    "confidence": 0.2
  },
  {
    "torch_api": "torch._dynamo.polyfills.builtins.any",
    "tvm_api": null,
    "mapping_type": "no_mapping",
    "direction": "torch_to_tvm",
    "torch_pattern": null,
    "tvm_pattern": null,
    "arg_mapping": {},
    "example_pairs": [],
    "constraints": "Not convertible",
    "notes": "NO_MAPPING: PyTorch's `any` refers to the Python built-in function for checking if any element in an iterable is true. The TVM candidates (`tvm.relay.op.reduce.any`, `tvm.tir.op.any`, `tvm.topi.reduction.any`) are all tensor or IR expression operations for logical OR reduction. The input types and domain of operation are different.",
    "confidence": 0.2
  },
  {
    "torch_api": "torch._dynamo.polyfills.builtins.sum",
    "tvm_api": null,
    "mapping_type": "no_mapping",
    "direction": "torch_to_tvm",
    "torch_pattern": null,
    "tvm_pattern": null,
    "arg_mapping": {},
    "example_pairs": [],
    "constraints": "Not convertible",
    "notes": "NO_MAPPING: PyTorch's `sum` refers to the Python built-in function for summing elements in an iterable. The TVM candidates (`tvm.relay.op.reduce.sum`, `tvm.topi.reduction.sum`) are all tensor reduction operations. The input types and domain of operation are different.",
    "confidence": 0.2
  },
  {
    "torch_api": "torch._export.serde.serialize.register_extension",
    "tvm_api": null,
    "mapping_type": "no_mapping",
    "direction": "torch_to_tvm",
    "torch_pattern": null,
    "tvm_pattern": null,
    "arg_mapping": {},
    "example_pairs": [],
    "constraints": "Not convertible",
    "notes": "NO_MAPPING: PyTorch's `register_extension` is for customizing serialization/deserialization of node types. TVM's `tvm._ffi.registry.register_extension` is for registering Python classes for FFI integration. Although both use 'register_extension', their purposes within their respective frameworks are distinct.",
    "confidence": 0.2
  },
  {
    "torch_api": "torch._higher_order_ops.scan.scan",
    "tvm_api": "tvm.te.operation.scan",
    "mapping_type": "direct",
    "direction": "torch_to_tvm",
    "torch_pattern": "torch.scan({{combine_fn}}, {{init}}, {{xs}}, dim={{dim}}, reverse={{reverse}})",
    "tvm_pattern": "tvm.te.operation.scan(init={{init_tvm}}, update={{update_tvm}}, state_placeholder={{state_placeholder_tvm}}, inputs={{inputs_tvm}})",
    "arg_mapping": {
      "combine_fn": "update_tvm",
      "init": "init_tvm",
      "xs": "inputs_tvm"
    },
    "example_pairs": [
      {
        "torch": "result, last_state = torch.scan(lambda x, y: (x + y, x + y), torch.zeros(1), torch.arange(5))",
        "tvm": "import tvm.te as te\ndef _update_fn(state, inputs):\n    new_state = state + inputs\n    return new_state, new_state\ninit_val = te.placeholder((1,), name='init_val')\ninput_seq = te.placeholder((5,), name='input_seq')\nstate_ph = te.placeholder((1,), name='state_ph')\nresult_tvm, last_state_tvm = tvm.te.operation.scan(init=[init_val], update=_update_fn, state_placeholder=[state_ph], inputs=[input_seq])"
      }
    ],
    "constraints": "PyTorch's `combine_fn` returns `(carry_output, scan_output)`. TVM's `update` function also expects to return a tuple of `(new_state, scan_output)`. `dim` and `reverse` parameters in PyTorch would need to be integrated into the `update` logic or TE scheduling in TVM, as they are not direct parameters of the TVM scan op.",
    "notes": "Strong conceptual and functional mapping for sequence scanning operation in the Tensor Expression (TE) framework.",
    "confidence": 0.85
  },
  {
    "torch_api": "torch._higher_order_ops.while_loop.while_loop",
    "tvm_api": "tvm.relay.loops.while_loop",
    "mapping_type": "direct",
    "direction": "torch_to_tvm",
    "torch_pattern": "torch.while_loop({{cond_fn}}, {{body_fn}}, {{carried_inputs}})",
    "tvm_pattern": "tvm.relay.loops.while_loop(cond={{cond_tvm}}, loop_vars={{loop_vars_tvm}}, loop_bodies={{loop_bodies_tvm}})",
    "arg_mapping": {
      "cond_fn": "cond_tvm",
      "body_fn": "loop_bodies_tvm",
      "carried_inputs": "loop_vars_tvm"
    },
    "example_pairs": [
      {
        "torch": "def cond(i, x): return i < 5\ndef body(i, x): return i + 1, x * 2\nfinal_i, final_x = torch.while_loop(cond, body, (torch.tensor(0), torch.tensor(1)))",
        "tvm": "import tvm.relay as relay\ndef cond_relay(i, x): return relay.op.less(i, relay.const(5))\ndef body_relay(i, x): return relay.op.add(i, relay.const(1)), relay.op.multiply(x, relay.const(2))\ninit_i = relay.var('i_init'); init_x = relay.var('x_init')\nfinal_i_tvm, final_x_tvm = tvm.relay.loops.while_loop(cond_relay, (init_i, init_x), body_relay)"
      }
    ],
    "constraints": "The `cond_fn` and `body_fn` in PyTorch must be convertible to Relay functions. The `carried_inputs` in PyTorch maps to a tuple of initial loop variables in TVM.",
    "notes": "Excellent and direct functional mapping for implementing while loops as a higher-order operation within the computation graph.",
    "confidence": 0.95
  },
  {
    "torch_api": "torch._inductor.__autotune_main__.main",
    "tvm_api": null,
    "mapping_type": "no_mapping",
    "direction": "torch_to_tvm",
    "torch_pattern": null,
    "tvm_pattern": null,
    "arg_mapping": {},
    "example_pairs": [],
    "constraints": "Not convertible",
    "notes": "NO_MAPPING: PyTorch's `main` (`torch._inductor.__autotune_main__.main`) is the entry point for an autotuning subprocess in TorchInductor. The TVM candidates (`tvm.auto_scheduler.measure_record.main`, `tvm.auto_scheduler.testing.tune_onnx.main`, `tvm.auto_scheduler.testing.tune_relay.main`) are also main functions for auto-scheduling or tuning, but they belong to different frameworks (TVM's auto-scheduler). They are analogous in high-level purpose but not directly mappable APIs.",
    "confidence": 0.3
  },
  {
    "torch_api": "torch._inductor.__init__.compile",
    "tvm_api": null,
    "mapping_type": "no_mapping",
    "direction": "torch_to_tvm",
    "torch_pattern": null,
    "tvm_pattern": null,
    "arg_mapping": {},
    "example_pairs": [],
    "constraints": "Not convertible",
    "notes": "NO_MAPPING: PyTorch's `torch._inductor.__init__.compile` compiles a `torch.fx.GraphModule` using TorchInductor. TVM's `tvm.relay.backend.vm.compile` compiles a `tvm.IRModule`. A direct mapping is not possible as it would require converting an FX graph to a Relay IRModule, which is a significant intermediate step not covered by this API translation.",
    "confidence": 0.3
  },
  {
    "torch_api": "torch._inductor.decomposition.full",
    "tvm_api": "tvm.relay.op.transform.full",
    "mapping_type": "direct",
    "direction": "torch_to_tvm",
    "torch_pattern": "torch.full({{size}}, {{fill_value}}, **kwargs)",
    "tvm_pattern": "tvm.relay.op.transform.full({{fill_value_tvm}}, shape={{size_tvm}}, dtype={{dtype_tvm}})",
    "arg_mapping": {
      "size": "size_tvm",
      "fill_value": "fill_value_tvm",
      "dtype": "dtype_tvm"
    },
    "example_pairs": [
      {
        "torch": "x = torch.full([2, 3], 5.0, dtype=torch.float32)",
        "tvm": "x = tvm.relay.op.transform.full(tvm.tir.FloatImm('float32', 5.0), shape=[2, 3], dtype='float32')"
      }
    ],
    "constraints": "TVM's `fill_value` parameter is first, then `shape`. Dtype should be explicitly provided or inferred.",
    "notes": "Direct functional mapping for creating a tensor filled with a scalar value. Same as API 5.",
    "confidence": 0.9
  },
  {
    "torch_api": "torch._inductor.decomposition.add",
    "tvm_api": "tvm.relay.op.tensor.add",
    "mapping_type": "direct",
    "direction": "torch_to_tvm",
    "torch_pattern": "torch.add({{x}}, {{y}}, *, alpha={{alpha}})",
    "tvm_pattern": "tvm.relay.op.tensor.add({{lhs}}, {{rhs}})",
    "arg_mapping": {
      "x": "lhs",
      "y": "rhs"
    },
    "example_pairs": [
      {
        "torch": "z = torch.add(x, y)",
        "tvm": "z_tvm = tvm.relay.op.tensor.add(x_tvm, y_tvm)"
      },
      {
        "torch": "z = torch.add(x, y, alpha=0.5)",
        "tvm": "z_tvm = tvm.relay.op.tensor.add(x_tvm, tvm.relay.op.tensor.multiply(y_tvm, tvm.relay.const(0.5, 'float32')))"
      }
    ],
    "constraints": "PyTorch's `alpha` parameter, if not None, implies a scaled addition (`x + alpha * y`). TVM's `add` is a direct element-wise addition. For `alpha != None`, a composite operation (`multiply` then `add`) would be needed in TVM. The PyTorch decomposition explicitly handles complex tensors; TVM's add needs to support complex dtypes for a full match.",
    "notes": "Direct element-wise addition mapping. The `alpha` parameter is a composite operation in TVM if present.",
    "confidence": 0.85
  },
  {
    "torch_api": "torch._inductor.decomposition.full_like",
    "tvm_api": "tvm.relay.op.transform.full_like",
    "mapping_type": "direct",
    "direction": "torch_to_tvm",
    "torch_pattern": "torch.full_like({{self}}, {{fill_value}}, **kwargs)",
    "tvm_pattern": "tvm.relay.op.transform.full_like({{data}}, {{fill_value_tvm}})",
    "arg_mapping": {
      "self": "data",
      "fill_value": "fill_value_tvm"
    },
    "example_pairs": [
      {
        "torch": "z = torch.full_like(x, 1.0)",
        "tvm": "z_tvm = tvm.relay.op.transform.full_like(x_tvm, tvm.tir.FloatImm('float32', 1.0))"
      }
    ],
    "constraints": "TVM's `full_like` uses the input tensor's shape and dtype. PyTorch's API allows overriding `dtype`, `layout`, `device`, etc., which would require explicit conversion ops in TVM if desired.",
    "notes": "Direct functional mapping to create a tensor with the same shape as an input tensor, filled with a scalar value. Same as API 44.",
    "confidence": 0.95
  },
  {
    "torch_api": "torch._inductor.decomposition.adaptive_max_pool2d",
    "tvm_api": "tvm.relay.op.nn.nn.adaptive_max_pool2d",
    "mapping_type": "direct",
    "direction": "torch_to_tvm",
    "torch_pattern": "torch.adaptive_max_pool2d({{x}}, {{output_size}})",
    "tvm_pattern": "tvm.relay.op.nn.nn.adaptive_max_pool2d({{data}}, output_size={{output_size_tvm}})",
    "arg_mapping": {
      "x": "data",
      "output_size": "output_size_tvm"
    },
    "example_pairs": [
      {
        "torch": "output, indices = torch.adaptive_max_pool2d(input_tensor, (7, 7))",
        "tvm": "output_tvm = tvm.relay.op.nn.nn.adaptive_max_pool2d(input_tensor_tvm, output_size=(7, 7))"
      }
    ],
    "constraints": "PyTorch's `adaptive_max_pool2d` returns both the output tensor and the max indices. TVM Relay's `adaptive_max_pool2d` function typically only returns the output tensor. If the indices are required, this would be a partial or composite mapping.",
    "notes": "Maps the primary output (the max-pooled tensor) functionality. The indices output by PyTorch's version are not directly available from the TVM Relay op.",
    "confidence": 0.85
  },
  {
    "torch_api": "torch._inductor.lowering.where",
    "tvm_api": "tvm.relay.op.transform.where",
    "mapping_type": "direct",
    "direction": "torch_to_tvm",
    "torch_pattern": "torch.where({{cond}}, {{a}}, {{b}})",
    "tvm_pattern": "tvm.relay.op.transform.where({{condition_tvm}}, {{x_tvm}}, {{y_tvm}})",
    "arg_mapping": {
      "cond": "condition_tvm",
      "a": "x_tvm",
      "b": "y_tvm"
    },
    "example_pairs": [
      {
        "torch": "result = torch.where(condition_tensor, x_tensor, y_tensor)",
        "tvm": "result_tvm = tvm.relay.op.transform.where(condition_tensor_tvm, x_tensor_tvm, y_tensor_tvm)"
      }
    ],
    "constraints": "None. Both support broadcasting semantics.",
    "notes": "Direct element-wise selection based on a condition, with support for broadcasting. TVM's op is `relay.op.transform.where`.",
    "confidence": 0.95
  },
  {
    "torch_api": "torch._inductor.lowering.squeeze",
    "tvm_api": "tvm.relay.op.transform.squeeze",
    "mapping_type": "direct",
    "direction": "torch_to_tvm",
    "torch_pattern": "torch.squeeze({{x}}, dim={{dim}})",
    "tvm_pattern": "tvm.relay.op.transform.squeeze({{data}}, axis={{axis}})",
    "arg_mapping": {
      "x": "data",
      "dim": "axis"
    },
    "example_pairs": [
      {
        "torch": "output = torch.squeeze(input_tensor, dim=0)",
        "tvm": "output_tvm = tvm.relay.op.transform.squeeze(input_tensor_tvm, axis=0)"
      },
      {
        "torch": "output = torch.squeeze(input_tensor)",
        "tvm": "output_tvm = tvm.relay.op.transform.squeeze(input_tensor_tvm)"
      }
    ],
    "constraints": "None.",
    "notes": "Direct functional mapping for removing dimensions of size 1 from a tensor.",
    "confidence": 0.95
  },
  {
    "torch_api": "torch._inductor.lowering.isinf",
    "tvm_api": "tvm.relay.op.tensor.isinf",
    "mapping_type": "direct",
    "direction": "torch_to_tvm",
    "torch_pattern": "torch.isinf({{x}})",
    "tvm_pattern": "tvm.relay.op.tensor.isinf({{data}})",
    "arg_mapping": {
      "x": "data"
    },
    "example_pairs": [
      {
        "torch": "result = torch.isinf(input_tensor)",
        "tvm": "result_tvm = tvm.relay.op.tensor.isinf(input_tensor_tvm)"
      }
    ],
    "constraints": "PyTorch's lowering explicitly returns False for integer types. TVM's `isinf` operates on floating-point types; for integer types, the result might need to be handled explicitly as `False` if TVM's op doesn't implicitly do so or raise an error.",
    "notes": "Direct element-wise check for infinity.",
    "confidence": 0.9
  },
  {
    "torch_api": "torch._inductor.lowering.isnan",
    "tvm_api": "tvm.relay.op.tensor.isnan",
    "mapping_type": "direct",
    "direction": "torch_to_tvm",
    "torch_pattern": "torch.isnan({{x}})",
    "tvm_pattern": "tvm.relay.op.tensor.isnan({{data}})",
    "arg_mapping": {
      "x": "data"
    },
    "example_pairs": [
      {
        "torch": "result = torch.isnan(input_tensor)",
        "tvm": "result_tvm = tvm.relay.op.tensor.isnan(input_tensor_tvm)"
      }
    ],
    "constraints": "PyTorch's lowering explicitly returns False for integer types. TVM's `isnan` operates on floating-point types; for integer types, the result might need to be handled explicitly as `False` if TVM's op doesn't implicitly do so or raise an error.",
    "notes": "Direct element-wise check for NaN.",
    "confidence": 0.9
  },
  {
    "torch_api": "torch._inductor.lowering.ceil",
    "tvm_api": "tvm.relay.op.tensor.ceil",
    "mapping_type": "direct",
    "direction": "torch_to_tvm",
    "torch_pattern": "torch.ceil({{x}})",
    "tvm_pattern": "tvm.relay.op.tensor.ceil({{data}})",
    "arg_mapping": {
      "x": "data"
    },
    "example_pairs": [
      {
        "torch": "output = torch.ceil(input_tensor)",
        "tvm": "output_tvm = tvm.relay.op.tensor.ceil(input_tensor_tvm)"
      }
    ],
    "constraints": "PyTorch's lowering explicitly returns a clone for integer types. TVM's `ceil` is typically for floating-point values; its behavior on integer types (e.g., identity or error) should be consistent or handled explicitly if integer clone is required.",
    "notes": "Direct element-wise ceiling function.",
    "confidence": 0.9
  },
  {
    "torch_api": "torch._inductor.lowering.floor",
    "tvm_api": "tvm.relay.op.tensor.floor",
    "mapping_type": "direct",
    "direction": "torch_to_tvm",
    "torch_pattern": "torch.floor({{x}})",
    "tvm_pattern": "tvm.relay.op.tensor.floor({{data}})",
    "arg_mapping": {
      "x": "data"
    },
    "example_pairs": [
      {
        "torch": "output = torch.floor(input_tensor)",
        "tvm": "output_tvm = tvm.relay.op.tensor.floor(input_tensor_tvm)"
      }
    ],
    "constraints": "PyTorch's lowering explicitly returns a clone for integer types. TVM's `floor` is typically for floating-point values; its behavior on integer types (e.g., identity or error) should be consistent or handled explicitly if integer clone is required.",
    "notes": "Direct element-wise floor function.",
    "confidence": 0.9
  },
  {
    "torch_api": "torch._inductor.lowering.round",
    "tvm_api": "tvm.relay.op.tensor.round",
    "mapping_type": "direct",
    "direction": "torch_to_tvm",
    "torch_pattern": "torch.round({{x}})",
    "tvm_pattern": "tvm.relay.op.tensor.round({{data}})",
    "arg_mapping": {
      "x": "data"
    },
    "example_pairs": [
      {
        "torch": "output = torch.round(input_tensor)",
        "tvm": "output_tvm = tvm.relay.op.tensor.round(input_tensor_tvm)"
      }
    ],
    "constraints": "PyTorch's lowering explicitly returns a clone for integer types. TVM's `round` is typically for floating-point values; its behavior on integer types (e.g., identity or error) should be consistent or handled explicitly if integer clone is required.",
    "notes": "Direct element-wise round to the nearest integer function.",
    "confidence": 0.9
  },
  {
    "torch_api": "torch._inductor.lowering.trunc",
    "tvm_api": "tvm.relay.op.tensor.trunc",
    "mapping_type": "direct",
    "direction": "torch_to_tvm",
    "torch_pattern": "torch.trunc({{x}})",
    "tvm_pattern": "tvm.relay.op.tensor.trunc({{data}})",
    "arg_mapping": {
      "x": "data"
    },
    "example_pairs": [
      {
        "torch": "output = torch.trunc(input_tensor)",
        "tvm": "output_tvm = tvm.relay.op.tensor.trunc(input_tensor_tvm)"
      }
    ],
    "constraints": "PyTorch's lowering explicitly returns a clone for integer types. TVM's `trunc` is typically for floating-point values; its behavior on integer types (e.g., identity or error) should be consistent or handled explicitly if integer clone is required.",
    "notes": "Direct element-wise truncation function (nearest integer closer to zero).",
    "confidence": 0.9
  },
  {
    "torch_api": "torch._inductor.lowering.split",
    "tvm_api": "tvm.relay.op.transform.split",
    "mapping_type": "direct",
    "direction": "torch_to_tvm",
    "torch_pattern": "torch.split({{x}}, {{sizes}}, dim={{dim}})",
    "tvm_pattern": "tvm.relay.op.transform.split({{data}}, indices_or_sections={{indices_or_sections}}, axis={{axis}})",
    "arg_mapping": {
      "x": "data",
      "sizes": "indices_or_sections",
      "dim": "axis"
    },
    "example_pairs": [
      {
        "torch": "t1, t2 = torch.split(my_tensor, 5, dim=0)",
        "tvm": "t1_tvm, t2_tvm = tvm.relay.op.transform.split(my_tensor_tvm, 5, axis=0)"
      },
      {
        "torch": "t1, t2, t3 = torch.split(my_tensor, [1, 2, 3], dim=1)",
        "tvm": "t1_tvm, t2_tvm, t3_tvm = tvm.relay.op.transform.split(my_tensor_tvm, (1, 2, 3), axis=1)"
      }
    ],
    "constraints": "PyTorch's `sizes` argument can be an integer or a list of integers. TVM's `indices_or_sections` expects an integer or a tuple of integers.",
    "notes": "Direct functional mapping for splitting a tensor along a dimension. Same as API 11 and 22.",
    "confidence": 0.95
  },
  {
    "torch_api": "torch._inductor.lowering.unbind",
    "tvm_api": "tvm.relay.frontend.common.unbind",
    "mapping_type": "direct",
    "direction": "torch_to_tvm",
    "torch_pattern": "torch.unbind({{x}}, dim={{dim}})",
    "tvm_pattern": "tvm.relay.frontend.common.unbind({{data}}, axis={{axis}})",
    "arg_mapping": {
      "x": "data",
      "dim": "axis"
    },
    "example_pairs": [
      {
        "torch": "tensors = torch.unbind(input_tensor, dim=0)",
        "tvm": "tensors_tvm = tvm.relay.frontend.common.unbind(input_tensor_tvm, axis=0)"
      }
    ],
    "constraints": "None.",
    "notes": "Direct functional mapping to remove a tensor dimension and return a tuple/list of slices along that dimension.",
    "confidence": 0.95
  },
  {
    "torch_api": "torch._inductor.lowering.rand",
    "tvm_api": null,
    "mapping_type": "no_mapping",
    "direction": "torch_to_tvm",
    "torch_pattern": null,
    "tvm_pattern": null,
    "arg_mapping": {},
    "example_pairs": [],
    "constraints": "Not convertible",
    "notes": "NO_MAPPING: PyTorch's `rand` (`aten.rand`) generates random numbers as a graph operation for execution on a device. The TVM candidate `tvm.relay.testing.__init__.rand` is a testing utility that creates a pre-filled NumPy array and wraps it into a `tvm.nd.array` on the host, not a graph-level random number generation operator.",
    "confidence": 0.3
  },
  {
    "torch_api": "torch._inductor.lowering.searchsorted",
    "tvm_api": "tvm.relay.op.algorithm.searchsorted",
    "mapping_type": "direct",
    "direction": "torch_to_tvm",
    "torch_pattern": "torch.searchsorted({{sorted_sequence}}, {{self}}, *, out_int32={{out_int32}}, right={{right}})",
    "tvm_pattern": "tvm.relay.op.algorithm.searchsorted(sorted_sequence={{sorted_sequence_tvm}}, values={{values_tvm}}, right={{right_tvm}}, dtype={{dtype_tvm}})",
    "arg_mapping": {
      "sorted_sequence": "sorted_sequence_tvm",
      "self": "values_tvm",
      "right": "right_tvm",
      "out_int32": "dtype_tvm"
    },
    "example_pairs": [
      {
        "torch": "result = torch.searchsorted(sorted_tensor, values_tensor, right=False, out_int32=True)",
        "tvm": "result_tvm = tvm.relay.op.algorithm.searchsorted(sorted_sequence_tvm, values_tvm, right=False, dtype='int32')"
      }
    ],
    "constraints": "PyTorch's `self` maps to TVM's `values` parameter. `out_int32=True` in PyTorch maps to `dtype='int32'` in TVM (otherwise default `int64`). PyTorch has a `sorter` parameter not directly in TVM's `searchsorted` signature.",
    "notes": "Direct functional mapping for finding insertion points in a sorted sequence.",
    "confidence": 0.9
  },
  {
    "torch_api": "torch._inductor.lowering.copy",
    "tvm_api": "tvm.relay.op.tensor.copy",
    "mapping_type": "direct",
    "direction": "torch_to_tvm",
    "torch_pattern": "torch.copy({{self}}, {{src}}, non_blocking={{non_blocking}})",
    "tvm_pattern": "tvm.relay.op.tensor.copy({{data}})",
    "arg_mapping": {
      "src": "data"
    },
    "example_pairs": [
      {
        "torch": "target.copy_(source)",
        "tvm": "target_tvm = tvm.relay.op.tensor.copy(source_tvm)"
      }
    ],
    "constraints": "PyTorch's `copy` (and its Inductor lowering) handles device transfers, dtype conversions, and shape expansion. TVM's `relay.op.tensor.copy` is a simple element-wise copy assuming compatible inputs. Explicit TVM ops for device, dtype, and shape adjustments would be needed if the PyTorch `copy` includes these more complex semantics.",
    "notes": "Maps the core data copying operation. The full semantic richness of PyTorch's `copy` (e.g., device/dtype/shape handling) requires composite TVM operations if not implicitly handled by the graph context.",
    "confidence": 0.8
  },
  {
    "torch_api": "torch._inductor.lowering.full_like",
    "tvm_api": "tvm.relay.op.transform.full_like",
    "mapping_type": "direct",
    "direction": "torch_to_tvm",
    "torch_pattern": "torch.full_like({{x}}, {{fill_value}}, **kwargs)",
    "tvm_pattern": "tvm.relay.op.transform.full_like({{data}}, {{fill_value_tvm}})",
    "arg_mapping": {
      "x": "data",
      "fill_value": "fill_value_tvm"
    },
    "example_pairs": [
      {
        "torch": "z = torch.full_like(x, 1.0)",
        "tvm": "z_tvm = tvm.relay.op.transform.full_like(x_tvm, tvm.tir.FloatImm('float32', 1.0))"
      }
    ],
    "constraints": "TVM's `full_like` uses the input tensor's shape and dtype. PyTorch's API allows overriding `dtype`, `layout`, `device`, etc., which would require explicit conversion ops in TVM if desired.",
    "notes": "Direct functional mapping to create a tensor with the same shape as an input tensor, filled with a scalar value. Same as API 44.",
    "confidence": 0.95
  },
  {
    "torch_api": "torch._inductor.lowering.empty",
    "tvm_api": null,
    "mapping_type": "no_mapping",
    "direction": "torch_to_tvm",
    "torch_pattern": null,
    "tvm_pattern": null,
    "arg_mapping": {},
    "example_pairs": [],
    "constraints": "Not convertible",
    "notes": "NO_MAPPING: PyTorch's `empty` creates a symbolic, uninitialized tensor within the computation graph. The TVM candidate `tvm.runtime.ndarray.empty` is a runtime function to allocate an uninitialized `NDArray` on the host or device. It's a runtime memory allocation, not a graph-level operator equivalent to PyTorch's `empty` in the context of Inductor lowering.",
    "confidence": 0.3
  },
  {
    "torch_api": "torch._inductor.lowering.full",
    "tvm_api": "tvm.relay.op.transform.full",
    "mapping_type": "direct",
    "direction": "torch_to_tvm",
    "torch_pattern": "torch.full({{size}}, {{fill_value}}, **kwargs)",
    "tvm_pattern": "tvm.relay.op.transform.full({{fill_value_tvm}}, shape={{size_tvm}}, dtype={{dtype_tvm}})",
    "arg_mapping": {
      "size": "size_tvm",
      "fill_value": "fill_value_tvm",
      "dtype": "dtype_tvm"
    },
    "example_pairs": [
      {
        "torch": "x = torch.full([2, 3], 5.0, dtype=torch.float32)",
        "tvm": "x = tvm.relay.op.transform.full(tvm.tir.FloatImm('float32', 5.0), shape=[2, 3], dtype='float32')"
      }
    ],
    "constraints": "TVM's `fill_value` parameter is first, then `shape`. Dtype should be explicitly provided or inferred.",
    "notes": "Direct functional mapping for creating a tensor filled with a scalar value. Same as API 5 and 42.",
    "confidence": 0.9
  },
  {
    "torch_api": "torch._inductor.lowering.gather",
    "tvm_api": "tvm.relay.op.transform.gather",
    "mapping_type": "direct",
    "direction": "torch_to_tvm",
    "torch_pattern": "torch.gather({{x}}, {{dim}}, {{index}}, sparse_grad={{sparse_grad}})",
    "tvm_pattern": "tvm.relay.op.transform.gather({{data}}, {{axis}}, {{indices}})",
    "arg_mapping": {
      "x": "data",
      "dim": "axis",
      "index": "indices"
    },
    "example_pairs": [
      {
        "torch": "output = torch.gather(input_tensor, 0, index_tensor)",
        "tvm": "output_tvm = tvm.relay.op.transform.gather(input_tensor_tvm, 0, index_tensor_tvm)"
      }
    ],
    "constraints": "PyTorch's `sparse_grad` parameter is for backward computation and doesn't affect forward `gather`. TVM's `gather` does not have this parameter.",
    "notes": "Direct functional mapping for gathering elements along an axis.",
    "confidence": 0.95
  },
  {
    "torch_api": "torch._inductor.lowering.scatter",
    "tvm_api": "tvm.relay.op.transform.scatter",
    "mapping_type": "direct",
    "direction": "torch_to_tvm",
    "torch_pattern": "torch.scatter({{x}}, {{dim}}, {{index}}, {{src}}, **kwargs)",
    "tvm_pattern": "tvm.relay.op.transform.scatter({{data}}, {{indices}}, {{updates}}, {{axis}})",
    "arg_mapping": {
      "x": "data",
      "dim": "axis",
      "index": "indices",
      "src": "updates"
    },
    "example_pairs": [
      {
        "torch": "output = torch.scatter(input_tensor, 0, index_tensor, src_tensor)",
        "tvm": "output_tvm = tvm.relay.op.transform.scatter(input_tensor_tvm, index_tensor_tvm, src_tensor_tvm, 0)"
      }
    ],
    "constraints": "TVM's `scatter` updates data at specified positions. PyTorch's `scatter` also supports an optional `reduce` argument (e.g., 'sum', 'prod') which would require a composite TVM operation if used.",
    "notes": "Direct functional mapping for scattering values from a source tensor into specific positions of another tensor.",
    "confidence": 0.9
  },
  {
    "torch_api": "torch._inductor.lowering.scatter_add",
    "tvm_api": "tvm.relay.op.transform.scatter_add",
    "mapping_type": "direct",
    "direction": "torch_to_tvm",
    "torch_pattern": "torch.scatter_add({{x}}, {{dim}}, {{index}}, {{src}})",
    "tvm_pattern": "tvm.relay.op.transform.scatter_add({{data}}, {{indices}}, {{updates}}, {{axis}})",
    "arg_mapping": {
      "x": "data",
      "dim": "axis",
      "index": "indices",
      "src": "updates"
    },
    "example_pairs": [
      {
        "torch": "output = torch.scatter_add(input_tensor, 0, index_tensor, src_tensor)",
        "tvm": "output_tvm = tvm.relay.op.transform.scatter_add(input_tensor_tvm, index_tensor_tvm, src_tensor_tvm, 0)"
      }
    ],
    "constraints": "None.",
    "notes": "Direct functional mapping for adding values from a source tensor to specific positions of another tensor.",
    "confidence": 0.95
  },
  {
    "torch_api": "torch._inductor.lowering.adaptive_max_pool2d",
    "tvm_api": "tvm.relay.op.nn.nn.adaptive_max_pool2d",
    "mapping_type": "direct",
    "direction": "torch_to_tvm",
    "torch_pattern": "torch.adaptive_max_pool2d({{x}}, {{output_size}})",
    "tvm_pattern": "tvm.relay.op.nn.nn.adaptive_max_pool2d({{data}}, output_size={{output_size_tvm}})",
    "arg_mapping": {
      "x": "data",
      "output_size": "output_size_tvm"
    },
    "example_pairs": [
      {
        "torch": "output, indices = torch.adaptive_max_pool2d(input_tensor, (7, 7))",
        "tvm": "output_tvm = tvm.relay.op.nn.nn.adaptive_max_pool2d(input_tensor_tvm, output_size=(7, 7))"
      }
    ],
    "constraints": "PyTorch's `adaptive_max_pool2d` returns both the output tensor and the max indices. TVM Relay's `adaptive_max_pool2d` function typically only returns the output tensor. If the indices are required, this would be a partial or composite mapping. PyTorch's lowering explicitly checks for `torch.int64` and handles `output_size` zero cases by returning empty tensors; these behaviors must be separately managed in TVM if needed.",
    "notes": "Maps the primary output (the max-pooled tensor) functionality. The indices output by PyTorch's version are not directly available from the TVM Relay op. Same as API 45.",
    "confidence": 0.85
  },
  {
    "torch_api": "torch._inductor.lowering.avg_pool2d",
    "tvm_api": "tvm.relay.op.nn.nn.avg_pool2d",
    "mapping_type": "direct",
    "direction": "torch_to_tvm",
    "torch_pattern": "torch.avg_pool2d({{x}}, kernel_size={{kernel_size}}, stride={{stride}}, padding={{padding}}, ceil_mode={{ceil_mode}}, count_include_pad={{count_include_pad}})",
    "tvm_pattern": "tvm.relay.op.nn.nn.avg_pool2d(data={{data}}, pool_size={{pool_size_tvm}}, strides={{strides_tvm}}, padding={{padding_tvm}}, ceil_mode={{ceil_mode_tvm}}, count_include_pad={{count_include_pad_tvm}})",
    "arg_mapping": {
      "x": "data",
      "kernel_size": "pool_size_tvm",
      "stride": "strides_tvm",
      "padding": "padding_tvm",
      "ceil_mode": "ceil_mode_tvm",
      "count_include_pad": "count_include_pad_tvm"
    },
    "example_pairs": [
      {
        "torch": "output = torch.avg_pool2d(input_tensor, kernel_size=2, stride=2, padding=0)",
        "tvm": "output_tvm = tvm.relay.op.nn.nn.avg_pool2d(data=input_tensor_tvm, pool_size=(2, 2), strides=(2, 2), padding=(0, 0))"
      }
    ],
    "constraints": "PyTorch's `divisor_override` parameter is not directly available in TVM's `avg_pool2d`. If `divisor_override` is used, a composite operation (e.g., sum then divide) would be needed in TVM. TVM has additional parameters like `dilation`, `layout`, `out_layout` which are not explicit in PyTorch's signature but would take default values.",
    "notes": "Direct functional mapping for 2D average pooling with standard parameters.",
    "confidence": 0.9
  },
  {
    "torch_api": "torch._inductor.lowering.avg_pool3d",
    "tvm_api": "tvm.relay.op.nn.nn.avg_pool3d",
    "mapping_type": "direct",
    "direction": "torch_to_tvm",
    "torch_pattern": "avg_pool3d({{x}}, {{kernel_size}}, stride={{stride}}, padding={{padding}}, ceil_mode={{ceil_mode}}, count_include_pad={{count_include_pad}}, divisor_override={{divisor_override}})",
    "tvm_pattern": "tvm.relay.op.nn.nn.avg_pool3d({{data}}, pool_size={{pool_size}}, strides={{strides}}, padding={{padding}}, ceil_mode={{ceil_mode}}, count_include_pad={{count_include_pad}})",
    "arg_mapping": {
      "x": "data",
      "kernel_size": "pool_size",
      "stride": "strides",
      "padding": "padding",
      "ceil_mode": "ceil_mode",
      "count_include_pad": "count_include_pad"
    },
    "example_pairs": [
      {
        "torch": "result = avg_pool3d(x, (3,3,3), stride=(1,1,1), padding=(0,0,0), ceil_mode=False, count_include_pad=True)",
        "tvm": "result = tvm.relay.op.nn.nn.avg_pool3d(data, pool_size=(3,3,3), strides=(1,1,1), padding=(0,0,0), ceil_mode=False, count_include_pad=True)"
      }
    ],
    "constraints": "`divisor_override` parameter in Torch has no direct equivalent in TVM's `avg_pool3d`. TVM's `avg_pool3d` has `dilation`, `layout`, `out_layout` parameters not present in Torch's call. Default for `count_include_pad` is different (True in Torch, False in TVM).",
    "notes": "Direct mapping for the core average pooling functionality. Parameter names align well, with some differences in supported extra parameters and defaults.",
    "confidence": 0.85
  },
  {
    "torch_api": "torch._inductor.lowering.mean",
    "tvm_api": "tvm.relay.op.reduce.mean",
    "mapping_type": "direct",
    "direction": "torch_to_tvm",
    "torch_pattern": "mean({{x}}, axis={{axis}}, keepdim={{keepdim}}, dtype={{dtype}})",
    "tvm_pattern": "tvm.relay.op.reduce.mean({{data}}, axis={{axis}}, keepdims={{keepdims}})",
    "arg_mapping": {
      "x": "data",
      "axis": "axis",
      "keepdim": "keepdims"
    },
    "example_pairs": [
      {
        "torch": "result = mean(x, axis=0, keepdim=True)",
        "tvm": "result = tvm.relay.op.reduce.mean(data, axis=0, keepdims=True)"
      }
    ],
    "constraints": "`dtype` parameter in Torch is for output type promotion and would require an explicit `cast` operation in TVM (e.g., `tvm.relay.op.cast`) either before or after the `mean` operation. `exclude` parameter in TVM has no direct equivalent in Torch's call.",
    "notes": "Direct functional mapping. Parameter names for data, axis, and keepdims align well. Type promotion in Torch needs external handling in TVM.",
    "confidence": 0.9
  },
  {
    "torch_api": "torch._inductor.lowering.mul",
    "tvm_api": null,
    "mapping_type": "no_mapping",
    "direction": "torch_to_tvm",
    "torch_pattern": null,
    "tvm_pattern": null,
    "arg_mapping": {},
    "example_pairs": [],
    "constraints": "Not convertible",
    "notes": "NO_MAPPING: The provided TVM `mul` (`tvm.relay.qnn.op.qnn.mul`) is specifically for *quantized* multiplication. Torch's `mul` is a general element-wise multiplication. A general element-wise multiply for TVM Relay (e.g., `tvm.relay.op.tensor.multiply`) is not in the provided snippets.",
    "confidence": 0.2
  },
  {
    "torch_api": "torch._inductor.lowering.div",
    "tvm_api": "tvm.tir.op.div",
    "mapping_type": "direct",
    "direction": "torch_to_tvm",
    "torch_pattern": "div({{a}}, {{b}})",
    "tvm_pattern": "tvm.tir.op.div({{a}}, {{b}})",
    "arg_mapping": {
      "a": "a",
      "b": "b"
    },
    "example_pairs": [
      {
        "torch": "result = div(a, b)",
        "tvm": "result = tvm.tir.op.div(a, b)"
      }
    ],
    "constraints": "Torch's `div` performs type promotion (e.g., int to float) and can have different rounding modes. TVM's `tir.op.div` performs C/C++ semantics division (truncates towards zero for integers). If integer division with floor semantics or specific float division behavior is required, additional operations (e.g., `cast`, `floor`, `ceil`) might be necessary in TVM.",
    "notes": "Direct mapping for the division operation itself. Semantic differences regarding integer division and floating-point precision/rounding should be noted.",
    "confidence": 0.8
  },
  {
    "torch_api": "torch._inductor.lowering.fmod",
    "tvm_api": [
      "tvm.tir.op.fmod",
      "tvm.tir.op.mod"
    ],
    "mapping_type": "composite",
    "direction": "torch_to_tvm",
    "torch_pattern": "fmod({{a}}, {{b}})",
    "tvm_pattern": "if (is_integral({{a}})): tvm.tir.op.mod({{a}}, {{b}}) else: tvm.tir.op.fmod({{a}}, {{b}})",
    "arg_mapping": {
      "a": "a",
      "b": "b"
    },
    "example_pairs": [
      {
        "torch": "result_float = fmod(a_float, b_float)",
        "tvm": "result_float = tvm.tir.op.fmod(a_float, b_float)"
      },
      {
        "torch": "result_int = fmod(a_int, b_int)",
        "tvm": "result_int = tvm.tir.op.mod(a_int, b_int)"
      }
    ],
    "constraints": "The PyTorch `fmod` internally dispatches to `ops.mod` for integral types and `ops.fmod` for floating-point types. TVM requires separate operators (`tvm.tir.op.mod` and `tvm.tir.op.fmod`) depending on the input type. Type-dependent conditional logic must be applied during conversion.",
    "notes": "Composite mapping due to Torch's internal type-based dispatch. TVM provides distinct operators for float (`fmod`) and integer (`mod`) remainder operations.",
    "confidence": 0.85
  },
  {
    "torch_api": "torch._inductor.lowering.cumsum",
    "tvm_api": "tvm.relay.op.transform.cumsum",
    "mapping_type": "direct",
    "direction": "torch_to_tvm",
    "torch_pattern": "cumsum({{x}}, axis={{axis}}, dtype={{dtype}})",
    "tvm_pattern": "tvm.relay.op.transform.cumsum({{data}}, axis={{axis}}, dtype={{dtype}})",
    "arg_mapping": {
      "x": "data",
      "axis": "axis",
      "dtype": "dtype"
    },
    "example_pairs": [
      {
        "torch": "result = cumsum(x, axis=1, dtype=torch.float32)",
        "tvm": "result = tvm.relay.op.transform.cumsum(data, axis=1, dtype='float32')"
      }
    ],
    "constraints": "TVM's `cumsum` has an `exclusive` parameter that Torch's version does not directly expose. Default `dtype` handling for integers/booleans in Torch (promoting to `torch.int64`) should be explicitly managed or matched with TVM's `dtype` parameter.",
    "notes": "Direct functional mapping. Parameters align well, with TVM offering an additional `exclusive` option.",
    "confidence": 0.95
  },
  {
    "torch_api": "torch._inductor.lowering.cumprod",
    "tvm_api": "tvm.relay.op.transform.cumprod",
    "mapping_type": "direct",
    "direction": "torch_to_tvm",
    "torch_pattern": "cumprod({{x}}, axis={{axis}}, dtype={{dtype}})",
    "tvm_pattern": "tvm.relay.op.transform.cumprod({{data}}, axis={{axis}}, dtype={{dtype}})",
    "arg_mapping": {
      "x": "data",
      "axis": "axis",
      "dtype": "dtype"
    },
    "example_pairs": [
      {
        "torch": "result = cumprod(x, axis=1, dtype=torch.float32)",
        "tvm": "result = tvm.relay.op.transform.cumprod(data, axis=1, dtype='float32')"
      }
    ],
    "constraints": "TVM's `cumprod` has an `exclusive` parameter that Torch's version does not directly expose. Default `dtype` handling for integers/booleans in Torch (promoting to `torch.int64`) should be explicitly managed or matched with TVM's `dtype` parameter.",
    "notes": "Direct functional mapping. Parameters align well, with TVM offering an additional `exclusive` option.",
    "confidence": 0.95
  },
  {
    "torch_api": "torch._inductor.lowering.prod",
    "tvm_api": "tvm.relay.op.reduce.prod",
    "mapping_type": "direct",
    "direction": "torch_to_tvm",
    "torch_pattern": "prod({{x}}, axis={{axis}}, keepdims={{keepdims}}, dtype={{dtype}})",
    "tvm_pattern": "tvm.relay.op.reduce.prod({{data}}, axis={{axis}}, keepdims={{keepdims}})",
    "arg_mapping": {
      "x": "data",
      "axis": "axis",
      "keepdims": "keepdims"
    },
    "example_pairs": [
      {
        "torch": "result = prod(x, axis=0, keepdims=True)",
        "tvm": "result = tvm.relay.op.reduce.prod(data, axis=0, keepdims=True)"
      }
    ],
    "constraints": "`dtype` parameter in Torch is for output type promotion and would require an explicit `cast` operation in TVM (e.g., `tvm.relay.op.cast`) either before or after the `prod` operation. `exclude` parameter in TVM has no direct equivalent in Torch's call.",
    "notes": "Direct functional mapping. Parameter names for data, axis, and keepdims align well. Type promotion in Torch needs external handling in TVM.",
    "confidence": 0.9
  },
  {
    "torch_api": "torch._inductor.lowering.sort",
    "tvm_api": "tvm.relay.op.algorithm.sort",
    "mapping_type": "direct",
    "direction": "torch_to_tvm",
    "torch_pattern": "sort({{x}}, dim={{dim}}, descending={{descending}})",
    "tvm_pattern": "tvm.relay.op.algorithm.sort({{data}}, axis={{axis}}, is_ascend={{is_ascend}})",
    "arg_mapping": {
      "x": "data",
      "dim": "axis",
      "descending": "(not descending)"
    },
    "example_pairs": [
      {
        "torch": "result = sort(x, dim=-1, descending=False)",
        "tvm": "result = tvm.relay.op.algorithm.sort(data, axis=-1, is_ascend=True)"
      },
      {
        "torch": "result = sort(x, dim=0, descending=True)",
        "tvm": "result = tvm.relay.op.algorithm.sort(data, axis=0, is_ascend=False)"
      }
    ],
    "constraints": "The `descending` boolean in Torch needs to be converted to `is_ascend` boolean (True/False or 1/0) for TVM (e.g., `is_ascend = not descending`). Torch's `sort` returns a tuple `(values, indices)` while TVM's `sort` returns only the sorted values. If indices are needed, `argsort` should be used separately.",
    "notes": "Direct mapping for sorting the data. Parameter `dim` in Torch maps to `axis` in TVM, and `descending` maps to `is_ascend` with inverse logic.",
    "confidence": 0.9
  },
  {
    "torch_api": "torch._inductor.lowering.while_loop",
    "tvm_api": "tvm.relay.loops.while_loop",
    "mapping_type": "direct",
    "direction": "torch_to_tvm",
    "torch_pattern": "while_loop({{cond_fn}}, {{body_fn}}, {{carried_inputs}}, {{additional_inputs}}, stack_output={{stack_output}})",
    "tvm_pattern": "tvm.relay.loops.while_loop({{cond}}, {{loop_vars}}, {{loop_bodies}})",
    "arg_mapping": {
      "cond_fn": "cond",
      "body_fn": "loop_bodies",
      "carried_inputs": "loop_vars"
    },
    "example_pairs": [
      {
        "torch": "output = while_loop(cond_func, body_func, initial_inputs, [])",
        "tvm": "output = tvm.relay.loops.while_loop(cond_func_tvm, initial_inputs_tvm, body_func_tvm)"
      }
    ],
    "constraints": "Torch's `additional_inputs` and `stack_output` parameters do not have direct equivalents in TVM's `while_loop`. These would need to be handled either by incorporating into `loop_vars`/`loop_bodies` or by pre/post-processing the loop in TVM.",
    "notes": "Direct mapping for the core functional programming construct of a while loop, with `cond_fn`, `body_fn`, and `carried_inputs` aligning with `cond`, `loop_bodies`, and `loop_vars` respectively.",
    "confidence": 0.8
  },
  {
    "torch_api": "torch._inductor.test_operators.realize",
    "tvm_api": null,
    "mapping_type": "no_mapping",
    "direction": "torch_to_tvm",
    "torch_pattern": null,
    "tvm_pattern": null,
    "arg_mapping": {},
    "example_pairs": [],
    "constraints": "Not convertible",
    "notes": "NO_MAPPING: Torch's `realize` appears to be an internal graph operator for testing/graph manipulation. The TVM candidates are either a quantization pass (`tvm.relay.quantize.quantize.realize`) or a low-level TIR memory allocation construct (`tvm.script.ir_builder.tir.ir.realize`), neither of which directly correspond to the Torch API's apparent purpose as a tensor operator.",
    "confidence": 0.2
  },
  {
    "torch_api": "torch._inductor.utils.unique",
    "tvm_api": null,
    "mapping_type": "no_mapping",
    "direction": "torch_to_tvm",
    "torch_pattern": null,
    "tvm_pattern": null,
    "arg_mapping": {},
    "example_pairs": [],
    "constraints": "Not convertible",
    "notes": "NO_MAPPING: Torch's `unique` is a generic Python utility function for iterables (using `id(x)`), not a tensor operation. The TVM `unique` functions (`tvm.relay.op.transform.unique`, etc.) are tensor-specific operators for finding unique elements in a 1-D tensor.",
    "confidence": 0.2
  },
  {
    "torch_api": "torch._inductor.utils.ceildiv",
    "tvm_api": "tvm.tir.op.ceildiv",
    "mapping_type": "direct",
    "direction": "torch_to_tvm",
    "torch_pattern": "ceildiv({{number}}, {{denom}})",
    "tvm_pattern": "tvm.tir.op.ceildiv({{lhs}}, {{rhs}})",
    "arg_mapping": {
      "number": "lhs",
      "denom": "rhs"
    },
    "example_pairs": [
      {
        "torch": "result = ceildiv(10, 3)",
        "tvm": "result = tvm.tir.op.ceildiv(10, 3)"
      }
    ],
    "constraints": "Torch's `ceildiv` explicitly handles `sympy.Expr` inputs, which would require pre-evaluation or symbolic conversion to TVM expressions. TVM's `ceildiv` is a TIR-level operator primarily for integer expressions.",
    "notes": "Direct functional mapping for integer ceiling division.",
    "confidence": 0.95
  },
  {
    "torch_api": "torch._inductor.utils.argsort",
    "tvm_api": null,
    "mapping_type": "no_mapping",
    "direction": "torch_to_tvm",
    "torch_pattern": null,
    "tvm_pattern": null,
    "arg_mapping": {},
    "example_pairs": [],
    "constraints": "Not convertible",
    "notes": "NO_MAPPING: Torch's `argsort` is a generic Python utility function for sequences. The TVM `argsort` functions (`tvm.relay.op.algorithm.argsort`, etc.) are tensor-specific operators for returning indices that sort a tensor.",
    "confidence": 0.2
  },
  {
    "torch_api": "torch._inductor.analysis.profile_analysis.main",
    "tvm_api": null,
    "mapping_type": "no_mapping",
    "direction": "torch_to_tvm",
    "torch_pattern": null,
    "tvm_pattern": null,
    "arg_mapping": {},
    "example_pairs": [],
    "constraints": "Not convertible",
    "notes": "NO_MAPPING: These are both `main` functions, but they serve as command-line interface entry points for entirely different programs (PyTorch's for profile analysis, TVM's for auto-scheduler record management or tuning scripts). There is no functional equivalence.",
    "confidence": 0.2
  },
  {
    "torch_api": "torch._inductor.compile_worker.__main__.main",
    "tvm_api": null,
    "mapping_type": "no_mapping",
    "direction": "torch_to_tvm",
    "torch_pattern": null,
    "tvm_pattern": null,
    "arg_mapping": {},
    "example_pairs": [],
    "constraints": "Not convertible",
    "notes": "NO_MAPPING: These are both `main` functions, but they serve as command-line interface entry points for entirely different programs (PyTorch's for a compile worker, TVM's for auto-scheduler record management or tuning scripts). There is no functional equivalence.",
    "confidence": 0.2
  },
  {
    "torch_api": "torch._inductor.runtime.halide_helpers.rand",
    "tvm_api": null,
    "mapping_type": "no_mapping",
    "direction": "torch_to_tvm",
    "torch_pattern": null,
    "tvm_pattern": null,
    "arg_mapping": {},
    "example_pairs": [],
    "constraints": "Not convertible",
    "notes": "NO_MAPPING: Torch's `rand` in this context is a runtime random number generation utility within its specific runtime (using Halide/Philox). TVM's `tvm.relay.testing.rand` is a testing utility to create random *input* `NDArray`s from NumPy, not an operator to generate random numbers *within* a TVM Relay graph.",
    "confidence": 0.2
  },
  {
    "torch_api": "torch._inductor.runtime.runtime_utils.ceildiv",
    "tvm_api": "tvm.tir.op.ceildiv",
    "mapping_type": "direct",
    "direction": "torch_to_tvm",
    "torch_pattern": "ceildiv({{number}}, {{denom}})",
    "tvm_pattern": "tvm.tir.op.ceildiv({{lhs}}, {{rhs}})",
    "arg_mapping": {
      "number": "lhs",
      "denom": "rhs"
    },
    "example_pairs": [
      {
        "torch": "result = ceildiv(10, 3)",
        "tvm": "result = tvm.tir.op.ceildiv(10, 3)"
      }
    ],
    "constraints": "TVM's `ceildiv` is a TIR-level operator. Behavior for negative numbers might need verification for exact PyTorch compatibility.",
    "notes": "Direct functional mapping for integer ceiling division.",
    "confidence": 0.95
  },
  {
    "torch_api": "torch._inductor.runtime.triton_helpers.prod",
    "tvm_api": "tvm.relay.op.reduce.prod",
    "mapping_type": "direct",
    "direction": "torch_to_tvm",
    "torch_pattern": "prod({{input}}, {{axis}})",
    "tvm_pattern": "tvm.relay.op.reduce.prod({{data}}, axis={{axis}})",
    "arg_mapping": {
      "input": "data",
      "axis": "axis"
    },
    "example_pairs": [
      {
        "torch": "result = prod(input_tensor, dim)",
        "tvm": "result = tvm.relay.op.reduce.prod(input_tensor, axis=dim)"
      }
    ],
    "constraints": "Torch's `prod` is a Triton kernel, while TVM's `prod` is a Relay operator. While functionally equivalent for the reduction, the implementation context differs. TVM `prod` has `keepdims` and `exclude` parameters not directly exposed in the Triton helper snippet.",
    "notes": "Direct functional mapping for product reduction across an axis.",
    "confidence": 0.9
  },
  {
    "torch_api": "torch._inductor.runtime.triton_helpers.minimum",
    "tvm_api": "tvm.relay.op.tensor.minimum",
    "mapping_type": "direct",
    "direction": "torch_to_tvm",
    "torch_pattern": "minimum({{a}}, {{b}})",
    "tvm_pattern": "tvm.relay.op.tensor.minimum({{lhs}}, {{rhs}})",
    "arg_mapping": {
      "a": "lhs",
      "b": "rhs"
    },
    "example_pairs": [
      {
        "torch": "result = minimum(a, b)",
        "tvm": "result = tvm.relay.op.tensor.minimum(a, b)"
      }
    ],
    "constraints": "The Triton helper explicitly handles NaN values (`mask |= a != a`). TVM's `minimum` typically follows IEEE 754 standard for floating-point comparisons where `min(NaN, x) = x`. If NaN propagation is strictly required, additional masking or conditional logic might be needed in TVM.",
    "notes": "Direct element-wise minimum. NaN handling is a potential difference in behavior.",
    "confidence": 0.85
  },
  {
    "torch_api": "torch._inductor.runtime.triton_helpers.maximum",
    "tvm_api": "tvm.relay.op.tensor.maximum",
    "mapping_type": "direct",
    "direction": "torch_to_tvm",
    "torch_pattern": "maximum({{a}}, {{b}})",
    "tvm_pattern": "tvm.relay.op.tensor.maximum({{lhs}}, {{rhs}})",
    "arg_mapping": {
      "a": "lhs",
      "b": "rhs"
    },
    "example_pairs": [
      {
        "torch": "result = maximum(a, b)",
        "tvm": "result = tvm.relay.op.tensor.maximum(a, b)"
      }
    ],
    "constraints": "The Triton helper explicitly handles NaN values (`mask |= a != a`). TVM's `maximum` typically follows IEEE 754 standard for floating-point comparisons where `max(NaN, x) = x`. If NaN propagation is strictly required, additional masking or conditional logic might be needed in TVM.",
    "notes": "Direct element-wise maximum. NaN handling is a potential difference in behavior.",
    "confidence": 0.85
  },
  {
    "torch_api": "torch._inductor.runtime.triton_helpers.exp",
    "tvm_api": "tvm.relay.op.tensor.exp",
    "mapping_type": "direct",
    "direction": "torch_to_tvm",
    "torch_pattern": "exp({{x}}, use_fast_math={{use_fast_math}})",
    "tvm_pattern": "tvm.relay.op.tensor.exp({{data}})",
    "arg_mapping": {
      "x": "data"
    },
    "example_pairs": [
      {
        "torch": "result = exp(input_tensor, use_fast_math=True)",
        "tvm": "result = tvm.relay.op.tensor.exp(input_tensor)"
      }
    ],
    "constraints": "The `use_fast_math` parameter in the Triton helper is an optimization hint for the Triton JIT compiler. TVM's `exp` operator does not expose such a parameter directly, but TVM's backend compilers might apply similar optimizations based on target and compilation flags.",
    "notes": "Direct functional mapping for the element-wise exponential operation. The fast math option in Triton is a compiler-specific feature.",
    "confidence": 0.95
  },
  {
    "torch_api": "torch._inductor.runtime.triton_helpers.any",
    "tvm_api": "tvm.relay.op.reduce.any",
    "mapping_type": "direct",
    "direction": "torch_to_tvm",
    "torch_pattern": "any({{a}}, {{dim}})",
    "tvm_pattern": "tvm.relay.op.reduce.any({{data}}, axis={{axis}})",
    "arg_mapping": {
      "a": "data",
      "dim": "axis"
    },
    "example_pairs": [
      {
        "torch": "result = any(input_tensor, dim=0)",
        "tvm": "result = tvm.relay.op.reduce.any(input_tensor, axis=0)"
      }
    ],
    "constraints": "TVM's `any` has `keepdims` and `exclude` parameters not explicitly shown in the Triton helper snippet.",
    "notes": "Direct functional mapping for logical OR reduction across an axis.",
    "confidence": 0.9
  },
  {
    "torch_api": "torch._inductor.runtime.triton_heuristics.template",
    "tvm_api": null,
    "mapping_type": "no_mapping",
    "direction": "torch_to_tvm",
    "torch_pattern": null,
    "tvm_pattern": null,
    "arg_mapping": {},
    "example_pairs": [],
    "constraints": "Not convertible",
    "notes": "NO_MAPPING: Torch's `template` is a function for compiling Triton kernels based on specified parameters. TVM's `tvm.autotvm.task.task.template` is a decorator used within AutoTVM for defining tunable schedule templates. They share the name but have entirely different functionalities and contexts.",
    "confidence": 0.2
  },
  {
    "torch_api": "torch._lazy.ts_backend.init",
    "tvm_api": null,
    "mapping_type": "no_mapping",
    "direction": "torch_to_tvm",
    "torch_pattern": null,
    "tvm_pattern": null,
    "arg_mapping": {},
    "example_pairs": [],
    "constraints": "Not convertible",
    "notes": "NO_MAPPING: Torch's `init` initializes a specific lazy TorchScript backend. The TVM `tvm.script.ir_builder.tir.ir.init` is a low-level IR builder function for initializing a block, which is not functionally equivalent.",
    "confidence": 0.2
  },
  {
    "torch_api": "torch._numpy._binary_ufuncs_impl.matmul",
    "tvm_api": "tvm.relay.op.nn.nn.matmul",
    "mapping_type": "direct",
    "direction": "torch_to_tvm",
    "torch_pattern": "matmul({{x}}, {{y}})",
    "tvm_pattern": "tvm.relay.op.nn.nn.matmul({{tensor_a}}, {{tensor_b}})",
    "arg_mapping": {
      "x": "tensor_a",
      "y": "tensor_b"
    },
    "example_pairs": [
      {
        "torch": "result = matmul(tensor1, tensor2)",
        "tvm": "result = tvm.relay.op.nn.nn.matmul(tensor1_tvm, tensor2_tvm)"
      }
    ],
    "constraints": "Torch's `matmul` handles explicit type promotion and casting (e.g., bool to uint8, half to float32). This pre-processing would need to be explicitly managed in TVM. TVM's `matmul` has `units`, `out_dtype`, `transpose_a`, `transpose_b` parameters.",
    "notes": "Direct functional mapping for matrix multiplication. Type handling in PyTorch's NumPy compatibility layer needs careful translation to TVM.",
    "confidence": 0.8
  },
  {
    "torch_api": "torch._numpy._funcs_impl.copy",
    "tvm_api": "tvm.relay.op.tensor.copy",
    "mapping_type": "direct",
    "direction": "torch_to_tvm",
    "torch_pattern": "copy({{a}}, order={{order}}, subok={{subok}})",
    "tvm_pattern": "tvm.relay.op.tensor.copy({{data}})",
    "arg_mapping": {
      "a": "data"
    },
    "example_pairs": [
      {
        "torch": "result = copy(a_tensor)",
        "tvm": "result = tvm.relay.op.tensor.copy(a_tensor)"
      }
    ],
    "constraints": "Torch's `copy` has `order` and `subok` parameters (though `subok` is not supported in the snippet). TVM's `copy` is a simpler operation without these parameters.",
    "notes": "Direct functional mapping for creating a copy of a tensor.",
    "confidence": 0.95
  },
  {
    "torch_api": "torch._numpy._funcs_impl.concatenate",
    "tvm_api": "tvm.relay.op.tensor.concatenate",
    "mapping_type": "direct",
    "direction": "torch_to_tvm",
    "torch_pattern": "concatenate({{ar_tuple}}, axis={{axis}}, out={{out}}, dtype={{dtype}}, casting={{casting}})",
    "tvm_pattern": "tvm.relay.op.tensor.concatenate({{data}}, axis={{axis}})",
    "arg_mapping": {
      "ar_tuple": "data",
      "axis": "axis"
    },
    "example_pairs": [
      {
        "torch": "result = concatenate([t1, t2], axis=0)",
        "tvm": "result = tvm.relay.op.tensor.concatenate([t1, t2], axis=0)"
      }
    ],
    "constraints": "Torch's `concatenate` supports `out`, `dtype`, and `casting` parameters that are not directly available in TVM's `concatenate` operator. Type casting would need to be handled explicitly before concatenation in TVM.",
    "notes": "Direct functional mapping for concatenating tensors along an axis.",
    "confidence": 0.9
  },
  {
    "torch_api": "torch._numpy._funcs_impl.stack",
    "tvm_api": "tvm.relay.op.tensor.stack",
    "mapping_type": "direct",
    "direction": "torch_to_tvm",
    "torch_pattern": "stack({{arrays}}, axis={{axis}}, out={{out}}, dtype={{dtype}}, casting={{casting}})",
    "tvm_pattern": "tvm.relay.op.tensor.stack({{data}}, axis={{axis}})",
    "arg_mapping": {
      "arrays": "data",
      "axis": "axis"
    },
    "example_pairs": [
      {
        "torch": "result = stack([t1, t2], axis=0)",
        "tvm": "result = tvm.relay.op.tensor.stack([t1, t2], axis=0)"
      }
    ],
    "constraints": "Torch's `stack` supports `out`, `dtype`, and `casting` parameters that are not directly available in TVM's `stack` operator. Type casting would need to be handled explicitly before stacking in TVM.",
    "notes": "Direct functional mapping for stacking tensors along a new axis.",
    "confidence": 0.9
  },
  {
    "torch_api": "torch._numpy._funcs_impl.split",
    "tvm_api": "tvm.relay.op.transform.split",
    "mapping_type": "direct",
    "direction": "torch_to_tvm",
    "torch_pattern": "split({{ary}}, {{indices_or_sections}}, axis={{axis}})",
    "tvm_pattern": "tvm.relay.op.transform.split({{data}}, {{indices_or_sections}}, axis={{axis}})",
    "arg_mapping": {
      "ary": "data",
      "indices_or_sections": "indices_or_sections",
      "axis": "axis"
    },
    "example_pairs": [
      {
        "torch": "result = split(tensor, 2, axis=0)",
        "tvm": "result = tvm.relay.op.transform.split(tensor_tvm, 2, axis=0)"
      },
      {
        "torch": "result = split(tensor, [1, 3], axis=1)",
        "tvm": "result = tvm.relay.op.transform.split(tensor_tvm, [1, 3], axis=1)"
      }
    ],
    "constraints": "Torch's `_split_helper` used by `split` has a `strict` parameter not present in TVM. Functionally, `split` should map directly.",
    "notes": "Direct functional mapping for splitting a tensor into multiple sub-arrays.",
    "confidence": 0.95
  },
  {
    "torch_api": "torch._numpy._funcs_impl.arange",
    "tvm_api": "tvm.relay.op.transform.arange",
    "mapping_type": "direct",
    "direction": "torch_to_tvm",
    "torch_pattern": "arange(start={{start}}, stop={{stop}}, step={{step}}, dtype={{dtype}})",
    "tvm_pattern": "tvm.relay.op.transform.arange(start={{start}}, stop={{stop}}, step={{step}}, dtype={{dtype}})",
    "arg_mapping": {
      "start": "start",
      "stop": "stop",
      "step": "step",
      "dtype": "dtype"
    },
    "example_pairs": [
      {
        "torch": "result = arange(0, 10, 2, dtype=torch.int32)",
        "tvm": "result = tvm.relay.op.transform.arange(0, 10, 2, dtype='int32')"
      },
      {
        "torch": "result = arange(5, dtype=torch.float32)",
        "tvm": "result = tvm.relay.op.transform.arange(0, 5, 1, dtype='float32')"
      }
    ],
    "constraints": "Torch's `arange` has more flexible argument parsing (e.g., `arange(stop)` where `start` defaults to 0). This needs explicit translation for TVM. TVM's `dtype` defaults to 'float32' and `step` to 1. TVM `arange` also warns about undefined behavior when dtype is incompatible with start/stop/step.",
    "notes": "Direct functional mapping for generating evenly spaced values. Care must be taken to explicitly provide `start`, `stop`, `step`, and `dtype` to TVM.",
    "confidence": 0.9
  },
  {
    "torch_api": "torch._numpy._funcs_impl.empty",
    "tvm_api": "tvm.runtime.ndarray.empty",
    "mapping_type": "direct",
    "direction": "torch_to_tvm",
    "torch_pattern": "empty(shape={{shape}}, dtype={{dtype}}, order={{order}}, like={{like}})",
    "tvm_pattern": "tvm.runtime.ndarray.empty(shape={{shape}}, dtype={{dtype}})",
    "arg_mapping": {
      "shape": "shape",
      "dtype": "dtype"
    },
    "example_pairs": [
      {
        "torch": "result = empty((2, 3), dtype=torch.float32)",
        "tvm": "result = tvm.runtime.ndarray.empty((2, 3), dtype='float32')"
      }
    ],
    "constraints": "Torch's `empty` has `order` and `like` parameters (though `like` is not supported in the snippet). TVM's `empty` has `device` and `mem_scope` parameters not present in Torch's call. Default `dtype` in Torch is float, TVM is 'float32'.",
    "notes": "Direct functional mapping for creating an uninitialized array with a given shape and dtype.",
    "confidence": 0.95
  },
  {
    "torch_api": "torch._numpy._funcs_impl.full",
    "tvm_api": "tvm.relay.op.transform.full",
    "mapping_type": "direct",
    "direction": "torch_to_tvm",
    "torch_pattern": "full(shape={{shape}}, fill_value={{fill_value}}, dtype={{dtype}}, order={{order}}, like={{like}})",
    "tvm_pattern": "tvm.relay.op.transform.full({{fill_value}}, shape={{shape}}, dtype={{dtype}})",
    "arg_mapping": {
      "shape": "shape",
      "fill_value": "fill_value",
      "dtype": "dtype"
    },
    "example_pairs": [
      {
        "torch": "result = full((2, 3), 5.0, dtype=torch.float32)",
        "tvm": "result = tvm.relay.op.transform.full(5.0, shape=(2, 3), dtype='float32')"
      }
    ],
    "constraints": "Torch's `full` has `order` and `like` parameters (though `like` is not supported in the snippet). TVM's `full` expects `fill_value` as the first argument, then `shape` and `dtype` (different from Torch's order). Default `dtype` in Torch is derived from `fill_value`, while TVM's needs to be explicitly provided or inferred.",
    "notes": "Direct functional mapping for creating an array filled with a scalar value. Parameter order and default `dtype` handling need adjustment.",
    "confidence": 0.9
  },
  {
    "torch_api": "torch._numpy._funcs_impl.full_like",
    "tvm_api": "tvm.relay.op.transform.full_like",
    "mapping_type": "direct",
    "direction": "torch_to_tvm",
    "torch_pattern": "full_like({{a}}, {{fill_value}}, dtype={{dtype}}, order={{order}}, subok={{subok}}, shape={{shape}})",
    "tvm_pattern": "tvm.relay.op.transform.full_like({{data}}, {{fill_value}})",
    "arg_mapping": {
      "a": "data",
      "fill_value": "fill_value"
    },
    "example_pairs": [
      {
        "torch": "ref_tensor = torch.randn(2, 3); result = full_like(ref_tensor, 7.0, dtype=torch.float32)",
        "tvm": "ref_tensor_tvm = ...; result = tvm.relay.op.transform.full_like(ref_tensor_tvm, 7.0)"
      }
    ],
    "constraints": "Torch's `full_like` supports `dtype`, `order`, `subok`, and `shape` parameters. TVM's `full_like` is simpler, expecting `data` and `fill_value`. Explicit type casting would be needed if `dtype` differs, and `shape` modification would require a separate `reshape` operation in TVM.",
    "notes": "Direct functional mapping for creating a tensor with the same shape and type as input, filled with a scalar value.",
    "confidence": 0.85
  },
  {
    "torch_api": "torch._numpy._funcs_impl.ones",
    "tvm_api": "tvm.relay.op.tensor.ones",
    "mapping_type": "direct",
    "direction": "torch_to_tvm",
    "torch_pattern": "ones(shape={{shape}}, dtype={{dtype}}, order={{order}}, like={{like}})",
    "tvm_pattern": "tvm.relay.op.tensor.ones(shape={{shape}}, dtype={{dtype}})",
    "arg_mapping": {
      "shape": "shape",
      "dtype": "dtype"
    },
    "example_pairs": [
      {
        "torch": "result = ones((2, 3), dtype=torch.float32)",
        "tvm": "result = tvm.relay.op.tensor.ones(shape=(2, 3), dtype='float32')"
      }
    ],
    "constraints": "Torch's `ones` has `order` and `like` parameters (though `like` is not supported in the snippet). TVM's `ones` is simpler. Default `dtype` in Torch is float, TVM requires explicit `dtype`.",
    "notes": "Direct functional mapping for creating an array of ones.",
    "confidence": 0.95
  },
  {
    "torch_api": "torch._numpy._funcs_impl.ones_like",
    "tvm_api": "tvm.relay.op.tensor.ones_like",
    "mapping_type": "direct",
    "direction": "torch_to_tvm",
    "torch_pattern": "ones_like({{a}}, dtype={{dtype}}, order={{order}}, subok={{subok}}, shape={{shape}})",
    "tvm_pattern": "tvm.relay.op.tensor.ones_like({{data}})",
    "arg_mapping": {
      "a": "data"
    },
    "example_pairs": [
      {
        "torch": "ref_tensor = torch.randn(2, 3); result = ones_like(ref_tensor, dtype=torch.float32)",
        "tvm": "ref_tensor_tvm = ...; result = tvm.relay.op.tensor.ones_like(ref_tensor_tvm)"
      }
    ],
    "constraints": "Torch's `ones_like` supports `dtype`, `order`, `subok`, and `shape` parameters. TVM's `ones_like` is simpler, deriving type and shape from the input `data`. Explicit type casting would be needed if `dtype` differs, and `shape` modification would require a separate `reshape` operation in TVM.",
    "notes": "Direct functional mapping for creating a tensor of ones with the same shape and type as input.",
    "confidence": 0.85
  },
  {
    "torch_api": "torch._numpy._funcs_impl.zeros",
    "tvm_api": "tvm.relay.op.tensor.zeros",
    "mapping_type": "direct",
    "direction": "torch_to_tvm",
    "torch_pattern": "zeros(shape={{shape}}, dtype={{dtype}}, order={{order}}, like={{like}})",
    "tvm_pattern": "tvm.relay.op.tensor.zeros(shape={{shape}}, dtype={{dtype}})",
    "arg_mapping": {
      "shape": "shape",
      "dtype": "dtype"
    },
    "example_pairs": [
      {
        "torch": "result = zeros((2, 3), dtype=torch.float32)",
        "tvm": "result = tvm.relay.op.tensor.zeros(shape=(2, 3), dtype='float32')"
      }
    ],
    "constraints": "Torch's `zeros` has `order` and `like` parameters (though `like` is not supported in the snippet). TVM's `zeros` is simpler. Default `dtype` in Torch is float, TVM requires explicit `dtype`.",
    "notes": "Direct functional mapping for creating an array of zeros.",
    "confidence": 0.95
  },
  {
    "torch_api": "torch._numpy._funcs_impl.zeros_like",
    "tvm_api": "tvm.relay.op.tensor.zeros_like",
    "mapping_type": "direct",
    "direction": "torch_to_tvm",
    "torch_pattern": "zeros_like({{a}}, dtype={{dtype}}, order={{order}}, subok={{subok}}, shape={{shape}})",
    "tvm_pattern": "tvm.relay.op.tensor.zeros_like({{data}})",
    "arg_mapping": {
      "a": "data"
    },
    "example_pairs": [
      {
        "torch": "ref_tensor = torch.randn(2, 3); result = zeros_like(ref_tensor, dtype=torch.float32)",
        "tvm": "ref_tensor_tvm = ...; result = tvm.relay.op.tensor.zeros_like(ref_tensor_tvm)"
      }
    ],
    "constraints": "Torch's `zeros_like` supports `dtype`, `order`, `subok`, and `shape` parameters. TVM's `zeros_like` is simpler, deriving type and shape from the input `data`. Explicit type casting would be needed if `dtype` differs, and `shape` modification would require a separate `reshape` operation in TVM.",
    "notes": "Direct functional mapping for creating a tensor of zeros with the same shape and type as input.",
    "confidence": 0.85
  },
  {
    "torch_api": "torch._numpy._funcs_impl.where",
    "tvm_api": "tvm.relay.op.transform.where",
    "mapping_type": "direct",
    "direction": "torch_to_tvm",
    "torch_pattern": "where(condition={{condition}}, x={{x}}, y={{y}})",
    "tvm_pattern": "tvm.relay.op.transform.where(condition={{condition}}, x={{x}}, y={{y}})",
    "arg_mapping": {
      "condition": "condition",
      "x": "x",
      "y": "y"
    },
    "example_pairs": [
      {
        "torch": "result = where(condition_tensor, x_tensor, y_tensor)",
        "tvm": "result = tvm.relay.op.transform.where(condition_tensor_tvm, x_tensor_tvm, y_tensor_tvm)"
      }
    ],
    "constraints": "Torch's `where` can be called with only `condition` (e.g., `torch.where(condition)`) to return indices of true elements; this specific usage is not covered by TVM's `where` operator, which expects `condition`, `x`, and `y`. Type conversion of condition to boolean in Torch also needs to be considered.",
    "notes": "Direct functional mapping for element-wise selection based on a condition.",
    "confidence": 0.9
  },
  {
    "torch_api": "torch._numpy._funcs_impl.flip",
    "tvm_api": "tvm.topi.transform.flip",
    "mapping_type": "direct",
    "direction": "torch_to_tvm",
    "torch_pattern": "flip({{m}}, axis={{axis}})",
    "tvm_pattern": "tvm.topi.transform.flip({{a}}, axis={{axis}})",
    "arg_mapping": {
      "m": "a",
      "axis": "axis"
    },
    "example_pairs": [
      {
        "torch": "result = flip(tensor, axis=0)",
        "tvm": "result = tvm.topi.transform.flip(tensor_tvm, axis=0)"
      },
      {
        "torch": "result = flip(tensor, axis=None)",
        "tvm": "result = tvm.topi.transform.flip(tensor_tvm, axis=(0, 1, 2))"
      }
    ],
    "constraints": "If Torch's `axis` is `None`, it means flipping along all dimensions, which requires constructing a tuple of all axes for TVM. The snippet mentions NumPy's `flip` returns a view while Torch's copies; TVM's `flip` typically returns a new tensor.",
    "notes": "Direct functional mapping for reversing elements along a specified axis/axes.",
    "confidence": 0.9
  },
  {
    "torch_api": "torch._numpy._funcs_impl.broadcast_to",
    "tvm_api": "tvm.relay.op.transform.broadcast_to",
    "mapping_type": "direct",
    "direction": "torch_to_tvm",
    "torch_pattern": "broadcast_to(array={{array}}, shape={{shape}}, subok={{subok}})",
    "tvm_pattern": "tvm.relay.op.transform.broadcast_to({{data}}, shape={{shape}})",
    "arg_mapping": {
      "array": "data",
      "shape": "shape"
    },
    "example_pairs": [
      {
        "torch": "result = broadcast_to(array_tensor, (2, 4))",
        "tvm": "result = tvm.relay.op.transform.broadcast_to(array_tensor_tvm, (2, 4))"
      }
    ],
    "constraints": "Torch's `broadcast_to` has a `subok` parameter, which is not supported in TVM's `broadcast_to` operator. The behavior for `shape` if it's a TVM `Constant` or `Expr` is also mentioned in TVM's documentation.",
    "notes": "Direct functional mapping for broadcasting a tensor to a target shape.",
    "confidence": 0.95
  },
  {
    "torch_api": "torch._numpy._funcs_impl.meshgrid",
    "tvm_api": "tvm.relay.op.transform.meshgrid",
    "mapping_type": "direct",
    "direction": "torch_to_tvm",
    "torch_pattern": "meshgrid(*{{xi}}, copy={{copy}}, sparse={{sparse}}, indexing={{indexing}})",
    "tvm_pattern": "tvm.relay.op.transform.meshgrid({{data}}, indexing={{indexing}})",
    "arg_mapping": {
      "xi": "data",
      "indexing": "indexing"
    },
    "example_pairs": [
      {
        "torch": "x = torch.tensor([1,2]); y = torch.tensor([3,4]); X, Y = meshgrid(x, y, indexing='xy')",
        "tvm": "x_tvm = relay.const([1,2]); y_tvm = relay.const([3,4]); X_tvm, Y_tvm = tvm.relay.op.transform.meshgrid([x_tvm, y_tvm], indexing='xy')"
      }
    ],
    "constraints": "Torch's `meshgrid` supports `copy` and `sparse` parameters which do not have direct equivalents in TVM's `meshgrid`. The `*xi` input (variable number of arguments) must be explicitly passed as a list/tuple to TVM's `data` parameter.",
    "notes": "Direct functional mapping for creating coordinate matrices from vectors, supporting `xy` and `ij` indexing.",
    "confidence": 0.85
  },
  {
    "torch_api": "torch._numpy._funcs_impl.take",
    "tvm_api": "tvm.relay.op.transform.take",
    "mapping_type": "direct",
    "direction": "torch_to_tvm",
    "torch_pattern": "take({{a}}, indices={{indices}}, axis={{axis}}, out={{out}}, mode={{mode}})",
    "tvm_pattern": "tvm.relay.op.transform.take({{data}}, {{indices}}, axis={{axis}}, batch_dims={{batch_dims}}, mode={{mode_tvm}})",
    "arg_mapping": {
      "a": "data",
      "indices": "indices",
      "axis": "axis",
      "mode": "mode_tvm"
    },
    "example_pairs": [
      {
        "torch": "result = take(array_tensor, indices_tensor, axis=0)",
        "tvm": "result = tvm.relay.op.transform.take(array_tensor_tvm, indices_tensor_tvm, axis=0, mode='clip')"
      }
    ],
    "constraints": "Torch's `take` has an `out` parameter not present in TVM. Torch's `mode` is hardcoded to 'raise', while TVM's `mode` parameter can be 'clip', 'wrap', or 'fast' (default 'clip'). Torch's behavior for `axis=None` (flattening the array) needs explicit flattening in TVM before calling `take` if `axis` is omitted. TVM has an additional `batch_dims` parameter.",
    "notes": "Direct functional mapping for taking elements from an array along an axis. Care must be taken with argument differences and default behaviors.",
    "confidence": 0.8
  },
  {
    "torch_api": "torch._numpy._funcs_impl.unique",
    "tvm_api": "tvm.relay.op.transform.unique",
    "mapping_type": "direct",
    "direction": "torch_to_tvm",
    "torch_pattern": "unique({{ar}}, return_index={{return_index}}, return_inverse={{return_inverse}}, return_counts={{return_counts}}, axis={{axis}}, equal_nan={{equal_nan}})",
    "tvm_pattern": "tvm.relay.op.transform.unique({{data}}, is_sorted={{is_sorted}}, return_counts={{return_counts}})",
    "arg_mapping": {
      "ar": "data",
      "return_counts": "return_counts"
    },
    "example_pairs": [
      {
        "torch": "result = unique(array_tensor, return_counts=True)",
        "tvm": "result = tvm.relay.op.transform.unique(array_tensor_tvm, return_counts=True)"
      }
    ],
    "constraints": "Torch's `unique` supports `return_index`, `return_inverse`, `axis` (`dim`), and `equal_nan` which are not directly available as parameters in TVM's `unique`. TVM's `unique` has an `is_sorted` parameter. If `return_index` or `return_inverse` is required, additional operations or different TVM operators would be needed. TVM's `unique` specifically notes that `output` and `counts` are padded to the same length as `data` and elements with index >= num_unique[0] have undefined value.",
    "notes": "Direct mapping for finding unique elements and optionally their counts. Other return options from Torch's `unique` are not directly supported.",
    "confidence": 0.75
  },
  {
    "torch_api": "torch._numpy._funcs_impl.argwhere",
    "tvm_api": "tvm.relay.op.transform.argwhere",
    "mapping_type": "direct",
    "direction": "torch_to_tvm",
    "torch_pattern": "argwhere({{a}})",
    "tvm_pattern": "tvm.relay.op.transform.argwhere({{condition}})",
    "arg_mapping": {
      "a": "condition"
    },
    "example_pairs": [
      {
        "torch": "result = argwhere(condition_tensor)",
        "tvm": "result = tvm.relay.op.transform.argwhere(condition_tensor_tvm)"
      }
    ],
    "constraints": "None.",
    "notes": "Direct functional mapping for finding indices of non-zero (or True) elements.",
    "confidence": 0.95
  },
  {
    "torch_api": "torch._numpy._funcs_impl.clip",
    "tvm_api": "tvm.relay.op.tensor.clip",
    "mapping_type": "direct",
    "direction": "torch_to_tvm",
    "torch_pattern": "clip({{a}}, min={{min}}, max={{max}}, out={{out}})",
    "tvm_pattern": "tvm.relay.op.tensor.clip({{a}}, {{a_min}}, {{a_max}})",
    "arg_mapping": {
      "a": "a",
      "min": "a_min",
      "max": "a_max"
    },
    "example_pairs": [
      {
        "torch": "result = clip(tensor, min=0.0, max=1.0)",
        "tvm": "result = tvm.relay.op.tensor.clip(tensor_tvm, 0.0, 1.0)"
      }
    ],
    "constraints": "Torch's `clip` has an `out` parameter not present in TVM. Parameter names for min/max differ (`min`/`max` in Torch vs. `a_min`/`a_max` in TVM).",
    "notes": "Direct functional mapping for clamping tensor values between a minimum and maximum.",
    "confidence": 0.95
  },
  {
    "torch_api": "torch._numpy._funcs_impl.tile",
    "tvm_api": "tvm.relay.op.transform.tile",
    "mapping_type": "direct",
    "direction": "torch_to_tvm",
    "torch_pattern": "tile({{A}}, {{reps}})",
    "tvm_pattern": "tvm.relay.op.transform.tile({{data}}, {{reps}})",
    "arg_mapping": {
      "A": "data",
      "reps": "reps"
    },
    "example_pairs": [
      {
        "torch": "result = tile(tensor, (2, 3))",
        "tvm": "result = tvm.relay.op.transform.tile(tensor_tvm, (2, 3))"
      },
      {
        "torch": "result = tile(tensor, 2)",
        "tvm": "result = tvm.relay.op.transform.tile(tensor_tvm, (2,))"
      }
    ],
    "constraints": "Torch's `reps` can be an integer, which needs to be converted to a tuple `(reps,)` for TVM.",
    "notes": "Direct functional mapping for repeating an array multiple times (tiling).",
    "confidence": 0.95
  },
  {
    "torch_api": "torch._numpy._funcs_impl.trace",
    "tvm_api": null,
    "mapping_type": "no_mapping",
    "direction": "torch_to_tvm",
    "torch_pattern": null,
    "tvm_pattern": null,
    "arg_mapping": {},
    "example_pairs": [],
    "constraints": "Not convertible",
    "notes": "NO_MAPPING: Torch's `trace` computes the sum along diagonals of an array (mathematical trace). The TVM `tvm.tir.op.trace` is a debugging/instrumentation function to trace tensor data at runtime. They have the same name but completely different functionalities.",
    "confidence": 0.2
  },
  {
    "torch_api": "torch._numpy._funcs_impl.tensordot",
    "tvm_api": "tvm.topi.transform.tensordot",
    "mapping_type": "direct",
    "direction": "torch_to_tvm",
    "torch_pattern": "tensordot({{a}}, {{b}}, axes={{axes}})",
    "tvm_pattern": "tvm.topi.transform.tensordot({{a}}, {{b}}, axes={{axes}})",
    "arg_mapping": {
      "a": "a",
      "b": "b",
      "axes": "axes"
    },
    "example_pairs": [
      {
        "torch": "result = tensordot(a_tensor, b_tensor, axes=2)",
        "tvm": "result = tvm.topi.transform.tensordot(a_tensor_tvm, b_tensor_tvm, axes=2)"
      },
      {
        "torch": "result = tensordot(a_tensor, b_tensor, axes=([0], [1]))",
        "tvm": "result = tvm.topi.transform.tensordot(a_tensor_tvm, b_tensor_tvm, axes=([0], [1]))"
      }
    ],
    "constraints": "Torch's `tensordot` implicitly handles type promotion and casting; this would need explicit handling in TVM. Torch also converts integer `axes` to lists/tuples.",
    "notes": "Direct functional mapping for tensor dot product. `axes` parameter handling is consistent.",
    "confidence": 0.9
  },
  {
    "torch_api": "torch._numpy._funcs_impl.einsum",
    "tvm_api": "tvm.relay.op.tensor.einsum",
    "mapping_type": "direct",
    "direction": "torch_to_tvm",
    "torch_pattern": "einsum(*{{operands}}, out={{out}}, dtype={{dtype}}, order={{order}}, casting={{casting}}, optimize={{optimize}})",
    "tvm_pattern": "tvm.relay.op.tensor.einsum({{data}}, {{equation}})",
    "arg_mapping": {
      "operands": "data",
      "equation": "equation"
    },
    "example_pairs": [
      {
        "torch": "A = torch.randn(2, 3); B = torch.randn(3, 4); result = einsum('ij,jk->ik', A, B)",
        "tvm": "A_tvm = relay.var('A', shape=(2,3)); B_tvm = relay.var('B', shape=(3,4)); result = tvm.relay.op.tensor.einsum([A_tvm, B_tvm], 'ij,jk->ik')"
      }
    ],
    "constraints": "Torch's `einsum` allows `out`, `dtype`, `order`, `casting`, and `optimize` parameters which are not directly available in TVM's `einsum`. The `*operands` input must be passed as a list/tuple to TVM's `data` parameter. Type promotion and casting would need explicit handling for TVM.",
    "notes": "Direct functional mapping for Einstein summation. Additional Torch parameters require pre-processing or are not supported.",
    "confidence": 0.8
  },
  {
    "torch_api": "torch._numpy._funcs_impl.sort",
    "tvm_api": "tvm.relay.op.algorithm.sort",
    "mapping_type": "direct",
    "direction": "torch_to_tvm",
    "torch_pattern": "sort({{a}}, axis={{axis}}, kind={{kind}}, order={{order}})",
    "tvm_pattern": "tvm.relay.op.algorithm.sort({{data}}, axis={{axis}}, is_ascend={{is_ascend}})",
    "arg_mapping": {
      "a": "data",
      "axis": "axis",
      "descending": "(not descending)"
    },
    "example_pairs": [
      {
        "torch": "result = sort(tensor, axis=0, descending=False)",
        "tvm": "result = tvm.relay.op.algorithm.sort(tensor_tvm, axis=0, is_ascend=True)"
      }
    ],
    "constraints": "Torch's `sort` returns a tuple `(values, indices)` (this snippet specifically returns `.values`), while TVM's `sort` returns only the sorted values. If indices are also needed, `argsort` should be used. Torch parameters `kind` and `order` are not supported. `descending` in Torch maps to `is_ascend` in TVM (inverse logic).",
    "notes": "Direct functional mapping for sorting tensor values along an axis.",
    "confidence": 0.85
  },
  {
    "torch_api": "torch._numpy._funcs_impl.argsort",
    "tvm_api": "tvm.relay.op.algorithm.argsort",
    "mapping_type": "direct",
    "direction": "torch_to_tvm",
    "torch_pattern": "argsort({{a}}, axis={{axis}}, kind={{kind}}, order={{order}})",
    "tvm_pattern": "tvm.relay.op.algorithm.argsort({{data}}, axis={{axis}}, is_ascend={{is_ascend}}, dtype={{dtype}})",
    "arg_mapping": {
      "a": "data",
      "axis": "axis",
      "descending": "(not descending)"
    },
    "example_pairs": [
      {
        "torch": "result = argsort(tensor, axis=0, descending=False)",
        "tvm": "result = tvm.relay.op.algorithm.argsort(tensor_tvm, axis=0, is_ascend=True, dtype='int32')"
      }
    ],
    "constraints": "Torch parameters `kind` and `order` are not supported. `descending` in Torch maps to `is_ascend` in TVM (inverse logic). TVM's `argsort` has a `dtype` parameter for the output indices.",
    "notes": "Direct functional mapping for returning indices that would sort the array along a given axis.",
    "confidence": 0.9
  },
  {
    "torch_api": "torch._numpy._funcs_impl.searchsorted",
    "tvm_api": "tvm.relay.op.algorithm.searchsorted",
    "mapping_type": "direct",
    "direction": "torch_to_tvm",
    "torch_pattern": "searchsorted({{a}}, {{v}}, side={{side}}, sorter={{sorter}})",
    "tvm_pattern": "tvm.relay.op.algorithm.searchsorted({{sorted_sequence}}, {{values}}, right={{right}}, dtype={{dtype}})",
    "arg_mapping": {
      "a": "sorted_sequence",
      "v": "values",
      "side": "('right' if side == 'right' else 'left')"
    },
    "example_pairs": [
      {
        "torch": "a = torch.tensor([1,3,5]); v = torch.tensor([2,4]); result = searchsorted(a, v, side='left')",
        "tvm": "a_tvm = relay.const([1,3,5]); v_tvm = relay.const([2,4]); result = tvm.relay.op.algorithm.searchsorted(a_tvm, v_tvm, right=False)"
      }
    ],
    "constraints": "Torch's `searchsorted` supports a `sorter` parameter that is not directly available in TVM. Torch raises `NotImplementedError` for complex dtypes. The `side` parameter in Torch maps to `right` boolean in TVM (e.g., `side='left'` means `right=False`). TVM has a `dtype` parameter for the output indices.",
    "notes": "Direct functional mapping for finding insertion points in a sorted array.",
    "confidence": 0.9
  },
  {
    "torch_api": "torch._numpy._funcs_impl.squeeze",
    "tvm_api": "tvm.relay.op.transform.squeeze",
    "mapping_type": "direct",
    "direction": "torch_to_tvm",
    "torch_pattern": "squeeze({{a}}, axis={{axis}})",
    "tvm_pattern": "tvm.relay.op.transform.squeeze({{data}}, axis={{axis}})",
    "arg_mapping": {
      "a": "data",
      "axis": "axis"
    },
    "example_pairs": [
      {
        "torch": "result = squeeze(tensor, axis=1)",
        "tvm": "result = tvm.relay.op.transform.squeeze(tensor_tvm, axis=1)"
      },
      {
        "torch": "result = squeeze(tensor, axis=None)",
        "tvm": "result = tvm.relay.op.transform.squeeze(tensor_tvm, axis=None)"
      }
    ],
    "constraints": "Torch's internal implementation explicitly handles `axis=()` or `axis` being a tuple by iterating. TVM's `axis` can be `None`, `int`, `Tuple[int]`, or `List[int]` directly.",
    "notes": "Direct functional mapping for removing single-dimensional entries from shape.",
    "confidence": 0.95
  },
  {
    "torch_api": "torch._numpy._funcs_impl.reshape",
    "tvm_api": "tvm.relay.op.transform.reshape",
    "mapping_type": "direct",
    "direction": "torch_to_tvm",
    "torch_pattern": "reshape({{a}}, {{newshape}}, order={{order}})",
    "tvm_pattern": "tvm.relay.op.transform.reshape({{data}}, {{newshape_tvm}})",
    "arg_mapping": {
      "a": "data",
      "newshape": "newshape_tvm"
    },
    "example_pairs": [
      {
        "torch": "result = reshape(tensor, (2, 3))",
        "tvm": "result = tvm.relay.op.transform.reshape(tensor_tvm, (2, 3))"
      },
      {
        "torch": "result = reshape(tensor, -1)",
        "tvm": "result = tvm.relay.op.transform.reshape(tensor_tvm, (-1,))"
      }
    ],
    "constraints": "Torch's `newshape` can be an integer, which needs to be converted to a tuple `(newshape,)` for TVM. TVM's `newshape` supports special values (0, -1) for inference and copying dimensions, and `reshape` has an `allowzero` parameter not present in Torch. Torch's `order` parameter is explicitly not supported in the snippet.",
    "notes": "Direct functional mapping for reshaping an array.",
    "confidence": 0.9
  },
  {
    "torch_api": "torch._numpy._funcs_impl.transpose",
    "tvm_api": "tvm.relay.op.transform.transpose",
    "mapping_type": "direct",
    "direction": "torch_to_tvm",
    "torch_pattern": "transpose({{a}}, axes={{axes}})",
    "tvm_pattern": "tvm.relay.op.transform.transpose({{data}}, axes={{axes}})",
    "arg_mapping": {
      "a": "data",
      "axes": "axes"
    },
    "example_pairs": [
      {
        "torch": "result = transpose(tensor, axes=(1, 0))",
        "tvm": "result = tvm.relay.op.transform.transpose(tensor_tvm, axes=[1, 0])"
      },
      {
        "torch": "result = transpose(tensor, axes=None)",
        "tvm": "result = tvm.relay.op.transform.transpose(tensor_tvm, axes=None)"
      }
    ],
    "constraints": "Torch's `axes` can be `None`, a single integer, or a tuple/list. TVM's `axes` can also be `None` or a list/tuple of integers. Logic for converting single integer `axes` to a tuple `(axes,)` and handling `axes in [(), None, (None,)]` for reversing dimensions is required during conversion.",
    "notes": "Direct functional mapping for permuting array dimensions.",
    "confidence": 0.95
  },
  {
    "torch_api": "torch._numpy._funcs_impl.gradient",
    "tvm_api": null,
    "mapping_type": "no_mapping",
    "direction": "torch_to_tvm",
    "torch_pattern": null,
    "tvm_pattern": null,
    "arg_mapping": {},
    "example_pairs": [],
    "constraints": "Not convertible",
    "notes": "NO_MAPPING: Torch's `gradient` computes the *numerical gradient* (using finite differences). The TVM `gradient` functions (`tvm.relay.transform.transform.gradient`, `tvm.te.autodiff.gradient`) are for *automatic differentiation* (symbolic gradient computation). These are fundamentally different operations, despite the shared name.",
    "confidence": 0.2
  },
  {
    "torch_api": "torch._numpy._funcs_impl.round",
    "tvm_api": "tvm.relay.op.tensor.round",
    "mapping_type": "direct",
    "direction": "torch_to_tvm",
    "torch_pattern": "round({{a}}, decimals={{decimals}}, out={{out}})",
    "tvm_pattern": "tvm.relay.op.tensor.round({{data}})",
    "arg_mapping": {
      "a": "data"
    },
    "example_pairs": [
      {
        "torch": "result = round(tensor, decimals=0)",
        "tvm": "result = tvm.relay.op.tensor.round(tensor_tvm)"
      }
    ],
    "constraints": "TVM's `round` operator (from the snippets) does not have a `decimals` parameter; it always rounds to the nearest integer. Torch's `round` handles `decimals` and complex dtypes (with internal dispatch for real/imag parts). A mapping for `decimals != 0` or complex dtypes would require composite operations in TVM.",
    "notes": "Direct functional mapping only for rounding to zero decimal places. Other `decimals` values or complex types would need composite implementations.",
    "confidence": 0.7
  },
  {
    "torch_api": "torch._numpy._funcs_impl.pad",
    "tvm_api": "tvm.relay.op.nn.nn.pad",
    "mapping_type": "direct",
    "direction": "torch_to_tvm",
    "torch_pattern": "pad(array={{array}}, pad_width={{pad_width}}, mode={{mode}}, constant_values={{constant_values}})",
    "tvm_pattern": "tvm.relay.op.nn.nn.pad({{data}}, {{pad_width_tvm}}, pad_value={{pad_value}}, pad_mode={{pad_mode}})",
    "arg_mapping": {
      "array": "data",
      "pad_width": "pad_width_tvm",
      "mode": "pad_mode",
      "constant_values": "pad_value"
    },
    "example_pairs": [
      {
        "torch": "result = pad(tensor, ((1,1),(0,0)), mode='constant', constant_values=0)",
        "tvm": "result = tvm.relay.op.nn.nn.pad(tensor_tvm, ((1,1),(0,0)), pad_value=0, pad_mode='constant')"
      }
    ],
    "constraints": "Torch's `pad` in this NumPy compatibility layer explicitly restricts `mode` to 'constant'. It also preprocesses `pad_width` (flips and flattens). TVM's `pad` accepts `pad_width` as `((before_1, after_1), ..., (before_N, after_N))`. Conversion logic for `pad_width` must match. TVM supports 'constant', 'edge', 'reflect' for `pad_mode`, while the Torch snippet only maps 'constant'.",
    "notes": "Direct functional mapping for padding, specifically for `mode='constant'`. Careful conversion of `pad_width` format is necessary.",
    "confidence": 0.85
  },
  {
    "torch_api": "torch._numpy._ndarray.array",
    "tvm_api": "tvm.runtime.ndarray.array",
    "mapping_type": "direct",
    "direction": "torch_to_tvm",
    "torch_pattern": "array({{obj}}, dtype={{dtype}}, copy={{copy}}, order={{order}}, subok={{subok}}, ndmin={{ndmin}}, like={{like}})",
    "tvm_pattern": "tvm.runtime.ndarray.array({{arr}})",
    "arg_mapping": {
      "obj": "arr"
    },
    "example_pairs": [
      {
        "torch": "data = np.array([1, 2, 3]); result = array(data)",
        "tvm": "data = np.array([1, 2, 3]); result = tvm.runtime.ndarray.array(data)"
      }
    ],
    "constraints": "This is a direct mapping *only* when `obj` is a `numpy.ndarray`. Torch's `array` is a flexible NumPy-compatible constructor handling various input types (e.g., lists of Tensors, other `ndarray` objects) and parameters like `dtype`, `copy`, `order`, `subok`, `ndmin`, `like`. The TVM `array` from the snippet specifically takes a `numpy.ndarray` as input. More complex Torch `array` calls would require composite mappings or pre-processing.",
    "notes": "Direct mapping only for the case where a NumPy array is converted to a TVM NDArray. The full flexibility of Torch's `array` is not covered.",
    "confidence": 0.7
  },
  {
    "torch_api": "torch._numpy._ndarray.from_dlpack",
    "tvm_api": "tvm.runtime.ndarray.from_dlpack",
    "mapping_type": "direct",
    "direction": "torch_to_tvm",
    "torch_pattern": "from_dlpack({{x}})",
    "tvm_pattern": "tvm.runtime.ndarray.from_dlpack({{dltensor}})",
    "arg_mapping": {
      "x": "dltensor"
    },
    "example_pairs": [
      {
        "torch": "dl_tensor_obj = ...; result = from_dlpack(dl_tensor_obj)",
        "tvm": "dl_tensor_obj = ...; result = tvm.runtime.ndarray.from_dlpack(dl_tensor_obj)"
      }
    ],
    "constraints": "None.",
    "notes": "Direct functional mapping for creating an array from a DLPack capsule without memory copy.",
    "confidence": 0.98
  },
  {
    "torch_api": "torch._numpy._reductions_impl.argmax",
    "tvm_api": "tvm.relay.op.reduce.argmax",
    "mapping_type": "direct",
    "direction": "torch_to_tvm",
    "torch_pattern": "argmax({{a}}, axis={{axis}}, out={{out}}, keepdims={{keepdims}})",
    "tvm_pattern": "tvm.relay.op.reduce.argmax({{data}}, axis={{axis}}, keepdims={{keepdims}})",
    "arg_mapping": {
      "a": "data",
      "axis": "axis",
      "keepdims": "keepdims"
    },
    "example_pairs": [
      {
        "torch": "result = argmax(tensor, axis=0, keepdims=False)",
        "tvm": "result = tvm.relay.op.reduce.argmax(tensor_tvm, axis=0, keepdims=False)"
      }
    ],
    "constraints": "Torch's `argmax` raises `NotImplementedError` for complex dtypes and converts boolean inputs to `uint8`. This type handling would need to be explicit in TVM. Torch also has an `out` parameter. TVM's `argmax` has `exclude` and `select_last_index` parameters not present in Torch's call.",
    "notes": "Direct functional mapping for finding indices of maximum values. Type handling and additional parameters are differences.",
    "confidence": 0.85
  },
  {
    "torch_api": "torch._numpy._reductions_impl.argmin",
    "tvm_api": "tvm.relay.op.reduce.argmin",
    "mapping_type": "direct",
    "direction": "torch_to_tvm",
    "torch_pattern": "argmin({{a}}, axis={{axis}}, out={{out}}, keepdims={{keepdims}})",
    "tvm_pattern": "tvm.relay.op.reduce.argmin({{data}}, axis={{axis}}, keepdims={{keepdims}})",
    "arg_mapping": {
      "a": "data",
      "axis": "axis",
      "keepdims": "keepdims"
    },
    "example_pairs": [
      {
        "torch": "result = argmin(tensor, axis=0, keepdims=False)",
        "tvm": "result = tvm.relay.op.reduce.argmin(tensor_tvm, axis=0, keepdims=False)"
      }
    ],
    "constraints": "Torch's `argmin` raises `NotImplementedError` for complex dtypes and converts boolean inputs to `uint8`. This type handling would need to be explicit in TVM. Torch also has an `out` parameter. TVM's `argmin` has `exclude` and `select_last_index` parameters not present in Torch's call.",
    "notes": "Direct functional mapping for finding indices of minimum values. Type handling and additional parameters are differences.",
    "confidence": 0.85
  },
  {
    "torch_api": "torch._numpy._reductions_impl.any",
    "tvm_api": "tvm.relay.op.reduce.any",
    "mapping_type": "direct",
    "direction": "torch_to_tvm",
    "torch_pattern": "any({{a}}, axis={{axis}}, out={{out}}, keepdims={{keepdims}}, where={{where}})",
    "tvm_pattern": "tvm.relay.op.reduce.any({{data}}, axis={{axis}}, keepdims={{keepdims}})",
    "arg_mapping": {
      "a": "data",
      "axis": "axis",
      "keepdims": "keepdims"
    },
    "example_pairs": [
      {
        "torch": "result = any(bool_tensor, axis=0, keepdims=False)",
        "tvm": "result = tvm.relay.op.reduce.any(bool_tensor_tvm, axis=0, keepdims=False)"
      }
    ],
    "constraints": "Torch's `any` has `out` and `where` parameters which are not directly available in TVM's `any`. TVM's `any` has an `exclude` parameter not present in Torch's call.",
    "notes": "Direct functional mapping for logical OR reduction. Differences in auxiliary parameters exist.",
    "confidence": 0.85
  },
  {
    "torch_api": "torch._numpy._reductions_impl.all",
    "tvm_api": "tvm.relay.op.reduce.all",
    "mapping_type": "direct",
    "direction": "torch_to_tvm",
    "torch_pattern": "all({{a}}, axis={{axis}}, out={{out}}, keepdims={{keepdims}}, where={{where}})",
    "tvm_pattern": "tvm.relay.op.reduce.all({{data}}, axis={{axis}}, keepdims={{keepdims}})",
    "arg_mapping": {
      "a": "data",
      "axis": "axis",
      "keepdims": "keepdims"
    },
    "example_pairs": [
      {
        "torch": "result = all(bool_tensor, axis=0, keepdims=False)",
        "tvm": "result = tvm.relay.op.reduce.all(bool_tensor_tvm, axis=0, keepdims=False)"
      }
    ],
    "constraints": "Torch's `all` has `out` and `where` parameters which are not directly available in TVM's `all`. TVM's `all` has an `exclude` parameter not present in Torch's call.",
    "notes": "Direct functional mapping for logical AND reduction. Differences in auxiliary parameters exist.",
    "confidence": 0.85
  },
  {
    "torch_api": "torch._numpy._reductions_impl.sum",
    "tvm_api": "tvm.relay.op.reduce.sum",
    "mapping_type": "direct",
    "direction": "torch_to_tvm",
    "torch_pattern": "sum({{a}}, axis={{axis}}, dtype={{dtype}}, out={{out}}, keepdims={{keepdims}}, initial={{initial}}, where={{where}})",
    "tvm_pattern": "tvm.relay.op.reduce.sum({{data}}, axis={{axis}}, keepdims={{keepdims}})",
    "arg_mapping": {
      "a": "data",
      "axis": "axis",
      "keepdims": "keepdims"
    },
    "example_pairs": [
      {
        "torch": "result = sum(tensor, axis=0, keepdims=True, dtype=torch.float32)",
        "tvm": "result = tvm.relay.op.reduce.sum(tensor_tvm, axis=0, keepdims=True)"
      }
    ],
    "constraints": "Torch's `sum` handles `dtype` conversion (e.g., bool to int) and has `out`, `initial`, and `where` parameters. These are not directly available in TVM's `sum`. `dtype` conversion would require explicit `cast` in TVM. TVM's `sum` has an `exclude` parameter.",
    "notes": "Direct functional mapping for sum reduction. Differences in auxiliary parameters and type handling exist.",
    "confidence": 0.85
  },
  {
    "torch_api": "torch._numpy._reductions_impl.prod",
    "tvm_api": "tvm.relay.op.reduce.prod",
    "mapping_type": "direct",
    "direction": "torch_to_tvm",
    "torch_pattern": "torch._numpy._reductions_impl.prod(a, axis={{axis}}, keepdims={{keepdims}}, dtype={{dtype}})",
    "tvm_pattern": "tvm.relay.op.reduce.prod(data={{a}}, axis={{axis}}, keepdims={{keepdims}})",
    "arg_mapping": {
      "a": "data",
      "axis": "axis",
      "keepdims": "keepdims",
      "dtype": "null"
    },
    "example_pairs": [
      {
        "torch": "result = torch._numpy._reductions_impl.prod(input_tensor, axis=0, keepdims=True)",
        "tvm": "result = tvm.relay.op.reduce.prod(data=input_tensor, axis=0, keepdims=True)"
      },
      {
        "torch": "result = torch._numpy._reductions_impl.prod(input_tensor)",
        "tvm": "result = tvm.relay.op.reduce.prod(data=input_tensor)"
      }
    ],
    "constraints": "Only direct reduction along axes. PyTorch's 'dtype' argument for output type is not directly mapped as TVM typically relies on implicit type promotion or explicit cast operations. 'exclude', 'out', 'initial', 'where' arguments in PyTorch are not supported.",
    "notes": "Maps the core product reduction functionality.",
    "confidence": 0.9
  },
  {
    "torch_api": "torch._numpy._reductions_impl.mean",
    "tvm_api": "tvm.relay.op.reduce.mean",
    "mapping_type": "direct",
    "direction": "torch_to_tvm",
    "torch_pattern": "torch._numpy._reductions_impl.mean(a, axis={{axis}}, keepdims={{keepdims}}, dtype={{dtype}})",
    "tvm_pattern": "tvm.relay.op.reduce.mean(data={{a}}, axis={{axis}}, keepdims={{keepdims}})",
    "arg_mapping": {
      "a": "data",
      "axis": "axis",
      "keepdims": "keepdims",
      "dtype": "null"
    },
    "example_pairs": [
      {
        "torch": "result = torch._numpy._reductions_impl.mean(input_tensor, axis=1)",
        "tvm": "result = tvm.relay.op.reduce.mean(data=input_tensor, axis=1)"
      },
      {
        "torch": "result = torch._numpy._reductions_impl.mean(input_tensor, keepdims=True)",
        "tvm": "result = tvm.relay.op.reduce.mean(data=input_tensor, keepdims=True)"
      }
    ],
    "constraints": "Only direct mean reduction along axes. PyTorch's 'dtype' argument for output type is not directly mapped as TVM typically relies on implicit type promotion or explicit cast operations. 'out', 'where', 'exclude' arguments in PyTorch are not supported.",
    "notes": "Maps the core mean reduction functionality.",
    "confidence": 0.9
  },
  {
    "torch_api": "torch._numpy._reductions_impl.std",
    "tvm_api": "tvm.relay.op.reduce.std",
    "mapping_type": "direct",
    "direction": "torch_to_tvm",
    "torch_pattern": "torch._numpy._reductions_impl.std(a, axis={{axis}}, ddof={{ddof}}, keepdims={{keepdims}}, dtype={{dtype}})",
    "tvm_pattern": "tvm.relay.op.reduce.std(data={{a}}, axis={{axis}}, unbiased={{unbiased}}, keepdims={{keepdims}})",
    "arg_mapping": {
      "a": "data",
      "axis": "axis",
      "ddof": "unbiased",
      "keepdims": "keepdims",
      "dtype": "null"
    },
    "example_pairs": [
      {
        "torch": "result = torch._numpy._reductions_impl.std(input_tensor, axis=1, ddof=0)",
        "tvm": "result = tvm.relay.op.reduce.std(data=input_tensor, axis=1, unbiased=False)"
      },
      {
        "torch": "result = torch._numpy._reductions_impl.std(input_tensor, ddof=1)",
        "tvm": "result = tvm.relay.op.reduce.std(data=input_tensor, unbiased=True)"
      }
    ],
    "constraints": "PyTorch's 'ddof=0' maps to TVM's 'unbiased=False' (population standard deviation), and 'ddof=1' maps to 'unbiased=True' (sample standard deviation). Other 'ddof' values are not directly supported. PyTorch's 'dtype' argument for output type is not directly mapped. 'out', 'where', 'exclude' arguments in PyTorch are not supported.",
    "notes": "Maps the standard deviation reduction functionality, including the degrees of freedom parameter.",
    "confidence": 0.95
  },
  {
    "torch_api": "torch._numpy._reductions_impl.var",
    "tvm_api": null,
    "mapping_type": "no_mapping",
    "direction": "torch_to_tvm",
    "torch_pattern": null,
    "tvm_pattern": null,
    "arg_mapping": {},
    "example_pairs": [],
    "constraints": "Not convertible",
    "notes": "NO_MAPPING: No direct TVM Relay operator for 'var' (variance) reduction was found in the provided snippets. The `tvm.relay.op.reduce._variance` exists internally but is not exposed as a public API.",
    "confidence": 0.2
  },
  {
    "torch_api": "torch._numpy._reductions_impl.cumsum",
    "tvm_api": "tvm.relay.op.transform.cumsum",
    "mapping_type": "direct",
    "direction": "torch_to_tvm",
    "torch_pattern": "torch._numpy._reductions_impl.cumsum(a, axis={{axis}}, dtype={{dtype}})",
    "tvm_pattern": "tvm.relay.op.transform.cumsum(data={{a}}, axis={{axis}}, dtype={{dtype}}, exclusive=False)",
    "arg_mapping": {
      "a": "data",
      "axis": "axis",
      "dtype": "dtype"
    },
    "example_pairs": [
      {
        "torch": "result = torch._numpy._reductions_impl.cumsum(input_tensor, axis=0)",
        "tvm": "result = tvm.relay.op.transform.cumsum(data=input_tensor, axis=0, exclusive=False)"
      },
      {
        "torch": "result = torch._numpy._reductions_impl.cumsum(input_tensor, dtype=torch.float64)",
        "tvm": "result = tvm.relay.op.transform.cumsum(data=input_tensor, dtype='float64', exclusive=False)"
      }
    ],
    "constraints": "PyTorch's 'cumsum' is inclusive by default, which maps to TVM's 'exclusive=False'. The 'out' argument in PyTorch is not supported.",
    "notes": "Maps the cumulative sum functionality. TVM's 'exclusive' parameter allows for explicit control over inclusive/exclusive sum, with default matching PyTorch.",
    "confidence": 0.95
  },
  {
    "torch_api": "torch._numpy._reductions_impl.cumprod",
    "tvm_api": "tvm.relay.op.transform.cumprod",
    "mapping_type": "direct",
    "direction": "torch_to_tvm",
    "torch_pattern": "torch._numpy._reductions_impl.cumprod(a, axis={{axis}}, dtype={{dtype}})",
    "tvm_pattern": "tvm.relay.op.transform.cumprod(data={{a}}, axis={{axis}}, dtype={{dtype}}, exclusive=False)",
    "arg_mapping": {
      "a": "data",
      "axis": "axis",
      "dtype": "dtype"
    },
    "example_pairs": [
      {
        "torch": "result = torch._numpy._reductions_impl.cumprod(input_tensor, axis=0)",
        "tvm": "result = tvm.relay.op.transform.cumprod(data=input_tensor, axis=0, exclusive=False)"
      },
      {
        "torch": "result = torch._numpy._reductions_impl.cumprod(input_tensor, dtype=torch.float64)",
        "tvm": "result = tvm.relay.op.transform.cumprod(data=input_tensor, dtype='float64', exclusive=False)"
      }
    ],
    "constraints": "PyTorch's 'cumprod' is inclusive by default, which maps to TVM's 'exclusive=False'. The 'out' argument in PyTorch is not supported.",
    "notes": "Maps the cumulative product functionality. TVM's 'exclusive' parameter allows for explicit control over inclusive/exclusive product, with default matching PyTorch.",
    "confidence": 0.95
  },
  {
    "torch_api": "torch._numpy._ufuncs.matmul",
    "tvm_api": "tvm.relay.op.nn.nn.matmul",
    "mapping_type": "direct",
    "direction": "torch_to_tvm",
    "torch_pattern": "torch._numpy._ufuncs.matmul(x1, x2, dtype={{dtype}})",
    "tvm_pattern": "tvm.relay.op.nn.nn.matmul(tensor_a={{x1}}, tensor_b={{x2}}, out_dtype={{dtype}})",
    "arg_mapping": {
      "x1": "tensor_a",
      "x2": "tensor_b",
      "dtype": "out_dtype"
    },
    "example_pairs": [
      {
        "torch": "result = torch._numpy._ufuncs.matmul(tensor_a, tensor_b)",
        "tvm": "result = tvm.relay.op.nn.nn.matmul(tensor_a=tensor_a, tensor_b=tensor_b)"
      },
      {
        "torch": "result = torch._numpy._ufuncs.matmul(tensor_a, tensor_b, dtype=torch.float16)",
        "tvm": "result = tvm.relay.op.nn.nn.matmul(tensor_a=tensor_a, tensor_b=tensor_b, out_dtype='float16')"
      }
    ],
    "constraints": "Assumes standard matrix multiplication for 2D tensors or N-D tensors where the last two dimensions are matrix multiplied. PyTorch's broader broadcasting rules for N-D tensors and the `transpose_a`/`transpose_b` arguments in TVM might require additional explicit `transpose` operations in TVM for more complex PyTorch `matmul` use cases (e.g., when PyTorch infers transposes based on shape). Other PyTorch arguments like 'out', 'casting', 'order', 'subok', 'signature', 'extobj', 'axes', 'axis' are not directly mapped.",
    "notes": "Maps the core matrix multiplication operation.",
    "confidence": 0.75
  },
  {
    "torch_api": "torch._numpy._ufuncs.ldexp",
    "tvm_api": "tvm.tir.op.ldexp",
    "mapping_type": "direct",
    "direction": "torch_to_tvm",
    "torch_pattern": "torch._numpy._ufuncs.ldexp(x1, x2)",
    "tvm_pattern": "tvm.tir.op.ldexp(x1={{x1}}, x2={{x2}})",
    "arg_mapping": {
      "x1": "x1",
      "x2": "x2"
    },
    "example_pairs": [
      {
        "torch": "result = torch._numpy._ufuncs.ldexp(val1, val2)",
        "tvm": "result = tvm.tir.op.ldexp(x1=val1, x2=val2)"
      }
    ],
    "constraints": "Maps to a TIR intrinsic directly. PyTorch's `dtype` handling for result, 'out', 'where', 'casting', 'order', 'subok', 'signature', 'extobj' arguments are not directly mapped to this intrinsic.",
    "notes": "Direct mapping to the TIR intrinsic for `x1 * (2 ** x2)`.",
    "confidence": 0.95
  },
  {
    "torch_api": "torch._numpy.random.rand",
    "tvm_api": null,
    "mapping_type": "no_mapping",
    "direction": "torch_to_tvm",
    "torch_pattern": null,
    "tvm_pattern": null,
    "arg_mapping": {},
    "example_pairs": [],
    "constraints": "Not convertible as an operation within a TVM Relay graph.",
    "notes": "NO_MAPPING: The TVM `rand` function found in `tvm.relay.testing` is a host-side utility for generating numpy arrays for testing, not an operator to be included in a TVM graph for random number generation on the target device.",
    "confidence": 0.2
  },
  {
    "torch_api": "torch._numpy.random.uniform",
    "tvm_api": "tvm.relay.op.random.kernel.uniform",
    "mapping_type": "direct",
    "direction": "torch_to_tvm",
    "torch_pattern": "torch._numpy.random.uniform(low={{low}}, high={{high}}, size={{size}})",
    "tvm_pattern": "key, result = tvm.relay.op.random.kernel.uniform(key={{key}}, shape={{size}}, dtype={{dtype}}, low={{low}}, high={{high}})",
    "arg_mapping": {
      "low": "low",
      "high": "high",
      "size": "shape",
      "dtype": "dtype"
    },
    "example_pairs": [
      {
        "torch": "result = torch._numpy.random.uniform(low=0.0, high=1.0, size=(2, 3))",
        "tvm": "key, result = tvm.relay.op.random.kernel.uniform(key=threefry_key_expr, shape=(2, 3), dtype='float32', low=0.0, high=1.0)"
      }
    ],
    "constraints": "TVM's random operators require a `key` (e.g., from `threefry_key`) to manage the random state within the graph, which PyTorch's API abstracts. The `key` management needs to be added explicitly in TVM.",
    "notes": "Maps the uniform random number generation functionality.",
    "confidence": 0.85
  },
  {
    "torch_api": "torch._numpy.random.normal",
    "tvm_api": "tvm.relay.op.random.kernel.normal",
    "mapping_type": "direct",
    "direction": "torch_to_tvm",
    "torch_pattern": "torch._numpy.random.normal(loc={{loc}}, scale={{scale}}, size={{size}})",
    "tvm_pattern": "key, result = tvm.relay.op.random.kernel.normal(key={{key}}, shape={{size}}, dtype={{dtype}}, mean={{loc}}, scale={{scale}})",
    "arg_mapping": {
      "loc": "mean",
      "scale": "scale",
      "size": "shape",
      "dtype": "dtype"
    },
    "example_pairs": [
      {
        "torch": "result = torch._numpy.random.normal(loc=0.0, scale=1.0, size=(2, 3))",
        "tvm": "key, result = tvm.relay.op.random.kernel.normal(key=threefry_key_expr, shape=(2, 3), dtype='float32', mean=0.0, scale=1.0)"
      }
    ],
    "constraints": "TVM's random operators require a `key` (e.g., from `threefry_key`) to manage the random state within the graph, which PyTorch's API abstracts. The `key` management needs to be added explicitly in TVM.",
    "notes": "Maps the normal (Gaussian) random number generation functionality.",
    "confidence": 0.85
  },
  {
    "torch_api": "torch._numpy.testing.utils.assert_allclose",
    "tvm_api": "tvm.testing.utils.assert_allclose",
    "mapping_type": "direct",
    "direction": "torch_to_tvm",
    "torch_pattern": "torch._numpy.testing.utils.assert_allclose(actual={{actual}}, desired={{desired}}, rtol={{rtol}}, atol={{atol}})",
    "tvm_pattern": "tvm.testing.utils.assert_allclose(actual={{actual}}, desired={{desired}}, rtol={{rtol}}, atol={{atol}})",
    "arg_mapping": {
      "actual": "actual",
      "desired": "desired",
      "rtol": "rtol",
      "atol": "atol"
    },
    "example_pairs": [
      {
        "torch": "torch._numpy.testing.utils.assert_allclose(output, expected, rtol=1e-5, atol=1e-8)",
        "tvm": "tvm.testing.utils.assert_allclose(output, expected, rtol=1e-5, atol=1e-8)"
      }
    ],
    "constraints": "The TVM function is a wrapper for `np.testing.assert_allclose`. Other PyTorch arguments like 'equal_nan', 'err_msg', 'verbose', 'check_dtype' are not directly supported by the TVM wrapper signature.",
    "notes": "Directly maps the assertion utility for numerical closeness, commonly used in testing.",
    "confidence": 0.95
  },
  {
    "torch_api": "torch._prims_common.__init__.prod",
    "tvm_api": "tvm.topi.utils.prod",
    "mapping_type": "direct",
    "direction": "torch_to_tvm",
    "torch_pattern": "torch._prims_common.__init__.prod(xs={{input_sequence}})",
    "tvm_pattern": "tvm.topi.utils.prod(x={{input_sequence}})",
    "arg_mapping": {
      "xs": "x"
    },
    "example_pairs": [
      {
        "torch": "result = torch._prims_common.__init__.prod((1, 2, 3))",
        "tvm": "result = tvm.topi.utils.prod((1, 2, 3))"
      },
      {
        "torch": "result = torch._prims_common.__init__.prod([])",
        "tvm": "result = tvm.topi.utils.prod([])"
      }
    ],
    "constraints": "This mapping is for the utility function that takes a sequence/tuple and returns a scalar product, not for tensor reduction. Input must be a tuple in TVM's `topi.utils.prod`.",
    "notes": "Maps to a utility function for sequence product, matching the Python `reduce(operator.mul, ...)` behavior.",
    "confidence": 0.9
  },
  {
    "torch_api": "torch._refs.__init__.abs",
    "tvm_api": "tvm.relay.op.tensor.abs",
    "mapping_type": "direct",
    "direction": "torch_to_tvm",
    "torch_pattern": "torch._refs.__init__.abs(a={{input_tensor}})",
    "tvm_pattern": "tvm.relay.op.tensor.abs(data={{input_tensor}})",
    "arg_mapping": {
      "a": "data"
    },
    "example_pairs": [
      {
        "torch": "result = torch._refs.__init__.abs(input_tensor)",
        "tvm": "result = tvm.relay.op.tensor.abs(data=input_tensor)"
      }
    ],
    "constraints": "Element-wise operation.",
    "notes": "Direct mapping for element-wise absolute value.",
    "confidence": 0.95
  },
  {
    "torch_api": "torch._refs.__init__.acos",
    "tvm_api": "tvm.relay.op.tensor.acos",
    "mapping_type": "direct",
    "direction": "torch_to_tvm",
    "torch_pattern": "torch._refs.__init__.acos(a={{input_tensor}})",
    "tvm_pattern": "tvm.relay.op.tensor.acos(data={{input_tensor}})",
    "arg_mapping": {
      "a": "data"
    },
    "example_pairs": [
      {
        "torch": "result = torch._refs.__init__.acos(input_tensor)",
        "tvm": "result = tvm.relay.op.tensor.acos(data=input_tensor)"
      }
    ],
    "constraints": "Element-wise operation.",
    "notes": "Direct mapping for element-wise arc cosine.",
    "confidence": 0.95
  },
  {
    "torch_api": "torch._refs.__init__.acosh",
    "tvm_api": "tvm.relay.op.tensor.acosh",
    "mapping_type": "direct",
    "direction": "torch_to_tvm",
    "torch_pattern": "torch._refs.__init__.acosh(a={{input_tensor}})",
    "tvm_pattern": "tvm.relay.op.tensor.acosh(data={{input_tensor}})",
    "arg_mapping": {
      "a": "data"
    },
    "example_pairs": [
      {
        "torch": "result = torch._refs.__init__.acosh(input_tensor)",
        "tvm": "result = tvm.relay.op.tensor.acosh(data=input_tensor)"
      }
    ],
    "constraints": "Element-wise operation.",
    "notes": "Direct mapping for element-wise inverse hyperbolic cosine.",
    "confidence": 0.95
  },
  {
    "torch_api": "torch._refs.__init__.asin",
    "tvm_api": "tvm.relay.op.tensor.asin",
    "mapping_type": "direct",
    "direction": "torch_to_tvm",
    "torch_pattern": "torch._refs.__init__.asin(a={{input_tensor}})",
    "tvm_pattern": "tvm.relay.op.tensor.asin(data={{input_tensor}})",
    "arg_mapping": {
      "a": "data"
    },
    "example_pairs": [
      {
        "torch": "result = torch._refs.__init__.asin(input_tensor)",
        "tvm": "result = tvm.relay.op.tensor.asin(data=input_tensor)"
      }
    ],
    "constraints": "Element-wise operation.",
    "notes": "Direct mapping for element-wise arc sine.",
    "confidence": 0.95
  },
  {
    "torch_api": "torch._refs.__init__.asinh",
    "tvm_api": "tvm.relay.op.tensor.asinh",
    "mapping_type": "direct",
    "direction": "torch_to_tvm",
    "torch_pattern": "torch._refs.__init__.asinh(a={{input_tensor}})",
    "tvm_pattern": "tvm.relay.op.tensor.asinh(data={{input_tensor}})",
    "arg_mapping": {
      "a": "data"
    },
    "example_pairs": [
      {
        "torch": "result = torch._refs.__init__.asinh(input_tensor)",
        "tvm": "result = tvm.relay.op.tensor.asinh(data=input_tensor)"
      }
    ],
    "constraints": "Element-wise operation.",
    "notes": "Direct mapping for element-wise inverse hyperbolic sine.",
    "confidence": 0.95
  },
  {
    "torch_api": "torch._refs.__init__.atan",
    "tvm_api": "tvm.relay.op.tensor.atan",
    "mapping_type": "direct",
    "direction": "torch_to_tvm",
    "torch_pattern": "torch._refs.__init__.atan(a={{input_tensor}})",
    "tvm_pattern": "tvm.relay.op.tensor.atan(data={{input_tensor}})",
    "arg_mapping": {
      "a": "data"
    },
    "example_pairs": [
      {
        "torch": "result = torch._refs.__init__.atan(input_tensor)",
        "tvm": "result = tvm.relay.op.tensor.atan(data=input_tensor)"
      }
    ],
    "constraints": "Element-wise operation.",
    "notes": "Direct mapping for element-wise arc tangent.",
    "confidence": 0.95
  },
  {
    "torch_api": "torch._refs.__init__.atanh",
    "tvm_api": "tvm.relay.op.tensor.atanh",
    "mapping_type": "direct",
    "direction": "torch_to_tvm",
    "torch_pattern": "torch._refs.__init__.atanh(a={{input_tensor}})",
    "tvm_pattern": "tvm.relay.op.tensor.atanh(data={{input_tensor}})",
    "arg_mapping": {
      "a": "data"
    },
    "example_pairs": [
      {
        "torch": "result = torch._refs.__init__.atanh(input_tensor)",
        "tvm": "result = tvm.relay.op.tensor.atanh(data=input_tensor)"
      }
    ],
    "constraints": "Element-wise operation.",
    "notes": "Direct mapping for element-wise inverse hyperbolic tangent.",
    "confidence": 0.95
  },
  {
    "torch_api": "torch._refs.__init__.bitwise_not",
    "tvm_api": "tvm.relay.op.tensor.bitwise_not",
    "mapping_type": "direct",
    "direction": "torch_to_tvm",
    "torch_pattern": "torch._refs.__init__.bitwise_not(a={{input_tensor}})",
    "tvm_pattern": "tvm.relay.op.tensor.bitwise_not(data={{input_tensor}})",
    "arg_mapping": {
      "a": "data"
    },
    "example_pairs": [
      {
        "torch": "result = torch._refs.__init__.bitwise_not(input_tensor)",
        "tvm": "result = tvm.relay.op.tensor.bitwise_not(data=input_tensor)"
      }
    ],
    "constraints": "Element-wise operation. Typically used with integer types.",
    "notes": "Direct mapping for element-wise bitwise NOT.",
    "confidence": 0.95
  },
  {
    "torch_api": "torch._refs.__init__.ceil",
    "tvm_api": "tvm.relay.op.tensor.ceil",
    "mapping_type": "direct",
    "direction": "torch_to_tvm",
    "torch_pattern": "torch._refs.__init__.ceil(a={{input_tensor}})",
    "tvm_pattern": "tvm.relay.op.tensor.ceil(data={{input_tensor}})",
    "arg_mapping": {
      "a": "data"
    },
    "example_pairs": [
      {
        "torch": "result = torch._refs.__init__.ceil(input_tensor)",
        "tvm": "result = tvm.relay.op.tensor.ceil(data=input_tensor)"
      }
    ],
    "constraints": "Element-wise operation.",
    "notes": "Direct mapping for element-wise ceiling function.",
    "confidence": 0.95
  },
  {
    "torch_api": "torch._refs.__init__.cos",
    "tvm_api": "tvm.relay.op.tensor.cos",
    "mapping_type": "direct",
    "direction": "torch_to_tvm",
    "torch_pattern": "torch._refs.__init__.cos(a={{input_tensor}})",
    "tvm_pattern": "tvm.relay.op.tensor.cos(data={{input_tensor}})",
    "arg_mapping": {
      "a": "data"
    },
    "example_pairs": [
      {
        "torch": "result = torch._refs.__init__.cos(input_tensor)",
        "tvm": "result = tvm.relay.op.tensor.cos(data=input_tensor)"
      }
    ],
    "constraints": "Element-wise operation.",
    "notes": "Direct mapping for element-wise cosine function.",
    "confidence": 0.95
  },
  {
    "torch_api": "torch._refs.__init__.cosh",
    "tvm_api": "tvm.relay.op.tensor.cosh",
    "mapping_type": "direct",
    "direction": "torch_to_tvm",
    "torch_pattern": "torch._refs.__init__.cosh(a={{input_tensor}})",
    "tvm_pattern": "tvm.relay.op.tensor.cosh(data={{input_tensor}})",
    "arg_mapping": {
      "a": "data"
    },
    "example_pairs": [
      {
        "torch": "result = torch._refs.__init__.cosh(input_tensor)",
        "tvm": "result = tvm.relay.op.tensor.cosh(data=input_tensor)"
      }
    ],
    "constraints": "Element-wise operation.",
    "notes": "Direct mapping for element-wise hyperbolic cosine function.",
    "confidence": 0.95
  },
  {
    "torch_api": "torch._refs.__init__.erf",
    "tvm_api": "tvm.relay.op.tensor.erf",
    "mapping_type": "direct",
    "direction": "torch_to_tvm",
    "torch_pattern": "torch._refs.__init__.erf(a={{input_tensor}})",
    "tvm_pattern": "tvm.relay.op.tensor.erf(data={{input_tensor}})",
    "arg_mapping": {
      "a": "data"
    },
    "example_pairs": [
      {
        "torch": "result = torch._refs.__init__.erf(input_tensor)",
        "tvm": "result = tvm.relay.op.tensor.erf(data=input_tensor)"
      }
    ],
    "constraints": "Element-wise operation.",
    "notes": "Direct mapping for element-wise error function.",
    "confidence": 0.95
  },
  {
    "torch_api": "torch._refs.__init__.exp",
    "tvm_api": "tvm.relay.op.tensor.exp",
    "mapping_type": "direct",
    "direction": "torch_to_tvm",
    "torch_pattern": "torch._refs.__init__.exp(a={{input_tensor}})",
    "tvm_pattern": "tvm.relay.op.tensor.exp(data={{input_tensor}})",
    "arg_mapping": {
      "a": "data"
    },
    "example_pairs": [
      {
        "torch": "result = torch._refs.__init__.exp(input_tensor)",
        "tvm": "result = tvm.relay.op.tensor.exp(data=input_tensor)"
      }
    ],
    "constraints": "Element-wise operation.",
    "notes": "Direct mapping for element-wise exponential function.",
    "confidence": 0.95
  },
  {
    "torch_api": "torch._refs.__init__.exp2",
    "tvm_api": "tvm.tir.op.exp2",
    "mapping_type": "direct",
    "direction": "torch_to_tvm",
    "torch_pattern": "torch._refs.__init__.exp2(a={{input_tensor}})",
    "tvm_pattern": "tvm.tir.op.exp2(x={{input_tensor}})",
    "arg_mapping": {
      "a": "x"
    },
    "example_pairs": [
      {
        "torch": "result = torch._refs.__init__.exp2(input_tensor)",
        "tvm": "result = tvm.tir.op.exp2(x=input_tensor)"
      }
    ],
    "constraints": "Element-wise operation. Maps to a TIR intrinsic directly.",
    "notes": "Direct mapping for element-wise 2 to the power of x.",
    "confidence": 0.9
  },
  {
    "torch_api": "torch._refs.__init__.floor",
    "tvm_api": "tvm.relay.op.tensor.floor",
    "mapping_type": "direct",
    "direction": "torch_to_tvm",
    "torch_pattern": "torch._refs.__init__.floor(a={{input_tensor}})",
    "tvm_pattern": "tvm.relay.op.tensor.floor(data={{input_tensor}})",
    "arg_mapping": {
      "a": "data"
    },
    "example_pairs": [
      {
        "torch": "result = torch._refs.__init__.floor(input_tensor)",
        "tvm": "result = tvm.relay.op.tensor.floor(data=input_tensor)"
      }
    ],
    "constraints": "Element-wise operation.",
    "notes": "Direct mapping for element-wise floor function.",
    "confidence": 0.95
  },
  {
    "torch_api": "torch._refs.__init__.isfinite",
    "tvm_api": "tvm.relay.op.tensor.isfinite",
    "mapping_type": "direct",
    "direction": "torch_to_tvm",
    "torch_pattern": "torch._refs.__init__.isfinite(a={{input_tensor}})",
    "tvm_pattern": "tvm.relay.op.tensor.isfinite(data={{input_tensor}})",
    "arg_mapping": {
      "a": "data"
    },
    "example_pairs": [
      {
        "torch": "result = torch._refs.__init__.isfinite(input_tensor)",
        "tvm": "result = tvm.relay.op.tensor.isfinite(data=input_tensor)"
      }
    ],
    "constraints": "Element-wise operation. PyTorch's `isfinite` has fallback logic for non-float/complex dtypes (returning `ones_like`), which would need to be handled by composite operations in TVM if the input dtype is not float or complex. The direct mapping covers float/complex cases.",
    "notes": "Direct mapping for element-wise check of finiteness.",
    "confidence": 0.9
  },
  {
    "torch_api": "torch._refs.__init__.isinf",
    "tvm_api": "tvm.relay.op.tensor.isinf",
    "mapping_type": "direct",
    "direction": "torch_to_tvm",
    "torch_pattern": "torch._refs.__init__.isinf(a={{input_tensor}})",
    "tvm_pattern": "tvm.relay.op.tensor.isinf(data={{input_tensor}})",
    "arg_mapping": {
      "a": "data"
    },
    "example_pairs": [
      {
        "torch": "result = torch._refs.__init__.isinf(input_tensor)",
        "tvm": "result = tvm.relay.op.tensor.isinf(data=input_tensor)"
      }
    ],
    "constraints": "Element-wise operation. PyTorch's `isinf` has fallback logic for non-float/complex dtypes (returning `zeros_like`) and complex type specific logic, which would need to be handled by composite operations in TVM if the input dtype is not float.",
    "notes": "Direct mapping for element-wise check of infinity.",
    "confidence": 0.9
  },
  {
    "torch_api": "torch._refs.__init__.isnan",
    "tvm_api": "tvm.relay.op.tensor.isnan",
    "mapping_type": "direct",
    "direction": "torch_to_tvm",
    "torch_pattern": "torch._refs.__init__.isnan(a={{input_tensor}})",
    "tvm_pattern": "tvm.relay.op.tensor.isnan(data={{input_tensor}})",
    "arg_mapping": {
      "a": "data"
    },
    "example_pairs": [
      {
        "torch": "result = torch._refs.__init__.isnan(input_tensor)",
        "tvm": "result = tvm.relay.op.tensor.isnan(data=input_tensor)"
      }
    ],
    "constraints": "Element-wise operation.",
    "notes": "Direct mapping for element-wise check for NaN.",
    "confidence": 0.95
  },
  {
    "torch_api": "torch._refs.__init__.log",
    "tvm_api": "tvm.relay.op.tensor.log",
    "mapping_type": "direct",
    "direction": "torch_to_tvm",
    "torch_pattern": "torch._refs.__init__.log(a={{input_tensor}})",
    "tvm_pattern": "tvm.relay.op.tensor.log(data={{input_tensor}})",
    "arg_mapping": {
      "a": "data"
    },
    "example_pairs": [
      {
        "torch": "result = torch._refs.__init__.log(input_tensor)",
        "tvm": "result = tvm.relay.op.tensor.log(data=input_tensor)"
      }
    ],
    "constraints": "Element-wise operation (natural logarithm).",
    "notes": "Direct mapping for element-wise natural logarithm.",
    "confidence": 0.95
  },
  {
    "torch_api": "torch._refs.__init__.log1p",
    "tvm_api": "tvm.tir.op.log1p",
    "mapping_type": "direct",
    "direction": "torch_to_tvm",
    "torch_pattern": "torch._refs.__init__.log1p(a={{input_tensor}})",
    "tvm_pattern": "tvm.tir.op.log1p(x={{input_tensor}})",
    "arg_mapping": {
      "a": "x"
    },
    "example_pairs": [
      {
        "torch": "result = torch._refs.__init__.log1p(input_tensor)",
        "tvm": "result = tvm.tir.op.log1p(x=input_tensor)"
      }
    ],
    "constraints": "Element-wise operation. Maps to a TIR intrinsic directly. For Relay, this would typically be a composite `log(1 + x)`.",
    "notes": "Direct mapping for element-wise `log(1 + x)`.",
    "confidence": 0.9
  },
  {
    "torch_api": "torch._refs.__init__.log2",
    "tvm_api": "tvm.relay.op.tensor.log2",
    "mapping_type": "direct",
    "direction": "torch_to_tvm",
    "torch_pattern": "torch._refs.__init__.log2(a={{input_tensor}})",
    "tvm_pattern": "tvm.relay.op.tensor.log2(data={{input_tensor}})",
    "arg_mapping": {
      "a": "data"
    },
    "example_pairs": [
      {
        "torch": "result = torch._refs.__init__.log2(input_tensor)",
        "tvm": "result = tvm.relay.op.tensor.log2(data=input_tensor)"
      }
    ],
    "constraints": "Element-wise operation (base 2 logarithm).",
    "notes": "Direct mapping for element-wise base 2 logarithm.",
    "confidence": 0.95
  },
  {
    "torch_api": "torch._refs.__init__.log10",
    "tvm_api": "tvm.relay.op.tensor.log10",
    "mapping_type": "direct",
    "direction": "torch_to_tvm",
    "torch_pattern": "torch._refs.__init__.log10(a={{input_tensor}})",
    "tvm_pattern": "tvm.relay.op.tensor.log10(data={{input_tensor}})",
    "arg_mapping": {
      "a": "data"
    },
    "example_pairs": [
      {
        "torch": "result = torch._refs.__init__.log10(input_tensor)",
        "tvm": "result = tvm.relay.op.tensor.log10(data=input_tensor)"
      }
    ],
    "constraints": "Element-wise operation (base 10 logarithm).",
    "notes": "Direct mapping for element-wise base 10 logarithm.",
    "confidence": 0.95
  },
  {
    "torch_api": "torch._refs.__init__.log_softmax",
    "tvm_api": "tvm.relay.op.nn.nn.log_softmax",
    "mapping_type": "direct",
    "direction": "torch_to_tvm",
    "torch_pattern": "torch._refs.__init__.log_softmax(a={{input_tensor}}, dim={{dim}}, dtype={{dtype}})",
    "tvm_pattern": "tvm.relay.op.nn.nn.log_softmax(data={{input_tensor}}, axis={{dim}})",
    "arg_mapping": {
      "a": "data",
      "dim": "axis",
      "dtype": "null"
    },
    "example_pairs": [
      {
        "torch": "result = torch._refs.__init__.log_softmax(input_tensor, dim=1)",
        "tvm": "result = tvm.relay.op.nn.nn.log_softmax(data=input_tensor, axis=1)"
      }
    ],
    "constraints": "PyTorch's `dtype` argument for explicit output type conversion is not directly mapped to TVM's `log_softmax` signature and would require a separate `cast` operation.",
    "notes": "Direct mapping for the log softmax operation. While PyTorch shows a composite implementation, TVM provides a dedicated fused operator.",
    "confidence": 0.9
  },
  {
    "torch_api": "torch._refs.__init__.logsumexp",
    "tvm_api": "tvm.relay.op.reduce.logsumexp",
    "mapping_type": "direct",
    "direction": "torch_to_tvm",
    "torch_pattern": "torch._refs.__init__.logsumexp(self={{input_tensor}}, dim={{dim}}, keepdim={{keepdim}})",
    "tvm_pattern": "tvm.relay.op.reduce.logsumexp(data={{input_tensor}}, axis={{dim}}, keepdims={{keepdim}})",
    "arg_mapping": {
      "self": "data",
      "dim": "axis",
      "keepdim": "keepdims"
    },
    "example_pairs": [
      {
        "torch": "result = torch._refs.__init__.logsumexp(input_tensor, dim=0, keepdim=True)",
        "tvm": "result = tvm.relay.op.reduce.logsumexp(data=input_tensor, axis=0, keepdims=True)"
      }
    ],
    "constraints": "TVM's `logsumexp` supports single or multiple axes via 'axis' (int or tuple of int), similar to PyTorch's 'dim'.",
    "notes": "Direct mapping for the numerically stable log-sum-exp reduction operation. While PyTorch shows a composite implementation for numerical stability, TVM provides a dedicated fused operator.",
    "confidence": 0.95
  },
  {
    "torch_api": "torch._refs.__init__.round",
    "tvm_api": "tvm.relay.op.tensor.round",
    "mapping_type": "direct",
    "direction": "torch_to_tvm",
    "torch_pattern": "torch._refs.__init__.round(a={{input_tensor}}, decimals=0)",
    "tvm_pattern": "tvm.relay.op.tensor.round(data={{input_tensor}})",
    "arg_mapping": {
      "a": "data"
    },
    "example_pairs": [
      {
        "torch": "result = torch._refs.__init__.round(input_tensor)",
        "tvm": "result = tvm.relay.op.tensor.round(data=input_tensor)"
      }
    ],
    "constraints": "Element-wise operation. This direct mapping is for rounding to the nearest integer (i.e., PyTorch's `decimals=0`). If `decimals` is non-zero in PyTorch, it would require a composite mapping in TVM involving multiplication, rounding, and division.",
    "notes": "Direct mapping for element-wise rounding to the nearest integer.",
    "confidence": 0.9
  },
  {
    "torch_api": "torch._refs.__init__.rsqrt",
    "tvm_api": "tvm.relay.op.tensor.rsqrt",
    "mapping_type": "direct",
    "direction": "torch_to_tvm",
    "torch_pattern": "torch._refs.__init__.rsqrt(a={{input_tensor}})",
    "tvm_pattern": "tvm.relay.op.tensor.rsqrt(data={{input_tensor}})",
    "arg_mapping": {
      "a": "data"
    },
    "example_pairs": [
      {
        "torch": "result = torch._refs.__init__.rsqrt(input_tensor)",
        "tvm": "result = tvm.relay.op.tensor.rsqrt(data=input_tensor)"
      }
    ],
    "constraints": "Element-wise operation.",
    "notes": "Direct mapping for element-wise reciprocal square root.",
    "confidence": 0.95
  },
  {
    "torch_api": "torch._refs.__init__.sigmoid",
    "tvm_api": "tvm.relay.op.tensor.sigmoid",
    "mapping_type": "direct",
    "direction": "torch_to_tvm",
    "torch_pattern": "torch._refs.__init__.sigmoid(a={{input_tensor}})",
    "tvm_pattern": "tvm.relay.op.tensor.sigmoid(data={{input_tensor}})",
    "arg_mapping": {
      "a": "data"
    },
    "example_pairs": [
      {
        "torch": "result = torch._refs.__init__.sigmoid(input_tensor)",
        "tvm": "result = tvm.relay.op.tensor.sigmoid(data=input_tensor)"
      }
    ],
    "constraints": "Element-wise operation.",
    "notes": "Direct mapping for element-wise sigmoid function. While PyTorch shows a composite implementation, TVM provides a dedicated fused operator.",
    "confidence": 0.95
  },
  {
    "torch_api": "torch._refs.__init__.sign",
    "tvm_api": "tvm.relay.op.tensor.sign",
    "mapping_type": "direct",
    "direction": "torch_to_tvm",
    "torch_pattern": "torch._refs.__init__.sign(a={{input_tensor}})",
    "tvm_pattern": "tvm.relay.op.tensor.sign(data={{input_tensor}})",
    "arg_mapping": {
      "a": "data"
    },
    "example_pairs": [
      {
        "torch": "result = torch._refs.__init__.sign(input_tensor)",
        "tvm": "result = tvm.relay.op.tensor.sign(data=input_tensor)"
      }
    ],
    "constraints": "Element-wise operation. PyTorch's `sign` has special handling for complex dtypes, which would require a composite mapping in TVM if the input is complex.",
    "notes": "Direct mapping for element-wise sign function.",
    "confidence": 0.9
  },
  {
    "torch_api": "torch._refs.__init__.sin",
    "tvm_api": "tvm.relay.op.tensor.sin",
    "mapping_type": "direct",
    "direction": "torch_to_tvm",
    "torch_pattern": "torch._refs.__init__.sin(a={{input_tensor}})",
    "tvm_pattern": "tvm.relay.op.tensor.sin(data={{input_tensor}})",
    "arg_mapping": {
      "a": "data"
    },
    "example_pairs": [
      {
        "torch": "result = torch._refs.__init__.sin(input_tensor)",
        "tvm": "result = tvm.relay.op.tensor.sin(data=input_tensor)"
      }
    ],
    "constraints": "Element-wise operation.",
    "notes": "Direct mapping for element-wise sine function.",
    "confidence": 0.95
  },
  {
    "torch_api": "torch._refs.__init__.sinh",
    "tvm_api": "tvm.relay.op.tensor.sinh",
    "mapping_type": "direct",
    "direction": "torch_to_tvm",
    "torch_pattern": "torch._refs.__init__.sinh(a={{input_tensor}})",
    "tvm_pattern": "tvm.relay.op.tensor.sinh(data={{input_tensor}})",
    "arg_mapping": {
      "a": "data"
    },
    "example_pairs": [
      {
        "torch": "result = torch._refs.__init__.sinh(input_tensor)",
        "tvm": "result = tvm.relay.op.tensor.sinh(data=input_tensor)"
      }
    ],
    "constraints": "Element-wise operation.",
    "notes": "Direct mapping for element-wise hyperbolic sine function.",
    "confidence": 0.95
  },
  {
    "torch_api": "torch._refs.__init__.sqrt",
    "tvm_api": "tvm.relay.op.tensor.sqrt",
    "mapping_type": "direct",
    "direction": "torch_to_tvm",
    "torch_pattern": "torch._refs.__init__.sqrt(a={{input_tensor}})",
    "tvm_pattern": "tvm.relay.op.tensor.sqrt(data={{input_tensor}})",
    "arg_mapping": {
      "a": "data"
    },
    "example_pairs": [
      {
        "torch": "result = torch._refs.__init__.sqrt(input_tensor)",
        "tvm": "result = tvm.relay.op.tensor.sqrt(data=input_tensor)"
      }
    ],
    "constraints": "Element-wise operation.",
    "notes": "Direct mapping for element-wise square root function.",
    "confidence": 0.95
  },
  {
    "torch_api": "torch._refs.__init__.tan",
    "tvm_api": "tvm.relay.op.tensor.tan",
    "mapping_type": "direct",
    "direction": "torch_to_tvm",
    "torch_pattern": "torch._refs.__init__.tan(a={{input_tensor}})",
    "tvm_pattern": "tvm.relay.op.tensor.tan(data={{input_tensor}})",
    "arg_mapping": {
      "a": "data"
    },
    "example_pairs": [
      {
        "torch": "result = torch._refs.__init__.tan(input_tensor)",
        "tvm": "result = tvm.relay.op.tensor.tan(data=input_tensor)"
      }
    ],
    "constraints": "Element-wise operation.",
    "notes": "Direct mapping for element-wise tangent function.",
    "confidence": 0.95
  },
  {
    "torch_api": "torch._refs.__init__.tanh",
    "tvm_api": "tvm.relay.op.tensor.tanh",
    "mapping_type": "direct",
    "direction": "torch_to_tvm",
    "torch_pattern": "torch._refs.__init__.tanh(a={{input_tensor}})",
    "tvm_pattern": "tvm.relay.op.tensor.tanh(data={{input_tensor}})",
    "arg_mapping": {
      "a": "data"
    },
    "example_pairs": [
      {
        "torch": "result = torch._refs.__init__.tanh(input_tensor)",
        "tvm": "result = tvm.relay.op.tensor.tanh(data=input_tensor)"
      }
    ],
    "constraints": "Element-wise operation.",
    "notes": "Direct mapping for element-wise hyperbolic tangent function.",
    "confidence": 0.95
  },
  {
    "torch_api": "torch._refs.__init__.trunc",
    "tvm_api": "tvm.relay.op.tensor.trunc",
    "mapping_type": "direct",
    "direction": "torch_to_tvm",
    "torch_pattern": "torch._refs.__init__.trunc(a={{input_tensor}})",
    "tvm_pattern": "tvm.relay.op.tensor.trunc(data={{input_tensor}})",
    "arg_mapping": {
      "a": "data"
    },
    "example_pairs": [
      {
        "torch": "result = torch._refs.__init__.trunc(input_tensor)",
        "tvm": "result = tvm.relay.op.tensor.trunc(data=input_tensor)"
      }
    ],
    "constraints": "Element-wise operation.",
    "notes": "Direct mapping for element-wise truncation function.",
    "confidence": 0.95
  },
  {
    "torch_api": "torch._refs.__init__.add",
    "tvm_api": "tvm.relay.op.tensor.add",
    "mapping_type": "direct",
    "direction": "torch_to_tvm",
    "torch_pattern": "torch._refs.__init__.add(a={{lhs}}, b={{rhs}})",
    "tvm_pattern": "tvm.relay.op.tensor.add(lhs={{lhs}}, rhs={{rhs}})",
    "arg_mapping": {
      "a": "lhs",
      "b": "rhs"
    },
    "example_pairs": [
      {
        "torch": "result = torch._refs.__init__.add(tensor_a, tensor_b)",
        "tvm": "result = tvm.relay.op.tensor.add(lhs=tensor_a, rhs=tensor_b)"
      }
    ],
    "constraints": "Element-wise operation with broadcasting. PyTorch's `alpha` parameter (`a + alpha * b`) would require a composite mapping in TVM using `tvm.relay.op.tensor.mul` and `tvm.relay.op.tensor.add`.",
    "notes": "Direct mapping for element-wise addition.",
    "confidence": 0.95
  },
  {
    "torch_api": "torch._refs.__init__.atan2",
    "tvm_api": "tvm.tir.op.atan2",
    "mapping_type": "direct",
    "direction": "torch_to_tvm",
    "torch_pattern": "torch._refs.__init__.atan2(a={{y}}, b={{x}})",
    "tvm_pattern": "tvm.tir.op.atan2(x1={{y}}, x2={{x}})",
    "arg_mapping": {
      "a": "x1",
      "b": "x2"
    },
    "example_pairs": [
      {
        "torch": "result = torch._refs.__init__.atan2(tensor_y, tensor_x)",
        "tvm": "result = tvm.tir.op.atan2(x1=tensor_y, x2=tensor_x)"
      }
    ],
    "constraints": "Element-wise operation. Maps to a TIR intrinsic directly. For Relay, this would typically be a composite or require a dedicated op if one existed. PyTorch's `atan2(y, x)` convention aligns with TVM's `atan2(x1, x2)` where x1 is the y-coordinate.",
    "notes": "Direct mapping for element-wise arc tangent of y/x.",
    "confidence": 0.9
  },
  {
    "torch_api": "torch._refs.__init__.bitwise_and",
    "tvm_api": "tvm.relay.op.tensor.bitwise_and",
    "mapping_type": "direct",
    "direction": "torch_to_tvm",
    "torch_pattern": "torch._refs.__init__.bitwise_and(a={{lhs}}, b={{rhs}})",
    "tvm_pattern": "tvm.relay.op.tensor.bitwise_and(lhs={{lhs}}, rhs={{rhs}})",
    "arg_mapping": {
      "a": "lhs",
      "b": "rhs"
    },
    "example_pairs": [
      {
        "torch": "result = torch._refs.__init__.bitwise_and(tensor_a, tensor_b)",
        "tvm": "result = tvm.relay.op.tensor.bitwise_and(lhs=tensor_a, rhs=tensor_b)"
      }
    ],
    "constraints": "Element-wise operation with broadcasting. Typically used with integer types.",
    "notes": "Direct mapping for element-wise bitwise AND.",
    "confidence": 0.95
  },
  {
    "torch_api": "torch._refs.__init__.bitwise_or",
    "tvm_api": "tvm.relay.op.tensor.bitwise_or",
    "mapping_type": "direct",
    "direction": "torch_to_tvm",
    "torch_pattern": "torch._refs.__init__.bitwise_or(a={{lhs}}, b={{rhs}})",
    "tvm_pattern": "tvm.relay.op.tensor.bitwise_or(lhs={{lhs}}, rhs={{rhs}})",
    "arg_mapping": {
      "a": "lhs",
      "b": "rhs"
    },
    "example_pairs": [
      {
        "torch": "result = torch._refs.__init__.bitwise_or(tensor_a, tensor_b)",
        "tvm": "result = tvm.relay.op.tensor.bitwise_or(lhs=tensor_a, rhs=tensor_b)"
      }
    ],
    "constraints": "Element-wise operation with broadcasting. Typically used with integer types.",
    "notes": "Direct mapping for element-wise bitwise OR.",
    "confidence": 0.95
  },
  {
    "torch_api": "torch._refs.__init__.bitwise_xor",
    "tvm_api": "tvm.relay.op.tensor.bitwise_xor",
    "mapping_type": "direct",
    "direction": "torch_to_tvm",
    "torch_pattern": "torch._refs.__init__.bitwise_xor(a={{lhs}}, b={{rhs}})",
    "tvm_pattern": "tvm.relay.op.tensor.bitwise_xor(lhs={{lhs}}, rhs={{rhs}})",
    "arg_mapping": {
      "a": "lhs",
      "b": "rhs"
    },
    "example_pairs": [
      {
        "torch": "result = torch._refs.__init__.bitwise_xor(tensor_a, tensor_b)",
        "tvm": "result = tvm.relay.op.tensor.bitwise_xor(lhs=tensor_a, rhs=tensor_b)"
      }
    ],
    "constraints": "Element-wise operation with broadcasting. Typically used with integer types.",
    "notes": "Direct mapping for element-wise bitwise XOR.",
    "confidence": 0.95
  },
  {
    "torch_api": "torch._refs.__init__.copysign",
    "tvm_api": "tvm.tir.op.copysign",
    "mapping_type": "direct",
    "direction": "torch_to_tvm",
    "torch_pattern": "torch._refs.__init__.copysign(a={{magnitude_tensor}}, b={{sign_tensor}})",
    "tvm_pattern": "tvm.tir.op.copysign(x1={{magnitude_tensor}}, x2={{sign_tensor}})",
    "arg_mapping": {
      "a": "x1",
      "b": "x2"
    },
    "example_pairs": [
      {
        "torch": "result = torch._refs.__init__.copysign(tensor_a, tensor_b)",
        "tvm": "result = tvm.tir.op.copysign(x1=tensor_a, x2=tensor_b)"
      }
    ],
    "constraints": "Element-wise operation. Maps to a TIR intrinsic directly. Although PyTorch's ref implementation is composite, TVM provides a direct intrinsic. Inputs should be floating-point numbers.",
    "notes": "Direct mapping for `copysign` to the TIR intrinsic.",
    "confidence": 0.9
  },
  {
    "torch_api": "torch._refs.__init__.div",
    "tvm_api": "tvm.relay.op.tensor.divide",
    "mapping_type": "composite",
    "direction": "torch_to_tvm",
    "torch_pattern": "torch._refs.__init__.div(a={{lhs}}, b={{rhs}}, rounding_mode={{rounding_mode}})",
    "tvm_pattern": "tvm.relay.op.tensor.divide(lhs={{lhs}}, rhs={{rhs}}) OR tvm.relay.op.tensor.trunc_divide(lhs={{lhs}}, rhs={{rhs}}) OR tvm.relay.op.tensor.floor_divide(lhs={{lhs}}, rhs={{rhs}})",
    "arg_mapping": {
      "a": "lhs",
      "b": "rhs",
      "rounding_mode": "null"
    },
    "example_pairs": [
      {
        "torch": "result = torch._refs.__init__.div(tensor_a, tensor_b)",
        "tvm": "result = tvm.relay.op.tensor.divide(lhs=tensor_a, rhs=tensor_b)"
      },
      {
        "torch": "result = torch._refs.__init__.div(tensor_a, tensor_b, rounding_mode='trunc')",
        "tvm": "result = tvm.relay.op.tensor.trunc_divide(lhs=tensor_a, rhs=tensor_b)"
      },
      {
        "torch": "result = torch._refs.__init__.div(tensor_a, tensor_b, rounding_mode='floor')",
        "tvm": "result = tvm.relay.op.tensor.floor_divide(lhs=tensor_a, rhs=tensor_b)"
      }
    ],
    "constraints": "PyTorch's `div` delegates to specific division functions based on `rounding_mode`. This requires a composite mapping in TVM to `tvm.relay.op.tensor.divide` (for `rounding_mode=None`), `tvm.relay.op.tensor.trunc_divide` (for `'trunc'`), or `tvm.relay.op.tensor.floor_divide` (for `'floor'`). The `tvm.relay.op.tensor.divide` is inferred from the `floor_divide` snippet.",
    "notes": "Requires selecting the appropriate TVM division operator based on the `rounding_mode` parameter.",
    "confidence": 0.8
  },
  {
    "torch_api": "torch._refs.__init__.floor_divide",
    "tvm_api": "tvm.relay.op.tensor.floor_divide",
    "mapping_type": "direct",
    "direction": "torch_to_tvm",
    "torch_pattern": "torch._refs.__init__.floor_divide(a={{lhs}}, b={{rhs}})",
    "tvm_pattern": "tvm.relay.op.tensor.floor_divide(lhs={{lhs}}, rhs={{rhs}})",
    "arg_mapping": {
      "a": "lhs",
      "b": "rhs"
    },
    "example_pairs": [
      {
        "torch": "result = torch._refs.__init__.floor_divide(tensor_a, tensor_b)",
        "tvm": "result = tvm.relay.op.tensor.floor_divide(lhs=tensor_a, rhs=tensor_b)"
      }
    ],
    "constraints": "Element-wise operation with broadcasting.",
    "notes": "Direct mapping for element-wise floor division.",
    "confidence": 0.95
  },
  {
    "torch_api": "torch._refs.__init__.fmod",
    "tvm_api": "tvm.tir.op.fmod",
    "mapping_type": "direct",
    "direction": "torch_to_tvm",
    "torch_pattern": "torch._refs.__init__.fmod(a={{dividend}}, b={{divisor}})",
    "tvm_pattern": "tvm.tir.op.fmod(x={{dividend}}, y={{divisor}})",
    "arg_mapping": {
      "a": "x",
      "b": "y"
    },
    "example_pairs": [
      {
        "torch": "result = torch._refs.__init__.fmod(tensor_a, tensor_b)",
        "tvm": "result = tvm.tir.op.fmod(x=tensor_a, y=tensor_b)"
      }
    ],
    "constraints": "Element-wise operation. Maps to a TIR intrinsic directly. Returns remainder with the same sign as the dividend, consistent with C/C++ `fmod`.",
    "notes": "Direct mapping for floating-point remainder (`fmod`).",
    "confidence": 0.9
  },
  {
    "torch_api": "torch._refs.__init__.hypot",
    "tvm_api": "tvm.tir.op.hypot",
    "mapping_type": "direct",
    "direction": "torch_to_tvm",
    "torch_pattern": "torch._refs.__init__.hypot(a={{x1}}, b={{x2}})",
    "tvm_pattern": "tvm.tir.op.hypot(x1={{x1}}, x2={{x2}})",
    "arg_mapping": {
      "a": "x1",
      "b": "x2"
    },
    "example_pairs": [
      {
        "torch": "result = torch._refs.__init__.hypot(tensor_a, tensor_b)",
        "tvm": "result = tvm.tir.op.hypot(x1=tensor_a, x2=tensor_b)"
      }
    ],
    "constraints": "Element-wise operation. Maps to a TIR intrinsic directly. Equivalent to `sqrt(x1**2 + x2**2)`.",
    "notes": "Direct mapping for hypotenuse calculation (`sqrt(x1^2 + x2^2)`).",
    "confidence": 0.9
  },
  {
    "torch_api": "torch._refs.__init__.logical_and",
    "tvm_api": "tvm.relay.op.tensor.logical_and",
    "mapping_type": "direct",
    "direction": "torch_to_tvm",
    "torch_pattern": "torch._refs.__init__.logical_and(a={{lhs}}, b={{rhs}})",
    "tvm_pattern": "tvm.relay.op.tensor.logical_and(lhs={{lhs}}, rhs={{rhs}})",
    "arg_mapping": {
      "a": "lhs",
      "b": "rhs"
    },
    "example_pairs": [
      {
        "torch": "result = torch._refs.__init__.logical_and(tensor_a, tensor_b)",
        "tvm": "result = tvm.relay.op.tensor.logical_and(lhs=tensor_a, rhs=tensor_b)"
      }
    ],
    "constraints": "Element-wise operation with broadcasting. PyTorch's implicit conversion of non-boolean inputs to boolean (`a != 0`) needs to be handled by explicit `not_equal(a, 0)` operations in TVM before calling `logical_and`.",
    "notes": "Direct mapping for element-wise logical AND.",
    "confidence": 0.85
  },
  {
    "torch_api": "torch._refs.__init__.logical_not",
    "tvm_api": "tvm.relay.op.tensor.logical_not",
    "mapping_type": "direct",
    "direction": "torch_to_tvm",
    "torch_pattern": "torch._refs.__init__.logical_not(a={{input_tensor}})",
    "tvm_pattern": "tvm.relay.op.tensor.logical_not(data={{input_tensor}})",
    "arg_mapping": {
      "a": "data"
    },
    "example_pairs": [
      {
        "torch": "result = torch._refs.__init__.logical_not(input_tensor)",
        "tvm": "result = tvm.relay.op.tensor.logical_not(data=input_tensor)"
      }
    ],
    "constraints": "Element-wise operation. PyTorch's implicit conversion of non-boolean inputs to boolean (`a == 0`) needs to be handled by explicit `equal(a, 0)` operations in TVM before calling `logical_not`.",
    "notes": "Direct mapping for element-wise logical NOT.",
    "confidence": 0.85
  },
  {
    "torch_api": "torch._refs.__init__.logical_or",
    "tvm_api": "tvm.relay.op.tensor.logical_or",
    "mapping_type": "direct",
    "direction": "torch_to_tvm",
    "torch_pattern": "torch._refs.__init__.logical_or(a={{lhs}}, b={{rhs}})",
    "tvm_pattern": "tvm.relay.op.tensor.logical_or(lhs={{lhs}}, rhs={{rhs}})",
    "arg_mapping": {
      "a": "lhs",
      "b": "rhs"
    },
    "example_pairs": [
      {
        "torch": "result = torch._refs.__init__.logical_or(tensor_a, tensor_b)",
        "tvm": "result = tvm.relay.op.tensor.logical_or(lhs=tensor_a, rhs=tensor_b)"
      }
    ],
    "constraints": "Element-wise operation with broadcasting. PyTorch's implicit conversion of non-boolean inputs to boolean (`a != 0`) needs to be handled by explicit `not_equal(a, 0)` operations in TVM before calling `logical_or`.",
    "notes": "Direct mapping for element-wise logical OR.",
    "confidence": 0.85
  },
  {
    "torch_api": "torch._refs.__init__.logical_xor",
    "tvm_api": "tvm.relay.op.tensor.logical_xor",
    "mapping_type": "direct",
    "direction": "torch_to_tvm",
    "torch_pattern": "torch._refs.__init__.logical_xor(a={{lhs}}, b={{rhs}})",
    "tvm_pattern": "tvm.relay.op.tensor.logical_xor(lhs={{lhs}}, rhs={{rhs}})",
    "arg_mapping": {
      "a": "lhs",
      "b": "rhs"
    },
    "example_pairs": [
      {
        "torch": "result = torch._refs.__init__.logical_xor(tensor_a, tensor_b)",
        "tvm": "result = tvm.relay.op.tensor.logical_xor(lhs=tensor_a, rhs=tensor_b)"
      }
    ],
    "constraints": "Element-wise operation with broadcasting. PyTorch's implicit conversion of non-boolean inputs to boolean (`a != 0`) needs to be handled by explicit `not_equal(a, 0)` operations in TVM before calling `logical_xor`.",
    "notes": "Direct mapping for element-wise logical XOR.",
    "confidence": 0.85
  },
  {
    "torch_api": "torch._refs.__init__.maximum",
    "tvm_api": "tvm.relay.op.tensor.maximum",
    "mapping_type": "direct",
    "direction": "torch_to_tvm",
    "torch_pattern": "torch._refs.__init__.maximum(a={{lhs}}, b={{rhs}})",
    "tvm_pattern": "tvm.relay.op.tensor.maximum(lhs={{lhs}}, rhs={{rhs}})",
    "arg_mapping": {
      "a": "lhs",
      "b": "rhs"
    },
    "example_pairs": [
      {
        "torch": "result = torch._refs.__init__.maximum(tensor_a, tensor_b)",
        "tvm": "result = tvm.relay.op.tensor.maximum(lhs=tensor_a, rhs=tensor_b)"
      }
    ],
    "constraints": "Element-wise operation with broadcasting.",
    "notes": "Direct mapping for element-wise maximum.",
    "confidence": 0.95
  },
  {
    "torch_api": "torch._refs.__init__.minimum",
    "tvm_api": "tvm.relay.op.tensor.minimum",
    "mapping_type": "direct",
    "direction": "torch_to_tvm",
    "torch_pattern": "torch._refs.__init__.minimum(a={{lhs}}, b={{rhs}})",
    "tvm_pattern": "tvm.relay.op.tensor.minimum(lhs={{lhs}}, rhs={{rhs}})",
    "arg_mapping": {
      "a": "lhs",
      "b": "rhs"
    },
    "example_pairs": [
      {
        "torch": "result = torch._refs.__init__.minimum(tensor_a, tensor_b)",
        "tvm": "result = tvm.relay.op.tensor.minimum(lhs=tensor_a, rhs=tensor_b)"
      }
    ],
    "constraints": "Element-wise operation with broadcasting.",
    "notes": "Direct mapping for element-wise minimum.",
    "confidence": 0.95
  },
  {
    "torch_api": "torch._refs.__init__.mul",
    "tvm_api": null,
    "mapping_type": "no_mapping",
    "direction": "torch_to_tvm",
    "torch_pattern": null,
    "tvm_pattern": null,
    "arg_mapping": {},
    "example_pairs": [],
    "constraints": "Not convertible as a general element-wise operation.",
    "notes": "NO_MAPPING: No general `tvm.relay.op.tensor.mul` or `tvm.topi.broadcast.mul` was found in the provided snippets. The only `mul` provided is specific to quantized neural networks (`tvm.relay.qnn.op.qnn.mul`), which is not a general-purpose multiplication.",
    "confidence": 0.2
  },
  {
    "torch_api": "torch._refs.__init__.nextafter",
    "tvm_api": "tvm.tir.op.nextafter",
    "mapping_type": "direct",
    "direction": "torch_to_tvm",
    "torch_pattern": "torch._refs.__init__.nextafter(a={{x1}}, b={{x2}})",
    "tvm_pattern": "tvm.tir.op.nextafter(x1={{x1}}, x2={{x2}})",
    "arg_mapping": {
      "a": "x1",
      "b": "x2"
    },
    "example_pairs": [
      {
        "torch": "result = torch._refs.__init__.nextafter(tensor_a, tensor_b)",
        "tvm": "result = tvm.tir.op.nextafter(x1=tensor_a, x2=tensor_b)"
      }
    ],
    "constraints": "Element-wise operation. Maps to a TIR intrinsic directly. Inputs must be floating-point numbers.",
    "notes": "Direct mapping for finding the next representable floating-point value.",
    "confidence": 0.9
  },
  {
    "torch_api": "torch._refs.__init__.where",
    "tvm_api": "tvm.relay.op.transform.where",
    "mapping_type": "direct",
    "direction": "torch_to_tvm",
    "torch_pattern": "torch._refs.__init__.where(pred={{condition}}, a={{x}}, b={{y}})",
    "tvm_pattern": "tvm.relay.op.transform.where(condition={{condition}}, x={{x}}, y={{y}})",
    "arg_mapping": {
      "pred": "condition",
      "a": "x",
      "b": "y"
    },
    "example_pairs": [
      {
        "torch": "result = torch._refs.__init__.where(bool_tensor, tensor_a, tensor_b)",
        "tvm": "result = tvm.relay.op.transform.where(condition=bool_tensor, x=tensor_a, y=tensor_b)"
      }
    ],
    "constraints": "Element-wise operation with broadcasting. PyTorch explicitly checks that `pred.dtype is torch.bool`; TVM's `condition` argument is also expected to be boolean. PyTorch's handling of `a` or `b` being `None` would require a composite mapping.",
    "notes": "Direct mapping for element-wise conditional selection. Matches NumPy's `where` semantics.",
    "confidence": 0.95
  },
  {
    "torch_api": "torch._refs.__init__.all",
    "tvm_api": "tvm.relay.op.reduce.all",
    "mapping_type": "direct",
    "direction": "torch_to_tvm",
    "torch_pattern": "torch.all({{a}}, dim={{dim}}, keepdim={{keepdim}})",
    "tvm_pattern": "tvm.relay.op.reduce.all(data={{a}}, axis={{dim}}, keepdims={{keepdim}})",
    "arg_mapping": {
      "a": "data",
      "dim": "axis",
      "keepdim": "keepdims"
    },
    "example_pairs": [
      {
        "torch": "result = torch.all(x, dim=1)",
        "tvm": "result = tvm.relay.op.reduce.all(data=x, axis=1)"
      },
      {
        "torch": "result = torch.all(x, keepdim=True)",
        "tvm": "result = tvm.relay.op.reduce.all(data=x, keepdims=True)"
      }
    ],
    "constraints": "TVM's 'all' expects boolean input; PyTorch handles implicit conversion. PyTorch's special uint8 handling is not directly covered. TVM has an additional 'exclude' parameter not present in PyTorch.",
    "notes": "Direct mapping for logical AND reduction. PyTorch's `dim=None` implies reduction over all dimensions, which maps to TVM's `axis=None`.",
    "confidence": 0.9
  },
  {
    "torch_api": "torch._refs.__init__.any",
    "tvm_api": "tvm.relay.op.reduce.any",
    "mapping_type": "direct",
    "direction": "torch_to_tvm",
    "torch_pattern": "torch.any({{a}}, dim={{dim}}, keepdim={{keepdim}})",
    "tvm_pattern": "tvm.relay.op.reduce.any(data={{a}}, axis={{dim}}, keepdims={{keepdim}})",
    "arg_mapping": {
      "a": "data",
      "dim": "axis",
      "keepdim": "keepdims"
    },
    "example_pairs": [
      {
        "torch": "result = torch.any(x, dim=1)",
        "tvm": "result = tvm.relay.op.reduce.any(data=x, axis=1)"
      },
      {
        "torch": "result = torch.any(x, keepdim=True)",
        "tvm": "result = tvm.relay.op.reduce.any(data=x, keepdims=True)"
      }
    ],
    "constraints": "TVM's 'any' expects boolean input; PyTorch handles implicit conversion. PyTorch's special uint8 handling is not directly covered. TVM has an additional 'exclude' parameter not present in PyTorch.",
    "notes": "Direct mapping for logical OR reduction. PyTorch's `dim=None` implies reduction over all dimensions, which maps to TVM's `axis=None`.",
    "confidence": 0.9
  },
  {
    "torch_api": "torch._refs.__init__.sum",
    "tvm_api": "tvm.relay.op.reduce.sum",
    "mapping_type": "direct",
    "direction": "torch_to_tvm",
    "torch_pattern": "torch.sum({{a}}, dim={{dim}}, keepdim={{keepdim}}, dtype={{dtype}})",
    "tvm_pattern": "tvm.relay.op.reduce.sum(data={{a}}, axis={{dim}}, keepdims={{keepdim}})",
    "arg_mapping": {
      "a": "data",
      "dim": "axis",
      "keepdim": "keepdims"
    },
    "example_pairs": [
      {
        "torch": "result = torch.sum(x, dim=1)",
        "tvm": "result = tvm.relay.op.reduce.sum(data=x, axis=1)"
      },
      {
        "torch": "result = torch.sum(x, keepdim=True, dtype=torch.float32)",
        "tvm": "result = tvm.relay.op.reduce.sum(data=x, keepdims=True)\nresult = tvm.relay.op.cast(result, 'float32')"
      }
    ],
    "constraints": "PyTorch's `dtype` argument requires a separate `tvm.relay.op.cast` operation after the sum if the output dtype differs. PyTorch's `dim=()` or `dim=[]` maps to TVM's `axis=None`. TVM has an additional 'exclude' parameter not present in PyTorch.",
    "notes": "Direct mapping for sum reduction. PyTorch's `dim=None` implies reduction over all dimensions, which maps to TVM's `axis=None`.",
    "confidence": 0.9
  },
  {
    "torch_api": "torch._refs.__init__.prod",
    "tvm_api": "tvm.relay.op.reduce.prod",
    "mapping_type": "direct",
    "direction": "torch_to_tvm",
    "torch_pattern": "torch.prod({{a}}, dim={{dim}}, keepdim={{keepdim}}, dtype={{dtype}})",
    "tvm_pattern": "tvm.relay.op.reduce.prod(data={{a}}, axis={{dim}}, keepdims={{keepdim}})",
    "arg_mapping": {
      "a": "data",
      "dim": "axis",
      "keepdim": "keepdims"
    },
    "example_pairs": [
      {
        "torch": "result = torch.prod(x, dim=1)",
        "tvm": "result = tvm.relay.op.reduce.prod(data=x, axis=1)"
      },
      {
        "torch": "result = torch.prod(x, keepdim=True, dtype=torch.float32)",
        "tvm": "result = tvm.relay.op.reduce.prod(data=x, keepdims=True)\nresult = tvm.relay.op.cast(result, 'float32')"
      }
    ],
    "constraints": "PyTorch's `dtype` argument requires a separate `tvm.relay.op.cast` operation after the product if the output dtype differs. PyTorch's `dim=()` or `dim=[]` maps to TVM's `axis=None`. TVM has an additional 'exclude' parameter not present in PyTorch.",
    "notes": "Direct mapping for product reduction. PyTorch's `dim=None` implies reduction over all dimensions, which maps to TVM's `axis=None`.",
    "confidence": 0.9
  },
  {
    "torch_api": "torch._refs.__init__.var",
    "tvm_api": null,
    "mapping_type": "no_mapping",
    "direction": "torch_to_tvm",
    "torch_pattern": null,
    "tvm_pattern": null,
    "arg_mapping": {},
    "example_pairs": [],
    "constraints": "Not convertible",
    "notes": "NO_MAPPING: The TVM 'var' candidates provided (from `tvm.relay.expr`, `tvm.script.ir_builder.tir.ir`, `tvm.te.operation`) are for defining variables in the IR or TE, not for computing the variance of a tensor. A functional variance operator `tvm.relay.op.reduce.variance` exists but was not provided as a candidate for the name 'var'.",
    "confidence": 0.2
  },
  {
    "torch_api": "torch._refs.__init__.std",
    "tvm_api": "tvm.relay.op.reduce.std",
    "mapping_type": "direct",
    "direction": "torch_to_tvm",
    "torch_pattern": "torch.std({{a}}, dim={{dim}}, unbiased={{unbiased}}, keepdim={{keepdim}}, correction={{correction}})",
    "tvm_pattern": "tvm.relay.op.reduce.std(data={{a}}, axis={{dim}}, keepdims={{keepdim}}, unbiased={{unbiased}})",
    "arg_mapping": {
      "a": "data",
      "dim": "axis",
      "keepdim": "keepdims",
      "unbiased": "unbiased",
      "correction": "unbiased"
    },
    "example_pairs": [
      {
        "torch": "result = torch.std(x, dim=1)",
        "tvm": "result = tvm.relay.op.reduce.std(data=x, axis=1)"
      },
      {
        "torch": "result = torch.std(x, unbiased=True, keepdim=True)",
        "tvm": "result = tvm.relay.op.reduce.std(data=x, unbiased=True, keepdims=True)"
      },
      {
        "torch": "result = torch.std(x, correction=0, keepdim=True)",
        "tvm": "result = tvm.relay.op.reduce.std(data=x, unbiased=False, keepdims=True)"
      }
    ],
    "constraints": "PyTorch's `correction` (delta degrees of freedom) argument maps directly to `unbiased`: `correction=0` implies `unbiased=False`, `correction=1` or `None` implies `unbiased=True`. TVM has an additional 'exclude' parameter not present in PyTorch. PyTorch's `dim=None` or `dim=[]` maps to TVM's `axis=None`.",
    "notes": "Direct mapping for standard deviation reduction. PyTorch's `unbiased` and `correction` influence the Bessel's correction factor, directly mapping to TVM's `unbiased` parameter.",
    "confidence": 0.95
  },
  {
    "torch_api": "torch._refs.__init__.mean",
    "tvm_api": "tvm.relay.op.reduce.mean",
    "mapping_type": "direct",
    "direction": "torch_to_tvm",
    "torch_pattern": "torch.mean({{a}}, dim={{dim}}, keepdim={{keepdim}}, dtype={{dtype}})",
    "tvm_pattern": "tvm.relay.op.reduce.mean(data={{a}}, axis={{dim}}, keepdims={{keepdim}})",
    "arg_mapping": {
      "a": "data",
      "dim": "axis",
      "keepdim": "keepdims"
    },
    "example_pairs": [
      {
        "torch": "result = torch.mean(x, dim=1)",
        "tvm": "result = tvm.relay.op.reduce.mean(data=x, axis=1)"
      },
      {
        "torch": "result = torch.mean(x, keepdim=True, dtype=torch.float32)",
        "tvm": "result = tvm.relay.op.reduce.mean(data=x, keepdims=True)\nresult = tvm.relay.op.cast(result, 'float32')"
      }
    ],
    "constraints": "PyTorch's `dtype` argument requires a separate `tvm.relay.op.cast` operation after the mean if the output dtype differs. PyTorch's `dim=()` or `dim=[]` maps to TVM's `axis=None`. TVM has an additional 'exclude' parameter not present in PyTorch.",
    "notes": "Direct mapping for mean reduction. PyTorch's `dim=None` implies reduction over all dimensions, which maps to TVM's `axis=None`.",
    "confidence": 0.9
  },
  {
    "torch_api": "torch._refs.__init__.broadcast_to",
    "tvm_api": "tvm.relay.op.transform.broadcast_to",
    "mapping_type": "direct",
    "direction": "torch_to_tvm",
    "torch_pattern": "torch.broadcast_to({{a}}, size={{size}})",
    "tvm_pattern": "tvm.relay.op.transform.broadcast_to(data={{a}}, shape={{size}})",
    "arg_mapping": {
      "a": "data",
      "size": "shape"
    },
    "example_pairs": [
      {
        "torch": "result = torch.broadcast_to(x, (2, 3, 4))",
        "tvm": "result = tvm.relay.op.transform.broadcast_to(data=x, shape=(2, 3, 4))"
      }
    ],
    "constraints": "Assumes NumPy-style broadcasting rules are consistent.",
    "notes": "Direct mapping for broadcasting a tensor to a new shape.",
    "confidence": 0.95
  },
  {
    "torch_api": "torch._refs.__init__.flatten",
    "tvm_api": null,
    "mapping_type": "no_mapping",
    "direction": "torch_to_tvm",
    "torch_pattern": null,
    "tvm_pattern": null,
    "arg_mapping": {},
    "example_pairs": [],
    "constraints": "Not convertible directly due to differing functionality.",
    "notes": "NO_MAPPING: PyTorch's `flatten` allows flattening a range of dimensions (`start_dim` to `end_dim`) into one, while the provided `tvm.topi.nn.flatten` snippet describes an operation that flattens an input array into a 2-D array by collapsing all higher dimensions into the second dimension (i.e., `[batch_size, -1]`). The functionalities are not directly equivalent.",
    "confidence": 0.3
  },
  {
    "torch_api": "torch._refs.__init__.flip",
    "tvm_api": "tvm.topi.transform.flip",
    "mapping_type": "composite",
    "direction": "torch_to_tvm",
    "torch_pattern": "torch.flip({{a}}, dims={{dims}})",
    "tvm_pattern": "for d in {{dims}}: res = tvm.topi.transform.flip(res, axis=d)",
    "arg_mapping": {
      "a": "a",
      "dims": "d"
    },
    "example_pairs": [
      {
        "torch": "result = torch.flip(x, dims=(0,))",
        "tvm": "result = tvm.topi.transform.flip(a=x, axis=0)"
      },
      {
        "torch": "result = torch.flip(x, dims=(0, 2))",
        "tvm": "res = tvm.topi.transform.flip(a=x, axis=0)\nresult = tvm.topi.transform.flip(a=res, axis=2)"
      }
    ],
    "constraints": "TVM's `tvm.topi.transform.flip` takes a single `axis` argument, whereas PyTorch's `flip` takes a sequence of `dims`. If `dims` contains multiple axes, it requires a sequence of `tvm.topi.transform.flip` operations, making it a composite mapping.",
    "notes": "Mapping to TVM topi flip. If multiple dimensions are specified, repeated application is necessary.",
    "confidence": 0.8
  },
  {
    "torch_api": "torch._refs.__init__.stft",
    "tvm_api": "tvm.relay.op.transform.stft",
    "mapping_type": "direct",
    "direction": "torch_to_tvm",
    "torch_pattern": "torch.stft({{input}}, n_fft={{n_fft}}, hop_length={{hop_length}}, win_length={{win_length}}, window={{window}}, normalized={{normalized}}, onesided={{onesided}})",
    "tvm_pattern": "tvm.relay.op.transform.stft(data={{input}}, n_fft={{n_fft}}, hop_length={{hop_length}}, win_length={{win_length}}, window={{window}}, normalized={{normalized}}, onesided={{onesided}})",
    "arg_mapping": {
      "input": "data",
      "n_fft": "n_fft",
      "hop_length": "hop_length",
      "win_length": "win_length",
      "window": "window",
      "normalized": "normalized",
      "onesided": "onesided"
    },
    "example_pairs": [
      {
        "torch": "result = torch.stft(x, n_fft=400, hop_length=160, win_length=400, window=torch.hann_window(400), normalized=True, onesided=True)",
        "tvm": "result = tvm.relay.op.transform.stft(data=x, n_fft=400, hop_length=160, win_length=400, window=tvm_hann_window(400), normalized=True, onesided=True)"
      }
    ],
    "constraints": "PyTorch's `stft` has additional parameters like `center`, `pad_mode`, `return_complex`, `align_to_window` which are not directly available in the TVM Relay `stft` function signature. Output data type and complex handling should be verified.",
    "notes": "Direct mapping for the core STFT functionality and common parameters.",
    "confidence": 0.85
  },
  {
    "torch_api": "torch._refs.__init__.reshape",
    "tvm_api": "tvm.relay.op.transform.reshape",
    "mapping_type": "direct",
    "direction": "torch_to_tvm",
    "torch_pattern": "torch.reshape({{a}}, *{{shape}})",
    "tvm_pattern": "tvm.relay.op.transform.reshape(data={{a}}, newshape={{shape}})",
    "arg_mapping": {
      "a": "data",
      "shape": "newshape"
    },
    "example_pairs": [
      {
        "torch": "result = torch.reshape(x, (2, 3, 4))",
        "tvm": "result = tvm.relay.op.transform.reshape(data=x, newshape=(2, 3, 4))"
      },
      {
        "torch": "result = x.reshape(2, 3, 4)",
        "tvm": "result = tvm.relay.op.transform.reshape(data=x, newshape=(2, 3, 4))"
      }
    ],
    "constraints": "PyTorch's `*shape` argument style needs to be converted to a single tuple for `newshape`. TVM's `reshape` has an `allowzero` parameter not present in PyTorch.",
    "notes": "Direct mapping for reshaping a tensor. Both support -1 for inferred dimensions.",
    "confidence": 0.95
  },
  {
    "torch_api": "torch._refs.__init__.stack",
    "tvm_api": "tvm.relay.op.tensor.stack",
    "mapping_type": "direct",
    "direction": "torch_to_tvm",
    "torch_pattern": "torch.stack({{tensors}}, dim={{dim}})",
    "tvm_pattern": "tvm.relay.op.tensor.stack(data={{tensors}}, axis={{dim}})",
    "arg_mapping": {
      "tensors": "data",
      "dim": "axis"
    },
    "example_pairs": [
      {
        "torch": "result = torch.stack([x, y], dim=0)",
        "tvm": "result = tvm.relay.op.tensor.stack(data=[x, y], axis=0)"
      }
    ],
    "constraints": "PyTorch `dim` parameter needs to be canonicalized before passing to TVM `axis` for negative values (handled by PyTorch internally).",
    "notes": "Direct mapping for stacking tensors along a new dimension.",
    "confidence": 0.95
  },
  {
    "torch_api": "torch._refs.__init__.softmax",
    "tvm_api": "tvm.relay.op.nn.nn.softmax",
    "mapping_type": "direct",
    "direction": "torch_to_tvm",
    "torch_pattern": "torch.softmax({{a}}, dim={{dim}}, dtype={{dtype}})",
    "tvm_pattern": "tvm.relay.op.nn.nn.softmax(data={{a}}, axis={{dim}})",
    "arg_mapping": {
      "a": "data",
      "dim": "axis"
    },
    "example_pairs": [
      {
        "torch": "result = torch.softmax(x, dim=1)",
        "tvm": "result = tvm.relay.op.nn.nn.softmax(data=x, axis=1)"
      },
      {
        "torch": "result = torch.softmax(x, dim=-1, dtype=torch.float64)",
        "tvm": "result = tvm.relay.op.nn.nn.softmax(data=x, axis=-1)\nresult = tvm.relay.op.cast(result, 'float64')"
      }
    ],
    "constraints": "PyTorch's `dtype` argument requires a separate `tvm.relay.op.cast` operation after softmax if the output dtype differs.",
    "notes": "Direct mapping for softmax activation.",
    "confidence": 0.95
  },
  {
    "torch_api": "torch._refs.__init__.unbind",
    "tvm_api": "tvm.relay.frontend.common.unbind",
    "mapping_type": "direct",
    "direction": "torch_to_tvm",
    "torch_pattern": "torch.unbind({{t}}, dim={{dim}})",
    "tvm_pattern": "tvm.relay.frontend.common.unbind(data={{t}}, axis={{dim}})",
    "arg_mapping": {
      "t": "data",
      "dim": "axis"
    },
    "example_pairs": [
      {
        "torch": "result = torch.unbind(x, dim=0)",
        "tvm": "result = tvm.relay.frontend.common.unbind(data=x, axis=0)"
      }
    ],
    "constraints": "Input tensor must have at least one dimension.",
    "notes": "Direct mapping for unbinding a tensor, explicitly noted as being derived from PyTorch frontend in TVM. Handles canonicalization of `dim` internally in PyTorch.",
    "confidence": 0.98
  },
  {
    "torch_api": "torch._refs.__init__.squeeze",
    "tvm_api": "tvm.relay.op.transform.squeeze",
    "mapping_type": "direct",
    "direction": "torch_to_tvm",
    "torch_pattern": "torch.squeeze({{a}}, dim={{dim}})",
    "tvm_pattern": "tvm.relay.op.transform.squeeze(data={{a}}, axis={{dim}})",
    "arg_mapping": {
      "a": "data",
      "dim": "axis"
    },
    "example_pairs": [
      {
        "torch": "result = torch.squeeze(x, dim=0)",
        "tvm": "result = tvm.relay.op.transform.squeeze(data=x, axis=0)"
      },
      {
        "torch": "result = torch.squeeze(x)",
        "tvm": "result = tvm.relay.op.transform.squeeze(data=x, axis=None)"
      }
    ],
    "constraints": "PyTorch's `squeeze` may return a view, while TVM's `squeeze` creates a new tensor, though optimized to a view by the backend if possible.",
    "notes": "Direct mapping for removing singleton dimensions. `dim=None` (PyTorch) maps to `axis=None` (TVM) to squeeze all dimensions of size 1.",
    "confidence": 0.95
  },
  {
    "torch_api": "torch._refs.__init__.transpose",
    "tvm_api": "tvm.relay.op.transform.transpose",
    "mapping_type": "composite",
    "direction": "torch_to_tvm",
    "torch_pattern": "torch.transpose({{a}}, dim0={{dim0}}, dim1={{dim1}})",
    "tvm_pattern": "permutation = list(range(a.ndim))\npermutation[dim0] = dim1\npermutation[dim1] = dim0\nresult = tvm.relay.op.transform.transpose(data={{a}}, axes=permutation)",
    "arg_mapping": {
      "a": "data",
      "dim0": "dim0",
      "dim1": "dim1"
    },
    "example_pairs": [
      {
        "torch": "result = torch.transpose(x, 0, 2)",
        "tvm": "permutation = list(range(x.ndim))\npermutation[0] = 2\npermutation[2] = 0\nresult = tvm.relay.op.transform.transpose(data=x, axes=permutation)"
      }
    ],
    "constraints": "PyTorch `transpose` swaps two specific dimensions, while TVM `transpose` requires the full permutation of axes. A helper function to construct the permutation list is needed.",
    "notes": "Mapped by constructing the full permutation list `axes` for `tvm.relay.op.transform.transpose` based on the two dimensions to be swapped. PyTorch's internal `permute` call is similar in concept.",
    "confidence": 0.85
  },
  {
    "torch_api": "torch._refs.__init__.cumsum",
    "tvm_api": "tvm.relay.op.transform.cumsum",
    "mapping_type": "direct",
    "direction": "torch_to_tvm",
    "torch_pattern": "torch.cumsum({{a}}, dim={{dim}}, dtype={{dtype}})",
    "tvm_pattern": "tvm.relay.op.transform.cumsum(data={{a}}, axis={{dim}}, dtype={{dtype}})",
    "arg_mapping": {
      "a": "data",
      "dim": "axis",
      "dtype": "dtype"
    },
    "example_pairs": [
      {
        "torch": "result = torch.cumsum(x, dim=1)",
        "tvm": "result = tvm.relay.op.transform.cumsum(data=x, axis=1)"
      },
      {
        "torch": "result = torch.cumsum(x, dim=0, dtype=torch.float32)",
        "tvm": "result = tvm.relay.op.transform.cumsum(data=x, axis=0, dtype='float32')"
      }
    ],
    "constraints": "PyTorch's `dim` parameter needs to be canonicalized before passing to TVM `axis` for negative values (handled by PyTorch internally). Both default to inclusive scan.",
    "notes": "Direct mapping for cumulative sum. TVM `cumsum` supports `dtype` directly.",
    "confidence": 0.95
  },
  {
    "torch_api": "torch._refs.__init__.cumprod",
    "tvm_api": "tvm.relay.op.transform.cumprod",
    "mapping_type": "direct",
    "direction": "torch_to_tvm",
    "torch_pattern": "torch.cumprod({{a}}, dim={{dim}}, dtype={{dtype}})",
    "tvm_pattern": "tvm.relay.op.transform.cumprod(data={{a}}, axis={{dim}}, dtype={{dtype}})",
    "arg_mapping": {
      "a": "data",
      "dim": "axis",
      "dtype": "dtype"
    },
    "example_pairs": [
      {
        "torch": "result = torch.cumprod(x, dim=1)",
        "tvm": "result = tvm.relay.op.transform.cumprod(data=x, axis=1)"
      },
      {
        "torch": "result = torch.cumprod(x, dim=0, dtype=torch.float32)",
        "tvm": "result = tvm.relay.op.transform.cumprod(data=x, axis=0, dtype='float32')"
      }
    ],
    "constraints": "PyTorch's `dim` parameter needs to be canonicalized before passing to TVM `axis` for negative values (handled by PyTorch internally). Both default to inclusive scan.",
    "notes": "Direct mapping for cumulative product. TVM `cumprod` supports `dtype` directly.",
    "confidence": 0.95
  },
  {
    "torch_api": "torch._refs.__init__.empty",
    "tvm_api": "tvm.runtime.ndarray.empty",
    "mapping_type": "direct",
    "direction": "torch_to_tvm",
    "torch_pattern": "torch.empty(*{{shape}}, dtype={{dtype}}, device={{device}})",
    "tvm_pattern": "tvm.runtime.ndarray.empty(shape={{shape}}, dtype={{dtype}}, device={{device}})",
    "arg_mapping": {
      "shape": "shape",
      "dtype": "dtype",
      "device": "device"
    },
    "example_pairs": [
      {
        "torch": "x = torch.empty(2, 3, dtype=torch.float32, device='cpu')",
        "tvm": "x = tvm.runtime.ndarray.empty(shape=(2, 3), dtype='float32', device=tvm.cpu(0))"
      }
    ],
    "constraints": "PyTorch's `layout`, `requires_grad`, `pin_memory`, `memory_format` parameters are not supported by `tvm.runtime.ndarray.empty`. TVM device needs to be converted (e.g., 'cpu' to `tvm.cpu(0)`).",
    "notes": "Direct mapping for creating an uninitialized tensor.",
    "confidence": 0.9
  },
  {
    "torch_api": "torch._refs.__init__.zeros",
    "tvm_api": "tvm.relay.op.tensor.zeros",
    "mapping_type": "direct",
    "direction": "torch_to_tvm",
    "torch_pattern": "torch.zeros(*{{size}}, dtype={{dtype}})",
    "tvm_pattern": "tvm.relay.op.tensor.zeros(shape={{size}}, dtype={{dtype}})",
    "arg_mapping": {
      "size": "shape",
      "dtype": "dtype"
    },
    "example_pairs": [
      {
        "torch": "x = torch.zeros(2, 3, dtype=torch.float32)",
        "tvm": "x = tvm.relay.op.tensor.zeros(shape=(2, 3), dtype='float32')"
      }
    ],
    "constraints": "PyTorch's `layout`, `device`, `pin_memory`, `requires_grad` parameters are not supported by `tvm.relay.op.tensor.zeros`. PyTorch's default `dtype` behavior might require explicit specification in TVM.",
    "notes": "Direct mapping for creating a tensor filled with zeros.",
    "confidence": 0.9
  },
  {
    "torch_api": "torch._refs.__init__.ones",
    "tvm_api": "tvm.relay.op.tensor.ones",
    "mapping_type": "direct",
    "direction": "torch_to_tvm",
    "torch_pattern": "torch.ones(*{{size}}, dtype={{dtype}})",
    "tvm_pattern": "tvm.relay.op.tensor.ones(shape={{size}}, dtype={{dtype}})",
    "arg_mapping": {
      "size": "shape",
      "dtype": "dtype"
    },
    "example_pairs": [
      {
        "torch": "x = torch.ones(2, 3, dtype=torch.float32)",
        "tvm": "x = tvm.relay.op.tensor.ones(shape=(2, 3), dtype='float32')"
      }
    ],
    "constraints": "PyTorch's `layout`, `device`, `pin_memory`, `requires_grad` parameters are not supported by `tvm.relay.op.tensor.ones`. PyTorch's default `dtype` behavior might require explicit specification in TVM.",
    "notes": "Direct mapping for creating a tensor filled with ones.",
    "confidence": 0.9
  },
  {
    "torch_api": "torch._refs.__init__.arange",
    "tvm_api": "tvm.relay.op.transform.arange",
    "mapping_type": "direct",
    "direction": "torch_to_tvm",
    "torch_pattern": "torch.arange({{start}}, {{end}}, {{step}}, dtype={{dtype}})",
    "tvm_pattern": "tvm.relay.op.transform.arange(start={{start}}, stop={{end}}, step={{step}}, dtype={{dtype}})",
    "arg_mapping": {
      "start": "start",
      "end": "stop",
      "step": "step",
      "dtype": "dtype"
    },
    "example_pairs": [
      {
        "torch": "result = torch.arange(5)",
        "tvm": "result = tvm.relay.op.transform.arange(start=0, stop=5, step=1, dtype='float32')"
      },
      {
        "torch": "result = torch.arange(1, 10, 2, dtype=torch.int32)",
        "tvm": "result = tvm.relay.op.transform.arange(start=1, stop=10, step=2, dtype='int32')"
      }
    ],
    "constraints": "PyTorch's single-argument `arange(stop)` needs to be expanded to `arange(0, stop, 1)` for TVM. PyTorch's `layout`, `device`, `pin_memory`, `requires_grad` are not supported. Default `dtype` behavior may differ.",
    "notes": "Direct mapping for creating a tensor with evenly spaced values. TVM handles the `start`, `stop`, `step` arguments similarly to NumPy.",
    "confidence": 0.95
  },
  {
    "torch_api": "torch._refs.__init__.meshgrid",
    "tvm_api": "tvm.relay.op.transform.meshgrid",
    "mapping_type": "direct",
    "direction": "torch_to_tvm",
    "torch_pattern": "torch.meshgrid(*{{tensors}}, indexing={{indexing}})",
    "tvm_pattern": "tvm.relay.op.transform.meshgrid(data={{tensors}}, indexing={{indexing}})",
    "arg_mapping": {
      "tensors": "data",
      "indexing": "indexing"
    },
    "example_pairs": [
      {
        "torch": "grid_x, grid_y = torch.meshgrid(x, y, indexing='ij')",
        "tvm": "grid_x, grid_y = tvm.relay.op.transform.meshgrid(data=[x, y], indexing='ij')"
      }
    ],
    "constraints": "PyTorch's `*tensors` (varargs) or `Sequence[TensorLikeType]` needs to be converted to a list/tuple for TVM's `data` argument.",
    "notes": "Direct mapping for creating coordinate matrices from vectors, supporting 'ij' and 'xy' indexing.",
    "confidence": 0.95
  },
  {
    "torch_api": "torch._refs.__init__.meshgrid",
    "tvm_api": "tvm.relay.op.transform.meshgrid",
    "mapping_type": "direct",
    "direction": "torch_to_tvm",
    "torch_pattern": "torch.meshgrid(*{{tensors}}, indexing={{indexing}})",
    "tvm_pattern": "tvm.relay.op.transform.meshgrid(data={{tensors}}, indexing={{indexing}})",
    "arg_mapping": {
      "tensors": "data",
      "indexing": "indexing"
    },
    "example_pairs": [
      {
        "torch": "grid_x, grid_y = torch.meshgrid(x, y, indexing='ij')",
        "tvm": "grid_x, grid_y = tvm.relay.op.transform.meshgrid(data=[x, y], indexing='ij')"
      }
    ],
    "constraints": "PyTorch's `*tensors` (varargs) or `Sequence[TensorLikeType]` needs to be converted to a list/tuple for TVM's `data` argument.",
    "notes": "Direct mapping for creating coordinate matrices from vectors, supporting 'ij' and 'xy' indexing. (Duplicate entry in problem statement, identical mapping.)",
    "confidence": 0.95
  },
  {
    "torch_api": "torch._refs.__init__.meshgrid",
    "tvm_api": "tvm.relay.op.transform.meshgrid",
    "mapping_type": "direct",
    "direction": "torch_to_tvm",
    "torch_pattern": "torch.meshgrid(*{{tensors}}, indexing={{indexing}})",
    "tvm_pattern": "tvm.relay.op.transform.meshgrid(data={{tensors}}, indexing={{indexing}})",
    "arg_mapping": {
      "tensors": "data",
      "indexing": "indexing"
    },
    "example_pairs": [
      {
        "torch": "grid_x, grid_y = torch.meshgrid(x, y, indexing='ij')",
        "tvm": "grid_x, grid_y = tvm.relay.op.transform.meshgrid(data=[x, y], indexing='ij')"
      }
    ],
    "constraints": "PyTorch's `*tensors` (varargs) or `Sequence[TensorLikeType]` needs to be converted to a list/tuple for TVM's `data` argument.",
    "notes": "Direct mapping for creating coordinate matrices from vectors, supporting 'ij' and 'xy' indexing. (Duplicate entry in problem statement, identical mapping.)",
    "confidence": 0.95
  },
  {
    "torch_api": "torch._refs.__init__.full",
    "tvm_api": "tvm.relay.op.transform.full",
    "mapping_type": "direct",
    "direction": "torch_to_tvm",
    "torch_pattern": "torch.full({{shape}}, {{fill_value}}, dtype={{dtype}})",
    "tvm_pattern": "tvm.relay.op.transform.full(fill_value={{fill_value}}, shape={{shape}}, dtype={{dtype}})",
    "arg_mapping": {
      "shape": "shape",
      "fill_value": "fill_value",
      "dtype": "dtype"
    },
    "example_pairs": [
      {
        "torch": "x = torch.full((2, 3), 7.0, dtype=torch.float32)",
        "tvm": "x = tvm.relay.op.transform.full(fill_value=7.0, shape=(2, 3), dtype='float32')"
      }
    ],
    "constraints": "PyTorch's `layout`, `device`, `pin_memory`, `requires_grad` are not supported. TVM's `dtype` defaults to the `fill_value`'s type if not specified, which should align with PyTorch's `None` default.",
    "notes": "Direct mapping for creating a tensor of a given shape filled with a scalar value.",
    "confidence": 0.95
  },
  {
    "torch_api": "torch._refs.__init__.full_like",
    "tvm_api": "tvm.relay.op.transform.full_like",
    "mapping_type": "direct",
    "direction": "torch_to_tvm",
    "torch_pattern": "torch.full_like({{a}}, {{fill_value}}, dtype={{dtype}})",
    "tvm_pattern": "tvm.relay.op.transform.full_like(data={{a}}, fill_value={{fill_value}})",
    "arg_mapping": {
      "a": "data",
      "fill_value": "fill_value"
    },
    "example_pairs": [
      {
        "torch": "x = torch.randn(2, 3)\ny = torch.full_like(x, 5.0)",
        "tvm": "x = tvm.relay.op.random.uniform(key, low=0.0, high=1.0, shape=(2, 3), dtype='float32') # Placeholder for random data\ny = tvm.relay.op.transform.full_like(data=x, fill_value=5.0)"
      },
      {
        "torch": "x = torch.randn(2, 3)\ny = torch.full_like(x, 5.0, dtype=torch.int32)",
        "tvm": "x = tvm.relay.op.random.uniform(key, low=0.0, high=1.0, shape=(2, 3), dtype='float32') # Placeholder for random data\ny = tvm.relay.op.transform.full_like(data=x, fill_value=5.0)\ny = tvm.relay.op.cast(y, 'int32')"
      }
    ],
    "constraints": "PyTorch's `layout`, `device`, `pin_memory`, `requires_grad`, `memory_format` are not supported. If PyTorch's `dtype` differs from `a.dtype`, a separate `tvm.relay.op.cast` operation is needed after `full_like` in TVM.",
    "notes": "Direct mapping for creating a tensor with the same shape and `fill_value` as `a`.",
    "confidence": 0.9
  },
  {
    "torch_api": "torch._refs.__init__.zeros_like",
    "tvm_api": "tvm.relay.op.tensor.zeros_like",
    "mapping_type": "direct",
    "direction": "torch_to_tvm",
    "torch_pattern": "torch.zeros_like({{a}}, dtype={{dtype}})",
    "tvm_pattern": "tvm.relay.op.tensor.zeros_like(data={{a}})",
    "arg_mapping": {
      "a": "data"
    },
    "example_pairs": [
      {
        "torch": "x = torch.randn(2, 3)\ny = torch.zeros_like(x)",
        "tvm": "x = tvm.relay.op.random.uniform(key, low=0.0, high=1.0, shape=(2, 3), dtype='float32')\ny = tvm.relay.op.tensor.zeros_like(data=x)"
      },
      {
        "torch": "x = torch.randn(2, 3)\ny = torch.zeros_like(x, dtype=torch.int32)",
        "tvm": "x = tvm.relay.op.random.uniform(key, low=0.0, high=1.0, shape=(2, 3), dtype='float32')\ny = tvm.relay.op.tensor.zeros_like(data=x)\ny = tvm.relay.op.cast(y, 'int32')"
      }
    ],
    "constraints": "PyTorch's `layout`, `device`, `pin_memory`, `requires_grad`, `memory_format` are not supported. If PyTorch's `dtype` differs from `a.dtype`, a separate `tvm.relay.op.cast` operation is needed after `zeros_like` in TVM. Handles boolean `False` correctly through type system.",
    "notes": "Direct mapping for creating a tensor of zeros with the same shape and `dtype` as input.",
    "confidence": 0.9
  },
  {
    "torch_api": "torch._refs.__init__.ones_like",
    "tvm_api": "tvm.relay.op.tensor.ones_like",
    "mapping_type": "direct",
    "direction": "torch_to_tvm",
    "torch_pattern": "torch.ones_like({{a}}, dtype={{dtype}})",
    "tvm_pattern": "tvm.relay.op.tensor.ones_like(data={{a}})",
    "arg_mapping": {
      "a": "data"
    },
    "example_pairs": [
      {
        "torch": "x = torch.randn(2, 3)\ny = torch.ones_like(x)",
        "tvm": "x = tvm.relay.op.random.uniform(key, low=0.0, high=1.0, shape=(2, 3), dtype='float32')\ny = tvm.relay.op.tensor.ones_like(data=x)"
      },
      {
        "torch": "x = torch.randn(2, 3)\ny = torch.ones_like(x, dtype=torch.bool)",
        "tvm": "x = tvm.relay.op.random.uniform(key, low=0.0, high=1.0, shape=(2, 3), dtype='float32')\ny = tvm.relay.op.tensor.ones_like(data=x)\ny = tvm.relay.op.cast(y, 'bool')"
      }
    ],
    "constraints": "PyTorch's `layout`, `device`, `pin_memory`, `requires_grad`, `memory_format` are not supported. If PyTorch's `dtype` differs from `a.dtype`, a separate `tvm.relay.op.cast` operation is needed after `ones_like` in TVM. Handles boolean `True` correctly through type system.",
    "notes": "Direct mapping for creating a tensor of ones with the same shape and `dtype` as input.",
    "confidence": 0.9
  },
  {
    "torch_api": "torch._refs.__init__.equal",
    "tvm_api": [
      "tvm.relay.op.tensor.equal",
      "tvm.relay.op.reduce.all"
    ],
    "mapping_type": "composite",
    "direction": "torch_to_tvm",
    "torch_pattern": "torch.equal({{a}}, {{b}})",
    "tvm_pattern": "intermediate = tvm.relay.op.tensor.equal(lhs={{a}}, rhs={{b}})\nresult = tvm.relay.op.reduce.all(data=intermediate)",
    "arg_mapping": {
      "a": "lhs",
      "b": "rhs"
    },
    "example_pairs": [
      {
        "torch": "result = torch.equal(x, y)",
        "tvm": "intermediate = tvm.relay.op.tensor.equal(lhs=x, rhs=y)\nresult = tvm.relay.op.reduce.all(data=intermediate)"
      }
    ],
    "constraints": "PyTorch `equal` also performs shape and dtype checks internally and returns a scalar boolean. TVM `tensor.equal` performs element-wise comparison returning a boolean tensor, which then needs `reduce.all` to match PyTorch's scalar output. Explicit shape and dtype comparison would be needed if not handled by TVM's graph representation.",
    "notes": "Mapped as a composite of element-wise equality followed by a reduction to check if all elements are equal, consistent with PyTorch's definition.",
    "confidence": 0.8
  },
  {
    "torch_api": "torch._refs.__init__.trace",
    "tvm_api": null,
    "mapping_type": "no_mapping",
    "direction": "torch_to_tvm",
    "torch_pattern": null,
    "tvm_pattern": null,
    "arg_mapping": {},
    "example_pairs": [],
    "constraints": "Not convertible",
    "notes": "NO_MAPPING: The TVM 'trace' candidate (`tvm.tir.op.trace`) is for runtime data tracing/debugging, not for computing the mathematical trace (sum of diagonal elements) of a matrix. The PyTorch implementation uses `torch.diag` and `torch.sum`, but `torch.diag` was not provided as a TVM candidate.",
    "confidence": 0.2
  },
  {
    "torch_api": "torch._refs.__init__.normal",
    "tvm_api": "tvm.relay.op.random.kernel.normal",
    "mapping_type": "direct",
    "direction": "torch_to_tvm",
    "torch_pattern": "torch.normal(mean={{mean}}, std={{std}}, size={{size}}, dtype={{dtype}})",
    "tvm_pattern": "result = tvm.relay.op.random.kernel.normal(key={{key_var}}, shape={{size}}, dtype={{dtype}}, mean={{mean}}, scale={{std}})",
    "arg_mapping": {
      "mean": "mean",
      "std": "scale",
      "size": "shape",
      "dtype": "dtype"
    },
    "example_pairs": [
      {
        "torch": "result = torch.normal(mean=0.0, std=1.0, size=(2, 3))",
        "tvm": "key_var = tvm.relay.op.random.threefry_key(0) # or another key\nresult = tvm.relay.op.random.kernel.normal(key=key_var, shape=(2, 3), dtype='float32', mean=0.0, scale=1.0)"
      }
    ],
    "constraints": "TVM's `normal` requires a `key` (generator state) as the first argument, which needs to be managed externally (e.g., `tvm.relay.op.random.threefry_key`). PyTorch `mean` and `std` can be tensors, while TVM `mean` and `scale` are scalars. This mapping assumes scalar `mean` and `std`.",
    "notes": "Direct mapping for generating random numbers from a normal distribution, with additional handling for the random generator key.",
    "confidence": 0.75
  },
  {
    "torch_api": "torch._refs.nn.functional.__init__.dropout",
    "tvm_api": "tvm.relay.op.nn.nn.dropout",
    "mapping_type": "direct",
    "direction": "torch_to_tvm",
    "torch_pattern": "torch.nn.functional.dropout({{a}}, p={{p}}, training={{training}})",
    "tvm_pattern": "result = tvm.relay.op.nn.nn.dropout(data={{a}}, rate={{p}})",
    "arg_mapping": {
      "a": "data",
      "p": "rate"
    },
    "example_pairs": [
      {
        "torch": "result = torch.nn.functional.dropout(x, p=0.5, training=True)",
        "tvm": "result = tvm.relay.op.nn.nn.dropout(data=x, rate=0.5)"
      }
    ],
    "constraints": "TVM's `dropout` implicitly applies `training=True` logic. PyTorch's `training=False` (return original input) or `p=1` (return zeros) logic needs to be handled via conditional graph construction if these branches are taken. The `inplace` argument is not supported by the PyTorch ref or TVM op.",
    "notes": "Direct mapping for the dropout operation during training.",
    "confidence": 0.85
  },
  {
    "torch_api": "torch._refs.nn.functional.__init__.relu",
    "tvm_api": "tvm.relay.op.nn.nn.relu",
    "mapping_type": "direct",
    "direction": "torch_to_tvm",
    "torch_pattern": "torch.nn.functional.relu({{a}})",
    "tvm_pattern": "tvm.relay.op.nn.nn.relu(data={{a}})",
    "arg_mapping": {
      "a": "data"
    },
    "example_pairs": [
      {
        "torch": "result = torch.nn.functional.relu(x)",
        "tvm": "result = tvm.relay.op.nn.nn.relu(data=x)"
      }
    ],
    "constraints": "PyTorch's `inplace` argument is not supported in the ref implementation and not available in TVM's functional ReLU.",
    "notes": "Direct mapping for Rectified Linear Unit activation.",
    "confidence": 0.98
  },
  {
    "torch_api": "torch._refs.nn.functional.__init__.group_norm",
    "tvm_api": "tvm.relay.op.nn.nn.group_norm",
    "mapping_type": "direct",
    "direction": "torch_to_tvm",
    "torch_pattern": "torch.nn.functional.group_norm(input={{input}}, num_groups={{num_groups}}, weight={{weight}}, bias={{bias}}, eps={{eps}})",
    "tvm_pattern": "tvm.relay.op.nn.nn.group_norm(data={{input}}, gamma={{weight}}, beta={{bias}}, num_groups={{num_groups}}, epsilon={{eps}})",
    "arg_mapping": {
      "input": "data",
      "num_groups": "num_groups",
      "weight": "gamma",
      "bias": "beta",
      "eps": "epsilon"
    },
    "example_pairs": [
      {
        "torch": "result = torch.nn.functional.group_norm(x, 2, weight=w, bias=b, eps=1e-5)",
        "tvm": "result = tvm.relay.op.nn.nn.group_norm(data=x, gamma=w, beta=b, num_groups=2, epsilon=1e-5)"
      }
    ],
    "constraints": "TVM's `group_norm` has `axis`, `center`, `scale` parameters that are often implicitly handled or defaulted in PyTorch. The default axis (1) and `center`/`scale` (True) are assumed to be consistent.",
    "notes": "Direct mapping for group normalization. PyTorch's `weight` and `bias` map to TVM's `gamma` and `beta`.",
    "confidence": 0.9
  },
  {
    "torch_api": "torch._refs.nn.functional.__init__.layer_norm",
    "tvm_api": "tvm.relay.op.nn.nn.layer_norm",
    "mapping_type": "composite",
    "direction": "torch_to_tvm",
    "torch_pattern": "torch.nn.functional.layer_norm(input={{input}}, normalized_shape={{normalized_shape}}, weight={{weight}}, bias={{bias}}, eps={{eps}})",
    "tvm_pattern": "axis_indices = [input.ndim - len({{normalized_shape}}), ..., input.ndim - 1] # Compute axis based on normalized_shape\ntvm.relay.op.nn.nn.layer_norm(data={{input}}, gamma={{weight}}, beta={{bias}}, axis=axis_indices, epsilon={{eps}})",
    "arg_mapping": {
      "input": "data",
      "normalized_shape": "normalized_shape",
      "weight": "gamma",
      "bias": "beta",
      "eps": "epsilon"
    },
    "example_pairs": [
      {
        "torch": "result = torch.nn.functional.layer_norm(x, (10,), weight=w, bias=b, eps=1e-5)",
        "tvm": "axis_indices = [-1] # For (10,) normalized_shape on input.ndim-1\nresult = tvm.relay.op.nn.nn.layer_norm(data=x, gamma=w, beta=b, axis=axis_indices, epsilon=1e-5)"
      }
    ],
    "constraints": "PyTorch's `normalized_shape` (tuple of trailing dimensions) needs to be converted into a list of explicit axis indices for TVM's `axis` parameter. TVM `layer_norm` also has `center` and `scale` parameters (defaulting to True) that are not explicit in PyTorch's functional API.",
    "notes": "Mapped by converting `normalized_shape` to `axis` indices. This typically involves identifying the last `len(normalized_shape)` dimensions of the input tensor.",
    "confidence": 0.85
  },
  {
    "torch_api": "torch._refs.nn.functional.__init__.leaky_relu",
    "tvm_api": "tvm.relay.op.nn.nn.leaky_relu",
    "mapping_type": "direct",
    "direction": "torch_to_tvm",
    "torch_pattern": "torch.nn.functional.leaky_relu({{a}}, negative_slope={{negative_slope}})",
    "tvm_pattern": "tvm.relay.op.nn.nn.leaky_relu(data={{a}}, alpha={{negative_slope}})",
    "arg_mapping": {
      "a": "data",
      "negative_slope": "alpha"
    },
    "example_pairs": [
      {
        "torch": "result = torch.nn.functional.leaky_relu(x, negative_slope=0.1)",
        "tvm": "result = tvm.relay.op.nn.nn.leaky_relu(data=x, alpha=0.1)"
      }
    ],
    "constraints": "PyTorch's `inplace` argument is not supported in the ref implementation and not available in TVM's functional Leaky ReLU.",
    "notes": "Direct mapping for Leaky ReLU activation.",
    "confidence": 0.98
  },
  {
    "torch_api": "torch._refs.nn.functional.__init__.softmax",
    "tvm_api": "tvm.relay.op.nn.nn.softmax",
    "mapping_type": "direct",
    "direction": "torch_to_tvm",
    "torch_pattern": "torch.nn.functional.softmax({{a}}, dim={{dim}}, dtype={{dtype}})",
    "tvm_pattern": "tvm.relay.op.nn.nn.softmax(data={{a}}, axis={{dim}})",
    "arg_mapping": {
      "a": "data",
      "dim": "axis"
    },
    "example_pairs": [
      {
        "torch": "result = torch.nn.functional.softmax(x, dim=1)",
        "tvm": "result = tvm.relay.op.nn.nn.softmax(data=x, axis=1)"
      },
      {
        "torch": "result = torch.nn.functional.softmax(x, dim=-1, dtype=torch.float64)",
        "tvm": "result = tvm.relay.op.nn.nn.softmax(data=x, axis=-1)\nresult = tvm.relay.op.cast(result, 'float64')"
      }
    ],
    "constraints": "PyTorch requires `dim` to be explicitly provided (`dim is not None`). PyTorch's `dtype` argument requires a separate `tvm.relay.op.cast` operation after the softmax if the output dtype differs.",
    "notes": "Direct mapping for softmax activation (functional variant).",
    "confidence": 0.95
  },
  {
    "torch_api": "torch._refs.nn.functional.__init__.log_softmax",
    "tvm_api": "tvm.relay.op.nn.nn.log_softmax",
    "mapping_type": "direct",
    "direction": "torch_to_tvm",
    "torch_pattern": "torch.nn.functional.log_softmax({{a}}, dim={{dim}}, dtype={{dtype}})",
    "tvm_pattern": "tvm.relay.op.nn.nn.log_softmax(data={{a}}, axis={{dim}})",
    "arg_mapping": {
      "a": "data",
      "dim": "axis"
    },
    "example_pairs": [
      {
        "torch": "result = torch.nn.functional.log_softmax(x, dim=1)",
        "tvm": "result = tvm.relay.op.nn.nn.log_softmax(data=x, axis=1)"
      },
      {
        "torch": "result = torch.nn.functional.log_softmax(x, dim=-1, dtype=torch.float64)",
        "tvm": "result = tvm.relay.op.nn.nn.log_softmax(data=x, axis=-1)\nresult = tvm.relay.op.cast(result, 'float64')"
      }
    ],
    "constraints": "PyTorch requires `dim` to be explicitly provided (`dim is not None`). PyTorch's `dtype` argument requires a separate `tvm.relay.op.cast` operation after the log_softmax if the output dtype differs.",
    "notes": "Direct mapping for log softmax activation (functional variant).",
    "confidence": 0.95
  },
  {
    "torch_api": "torch._refs.nn.functional.__init__.nll_loss",
    "tvm_api": "tvm.relay.op.nn.nn.nll_loss",
    "mapping_type": "direct",
    "direction": "torch_to_tvm",
    "torch_pattern": "torch.nn.functional.nll_loss(input={{input}}, target={{target}}, weight={{weight}}, reduction={{reduction}}, ignore_index={{ignore_index}})",
    "tvm_pattern": "tvm.relay.op.nn.nn.nll_loss(predictions={{input}}, targets={{target}}, weights={{weight}}, reduction={{reduction}}, ignore_index={{ignore_index}})",
    "arg_mapping": {
      "input": "predictions",
      "target": "targets",
      "weight": "weights",
      "reduction": "reduction",
      "ignore_index": "ignore_index"
    },
    "example_pairs": [
      {
        "torch": "loss = torch.nn.functional.nll_loss(output, target, reduction='mean')",
        "tvm": "loss = tvm.relay.op.nn.nn.nll_loss(predictions=output, targets=target, weights=None, reduction='mean', ignore_index=-100)"
      }
    ],
    "constraints": "PyTorch has deprecated `size_average` and `reduce` arguments, which map to `reduction` in TVM. `weight` can be `None` in PyTorch, mapping to `None` in TVM.",
    "notes": "Direct mapping for Negative Log Likelihood Loss.",
    "confidence": 0.95
  },
  {
    "torch_api": "torch._refs.nn.functional.__init__.prelu",
    "tvm_api": "tvm.relay.op.nn.nn.prelu",
    "mapping_type": "direct",
    "direction": "torch_to_tvm",
    "torch_pattern": "torch.nn.functional.prelu({{a}}, {{weight}})",
    "tvm_pattern": "tvm.relay.op.nn.nn.prelu(data={{a}}, alpha={{weight}})",
    "arg_mapping": {
      "a": "data",
      "weight": "alpha"
    },
    "example_pairs": [
      {
        "torch": "result = torch.nn.functional.prelu(x, p_weight)",
        "tvm": "result = tvm.relay.op.nn.nn.prelu(data=x, alpha=p_weight)"
      }
    ],
    "constraints": "PyTorch's `weight` can be a scalar or a 1D tensor representing channel-wise slopes, mapping to TVM's `alpha`. TVM's `prelu` has an `axis` parameter (default 1) that can be specified, while PyTorch infers this implicitly or assumes channel-first.",
    "notes": "Direct mapping for Parametric ReLU activation.",
    "confidence": 0.95
  },
  {
    "torch_api": "torch._refs.special.__init__.log_softmax",
    "tvm_api": "tvm.relay.op.nn.nn.log_softmax",
    "mapping_type": "direct",
    "direction": "torch_to_tvm",
    "torch_pattern": "torch.special.log_softmax({{a}}, dim={{dim}}, dtype={{dtype}})",
    "tvm_pattern": "tvm.relay.op.nn.nn.log_softmax(data={{a}}, axis={{dim}})",
    "arg_mapping": {
      "a": "data",
      "dim": "axis"
    },
    "example_pairs": [
      {
        "torch": "result = torch.special.log_softmax(x, dim=1)",
        "tvm": "result = tvm.relay.op.nn.nn.log_softmax(data=x, axis=1)"
      }
    ],
    "constraints": "PyTorch's `dtype` argument requires a separate `tvm.relay.op.cast` operation after the log_softmax if the output dtype differs.",
    "notes": "Direct forwarding of `torch.log_softmax` (same mapping as `torch._refs.nn.functional.__init__.log_softmax`).",
    "confidence": 0.95
  },
  {
    "torch_api": "torch._refs.special.__init__.softmax",
    "tvm_api": "tvm.relay.op.nn.nn.softmax",
    "mapping_type": "direct",
    "direction": "torch_to_tvm",
    "torch_pattern": "torch.special.softmax({{a}}, dim={{dim}}, dtype={{dtype}})",
    "tvm_pattern": "tvm.relay.op.nn.nn.softmax(data={{a}}, axis={{dim}})",
    "arg_mapping": {
      "a": "data",
      "dim": "axis"
    },
    "example_pairs": [
      {
        "torch": "result = torch.special.softmax(x, dim=1)",
        "tvm": "result = tvm.relay.op.nn.nn.softmax(data=x, axis=1)"
      }
    ],
    "constraints": "PyTorch's `dtype` argument requires a separate `tvm.relay.op.cast` operation after the softmax if the output dtype differs.",
    "notes": "Direct forwarding of `torch.softmax` (same mapping as `torch._refs.nn.functional.__init__.softmax`).",
    "confidence": 0.95
  },
  {
    "torch_api": "torch.ao.nn.quantized.functional.avg_pool2d",
    "tvm_api": null,
    "mapping_type": "no_mapping",
    "direction": "torch_to_tvm",
    "torch_pattern": null,
    "tvm_pattern": null,
    "arg_mapping": {},
    "example_pairs": [],
    "constraints": "Not convertible directly due to quantization semantics.",
    "notes": "NO_MAPPING: This is a *quantized* average pooling operation in PyTorch. The provided TVM `avg_pool2d` is a standard floating-point operation. A direct equivalent in TVM's QNN module (e.g., `qnn.avg_pool2d`) was not provided as a candidate function. Converting between quantized and float domains requires explicit dequantization/quantization operations around the float operation.",
    "confidence": 0.2
  },
  {
    "torch_api": "torch.ao.nn.quantized.functional.avg_pool3d",
    "tvm_api": null,
    "mapping_type": "no_mapping",
    "direction": "torch_to_tvm",
    "torch_pattern": null,
    "tvm_pattern": null,
    "arg_mapping": {},
    "example_pairs": [],
    "constraints": "Not convertible directly due to quantization semantics.",
    "notes": "NO_MAPPING: This is a *quantized* average pooling operation in PyTorch. The provided TVM `avg_pool3d` is a standard floating-point operation. A direct equivalent in TVM's QNN module (e.g., `qnn.avg_pool3d`) was not provided as a candidate function. Converting between quantized and float domains requires explicit dequantization/quantization operations around the float operation.",
    "confidence": 0.2
  },
  {
    "torch_api": "torch.ao.nn.quantized.functional.adaptive_avg_pool2d",
    "tvm_api": null,
    "mapping_type": "no_mapping",
    "direction": "torch_to_tvm",
    "torch_pattern": null,
    "tvm_pattern": null,
    "arg_mapping": {},
    "example_pairs": [],
    "constraints": "Not convertible directly due to quantization semantics.",
    "notes": "NO_MAPPING: This is a *quantized* adaptive average pooling operation in PyTorch. The provided TVM `adaptive_avg_pool2d` is a standard floating-point operation. A direct equivalent in TVM's QNN module was not provided as a candidate function. Converting between quantized and float domains requires explicit dequantization/quantization operations around the float operation.",
    "confidence": 0.2
  },
  {
    "torch_api": "torch.ao.nn.quantized.functional.adaptive_avg_pool3d",
    "tvm_api": null,
    "mapping_type": "no_mapping",
    "direction": "torch_to_tvm",
    "torch_pattern": null,
    "tvm_pattern": null,
    "arg_mapping": {},
    "example_pairs": [],
    "constraints": "Not convertible directly due to quantization semantics.",
    "notes": "NO_MAPPING: This is a *quantized* adaptive average pooling operation in PyTorch. The provided TVM `adaptive_avg_pool3d` is a standard floating-point operation. A direct equivalent in TVM's QNN module was not provided as a candidate function. Converting between quantized and float domains requires explicit dequantization/quantization operations around the float operation.",
    "confidence": 0.2
  },
  {
    "torch_api": "torch.ao.nn.quantized.functional.conv1d",
    "tvm_api": null,
    "mapping_type": "no_mapping",
    "direction": "torch_to_tvm",
    "torch_pattern": null,
    "tvm_pattern": null,
    "arg_mapping": {},
    "example_pairs": [],
    "constraints": "Not convertible directly due to quantization semantics.",
    "notes": "NO_MAPPING: This is a *quantized* 1D convolution operation in PyTorch. The provided TVM `conv1d` candidates are for standard floating-point convolution. While TVM's QNN module likely has a `qnn.conv1d`, it was not provided as a candidate function for the name `conv1d` in the snippets.",
    "confidence": 0.2
  },
  {
    "torch_api": "torch.ao.nn.quantized.functional.conv2d",
    "tvm_api": "tvm.relay.qnn.op.qnn.conv2d",
    "mapping_type": "direct",
    "direction": "torch_to_tvm",
    "torch_pattern": "torch.ao.nn.quantized.functional.conv2d(input={{input}}, weight={{weight}}, bias={{bias}}, stride={{stride}}, padding={{padding}}, dilation={{dilation}}, groups={{groups}}, scale={{scale}}, zero_point={{zero_point}})",
    "tvm_pattern": "tvm.relay.qnn.op.qnn.conv2d(data={{input}}, kernel={{weight}}, input_zero_point=get_qparam({{input}}, 'zero_point'), kernel_zero_point=get_qparam({{weight}}, 'zero_point'), input_scale=get_qparam({{input}}, 'scale'), kernel_scale=get_qparam({{weight}}, 'scale'), strides={{stride}}, padding={{padding}}, dilation={{dilation}}, groups={{groups}}, out_dtype='int32')",
    "arg_mapping": {
      "input": "data",
      "weight": "kernel",
      "stride": "strides",
      "padding": "padding",
      "dilation": "dilation",
      "groups": "groups",
      "scale": "output_scale_placeholder",
      "zero_point": "output_zero_point_placeholder"
    },
    "example_pairs": [
      {
        "torch": "result = torch.ao.nn.quantized.functional.conv2d(input_q, weight_q, bias_fp, stride=1, padding=0, scale=0.1, zero_point=0)",
        "tvm": "input_scale_expr, input_zero_point_expr = get_qparam(input_q, 'scale'), get_qparam(input_q, 'zero_point')\nkernel_scale_expr, kernel_zero_point_expr = get_qparam(weight_q, 'scale'), get_qparam(weight_q, 'zero_point')\nconv_out_int32 = tvm.relay.qnn.op.qnn.conv2d(data=input_q, kernel=weight_q, input_zero_point=input_zero_point_expr, kernel_zero_point=kernel_zero_point_expr, input_scale=input_scale_expr, kernel_scale=kernel_scale_expr, strides=(1, 1), padding=(0, 0), dilation=(1, 1), groups=1, out_dtype='int32')\n# Bias and output quantization would follow this."
      }
    ],
    "constraints": "TVM's `qnn.conv2d` requires explicit `input_scale`, `input_zero_point`, `kernel_scale`, `kernel_zero_point`. These need to be extracted from the quantized PyTorch `input` and `weight` tensors. The `bias` parameter in PyTorch is typically applied after the core convolution and would need separate handling (e.g., `qnn.add` or dequantize+add+quantize). PyTorch `scale` and `zero_point` are for the output tensor; TVM's `qnn.conv2d` returns `int32` accumulator, subsequent `qnn.requantize` handles final output scale/zero-point.",
    "notes": "Direct mapping to TVM's quantized convolution operation. Requires careful management of quantization parameters for input, weight, and output.",
    "confidence": 0.8
  },
  {
    "torch_api": "torch.ao.nn.quantized.functional.conv3d",
    "tvm_api": null,
    "mapping_type": "no_mapping",
    "direction": "torch_to_tvm",
    "torch_pattern": null,
    "tvm_pattern": null,
    "arg_mapping": {},
    "example_pairs": [],
    "constraints": "Not convertible directly due to quantization semantics.",
    "notes": "NO_MAPPING: This is a *quantized* 3D convolution operation in PyTorch. The provided TVM `conv3d` candidates are for standard floating-point convolution. While TVM's QNN module likely has a `qnn.conv3d`, it was not provided as a candidate function for the name `conv3d` in the snippets.",
    "confidence": 0.2
  },
  {
    "torch_api": "torch.ao.nn.quantized.functional.max_pool1d",
    "tvm_api": null,
    "mapping_type": "no_mapping",
    "direction": "torch_to_tvm",
    "torch_pattern": null,
    "tvm_pattern": null,
    "arg_mapping": {},
    "example_pairs": [],
    "constraints": "Not convertible directly due to quantization semantics.",
    "notes": "NO_MAPPING: This is a *quantized* max pooling operation in PyTorch. The provided TVM `max_pool1d` is a standard floating-point operation. A direct equivalent in TVM's QNN module was not provided as a candidate function. PyTorch's `return_indices` is also not supported.",
    "confidence": 0.2
  },
  {
    "torch_api": "torch.ao.nn.quantized.functional.max_pool2d",
    "tvm_api": null,
    "mapping_type": "no_mapping",
    "direction": "torch_to_tvm",
    "torch_pattern": null,
    "tvm_pattern": null,
    "arg_mapping": {},
    "example_pairs": [],
    "constraints": "Not convertible directly due to quantization semantics.",
    "notes": "NO_MAPPING: This is a *quantized* max pooling operation in PyTorch. The provided TVM `max_pool2d` is a standard floating-point operation. A direct equivalent in TVM's QNN module was not provided as a candidate function. PyTorch's `return_indices` is also not supported.",
    "confidence": 0.2
  },
  {
    "torch_api": "torch.ao.nn.quantized.functional.leaky_relu",
    "tvm_api": "tvm.relay.qnn.op.qnn.leaky_relu",
    "mapping_type": "direct",
    "direction": "torch_to_tvm",
    "torch_pattern": "torch.ao.nn.quantized.functional.leaky_relu(input={{input}}, negative_slope={{negative_slope}}, scale={{scale}}, zero_point={{zero_point}})",
    "tvm_pattern": "tvm.relay.qnn.op.qnn.leaky_relu(x={{input}}, alpha={{negative_slope}}, input_scale=get_qparam({{input}}, 'scale'), input_zero_point=get_qparam({{input}}, 'zero_point'), output_scale={{scale}}, output_zero_point={{zero_point}})",
    "arg_mapping": {
      "input": "x",
      "negative_slope": "alpha",
      "scale": "output_scale",
      "zero_point": "output_zero_point"
    },
    "example_pairs": [
      {
        "torch": "result = torch.ao.nn.quantized.functional.leaky_relu(x_q, negative_slope=0.1, scale=s_out, zero_point=zp_out)",
        "tvm": "input_scale_expr, input_zero_point_expr = get_qparam(x_q, 'scale'), get_qparam(x_q, 'zero_point')\nresult = tvm.relay.qnn.op.qnn.leaky_relu(x=x_q, alpha=0.1, input_scale=input_scale_expr, input_zero_point=input_zero_point_expr, output_scale=s_out, output_zero_point=zp_out)"
      }
    ],
    "constraints": "TVM's `qnn.leaky_relu` requires explicit `input_scale` and `input_zero_point` parameters, which need to be extracted from the quantized PyTorch `input` tensor. PyTorch's `inplace` argument is not supported.",
    "notes": "Direct mapping to TVM's quantized Leaky ReLU operation, requiring explicit input quantization parameters.",
    "confidence": 0.9
  },
  {
    "torch_api": "torch.ao.nn.quantized.functional.hardswish",
    "tvm_api": "tvm.relay.qnn.op.qnn.hardswish",
    "mapping_type": "direct",
    "direction": "torch_to_tvm",
    "torch_pattern": "torch.ao.nn.quantized.functional.hardswish(input={{input}}, scale={{scale}}, zero_point={{zero_point}})",
    "tvm_pattern": "tvm.relay.qnn.op.qnn.hardswish(x={{input}}, scale=get_qparam({{input}}, 'scale'), zero_point=get_qparam({{input}}, 'zero_point'), output_scale={{scale}}, output_zero_point={{zero_point}})",
    "arg_mapping": {
      "input": "x",
      "scale": "output_scale",
      "zero_point": "output_zero_point"
    },
    "example_pairs": [
      {
        "torch": "result = torch.ao.nn.quantized.functional.hardswish(x_q, scale=s_out, zero_point=zp_out)",
        "tvm": "input_scale_expr, input_zero_point_expr = get_qparam(x_q, 'scale'), get_qparam(x_q, 'zero_point')\nresult = tvm.relay.qnn.op.qnn.hardswish(x=x_q, scale=input_scale_expr, zero_point=input_zero_point_expr, output_scale=s_out, output_zero_point=zp_out)"
      }
    ],
    "constraints": "TVM's `qnn.hardswish` requires explicit input quantization parameters (`scale`, `zero_point` for the input `x`), which need to be extracted from the quantized PyTorch `input` tensor. PyTorch's `scale` and `zero_point` directly passed are for the *output* in TVM's convention.",
    "notes": "Direct mapping to TVM's quantized Hardswish operation, requiring explicit input quantization parameters.",
    "confidence": 0.9
  },
  {
    "torch_api": "torch.ao.quantization.quantize.quantize",
    "tvm_api": "tvm.relay.quantize.quantize.quantize",
    "mapping_type": "direct",
    "direction": "torch_to_tvm",
    "torch_pattern": "quantized_model = torch.ao.quantization.quantize.quantize(model={{model}}, run_fn={{run_fn}}, run_args={{run_args}})",
    "tvm_pattern": "relay_mod, params = tvm.relay.frontend.from_pytorch(torch_model_to_graph_module({{model}}), input_shapes, input_dtypes)\nquantized_mod = tvm.relay.quantize.quantize.quantize(mod=relay_mod, params=params, dataset=create_tvm_dataset({{run_args}}))",
    "arg_mapping": {
      "model": "mod",
      "run_args": "dataset"
    },
    "example_pairs": [
      {
        "torch": "quant_model = torch.ao.quantization.quantize.quantize(float_model, calibrate_model, calibration_data)",
        "tvm": "relay_mod, params = tvm.relay.frontend.from_pytorch(float_model_to_graph_module(float_model), input_shapes, input_dtypes)\nquant_mod = tvm.relay.quantize.quantize.quantize(mod=relay_mod, params=params, dataset=tvm_calibration_dataset(calibration_data))"
      }
    ],
    "constraints": "Requires conversion of PyTorch model to TVM IRModule (`tvm.relay.frontend.from_pytorch`) and calibration data to TVM dataset format. PyTorch's `run_fn`, `mapping`, `inplace` are higher-level workflow elements not directly mapped to TVM's `quantize` function signature but are part of the overall model conversion process.",
    "notes": "High-level mapping for the entire post-training static quantization workflow. This is a conceptual mapping as it involves pre-processing (model to IRModule) and dataset creation.",
    "confidence": 0.7
  },
  {
    "torch_api": "torch.ao.quantization.quantize.convert",
    "tvm_api": null,
    "mapping_type": "no_mapping",
    "direction": "torch_to_tvm",
    "torch_pattern": null,
    "tvm_pattern": null,
    "arg_mapping": {},
    "example_pairs": [],
    "constraints": "Not convertible",
    "notes": "NO_MAPPING: The provided TVM `convert` candidates are specific to sparse matrix optimization (`bsr_conv2d`, `bsr_dense`) or graph simplification (`simplify_fc_transpose`), not for converting a calibrated model to a quantized one as `torch.ao.quantization.quantize.convert` does. This is a high-level quantization workflow step.",
    "confidence": 0.2
  },
  {
    "torch_api": "torch.ao.quantization.fx.convert.convert",
    "tvm_api": null,
    "mapping_type": "no_mapping",
    "direction": "torch_to_tvm",
    "torch_pattern": null,
    "tvm_pattern": null,
    "arg_mapping": {},
    "example_pairs": [],
    "constraints": "Not convertible",
    "notes": "NO_MAPPING: The provided TVM `convert` candidates are specific to sparse matrix optimization (`bsr_conv2d`, `bsr_dense`) or graph simplification (`simplify_fc_transpose`), not for converting an FX GraphModule to a quantized model as `torch.ao.quantization.fx.convert.convert` does. This is a high-level quantization workflow step.",
    "confidence": 0.2
  },
  {
    "torch_api": "torch.compiler.__init__.compile",
    "tvm_api": "tvm.relay.backend.vm.compile",
    "mapping_type": "composite",
    "direction": "torch_to_tvm",
    "torch_pattern": "compiled_func = torch.compile({{func}})",
    "tvm_pattern": "relay_mod, params = tvm.relay.frontend.from_pytorch({{func_to_graph_module_representation}}(), input_shapes, input_dtypes)\ncompiled_executor = tvm.relay.backend.vm.compile(mod=relay_mod, target={{target}}, params=params)",
    "arg_mapping": {
      "func": "func_to_graph_module_representation"
    },
    "example_pairs": [
      {
        "torch": "compiled_model = torch.compile(my_model)",
        "tvm": "relay_mod, params = tvm.relay.frontend.from_pytorch(my_model_as_graph_module(), input_shapes, input_dtypes)\nexecutor = tvm.relay.backend.vm.compile(mod=relay_mod, target='cuda', params=params)"
      }
    ],
    "constraints": "This is a conceptual mapping. `torch.compile` takes a Python callable/module. TVM's `compile` takes an `IRModule`. The PyTorch model must first be converted to a TVM Relay IRModule (e.g., via `tvm.relay.frontend.from_pytorch`), and execution parameters (like `target`) must be explicitly provided for TVM.",
    "notes": "High-level mapping between PyTorch's `compile` and TVM's `vm.compile`, representing the overall compilation process from a high-level model to an executable artifact.",
    "confidence": 0.7
  },
  {
    "torch_api": "torch.cuda.__init__.init",
    "tvm_api": null,
    "mapping_type": "no_mapping",
    "direction": "torch_to_tvm",
    "torch_pattern": null,
    "tvm_pattern": null,
    "arg_mapping": {},
    "example_pairs": [],
    "constraints": "Not convertible",
    "notes": "NO_MAPPING: The TVM `init` function from `tvm.script.ir_builder.tir.ir` is used for initializing an IR Block. It does not correspond to initializing the CUDA runtime state as `torch.cuda.init` does. TVM manages CUDA device contexts via `tvm.cuda()` or `tvm.device()` functions, not a separate `init` call.",
    "confidence": 0.2
  },
  {
    "torch_api": "torch.cuda._memory_viz.trace",
    "tvm_api": null,
    "mapping_type": "no_mapping",
    "direction": "torch_to_tvm",
    "torch_pattern": null,
    "tvm_pattern": null,
    "arg_mapping": {},
    "example_pairs": [],
    "constraints": "Not convertible",
    "notes": "NO_MAPPING: The TVM `trace` function from `tvm.tir.op` is a compiler intrinsic for tracing tensor *data* during program execution, typically for debugging. It is not designed for CUDA memory visualization or profiling, which is the purpose of `torch.cuda._memory_viz.trace`.",
    "confidence": 0.2
  },
  {
    "torch_api": "torch.cuda.nccl.broadcast",
    "tvm_api": null,
    "mapping_type": "no_mapping",
    "direction": "torch_to_tvm",
    "torch_pattern": null,
    "tvm_pattern": null,
    "arg_mapping": {},
    "example_pairs": [],
    "constraints": "Not convertible",
    "notes": "NO_MAPPING: The TVM `broadcast` intrinsic from `tvm.script.parser_v1.tir.intrin` is for scalar broadcasting to a vector (SIMD lanes) at the TIR level. It is not a distributed collective communication operation like NCCL broadcast in PyTorch, which operates across multiple devices/nodes. TVM's Relay typically handles distributed collectives via `relay.op.comm` but no matching function was provided for the name `broadcast`.",
    "confidence": 0.2
  },
  {
    "torch_api": "torch.cuda.nvtx.range",
    "tvm_api": null,
    "mapping_type": "no_mapping",
    "direction": "torch_to_tvm",
    "torch_pattern": null,
    "tvm_pattern": null,
    "arg_mapping": {},
    "example_pairs": [],
    "constraints": "Not convertible",
    "notes": "NO_MAPPING: The TVM `range` function from `tvm.script.parser_v1.tir.intrin` is used for defining iteration ranges within loop structures in TIR. It has no relation to NVTX profiling ranges as used in PyTorch for performance tracing.",
    "confidence": 0.2
  },
  {
    "torch_api": "torch.cuda.profiler.init",
    "tvm_api": null,
    "mapping_type": "no_mapping",
    "direction": "torch_to_tvm",
    "torch_pattern": null,
    "tvm_pattern": null,
    "arg_mapping": {},
    "example_pairs": [],
    "constraints": "Not convertible",
    "notes": "NO_MAPPING: The TVM `init` function from `tvm.script.ir_builder.tir.ir` is for initializing an IR Block. It does not correspond to initializing a CUDA profiler. TVM's profiling mechanisms are usually integrated via its runtime or specific backend configurations, not a direct Python `init` call.",
    "confidence": 0.2
  },
  {
    "torch_api": "torch.distributed._functional_collectives.broadcast",
    "tvm_api": null,
    "mapping_type": "no_mapping",
    "direction": "torch_to_tvm",
    "torch_pattern": null,
    "tvm_pattern": null,
    "arg_mapping": {},
    "example_pairs": [],
    "constraints": "Not convertible",
    "notes": "NO_MAPPING: The TVM `broadcast` intrinsic from `tvm.script.parser_v1.tir.intrin` is for scalar broadcasting to a vector (SIMD lanes) at the TIR level. It is not a distributed collective communication operation across multiple devices/nodes, which is the domain of `torch.distributed` functional collectives. TVM's Relay typically handles distributed collectives via `relay.op.comm` but no matching function was provided for the name `broadcast`.",
    "confidence": 0.2
  },
  {
    "torch_api": "torch.distributed.collective_utils.broadcast",
    "tvm_api": null,
    "mapping_type": "no_mapping",
    "direction": "torch_to_tvm",
    "torch_pattern": null,
    "tvm_pattern": null,
    "arg_mapping": {},
    "example_pairs": [],
    "constraints": "Not convertible",
    "notes": "NO_MAPPING: The TVM `broadcast` intrinsic from `tvm.script.parser_v1.tir.intrin` is for scalar broadcasting to a vector (SIMD lanes) at the TIR level. It is not a distributed collective communication utility like `torch.distributed.collective_utils.broadcast`, which handles data or function results across a process group. TVM's Relay typically handles distributed collectives via `relay.op.comm` but no matching function was provided for the name `broadcast`.",
    "confidence": 0.2
  },
  {
    "torch_api": "torch.distributed.distributed_c10d.get_rank",
    "tvm_api": null,
    "mapping_type": "no_mapping",
    "direction": "torch_to_tvm",
    "torch_pattern": null,
    "tvm_pattern": null,
    "arg_mapping": {},
    "example_pairs": [],
    "constraints": "Not convertible",
    "notes": "NO_MAPPING: PyTorch's get_rank is for distributed process rank. TVM's get_rank (autotvm.utils) is for ranking numerical values within an array, which is semantically different.",
    "confidence": 0.2
  },
  {
    "torch_api": "torch.distributed.distributed_c10d.broadcast",
    "tvm_api": null,
    "mapping_type": "no_mapping",
    "direction": "torch_to_tvm",
    "torch_pattern": null,
    "tvm_pattern": null,
    "arg_mapping": {},
    "example_pairs": [],
    "constraints": "Not convertible",
    "notes": "NO_MAPPING: PyTorch's broadcast is a distributed collective communication operation. TVM's broadcast (tir.intrin) is a low-level intrinsic for vectorizing a scalar value, which is semantically different.",
    "confidence": 0.2
  },
  {
    "torch_api": "torch.distributed.distributed_c10d.gather",
    "tvm_api": null,
    "mapping_type": "no_mapping",
    "direction": "torch_to_tvm",
    "torch_pattern": null,
    "tvm_pattern": null,
    "arg_mapping": {},
    "example_pairs": [],
    "constraints": "Not convertible",
    "notes": "NO_MAPPING: PyTorch's gather is a distributed collective communication operation. TVM's gather (relay.op.transform or topi.transform) is a tensor indexing/slicing operation, which is semantically different.",
    "confidence": 0.2
  },
  {
    "torch_api": "torch.distributed.distributed_c10d.scatter",
    "tvm_api": null,
    "mapping_type": "no_mapping",
    "direction": "torch_to_tvm",
    "torch_pattern": null,
    "tvm_pattern": null,
    "arg_mapping": {},
    "example_pairs": [],
    "constraints": "Not convertible",
    "notes": "NO_MAPPING: PyTorch's scatter is a distributed collective communication operation. TVM's scatter (relay.op.transform or topi.scatter) is a tensor update operation, which is semantically different.",
    "confidence": 0.2
  },
  {
    "torch_api": "torch.distributed.launch.parse_args",
    "tvm_api": null,
    "mapping_type": "no_mapping",
    "direction": "torch_to_tvm",
    "torch_pattern": null,
    "tvm_pattern": null,
    "arg_mapping": {},
    "example_pairs": [],
    "constraints": "Not convertible",
    "notes": "NO_MAPPING: Both PyTorch and TVM have `parse_args` functions, but they are highly specific to their respective command-line interfaces and not general-purpose computational APIs.",
    "confidence": 0.2
  },
  {
    "torch_api": "torch.distributed.launch.main",
    "tvm_api": null,
    "mapping_type": "no_mapping",
    "direction": "torch_to_tvm",
    "torch_pattern": null,
    "tvm_pattern": null,
    "arg_mapping": {},
    "example_pairs": [],
    "constraints": "Not convertible",
    "notes": "NO_MAPPING: Similar to parse_args, 'main' functions are entry points for specific CLI utilities and do not have a general computational mapping.",
    "confidence": 0.2
  },
  {
    "torch_api": "torch.distributed.run.parse_args",
    "tvm_api": null,
    "mapping_type": "no_mapping",
    "direction": "torch_to_tvm",
    "torch_pattern": null,
    "tvm_pattern": null,
    "arg_mapping": {},
    "example_pairs": [],
    "constraints": "Not convertible",
    "notes": "NO_MAPPING: Both PyTorch and TVM have `parse_args` functions, but they are highly specific to their respective command-line interfaces and not general-purpose computational APIs.",
    "confidence": 0.2
  },
  {
    "torch_api": "torch.distributed.run.main",
    "tvm_api": null,
    "mapping_type": "no_mapping",
    "direction": "torch_to_tvm",
    "torch_pattern": null,
    "tvm_pattern": null,
    "arg_mapping": {},
    "example_pairs": [],
    "constraints": "Not convertible",
    "notes": "NO_MAPPING: Similar to parse_args, 'main' functions are entry points for specific CLI utilities and do not have a general computational mapping.",
    "confidence": 0.2
  },
  {
    "torch_api": "torch.distributed._composable.checkpoint_activation.checkpoint",
    "tvm_api": "tvm.relay.op.annotation.annotation.checkpoint",
    "mapping_type": "direct",
    "direction": "torch_to_tvm",
    "torch_pattern": "checkpoint({{module}})",
    "tvm_pattern": "tvm.relay.op.annotation.annotation.checkpoint({{expression}})",
    "arg_mapping": {
      "module": "expression"
    },
    "example_pairs": [
      {
        "torch": "checkpoint(my_module)",
        "tvm": "tvm.relay.op.annotation.annotation.checkpoint(my_relay_expr)"
      }
    ],
    "constraints": "Conceptual mapping for memory optimization. Requires `module` to be converted to a Relay expression. The TVM API is an annotation for a graph pass, not a runtime function.",
    "notes": "Both functions serve the purpose of marking a point for checkpointing-based memory optimization in their respective graph/module representations.",
    "confidence": 0.8
  },
  {
    "torch_api": "torch.distributed._shard.sharded_tensor.__init__.empty",
    "tvm_api": null,
    "mapping_type": "no_mapping",
    "direction": "torch_to_tvm",
    "torch_pattern": null,
    "tvm_pattern": null,
    "arg_mapping": {},
    "example_pairs": [],
    "constraints": "Not convertible",
    "notes": "NO_MAPPING: PyTorch's empty for ShardedTensor creates a distributed tensor abstraction. TVM's empty (runtime.ndarray) creates a local NDArray. There is no direct TVM counterpart for the distributed tensor concept or sharding specification.",
    "confidence": 0.3
  },
  {
    "torch_api": "torch.distributed._shard.sharded_tensor.__init__.ones",
    "tvm_api": null,
    "mapping_type": "no_mapping",
    "direction": "torch_to_tvm",
    "torch_pattern": null,
    "tvm_pattern": null,
    "arg_mapping": {},
    "example_pairs": [],
    "constraints": "Not convertible",
    "notes": "NO_MAPPING: PyTorch's ones for ShardedTensor creates a distributed tensor abstraction. TVM's ones (relay.op.tensor) creates a local tensor expression. There is no direct TVM counterpart for the distributed tensor concept or sharding specification.",
    "confidence": 0.3
  },
  {
    "torch_api": "torch.distributed._shard.sharded_tensor.__init__.zeros",
    "tvm_api": null,
    "mapping_type": "no_mapping",
    "direction": "torch_to_tvm",
    "torch_pattern": null,
    "tvm_pattern": null,
    "arg_mapping": {},
    "example_pairs": [],
    "constraints": "Not convertible",
    "notes": "NO_MAPPING: PyTorch's zeros for ShardedTensor creates a distributed tensor abstraction. TVM's zeros (relay.op.tensor) creates a local tensor expression. There is no direct TVM counterpart for the distributed tensor concept or sharding specification.",
    "confidence": 0.3
  },
  {
    "torch_api": "torch.distributed._shard.sharded_tensor.__init__.full",
    "tvm_api": null,
    "mapping_type": "no_mapping",
    "direction": "torch_to_tvm",
    "torch_pattern": null,
    "tvm_pattern": null,
    "arg_mapping": {},
    "example_pairs": [],
    "constraints": "Not convertible",
    "notes": "NO_MAPPING: PyTorch's full for ShardedTensor creates a distributed tensor abstraction. TVM's full (relay.op.transform or topi.tensor) creates a local tensor expression. There is no direct TVM counterpart for the distributed tensor concept or sharding specification.",
    "confidence": 0.3
  },
  {
    "torch_api": "torch.distributed._shard.sharded_tensor.__init__.rand",
    "tvm_api": null,
    "mapping_type": "no_mapping",
    "direction": "torch_to_tvm",
    "torch_pattern": null,
    "tvm_pattern": null,
    "arg_mapping": {},
    "example_pairs": [],
    "constraints": "Not convertible",
    "notes": "NO_MAPPING: PyTorch's rand for ShardedTensor creates a distributed tensor abstraction. TVM's rand (relay.testing) creates a local NDArray with random data. There is no direct TVM counterpart for the distributed tensor concept or sharding specification.",
    "confidence": 0.3
  },
  {
    "torch_api": "torch.distributed._shard.sharded_tensor._ops.binary_cmp.equal",
    "tvm_api": null,
    "mapping_type": "no_mapping",
    "direction": "torch_to_tvm",
    "torch_pattern": null,
    "tvm_pattern": null,
    "arg_mapping": {},
    "example_pairs": [],
    "constraints": "Not convertible",
    "notes": "NO_MAPPING: PyTorch's equal for ShardedTensor implies distributed comparison. TVM's equal (relay.op.tensor or topi.broadcast) is an element-wise comparison for local tensors. The distributed aspect is not directly handled by these TVM APIs.",
    "confidence": 0.3
  },
  {
    "torch_api": "torch.distributed._symmetric_memory.__init__.empty",
    "tvm_api": null,
    "mapping_type": "no_mapping",
    "direction": "torch_to_tvm",
    "torch_pattern": null,
    "tvm_pattern": null,
    "arg_mapping": {},
    "example_pairs": [],
    "constraints": "Not convertible",
    "notes": "NO_MAPPING: PyTorch's empty for symmetric memory creates a specific distributed/shared memory tensor. TVM's empty (runtime.ndarray) creates a local NDArray. There is no direct TVM counterpart for this specialized memory management.",
    "confidence": 0.3
  },
  {
    "torch_api": "torch.distributed._symmetric_memory.__init__.empty",
    "tvm_api": null,
    "mapping_type": "no_mapping",
    "direction": "torch_to_tvm",
    "torch_pattern": null,
    "tvm_pattern": null,
    "arg_mapping": {},
    "example_pairs": [],
    "constraints": "Not convertible",
    "notes": "NO_MAPPING: PyTorch's empty for symmetric memory creates a specific distributed/shared memory tensor. TVM's empty (runtime.ndarray) creates a local NDArray. There is no direct TVM counterpart for this specialized memory management.",
    "confidence": 0.3
  },
  {
    "torch_api": "torch.distributed._symmetric_memory.__init__.empty",
    "tvm_api": null,
    "mapping_type": "no_mapping",
    "direction": "torch_to_tvm",
    "torch_pattern": null,
    "tvm_pattern": null,
    "arg_mapping": {},
    "example_pairs": [],
    "constraints": "Not convertible",
    "notes": "NO_MAPPING: PyTorch's empty for symmetric memory creates a specific distributed/shared memory tensor. TVM's empty (runtime.ndarray) creates a local NDArray. There is no direct TVM counterpart for this specialized memory management.",
    "confidence": 0.3
  },
  {
    "torch_api": "torch.distributed.checkpoint.state_dict_loader.load",
    "tvm_api": null,
    "mapping_type": "no_mapping",
    "direction": "torch_to_tvm",
    "torch_pattern": null,
    "tvm_pattern": null,
    "arg_mapping": {},
    "example_pairs": [],
    "constraints": "Not convertible",
    "notes": "NO_MAPPING: PyTorch's load is for high-level checkpoint serialization/deserialization. TVM's load (tir.intrin) is a low-level intrinsic for reading from memory, which is semantically different.",
    "confidence": 0.2
  },
  {
    "torch_api": "torch.distributed.elastic.utils.logging.get_logger",
    "tvm_api": null,
    "mapping_type": "no_mapping",
    "direction": "torch_to_tvm",
    "torch_pattern": null,
    "tvm_pattern": null,
    "arg_mapping": {},
    "example_pairs": [],
    "constraints": "Not convertible",
    "notes": "NO_MAPPING: Both functions return a Python logging.Logger, but PyTorch's version is specialized for its distributed elastic context with environment variable configuration, which is not directly mapped to TVM's context-specific logger.",
    "confidence": 0.4
  },
  {
    "torch_api": "torch.distributed.nn.functional.broadcast",
    "tvm_api": null,
    "mapping_type": "no_mapping",
    "direction": "torch_to_tvm",
    "torch_pattern": null,
    "tvm_pattern": null,
    "arg_mapping": {},
    "example_pairs": [],
    "constraints": "Not convertible",
    "notes": "NO_MAPPING: PyTorch's broadcast is a distributed collective communication operation. TVM's broadcast (tir.intrin) is a low-level intrinsic for vectorizing a scalar value, which is semantically different.",
    "confidence": 0.2
  },
  {
    "torch_api": "torch.distributed.nn.functional.gather",
    "tvm_api": null,
    "mapping_type": "no_mapping",
    "direction": "torch_to_tvm",
    "torch_pattern": null,
    "tvm_pattern": null,
    "arg_mapping": {},
    "example_pairs": [],
    "constraints": "Not convertible",
    "notes": "NO_MAPPING: PyTorch's gather is a distributed collective communication operation. TVM's gather (relay.op.transform or topi.transform) is a tensor indexing/slicing operation, which is semantically different.",
    "confidence": 0.2
  },
  {
    "torch_api": "torch.distributed.nn.functional.scatter",
    "tvm_api": null,
    "mapping_type": "no_mapping",
    "direction": "torch_to_tvm",
    "torch_pattern": null,
    "tvm_pattern": null,
    "arg_mapping": {},
    "example_pairs": [],
    "constraints": "Not convertible",
    "notes": "NO_MAPPING: PyTorch's scatter is a distributed collective communication operation. TVM's scatter (relay.op.transform or topi.scatter) is a tensor update operation, which is semantically different.",
    "confidence": 0.2
  },
  {
    "torch_api": "torch.distributed.tensor._api.ones",
    "tvm_api": null,
    "mapping_type": "no_mapping",
    "direction": "torch_to_tvm",
    "torch_pattern": null,
    "tvm_pattern": null,
    "arg_mapping": {},
    "example_pairs": [],
    "constraints": "Not convertible",
    "notes": "NO_MAPPING: PyTorch's ones for DTensor creates a distributed tensor abstraction. TVM's ones (relay.op.tensor) creates a local tensor expression. There is no direct TVM counterpart for the distributed tensor concept or device mesh/placements.",
    "confidence": 0.3
  },
  {
    "torch_api": "torch.distributed.tensor._api.empty",
    "tvm_api": null,
    "mapping_type": "no_mapping",
    "direction": "torch_to_tvm",
    "torch_pattern": null,
    "tvm_pattern": null,
    "arg_mapping": {},
    "example_pairs": [],
    "constraints": "Not convertible",
    "notes": "NO_MAPPING: PyTorch's empty for DTensor creates a distributed tensor abstraction. TVM's empty (runtime.ndarray) creates a local NDArray. There is no direct TVM counterpart for the distributed tensor concept or device mesh/placements.",
    "confidence": 0.3
  },
  {
    "torch_api": "torch.distributed.tensor._api.full",
    "tvm_api": null,
    "mapping_type": "no_mapping",
    "direction": "torch_to_tvm",
    "torch_pattern": null,
    "tvm_pattern": null,
    "arg_mapping": {},
    "example_pairs": [],
    "constraints": "Not convertible",
    "notes": "NO_MAPPING: PyTorch's full for DTensor creates a distributed tensor abstraction. TVM's full (relay.op.transform or topi.tensor) creates a local tensor expression. There is no direct TVM counterpart for the distributed tensor concept or device mesh/placements.",
    "confidence": 0.3
  },
  {
    "torch_api": "torch.distributed.tensor._api.rand",
    "tvm_api": null,
    "mapping_type": "no_mapping",
    "direction": "torch_to_tvm",
    "torch_pattern": null,
    "tvm_pattern": null,
    "arg_mapping": {},
    "example_pairs": [],
    "constraints": "Not convertible",
    "notes": "NO_MAPPING: PyTorch's rand for DTensor creates a distributed tensor abstraction. TVM's rand (relay.testing) creates a local NDArray with random data. There is no direct TVM counterpart for the distributed tensor concept or device mesh/placements.",
    "confidence": 0.3
  },
  {
    "torch_api": "torch.distributed.tensor._api.zeros",
    "tvm_api": null,
    "mapping_type": "no_mapping",
    "direction": "torch_to_tvm",
    "torch_pattern": null,
    "tvm_pattern": null,
    "arg_mapping": {},
    "example_pairs": [],
    "constraints": "Not convertible",
    "notes": "NO_MAPPING: PyTorch's zeros for DTensor creates a distributed tensor abstraction. TVM's zeros (relay.op.tensor) creates a local tensor expression. There is no direct TVM counterpart for the distributed tensor concept or device mesh/placements.",
    "confidence": 0.3
  },
  {
    "torch_api": "torch.distributed.tensor._ops.utils.prod",
    "tvm_api": null,
    "mapping_type": "no_mapping",
    "direction": "torch_to_tvm",
    "torch_pattern": null,
    "tvm_pattern": null,
    "arg_mapping": {},
    "example_pairs": [],
    "constraints": "Not convertible",
    "notes": "NO_MAPPING: PyTorch's prod (utils) is a Python utility for multiplying integers. TVM's prod (relay.op.reduce, topi.reduction) are tensor reduction operations. TVM's topi.utils.prod takes a tuple and returns a TIR expression, not a Python int, making it unsuitable for a direct mapping.",
    "confidence": 0.2
  },
  {
    "torch_api": "torch.export.__init__.load",
    "tvm_api": null,
    "mapping_type": "no_mapping",
    "direction": "torch_to_tvm",
    "torch_pattern": null,
    "tvm_pattern": null,
    "arg_mapping": {},
    "example_pairs": [],
    "constraints": "Not convertible",
    "notes": "NO_MAPPING: PyTorch's load is for high-level ExportedProgram serialization/deserialization. TVM's load (tir.intrin) is a low-level intrinsic for reading from memory, which is semantically different.",
    "confidence": 0.2
  },
  {
    "torch_api": "torch.fx.annotate.annotate",
    "tvm_api": null,
    "mapping_type": "no_mapping",
    "direction": "torch_to_tvm",
    "torch_pattern": null,
    "tvm_pattern": null,
    "arg_mapping": {},
    "example_pairs": [],
    "constraints": "Not convertible",
    "notes": "NO_MAPPING: PyTorch's annotate is for providing type hints to the FX compiler. TVM's annotate (relay.quantize) is a graph pass for quantization annotation, which is semantically different.",
    "confidence": 0.2
  },
  {
    "torch_api": "torch.fx.experimental.shape_inference.infer_shape.infer_shape",
    "tvm_api": "tvm.relay.frontend.common.infer_shape",
    "mapping_type": "composite",
    "direction": "torch_to_tvm",
    "torch_pattern": "infer_shape({{gm}}, {{input_tensors}})",
    "tvm_pattern": "tvm.relay.frontend.common.infer_shape({{relay_expression}})",
    "arg_mapping": {
      "gm": "relay_expression",
      "input_tensors": "inferred_from_relay_expression_inputs"
    },
    "example_pairs": [],
    "constraints": "Requires conversion of Torch FX GraphModule (`gm`) to a TVM Relay expression (`relay_expression`). The `input_tensors` in PyTorch define the input shapes for inference; in TVM, these inputs are part of the Relay graph's structure.",
    "notes": "Both functions perform shape inference for computational graphs. However, the input graph formats (FX vs. Relay) are different, requiring graph conversion as a prerequisite.",
    "confidence": 0.7
  },
  {
    "torch_api": "torch.fx.experimental.unification.variable.var",
    "tvm_api": null,
    "mapping_type": "no_mapping",
    "direction": "torch_to_tvm",
    "torch_pattern": null,
    "tvm_pattern": null,
    "arg_mapping": {},
    "example_pairs": [],
    "constraints": "Not convertible",
    "notes": "NO_MAPPING: PyTorch's var (unification) creates symbolic variables for pattern matching. TVM's var (relay.expr, tir.ir, te.operation) creates symbolic variables for its IR, which are conceptually distinct in their usage and context.",
    "confidence": 0.2
  },
  {
    "torch_api": "torch.fx.experimental.unification.multipledispatch.core.dispatch",
    "tvm_api": null,
    "mapping_type": "no_mapping",
    "direction": "torch_to_tvm",
    "torch_pattern": null,
    "tvm_pattern": null,
    "arg_mapping": {},
    "example_pairs": [],
    "constraints": "Not convertible",
    "notes": "NO_MAPPING: PyTorch's dispatch (multipledispatch) is a Python language feature for function dispatch based on types. TVM's dispatch (topi.testing.common) is for selecting schedules based on TVM targets, which is semantically different.",
    "confidence": 0.2
  },
  {
    "torch_api": "torch.jit.__init__.annotate",
    "tvm_api": null,
    "mapping_type": "no_mapping",
    "direction": "torch_to_tvm",
    "torch_pattern": null,
    "tvm_pattern": null,
    "arg_mapping": {},
    "example_pairs": [],
    "constraints": "Not convertible",
    "notes": "NO_MAPPING: PyTorch's annotate is for providing type hints to the JIT compiler. TVM's annotate (relay.quantize) is a graph pass for quantization annotation, which is semantically different.",
    "confidence": 0.2
  },
  {
    "torch_api": "torch.jit._decompositions.var",
    "tvm_api": null,
    "mapping_type": "no_mapping",
    "direction": "torch_to_tvm",
    "torch_pattern": null,
    "tvm_pattern": null,
    "arg_mapping": {},
    "example_pairs": [],
    "constraints": "Not convertible",
    "notes": "NO_MAPPING: PyTorch's var (decompositions) computes statistical variance. TVM's var (relay.expr, tir.ir, te.operation) are for creating symbolic variables, which is semantically different.",
    "confidence": 0.2
  },
  {
    "torch_api": "torch.jit._monkeytype_config.get_type",
    "tvm_api": null,
    "mapping_type": "no_mapping",
    "direction": "torch_to_tvm",
    "torch_pattern": null,
    "tvm_pattern": null,
    "arg_mapping": {},
    "example_pairs": [],
    "constraints": "Not convertible",
    "notes": "NO_MAPPING: PyTorch's get_type (monkeytype_config) converts Python types to TorchScript string format. TVM's get_type functions are for ONNX type conversion or internal Relay type retrieval, which are semantically different contexts.",
    "confidence": 0.2
  },
  {
    "torch_api": "torch.jit._script.script",
    "tvm_api": null,
    "mapping_type": "no_mapping",
    "direction": "torch_to_tvm",
    "torch_pattern": null,
    "tvm_pattern": null,
    "arg_mapping": {},
    "example_pairs": [],
    "constraints": "Not convertible",
    "notes": "NO_MAPPING: PyTorch's script compiles Python code to TorchScript. TVM's script (printer.entry) prints TVM IR as TVMScript, and tvm.te.hybrid.script compiles Python to TVM Hybrid Script, a different IR. There is no direct mapping for compiling to TorchScript within TVM.",
    "confidence": 0.2
  },
  {
    "torch_api": "torch.jit._script.pad",
    "tvm_api": null,
    "mapping_type": "no_mapping",
    "direction": "torch_to_tvm",
    "torch_pattern": null,
    "tvm_pattern": null,
    "arg_mapping": {},
    "example_pairs": [],
    "constraints": "Not convertible",
    "notes": "NO_MAPPING: PyTorch's pad (jit._script) is a utility for string padding. TVM's pad (relay.op.nn.nn, topi.nn) are tensor padding operations, which is semantically different.",
    "confidence": 0.2
  },
  {
    "torch_api": "torch.jit._serialization.load",
    "tvm_api": null,
    "mapping_type": "no_mapping",
    "direction": "torch_to_tvm",
    "torch_pattern": null,
    "tvm_pattern": null,
    "arg_mapping": {},
    "example_pairs": [],
    "constraints": "Not convertible",
    "notes": "NO_MAPPING: PyTorch's load is for high-level ScriptModule/ScriptFunction serialization/deserialization. TVM's load (tir.intrin) is a low-level intrinsic for reading from memory, which is semantically different.",
    "confidence": 0.2
  },
  {
    "torch_api": "torch.jit._shape_functions.broadcast",
    "tvm_api": null,
    "mapping_type": "no_mapping",
    "direction": "torch_to_tvm",
    "torch_pattern": null,
    "tvm_pattern": null,
    "arg_mapping": {},
    "example_pairs": [],
    "constraints": "Not convertible",
    "notes": "NO_MAPPING: PyTorch's broadcast (shape_functions) calculates an output shape from input shapes. TVM's broadcast (tir.intrin) is a low-level intrinsic for vectorizing a scalar. There is no direct TVM API that takes lists of ints (shapes) and returns an output shape list in the same manner.",
    "confidence": 0.2
  },
  {
    "torch_api": "torch.jit._shape_functions.adaptive_avg_pool2d",
    "tvm_api": null,
    "mapping_type": "no_mapping",
    "direction": "torch_to_tvm",
    "torch_pattern": null,
    "tvm_pattern": null,
    "arg_mapping": {},
    "example_pairs": [],
    "constraints": "Not convertible",
    "notes": "NO_MAPPING: PyTorch's adaptive_avg_pool2d (shape_functions) calculates an output shape. TVM's adaptive_avg_pool2d (relay.op.nn.nn) performs the actual pooling computation on tensor data. There is no direct TVM API that solely infers shape from input shapes as lists of ints.",
    "confidence": 0.2
  },
  {
    "torch_api": "torch.jit._shape_functions.max_pool2d",
    "tvm_api": null,
    "mapping_type": "no_mapping",
    "direction": "torch_to_tvm",
    "torch_pattern": null,
    "tvm_pattern": null,
    "arg_mapping": {},
    "example_pairs": [],
    "constraints": "Not convertible",
    "notes": "NO_MAPPING: PyTorch's max_pool2d (shape_functions) calculates an output shape. TVM's max_pool2d (relay.op.nn.nn) performs the actual pooling computation on tensor data. There is no direct TVM API that solely infers shape from input shapes as lists of ints.",
    "confidence": 0.2
  },
  {
    "torch_api": "torch.jit._shape_functions.squeeze",
    "tvm_api": null,
    "mapping_type": "no_mapping",
    "direction": "torch_to_tvm",
    "torch_pattern": null,
    "tvm_pattern": null,
    "arg_mapping": {},
    "example_pairs": [],
    "constraints": "Not convertible",
    "notes": "NO_MAPPING: PyTorch's squeeze (shape_functions) calculates an output shape. TVM's squeeze (relay.op.transform, topi.transform) performs the actual tensor reshaping. There is no direct TVM API that solely infers shape from input shapes as lists of ints.",
    "confidence": 0.2
  },
  {
    "torch_api": "torch.jit._shape_functions.stack",
    "tvm_api": null,
    "mapping_type": "no_mapping",
    "direction": "torch_to_tvm",
    "torch_pattern": null,
    "tvm_pattern": null,
    "arg_mapping": {},
    "example_pairs": [],
    "constraints": "Not convertible",
    "notes": "NO_MAPPING: PyTorch's stack (shape_functions) calculates an output shape. TVM's stack (relay.op.tensor, topi.transform) performs the actual tensor stacking. There is no direct TVM API that solely infers shape from input shapes as lists of ints.",
    "confidence": 0.2
  },
  {
    "torch_api": "torch.jit._shape_functions.matmul",
    "tvm_api": null,
    "mapping_type": "no_mapping",
    "direction": "torch_to_tvm",
    "torch_pattern": null,
    "tvm_pattern": null,
    "arg_mapping": {},
    "example_pairs": [],
    "constraints": "Not convertible",
    "notes": "NO_MAPPING: PyTorch's matmul (shape_functions) calculates an output shape. TVM's matmul (relay.op.nn.nn) performs the actual matrix multiplication on tensor data. There is no direct TVM API that solely infers shape from input shapes as lists of ints.",
    "confidence": 0.2
  },
  {
    "torch_api": "torch.jit._shape_functions.transpose",
    "tvm_api": null,
    "mapping_type": "no_mapping",
    "direction": "torch_to_tvm",
    "torch_pattern": null,
    "tvm_pattern": null,
    "arg_mapping": {},
    "example_pairs": [],
    "constraints": "Not convertible",
    "notes": "NO_MAPPING: PyTorch's transpose (shape_functions) calculates an output shape. TVM's transpose (relay.op.transform, topi.transform) performs the actual tensor transposition. There is no direct TVM API that solely infers shape from input shapes as lists of ints.",
    "confidence": 0.2
  },
  {
    "torch_api": "torch.jit._shape_functions.conv1d",
    "tvm_api": null,
    "mapping_type": "no_mapping",
    "direction": "torch_to_tvm",
    "torch_pattern": null,
    "tvm_pattern": null,
    "arg_mapping": {},
    "example_pairs": [],
    "constraints": "Not convertible",
    "notes": "NO_MAPPING: PyTorch's conv1d (shape_functions) calculates an output shape. TVM's conv1d (relay.op.nn.nn, topi.nn) performs the actual convolution. There is no direct TVM API that solely infers shape from input shapes as lists of ints.",
    "confidence": 0.2
  },
  {
    "torch_api": "torch.jit._shape_functions.conv2d",
    "tvm_api": null,
    "mapping_type": "no_mapping",
    "direction": "torch_to_tvm",
    "torch_pattern": null,
    "tvm_pattern": null,
    "arg_mapping": {},
    "example_pairs": [],
    "constraints": "Not convertible",
    "notes": "NO_MAPPING: PyTorch's conv2d (shape_functions) calculates an output shape. TVM's conv2d (relay.op.nn.nn) performs the actual convolution. There is no direct TVM API that solely infers shape from input shapes as lists of ints.",
    "confidence": 0.2
  },
  {
    "torch_api": "torch.jit._shape_functions.batch_norm",
    "tvm_api": null,
    "mapping_type": "no_mapping",
    "direction": "torch_to_tvm",
    "torch_pattern": null,
    "tvm_pattern": null,
    "arg_mapping": {},
    "example_pairs": [],
    "constraints": "Not convertible",
    "notes": "NO_MAPPING: PyTorch's batch_norm (shape_functions) calculates an output shape. TVM's batch_norm (relay.op.nn.nn) performs the actual batch normalization. There is no direct TVM API that solely infers shape from input shapes as lists of ints.",
    "confidence": 0.2
  },
  {
    "torch_api": "torch.jit._shape_functions.conv3d",
    "tvm_api": null,
    "mapping_type": "no_mapping",
    "direction": "torch_to_tvm",
    "torch_pattern": null,
    "tvm_pattern": null,
    "arg_mapping": {},
    "example_pairs": [],
    "constraints": "Not convertible",
    "notes": "NO_MAPPING: PyTorch's conv3d (shape_functions) calculates an output shape. TVM's conv3d (relay.op.nn.nn) performs the actual convolution. There is no direct TVM API that solely infers shape from input shapes as lists of ints.",
    "confidence": 0.2
  },
  {
    "torch_api": "torch.jit._shape_functions.flatten",
    "tvm_api": null,
    "mapping_type": "no_mapping",
    "direction": "torch_to_tvm",
    "torch_pattern": null,
    "tvm_pattern": null,
    "arg_mapping": {},
    "example_pairs": [],
    "constraints": "Not convertible",
    "notes": "NO_MAPPING: PyTorch's flatten (shape_functions) calculates an output shape. TVM's flatten (topi.nn) performs the actual tensor flattening. There is no direct TVM API that solely infers shape from input shapes as lists of ints.",
    "confidence": 0.2
  },
  {
    "torch_api": "torch.jit._shape_functions.argmax",
    "tvm_api": null,
    "mapping_type": "no_mapping",
    "direction": "torch_to_tvm",
    "torch_pattern": null,
    "tvm_pattern": null,
    "arg_mapping": {},
    "example_pairs": [],
    "constraints": "Not convertible",
    "notes": "NO_MAPPING: PyTorch's argmax (shape_functions) calculates an output shape. TVM's argmax (relay.op.reduce, topi.reduction) performs the actual argmax computation. There is no direct TVM API that solely infers shape from input shapes as lists of ints.",
    "confidence": 0.2
  },
  {
    "torch_api": "torch.jit._shape_functions.topk",
    "tvm_api": null,
    "mapping_type": "no_mapping",
    "direction": "torch_to_tvm",
    "torch_pattern": null,
    "tvm_pattern": null,
    "arg_mapping": {},
    "example_pairs": [],
    "constraints": "Not convertible",
    "notes": "NO_MAPPING: PyTorch's topk (shape_functions) calculates an output shape. TVM's topk (relay.op.algorithm, topi.sort) performs the actual topk computation. There is no direct TVM API that solely infers shape from input shapes as lists of ints.",
    "confidence": 0.2
  },
  {
    "torch_api": "torch.jit._trace.trace",
    "tvm_api": null,
    "mapping_type": "no_mapping",
    "direction": "torch_to_tvm",
    "torch_pattern": null,
    "tvm_pattern": null,
    "arg_mapping": {},
    "example_pairs": [],
    "constraints": "Not convertible",
    "notes": "NO_MAPPING: PyTorch's trace traces a function to generate a TorchScript graph (compiler feature). TVM's trace (tir.op) is for runtime data debugging/profiling. Semantically different.",
    "confidence": 0.2
  },
  {
    "torch_api": "torch.masked._ops.sum",
    "tvm_api": "tvm.relay.op.reduce.sum",
    "mapping_type": "composite",
    "direction": "torch_to_tvm",
    "torch_pattern": "torch.masked._ops.sum(input={{input_tensor}}, dim={{dim}}, keepdim={{keepdim}}, mask={{mask}})",
    "tvm_pattern": "tvm.relay.op.reduce.sum(tvm.relay.op.where({{mask}}, {{input_tensor}}, 0.0), axis={{dim}}, keepdims={{keepdim}})",
    "arg_mapping": {
      "input_tensor": "input_tensor",
      "dim": "dim",
      "keepdim": "keepdim",
      "mask": "mask"
    },
    "example_pairs": [
      {
        "torch": "result = torch.masked._ops.sum(input_tensor, dim=0, mask=mask_tensor)",
        "tvm": "result = tvm.relay.op.reduce.sum(tvm.relay.op.where(mask_tensor, input_tensor, 0.0), axis=0, keepdims=False)"
      }
    ],
    "constraints": "The `dtype` argument might require explicit casting in TVM. Masked elements are effectively replaced by 0 before summing.",
    "notes": "The PyTorch masked sum requires incorporating the mask into the input tensor before performing the reduction. TVM's `where` operator can achieve this.",
    "confidence": 0.85
  },
  {
    "torch_api": "torch.masked._ops.prod",
    "tvm_api": "tvm.relay.op.reduce.prod",
    "mapping_type": "composite",
    "direction": "torch_to_tvm",
    "torch_pattern": "torch.masked._ops.prod(input={{input_tensor}}, dim={{dim}}, keepdim={{keepdim}}, mask={{mask}})",
    "tvm_pattern": "tvm.relay.op.reduce.prod(tvm.relay.op.where({{mask}}, {{input_tensor}}, 1.0), axis={{dim}}, keepdims={{keepdim}})",
    "arg_mapping": {
      "input_tensor": "input_tensor",
      "dim": "dim",
      "keepdim": "keepdim",
      "mask": "mask"
    },
    "example_pairs": [
      {
        "torch": "result = torch.masked._ops.prod(input_tensor, dim=0, mask=mask_tensor)",
        "tvm": "result = tvm.relay.op.reduce.prod(tvm.relay.op.where(mask_tensor, input_tensor, 1.0), axis=0, keepdims=False)"
      }
    ],
    "constraints": "The `dtype` argument might require explicit casting in TVM. Masked elements are effectively replaced by 1 before taking the product.",
    "notes": "The PyTorch masked product requires incorporating the mask into the input tensor before performing the reduction. TVM's `where` operator can achieve this.",
    "confidence": 0.85
  },
  {
    "torch_api": "torch.masked._ops.cumsum",
    "tvm_api": "tvm.relay.op.transform.cumsum",
    "mapping_type": "composite",
    "direction": "torch_to_tvm",
    "torch_pattern": "torch.masked._ops.cumsum(input={{input_tensor}}, dim={{dim}}, dtype={{dtype}}, mask={{mask}})",
    "tvm_pattern": "tvm.relay.op.transform.cumsum(tvm.relay.op.where({{mask}}, {{input_tensor}}, 0.0), axis={{dim}}, dtype={{dtype}})",
    "arg_mapping": {
      "input_tensor": "input_tensor",
      "dim": "dim",
      "dtype": "dtype",
      "mask": "mask"
    },
    "example_pairs": [
      {
        "torch": "result = torch.masked._ops.cumsum(input_tensor, dim=0, mask=mask_tensor, dtype=torch.float32)",
        "tvm": "result = tvm.relay.op.transform.cumsum(tvm.relay.op.where(mask_tensor, input_tensor, 0.0), axis=0, dtype=\"float32\")"
      }
    ],
    "constraints": "Masked elements are effectively replaced by 0 before cumulative sum. TVM `cumsum` `exclusive` argument is not directly mapped from PyTorch `cumsum` (which is inclusive by default).",
    "notes": "The PyTorch masked cumulative sum requires incorporating the mask into the input tensor by setting masked values to zero before applying `cumsum`.",
    "confidence": 0.85
  },
  {
    "torch_api": "torch.masked._ops.cumprod",
    "tvm_api": "tvm.relay.op.transform.cumprod",
    "mapping_type": "composite",
    "direction": "torch_to_tvm",
    "torch_pattern": "torch.masked._ops.cumprod(input={{input_tensor}}, dim={{dim}}, dtype={{dtype}}, mask={{mask}})",
    "tvm_pattern": "tvm.relay.op.transform.cumprod(tvm.relay.op.where({{mask}}, {{input_tensor}}, 1.0), axis={{dim}}, dtype={{dtype}})",
    "arg_mapping": {
      "input_tensor": "input_tensor",
      "dim": "dim",
      "dtype": "dtype",
      "mask": "mask"
    },
    "example_pairs": [
      {
        "torch": "result = torch.masked._ops.cumprod(input_tensor, dim=0, mask=mask_tensor, dtype=torch.float32)",
        "tvm": "result = tvm.relay.op.transform.cumprod(tvm.relay.op.where(mask_tensor, input_tensor, 1.0), axis=0, dtype=\"float32\")"
      }
    ],
    "constraints": "Masked elements are effectively replaced by 1 before cumulative product. TVM `cumprod` `exclusive` argument is not directly mapped from PyTorch `cumprod` (which is inclusive by default).",
    "notes": "The PyTorch masked cumulative product requires incorporating the mask into the input tensor by setting masked values to one before applying `cumprod`.",
    "confidence": 0.85
  },
  {
    "torch_api": "torch.masked._ops.argmax",
    "tvm_api": "tvm.relay.op.reduce.argmax",
    "mapping_type": "composite",
    "direction": "torch_to_tvm",
    "torch_pattern": "torch.masked._ops.argmax(input={{input_tensor}}, dim={{dim}}, keepdim={{keepdim}}, mask={{mask}})",
    "tvm_pattern": "tvm.relay.op.reduce.argmax(tvm.relay.op.where({{mask}}, {{input_tensor}}, -float('inf')), axis={{dim}}, keepdims={{keepdim}})",
    "arg_mapping": {
      "input_tensor": "input_tensor",
      "dim": "dim",
      "keepdim": "keepdim",
      "mask": "mask"
    },
    "example_pairs": [
      {
        "torch": "result = torch.masked._ops.argmax(input_tensor, dim=0, mask=mask_tensor)",
        "tvm": "result = tvm.relay.op.reduce.argmax(tvm.relay.op.where(mask_tensor, input_tensor, -float('inf')), axis=0, keepdims=False)"
      }
    ],
    "constraints": "The `dtype` argument might require explicit casting in TVM. Masked elements are effectively replaced by negative infinity to ensure they are not chosen as maximum.",
    "notes": "The PyTorch masked argmax requires pre-processing the input tensor to set masked values to a very low value before finding the maximum index.",
    "confidence": 0.85
  },
  {
    "torch_api": "torch.masked._ops.argmin",
    "tvm_api": "tvm.relay.op.reduce.argmin",
    "mapping_type": "composite",
    "direction": "torch_to_tvm",
    "torch_pattern": "torch.masked._ops.argmin(input={{input_tensor}}, dim={{dim}}, keepdim={{keepdim}}, mask={{mask}})",
    "tvm_pattern": "tvm.relay.op.reduce.argmin(tvm.relay.op.where({{mask}}, {{input_tensor}}, float('inf')), axis={{dim}}, keepdims={{keepdim}})",
    "arg_mapping": {
      "input_tensor": "input_tensor",
      "dim": "dim",
      "keepdim": "keepdim",
      "mask": "mask"
    },
    "example_pairs": [
      {
        "torch": "result = torch.masked._ops.argmin(input_tensor, dim=0, mask=mask_tensor)",
        "tvm": "result = tvm.relay.op.reduce.argmin(tvm.relay.op.where(mask_tensor, input_tensor, float('inf')), axis=0, keepdims=False)"
      }
    ],
    "constraints": "The `dtype` argument might require explicit casting in TVM. Masked elements are effectively replaced by positive infinity to ensure they are not chosen as minimum.",
    "notes": "The PyTorch masked argmin requires pre-processing the input tensor to set masked values to a very high value before finding the minimum index.",
    "confidence": 0.85
  },
  {
    "torch_api": "torch.masked._ops.mean",
    "tvm_api": "tvm.relay.op.reduce.mean",
    "mapping_type": "composite",
    "direction": "torch_to_tvm",
    "torch_pattern": "torch.masked._ops.mean(input={{input_tensor}}, dim={{dim}}, keepdim={{keepdim}}, mask={{mask}})",
    "tvm_pattern": "result = tvm.relay.op.divide(tvm.relay.op.reduce.sum(tvm.relay.op.where({{mask}}, {{input_tensor}}, 0.0), axis={{dim}}, keepdims=True), tvm.relay.op.reduce.sum(tvm.relay.op.cast({{mask}}, \"float32\"), axis={{dim}}, keepdims=True))",
    "arg_mapping": {
      "input_tensor": "input_tensor",
      "dim": "dim",
      "keepdim": "keepdim",
      "mask": "mask"
    },
    "example_pairs": [
      {
        "torch": "result = torch.masked._ops.mean(input_tensor, dim=0, mask=mask_tensor)",
        "tvm": "masked_input = tvm.relay.op.where(mask_tensor, input_tensor, 0.0)\nmask_sum = tvm.relay.op.reduce.sum(masked_input, axis=0, keepdims=True)\nunmasked_count = tvm.relay.op.reduce.sum(tvm.relay.op.cast(mask_tensor, \"float32\"), axis=0, keepdims=True)\nresult = tvm.relay.op.divide(mask_sum, unmasked_count)"
      }
    ],
    "constraints": "Handling of `nan` for fully masked dimensions is complex and not fully captured in the single-line pattern. `dtype` might require explicit casting. Requires a sequence of TVM operations (masking, sum, count, divide).",
    "notes": "The PyTorch masked mean requires summing only unmasked elements and dividing by the count of unmasked elements. This is a multi-step composite operation in TVM.",
    "confidence": 0.7
  },
  {
    "torch_api": "torch.masked._ops.logsumexp",
    "tvm_api": "tvm.relay.op.reduce.logsumexp",
    "mapping_type": "composite",
    "direction": "torch_to_tvm",
    "torch_pattern": "torch.masked._ops.logsumexp(input={{input_tensor}}, dim={{dim}}, keepdim={{keepdim}}, mask={{mask}})",
    "tvm_pattern": "tvm.relay.op.reduce.logsumexp(tvm.relay.op.where({{mask}}, {{input_tensor}}, -float('inf')), axis={{dim}}, keepdims={{keepdim}})",
    "arg_mapping": {
      "input_tensor": "input_tensor",
      "dim": "dim",
      "keepdim": "keepdim",
      "mask": "mask"
    },
    "example_pairs": [
      {
        "torch": "result = torch.masked._ops.logsumexp(input_tensor, dim=0, mask=mask_tensor)",
        "tvm": "result = tvm.relay.op.reduce.logsumexp(tvm.relay.op.where(mask_tensor, input_tensor, -float('inf')), axis=0, keepdims=False)"
      }
    ],
    "constraints": "The `dtype` argument might require explicit casting in TVM. Masked elements are effectively replaced by negative infinity to prevent them from contributing to the logsumexp.",
    "notes": "The PyTorch masked logsumexp requires pre-processing the input tensor to set masked values to negative infinity before applying `logsumexp`.",
    "confidence": 0.85
  },
  {
    "torch_api": "torch.masked._ops.var",
    "tvm_api": null,
    "mapping_type": "no_mapping",
    "direction": "torch_to_tvm",
    "torch_pattern": null,
    "tvm_pattern": null,
    "arg_mapping": {},
    "example_pairs": [],
    "constraints": "Not convertible",
    "notes": "NO_MAPPING: PyTorch's var (masked._ops) computes statistical variance with masking and `nan` handling. TVM's `var` candidates are for creating symbolic variables. While TVM has reduction ops for variance (`_variance` used by `std`), implementing masked variance with `nan` behavior and `correction` is complex and not directly available through a single TVM operator or a simple composite pattern within the given snippets.",
    "confidence": 0.3
  },
  {
    "torch_api": "torch.masked._ops.std",
    "tvm_api": null,
    "mapping_type": "no_mapping",
    "direction": "torch_to_tvm",
    "torch_pattern": null,
    "tvm_pattern": null,
    "arg_mapping": {},
    "example_pairs": [],
    "constraints": "Not convertible",
    "notes": "NO_MAPPING: PyTorch's std (masked._ops) computes statistical standard deviation with masking and `nan` handling. TVM's `std` (relay.op.reduce) is a base reduction operator. Implementing masked standard deviation with `nan` behavior and `correction` is a multi-step composite operation (similar to mean, but with variance and sqrt) that is too complex for a concise direct or composite pattern definition given the provided snippets.",
    "confidence": 0.3
  },
  {
    "torch_api": "torch.masked._ops.softmax",
    "tvm_api": "tvm.relay.op.nn.nn.softmax",
    "mapping_type": "composite",
    "direction": "torch_to_tvm",
    "torch_pattern": "torch.masked._ops.softmax(input={{input_tensor}}, dim={{dim}}, mask={{mask}})",
    "tvm_pattern": "tvm.relay.op.nn.nn.softmax(tvm.relay.op.where({{mask}}, {{input_tensor}}, -float('inf')), axis={{dim}})",
    "arg_mapping": {
      "input_tensor": "input_tensor",
      "dim": "dim",
      "mask": "mask"
    },
    "example_pairs": [
      {
        "torch": "result = torch.masked._ops.softmax(input_tensor, dim=0, mask=mask_tensor)",
        "tvm": "result = tvm.relay.op.nn.nn.softmax(tvm.relay.op.where(mask_tensor, input_tensor, -float('inf')), axis=0)"
      }
    ],
    "constraints": "The `dtype` argument might require explicit casting in TVM. Masked elements are effectively replaced by negative infinity before softmax to yield zero probability.",
    "notes": "The PyTorch masked softmax requires pre-processing the input tensor to set masked values to negative infinity before applying `softmax`.",
    "confidence": 0.85
  },
  {
    "torch_api": "torch.masked._ops.log_softmax",
    "tvm_api": null,
    "mapping_type": "no_mapping",
    "direction": "torch_to_tvm",
    "torch_pattern": null,
    "tvm_pattern": null,
    "arg_mapping": {},
    "example_pairs": [],
    "constraints": "TVM's log_softmax does not directly support the 'mask' argument or the MaskedTensor abstraction from torch.masked tensors.",
    "notes": "NO_MAPPING: The `torch.masked` functionality, particularly the `mask` argument and internal logic (`_combine_input_and_mask`), is not directly portable to TVM's `log_softmax` which operates on standard dense tensors. The intrinsic masked semantics would be lost.",
    "confidence": 0.4
  },
  {
    "torch_api": "torch.masked.maskedtensor._ops_refs.ones_like",
    "tvm_api": null,
    "mapping_type": "no_mapping",
    "direction": "torch_to_tvm",
    "torch_pattern": null,
    "tvm_pattern": null,
    "arg_mapping": {},
    "example_pairs": [],
    "constraints": "Not convertible as TVM does not have a direct concept of MaskedTensor or a way to preserve/reapply masks after tensor operations.",
    "notes": "NO_MAPPING: This API operates on `MaskedTensor` and preserves its masking semantics, which TVM does not natively support for basic tensor creation operations.",
    "confidence": 0.4
  },
  {
    "torch_api": "torch.masked.maskedtensor._ops_refs.where",
    "tvm_api": "tvm.relay.op.transform.where",
    "mapping_type": "composite",
    "direction": "torch_to_tvm",
    "torch_pattern": "torch.masked.where(condition_tensor, masked_x, masked_y)",
    "tvm_pattern": "new_data = tvm.relay.op.transform.where(condition_tensor, masked_x_data, masked_y_data);\nnew_mask = tvm.relay.op.transform.where(condition_tensor, masked_x_mask, masked_y_mask)",
    "arg_mapping": {
      "condition": "condition",
      "mx.get_data()": "x_data",
      "my.get_data()": "y_data",
      "mx.get_mask()": "x_mask",
      "my.get_mask()": "y_mask"
    },
    "example_pairs": [
      {
        "torch": "result = torch.masked.where(cond, masked_x, masked_y)",
        "tvm": "data_result = tvm.relay.op.transform.where(cond, masked_x_data, masked_y_data);\nmask_result = tvm.relay.op.transform.where(cond, masked_x_mask, masked_y_mask);\n# Result would need custom handling for MaskedTensor reconstruction."
      }
    ],
    "constraints": "Requires splitting MaskedTensor into data and mask components, applying 'where' to both separately, and then recomposing (which TVM does not natively support with a MaskedTensor equivalent).",
    "notes": "This is a composite mapping where the `where` operation is applied to both the data and mask components of the `MaskedTensor` independently. The reconstruction of a TVM-side 'MaskedTensor' equivalent is not part of this mapping.",
    "confidence": 0.8
  },
  {
    "torch_api": "torch.mtia.__init__.init",
    "tvm_api": null,
    "mapping_type": "no_mapping",
    "direction": "torch_to_tvm",
    "torch_pattern": null,
    "tvm_pattern": null,
    "arg_mapping": {},
    "example_pairs": [],
    "constraints": "Not convertible",
    "notes": "NO_MAPPING: This is a device-specific initialization function for PyTorch's MTIA backend, which has no direct equivalent in TVM's operator set or graph representation.",
    "confidence": 0.2
  },
  {
    "torch_api": "torch.nested._internal.ops.broadcast_to",
    "tvm_api": null,
    "mapping_type": "no_mapping",
    "direction": "torch_to_tvm",
    "torch_pattern": null,
    "tvm_pattern": null,
    "arg_mapping": {},
    "example_pairs": [],
    "constraints": "Not convertible as TVM does not natively support the 'NestedTensor' abstraction or its specific broadcasting rules.",
    "notes": "NO_MAPPING: This API operates on `NestedTensor`, a PyTorch-specific data structure for irregular tensors, which has no direct equivalent or built-in handling in TVM.",
    "confidence": 0.3
  },
  {
    "torch_api": "torch.nn.functional.adaptive_avg_pool2d",
    "tvm_api": "tvm.relay.op.nn.nn.adaptive_avg_pool2d",
    "mapping_type": "direct",
    "direction": "torch_to_tvm",
    "torch_pattern": "torch.nn.functional.adaptive_avg_pool2d(input, output_size)",
    "tvm_pattern": "tvm.relay.op.nn.adaptive_avg_pool2d(data, output_size, layout=\"NCHW\")",
    "arg_mapping": {
      "input": "data",
      "output_size": "output_size"
    },
    "example_pairs": [
      {
        "torch": "output = torch.nn.functional.adaptive_avg_pool2d(input_tensor, (7, 7))",
        "tvm": "output = tvm.relay.op.nn.adaptive_avg_pool2d(input_tensor, (7, 7), layout=\"NCHW\")"
      }
    ],
    "constraints": "Assumes default NCHW layout for TVM. PyTorch's `_list_with_default` for `output_size` behavior can be matched by TVM's `output_size=None` default or explicit tuple.",
    "notes": "Direct mapping for the core adaptive average pooling functionality.",
    "confidence": 0.95
  },
  {
    "torch_api": "torch.nn.functional.adaptive_avg_pool3d",
    "tvm_api": "tvm.relay.op.nn.nn.adaptive_avg_pool3d",
    "mapping_type": "direct",
    "direction": "torch_to_tvm",
    "torch_pattern": "torch.nn.functional.adaptive_avg_pool3d(input, output_size)",
    "tvm_pattern": "tvm.relay.op.nn.adaptive_avg_pool3d(data, output_size, layout=\"NCDHW\")",
    "arg_mapping": {
      "input": "data",
      "output_size": "output_size"
    },
    "example_pairs": [
      {
        "torch": "output = torch.nn.functional.adaptive_avg_pool3d(input_tensor, (3, 3, 3))",
        "tvm": "output = tvm.relay.op.nn.adaptive_avg_pool3d(input_tensor, (3, 3, 3), layout=\"NCDHW\")"
      }
    ],
    "constraints": "Assumes default NCDHW layout for TVM. PyTorch's `_list_with_default` for `output_size` behavior can be matched by TVM's `output_size=None` default or explicit tuple.",
    "notes": "Direct mapping for the core adaptive average pooling functionality.",
    "confidence": 0.95
  },
  {
    "torch_api": "torch.nn.functional.dropout",
    "tvm_api": "tvm.relay.op.nn.nn.dropout",
    "mapping_type": "direct",
    "direction": "torch_to_tvm",
    "torch_pattern": "torch.nn.functional.dropout(input, p=rate_val, training=training_flag, inplace=inplace_flag)",
    "tvm_pattern": "tvm.relay.op.nn.dropout(data, rate=rate_val)",
    "arg_mapping": {
      "input": "data",
      "p": "rate"
    },
    "example_pairs": [
      {
        "torch": "output = torch.nn.functional.dropout(input_tensor, p=0.5, training=True)",
        "tvm": "output = tvm.relay.op.nn.dropout(input_tensor, rate=0.5)"
      }
    ],
    "constraints": "TVM's dropout only takes `data` and `rate`. The `training` and `inplace` arguments in PyTorch are usually handled by graph transformations or implicit behavior in TVM (e.g., dropout often optimized away for inference).",
    "notes": "Direct mapping of the input and dropout probability. `training` and `inplace` are not directly mapped as separate TVM operator arguments.",
    "confidence": 0.9
  },
  {
    "torch_api": "torch.nn.functional.relu",
    "tvm_api": "tvm.relay.op.nn.nn.relu",
    "mapping_type": "direct",
    "direction": "torch_to_tvm",
    "torch_pattern": "torch.nn.functional.relu(input, inplace=inplace_flag)",
    "tvm_pattern": "tvm.relay.op.nn.relu(data)",
    "arg_mapping": {
      "input": "data"
    },
    "example_pairs": [
      {
        "torch": "output = torch.nn.functional.relu(input_tensor)",
        "tvm": "output = tvm.relay.op.nn.relu(input_tensor)"
      }
    ],
    "constraints": "The `inplace` argument is not directly mapped as a TVM operator argument.",
    "notes": "Direct mapping for the ReLU activation function.",
    "confidence": 0.98
  },
  {
    "torch_api": "torch.nn.functional.leaky_relu",
    "tvm_api": "tvm.relay.op.nn.nn.leaky_relu",
    "mapping_type": "direct",
    "direction": "torch_to_tvm",
    "torch_pattern": "torch.nn.functional.leaky_relu(input, negative_slope=alpha_value, inplace=inplace_flag)",
    "tvm_pattern": "tvm.relay.op.nn.leaky_relu(data, alpha=alpha_value)",
    "arg_mapping": {
      "input": "data",
      "negative_slope": "alpha"
    },
    "example_pairs": [
      {
        "torch": "output = torch.nn.functional.leaky_relu(input_tensor, negative_slope=0.1)",
        "tvm": "output = tvm.relay.op.nn.leaky_relu(input_tensor, alpha=0.1)"
      }
    ],
    "constraints": "The `inplace` argument is not directly mapped as a TVM operator argument. This mapping is for the float32 version, not the quantized one.",
    "notes": "Direct mapping for the Leaky ReLU activation function.",
    "confidence": 0.95
  },
  {
    "torch_api": "torch.nn.functional.softmax",
    "tvm_api": "tvm.relay.op.nn.nn.softmax",
    "mapping_type": "direct",
    "direction": "torch_to_tvm",
    "torch_pattern": "torch.nn.functional.softmax(input, dim=axis_int, dtype=dtype)",
    "tvm_pattern": "tvm.relay.op.nn.softmax(data, axis=axis_int)",
    "arg_mapping": {
      "input": "data",
      "dim": "axis"
    },
    "example_pairs": [
      {
        "torch": "output = torch.nn.functional.softmax(input_tensor, dim=1)",
        "tvm": "output = tvm.relay.op.nn.softmax(input_tensor, axis=1)"
      }
    ],
    "constraints": "The `dtype` argument might require an explicit `relay.cast` operation if the output dtype differs from the input. `_stacklevel` is an internal PyTorch argument not applicable to TVM.",
    "notes": "Direct mapping for the Softmax activation function.",
    "confidence": 0.98
  },
  {
    "torch_api": "torch.nn.functional.log_softmax",
    "tvm_api": "tvm.relay.op.nn.nn.log_softmax",
    "mapping_type": "direct",
    "direction": "torch_to_tvm",
    "torch_pattern": "torch.nn.functional.log_softmax(input, dim=axis_int, dtype=dtype)",
    "tvm_pattern": "tvm.relay.op.nn.log_softmax(data, axis=axis_int)",
    "arg_mapping": {
      "input": "data",
      "dim": "axis"
    },
    "example_pairs": [
      {
        "torch": "output = torch.nn.functional.log_softmax(input_tensor, dim=1)",
        "tvm": "output = tvm.relay.op.nn.log_softmax(input_tensor, axis=1)"
      }
    ],
    "constraints": "The `dtype` argument might require an explicit `relay.cast` operation if the output dtype differs from the input. `_stacklevel` is an internal PyTorch argument not applicable to TVM.",
    "notes": "Direct mapping for the Log Softmax activation function.",
    "confidence": 0.98
  },
  {
    "torch_api": "torch.nn.functional.tanh",
    "tvm_api": "tvm.relay.op.tensor.tanh",
    "mapping_type": "direct",
    "direction": "torch_to_tvm",
    "torch_pattern": "torch.nn.functional.tanh(input)",
    "tvm_pattern": "tvm.relay.op.tensor.tanh(data)",
    "arg_mapping": {
      "input": "data"
    },
    "example_pairs": [
      {
        "torch": "output = torch.nn.functional.tanh(input_tensor)",
        "tvm": "output = tvm.relay.op.tensor.tanh(input_tensor)"
      }
    ],
    "constraints": "This mapping is for the float32 version, not the quantized one. The `tir.op.tanh` is for low-level TIR, not Relay graph representation.",
    "notes": "Direct mapping for the Tanh activation function.",
    "confidence": 0.98
  },
  {
    "torch_api": "torch.nn.functional.sigmoid",
    "tvm_api": "tvm.relay.op.tensor.sigmoid",
    "mapping_type": "direct",
    "direction": "torch_to_tvm",
    "torch_pattern": "torch.nn.functional.sigmoid(input)",
    "tvm_pattern": "tvm.relay.op.tensor.sigmoid(data)",
    "arg_mapping": {
      "input": "data"
    },
    "example_pairs": [
      {
        "torch": "output = torch.nn.functional.sigmoid(input_tensor)",
        "tvm": "output = tvm.relay.op.tensor.sigmoid(input_tensor)"
      }
    ],
    "constraints": "This mapping is for the float32 version, not the quantized one. `tvm.te.hybrid.runtime.sigmoid` is a Python implementation for hybrid TE, not a Relay op.",
    "notes": "Direct mapping for the Sigmoid activation function.",
    "confidence": 0.98
  },
  {
    "torch_api": "torch.nn.functional.hardswish",
    "tvm_api": null,
    "mapping_type": "no_mapping",
    "direction": "torch_to_tvm",
    "torch_pattern": null,
    "tvm_pattern": null,
    "arg_mapping": {},
    "example_pairs": [],
    "constraints": "Not convertible to a non-quantized TVM operator based on provided snippets.",
    "notes": "NO_MAPPING: The provided TVM candidates only include a quantized version (`tvm.relay.qnn.op.qnn.hardswish`). A direct mapping for the standard (float32) `hardswish` is not available in the snippets.",
    "confidence": 0.4
  },
  {
    "torch_api": "torch.nn.functional.batch_norm",
    "tvm_api": "tvm.relay.op.nn.nn.batch_norm",
    "mapping_type": "direct",
    "direction": "torch_to_tvm",
    "torch_pattern": "torch.nn.functional.batch_norm(input, running_mean, running_var, weight=weight_tensor, bias=bias_tensor, training=training_flag, momentum=momentum_val, eps=epsilon_val)",
    "tvm_pattern": "tvm.relay.op.nn.batch_norm(data, gamma, beta, moving_mean, moving_var, axis=1, epsilon=epsilon_val, center=True, scale=True)",
    "arg_mapping": {
      "input": "data",
      "weight": "gamma",
      "bias": "beta",
      "running_mean": "moving_mean",
      "running_var": "moving_var",
      "eps": "epsilon"
    },
    "example_pairs": [
      {
        "torch": "output = torch.nn.functional.batch_norm(input_tensor, mean_tensor, var_tensor, weight_tensor, bias_tensor, training=False, eps=1e-5)",
        "tvm": "output, _, _ = tvm.relay.op.nn.batch_norm(input_tensor, weight_tensor, bias_tensor, mean_tensor, var_tensor, axis=1, epsilon=1e-5, center=True, scale=True)"
      }
    ],
    "constraints": "TVM's `batch_norm` returns a tuple (output, updated_mean, updated_variance). PyTorch typically expects only the output. The `training` and `momentum` arguments in PyTorch are not directly exposed as operator arguments in TVM's inference-focused `batch_norm` op. Assumes default `axis=1`, `center=True`, `scale=True` for TVM. PyTorch's `weight` and `bias` map to TVM's `gamma` and `beta` respectively.",
    "notes": "Direct conceptual mapping, with parameter renaming and handling of TVM's different output signature for `batch_norm` (returning updated mean/var).",
    "confidence": 0.85
  },
  {
    "torch_api": "torch.nn.functional.instance_norm",
    "tvm_api": "tvm.relay.op.nn.nn.instance_norm",
    "mapping_type": "direct",
    "direction": "torch_to_tvm",
    "torch_pattern": "torch.nn.functional.instance_norm(input, running_mean=mean_tensor, running_var=var_tensor, weight=weight_tensor, bias=bias_tensor, use_input_stats=use_stats_flag, momentum=momentum_val, eps=epsilon_val)",
    "tvm_pattern": "tvm.relay.op.nn.instance_norm(data, gamma, beta, axis=1, epsilon=epsilon_val, center=True, scale=True)",
    "arg_mapping": {
      "input": "data",
      "weight": "gamma",
      "bias": "beta",
      "eps": "epsilon"
    },
    "example_pairs": [
      {
        "torch": "output = torch.nn.functional.instance_norm(input_tensor, None, None, weight_tensor, bias_tensor, eps=1e-5)",
        "tvm": "output, _, _ = tvm.relay.op.nn.instance_norm(input_tensor, weight_tensor, bias_tensor, axis=1, epsilon=1e-5, center=True, scale=True)"
      }
    ],
    "constraints": "TVM's `instance_norm` returns a tuple (output, mean, variance). PyTorch's `running_mean`, `running_var`, `use_input_stats`, `momentum` are not directly mapped as operator arguments in TVM's functional graph. Assumes default `axis=1`, `center=True`, `scale=True` for TVM. PyTorch's `weight` and `bias` map to TVM's `gamma` and `beta` respectively.",
    "notes": "Direct conceptual mapping, with parameter renaming. TVM's instance_norm returns computed mean/var, which may need to be discarded if only output is needed.",
    "confidence": 0.85
  },
  {
    "torch_api": "torch.nn.functional.layer_norm",
    "tvm_api": "tvm.relay.op.nn.nn.layer_norm",
    "mapping_type": "composite",
    "direction": "torch_to_tvm",
    "torch_pattern": "torch.nn.functional.layer_norm(input, normalized_shape, weight=weight_tensor, bias=bias_tensor, eps=epsilon_val)",
    "tvm_pattern": "calculated_axis = [-i - 1 for i in range(len(normalized_shape))]; output = tvm.relay.op.nn.layer_norm(data, gamma, beta, axis=calculated_axis, epsilon=epsilon_val, center=True, scale=True)",
    "arg_mapping": {
      "input": "data",
      "normalized_shape": "calculated_axis",
      "weight": "gamma",
      "bias": "beta",
      "eps": "epsilon"
    },
    "example_pairs": [
      {
        "torch": "output = torch.nn.functional.layer_norm(input_tensor, [10, 20], weight_tensor, bias_tensor, eps=1e-5)",
        "tvm": "# Assuming input_tensor.ndim = 4, normalized_shape = [10, 20] means axes [-2, -1]\noutput = tvm.relay.op.nn.layer_norm(input_tensor, weight_tensor, bias_tensor, axis=[-2, -1], epsilon=1e-5, center=True, scale=True)"
      }
    ],
    "constraints": "The `normalized_shape` argument in PyTorch needs to be converted into an `axis` argument (or list of axes) for TVM's `layer_norm` based on the input tensor's rank. This usually involves mapping the trailing dimensions of `normalized_shape` to corresponding axis indices. Assumes `center=True` and `scale=True` for TVM. TVM's `layer_norm` also returns updated mean and variance, which might need to be discarded.",
    "notes": "Composite mapping because `normalized_shape` requires transformation into an `axis` parameter based on input tensor rank. PyTorch `weight` and `bias` map to TVM `gamma` and `beta`.",
    "confidence": 0.8
  },
  {
    "torch_api": "torch.nn.functional.group_norm",
    "tvm_api": "tvm.relay.op.nn.nn.group_norm",
    "mapping_type": "direct",
    "direction": "torch_to_tvm",
    "torch_pattern": "torch.nn.functional.group_norm(input, num_groups, weight=weight_tensor, bias=bias_tensor, eps=epsilon_val)",
    "tvm_pattern": "tvm.relay.op.nn.group_norm(data, gamma, beta, num_groups, axis=1, epsilon=epsilon_val, center=True, scale=True)",
    "arg_mapping": {
      "input": "data",
      "num_groups": "num_groups",
      "weight": "gamma",
      "bias": "beta",
      "eps": "epsilon"
    },
    "example_pairs": [
      {
        "torch": "output = torch.nn.functional.group_norm(input_tensor, 2, weight_tensor, bias_tensor, eps=1e-5)",
        "tvm": "output = tvm.relay.op.nn.group_norm(input_tensor, weight_tensor, bias_tensor, 2, axis=1, epsilon=1e-5, center=True, scale=True)"
      }
    ],
    "constraints": "Assumes default `axis=1`, `center=True`, `scale=True` for TVM, aligning with typical NCHW group normalization. PyTorch `weight` and `bias` map to TVM `gamma` and `beta`.",
    "notes": "Direct mapping for group normalization.",
    "confidence": 0.95
  },
  {
    "torch_api": "torch.nn.functional.nll_loss",
    "tvm_api": "tvm.relay.op.nn.nn.nll_loss",
    "mapping_type": "direct",
    "direction": "torch_to_tvm",
    "torch_pattern": "torch.nn.functional.nll_loss(input, target, weight=weight_tensor, ignore_index=ignore_idx, reduction=reduction_str)",
    "tvm_pattern": "tvm.relay.op.nn.nll_loss(predictions, targets, weights, reduction=reduction_str, ignore_index=ignore_idx)",
    "arg_mapping": {
      "input": "predictions",
      "target": "targets",
      "weight": "weights",
      "reduction": "reduction",
      "ignore_index": "ignore_index"
    },
    "example_pairs": [
      {
        "torch": "output = torch.nn.functional.nll_loss(logits, labels, weight=class_weights, ignore_index=-1, reduction='mean')",
        "tvm": "output = tvm.relay.op.nn.nll_loss(logits, labels, class_weights, reduction='mean', ignore_index=-1)"
      }
    ],
    "constraints": "PyTorch's `size_average` and `reduce` arguments are deprecated and their functionality is covered by the `reduction` string in TVM.",
    "notes": "Direct mapping for Negative Log Likelihood Loss.",
    "confidence": 0.95
  },
  {
    "torch_api": "torch.nn.functional.cross_entropy",
    "tvm_api": [
      "tvm.relay.op.nn.nn.log_softmax",
      "tvm.relay.op.nn.nn.nll_loss"
    ],
    "mapping_type": "composite",
    "direction": "torch_to_tvm",
    "torch_pattern": "torch.nn.functional.cross_entropy(input, target, weight=weight_tensor, ignore_index=ignore_idx, reduction=reduction_str, label_smoothing=label_smoothing_val)",
    "tvm_pattern": "log_probs = tvm.relay.op.nn.log_softmax(input, axis=1); output = tvm.relay.op.nn.nll_loss(log_probs, target, weight_tensor, reduction=reduction_str, ignore_index=ignore_idx)",
    "arg_mapping": {
      "input": "input",
      "target": "target",
      "weight": "weight_tensor",
      "ignore_index": "ignore_idx",
      "reduction": "reduction_str"
    },
    "example_pairs": [
      {
        "torch": "output = torch.nn.functional.cross_entropy(logits, labels, weight=class_weights, ignore_index=-1, reduction='mean')",
        "tvm": "log_probs = tvm.relay.op.nn.log_softmax(logits, axis=1);\noutput = tvm.relay.op.nn.nll_loss(log_probs, labels, class_weights, reduction='mean', ignore_index=-1)"
      }
    ],
    "constraints": "PyTorch's `cross_entropy` operates on logits. TVM requires a `log_softmax` followed by `nll_loss` to support all arguments like `weight`, `ignore_index`, `reduction`. The `label_smoothing` argument is not supported by TVM's `nll_loss` and would require a more complex composite mapping or manual implementation.",
    "notes": "Composite mapping by transforming `cross_entropy(logits)` into `log_softmax(logits) -> nll_loss`. This allows mapping of `weight`, `reduction`, and `ignore_index`. `label_smoothing` is not directly supported by this composite.",
    "confidence": 0.8
  },
  {
    "torch_api": "torch.nn.functional.grid_sample",
    "tvm_api": "tvm.relay.op.image.image.grid_sample",
    "mapping_type": "direct",
    "direction": "torch_to_tvm",
    "torch_pattern": "torch.nn.functional.grid_sample(input, grid, mode=method_str, padding_mode=padding_mode_str, align_corners=align_corners_bool)",
    "tvm_pattern": "tvm.relay.op.image.grid_sample(data, grid, method=method_str, layout='NCHW', padding_mode=padding_mode_str, align_corners=align_corners_bool)",
    "arg_mapping": {
      "input": "data",
      "grid": "grid",
      "mode": "method",
      "padding_mode": "padding_mode",
      "align_corners": "align_corners"
    },
    "example_pairs": [
      {
        "torch": "output = torch.nn.functional.grid_sample(input_tensor, grid_tensor, mode='bilinear', padding_mode='zeros', align_corners=True)",
        "tvm": "output = tvm.relay.op.image.grid_sample(input_tensor, grid_tensor, method='bilinear', layout='NCHW', padding_mode='zeros', align_corners=True)"
      }
    ],
    "constraints": "Assumes default 'NCHW' layout for TVM. PyTorch's 'mode' maps to TVM's 'method'.",
    "notes": "Direct mapping for grid sampling operation.",
    "confidence": 0.95
  },
  {
    "torch_api": "torch.nn.functional.affine_grid",
    "tvm_api": "tvm.relay.op.image.image.affine_grid",
    "mapping_type": "composite",
    "direction": "torch_to_tvm",
    "torch_pattern": "torch.nn.functional.affine_grid(theta, size, align_corners=align_corners_bool)",
    "tvm_pattern": "target_h = size[2] if len(size) == 4 else size[3]; target_w = size[3] if len(size) == 4 else size[4]; output = tvm.relay.op.image.affine_grid(data, target_shape=(target_h, target_w))",
    "arg_mapping": {
      "theta": "data",
      "size": "target_shape"
    },
    "example_pairs": [
      {
        "torch": "output = torch.nn.functional.affine_grid(theta_matrix, (1, 3, 24, 24), align_corners=True)",
        "tvm": "# Assuming input is 4D, size (N, C, H, W)\noutput = tvm.relay.op.image.affine_grid(theta_matrix, target_shape=(24, 24))"
      }
    ],
    "constraints": "PyTorch `size` specifies the full output tensor shape (e.g., N, C, H, W for 2D, or N, C, D, H, W for 3D), while TVM `target_shape` only specifies the spatial dimensions (H, W). This requires extracting the spatial dimensions from `size`. TVM's `affine_grid` expects a 3-D input [batch, 2, 3] for 2D transformation. PyTorch `align_corners` is not an explicit argument in TVM.",
    "notes": "Composite mapping due to differences in how target shape is specified. The `align_corners` behavior needs to be assumed to match TVM's default.",
    "confidence": 0.75
  },
  {
    "torch_api": "torch.nn.functional.pad",
    "tvm_api": "tvm.relay.op.nn.nn.pad",
    "mapping_type": "composite",
    "direction": "torch_to_tvm",
    "torch_pattern": "torch.nn.functional.pad(input, pad_list, mode=mode_str, value=value_scalar)",
    "tvm_pattern": "tvm.relay.op.nn.pad(data, pad_width=converted_pad_width, pad_mode=converted_mode_str, pad_value=value_scalar)",
    "arg_mapping": {
      "input": "data",
      "pad": "pad_width",
      "mode": "pad_mode",
      "value": "pad_value"
    },
    "example_pairs": [
      {
        "torch": "output = torch.nn.functional.pad(input_tensor, (1, 1, 2, 2), mode='constant', value=0.0)",
        "tvm": "# Assuming input_tensor is 4D (N,C,H,W), pad (1,1,2,2) means padding 1 to W, 2 to H\nconverted_pad_width = ((0,0),(0,0),(2,2),(1,1))\noutput = tvm.relay.op.nn.pad(input_tensor, converted_pad_width, pad_mode='constant', pad_value=0.0)"
      },
      {
        "torch": "output = torch.nn.functional.pad(input_tensor, (1, 1), mode='replicate')",
        "tvm": "# Assuming input_tensor is 2D (H,W), pad (1,1) means padding 1 to W\nconverted_pad_width = ((0,0),(1,1))\noutput = tvm.relay.op.nn.pad(input_tensor, converted_pad_width, pad_mode='edge')"
      }
    ],
    "constraints": "The PyTorch `pad` argument (list of ints) requires conversion to TVM's `pad_width` format (tuple of tuples). The order of dimensions for padding is reversed from PyTorch's convention (`dim_n_begin, dim_n_end, ..., dim_1_begin, dim_1_end`). PyTorch `mode='replicate'` maps to TVM `pad_mode='edge'`. `mode='circular'` is not supported by TVM's `pad` op directly.",
    "notes": "Composite mapping due to the required conversion of padding arguments format and mapping of 'replicate' mode.",
    "confidence": 0.8
  },
  {
    "torch_api": "torch.nn.parallel.comm.broadcast",
    "tvm_api": null,
    "mapping_type": "no_mapping",
    "direction": "torch_to_tvm",
    "torch_pattern": null,
    "tvm_pattern": null,
    "arg_mapping": {},
    "example_pairs": [],
    "constraints": "Not convertible",
    "notes": "NO_MAPPING: This is a distributed communication primitive (NCCL broadcast) that operates at a higher level of abstraction than TVM's tensor expression or Relay graph. The TVM `broadcast` candidate is a TIR intrinsic for scalar broadcasting.",
    "confidence": 0.2
  },
  {
    "torch_api": "torch.nn.parallel.comm.scatter",
    "tvm_api": null,
    "mapping_type": "no_mapping",
    "direction": "torch_to_tvm",
    "torch_pattern": null,
    "tvm_pattern": null,
    "arg_mapping": {},
    "example_pairs": [],
    "constraints": "Not convertible",
    "notes": "NO_MAPPING: This is a distributed communication primitive (scattering data across devices). The TVM `scatter` operators (`relay.op.transform.scatter`, `topi.scatter`) perform tensor updates at specific indices, which is a different semantic operation.",
    "confidence": 0.2
  },
  {
    "torch_api": "torch.nn.parallel.comm.gather",
    "tvm_api": null,
    "mapping_type": "no_mapping",
    "direction": "torch_to_tvm",
    "torch_pattern": null,
    "tvm_pattern": null,
    "arg_mapping": {},
    "example_pairs": [],
    "constraints": "Not convertible",
    "notes": "NO_MAPPING: This is a distributed communication primitive (gathering data from multiple devices). The TVM `gather` operators (`relay.op.transform.gather`, `topi.transform.gather`) perform tensor element selection based on indices, which is a different semantic operation.",
    "confidence": 0.2
  },
  {
    "torch_api": "torch.nn.parallel.scatter_gather.scatter",
    "tvm_api": null,
    "mapping_type": "no_mapping",
    "direction": "torch_to_tvm",
    "torch_pattern": null,
    "tvm_pattern": null,
    "arg_mapping": {},
    "example_pairs": [],
    "constraints": "Not convertible",
    "notes": "NO_MAPPING: This is a distributed data distribution primitive for data parallelism (slicing and distributing tensors across GPUs). The TVM `scatter` operators perform index-based tensor updates, which is a different semantic operation.",
    "confidence": 0.2
  },
  {
    "torch_api": "torch.nn.parallel.scatter_gather.scatter",
    "tvm_api": null,
    "mapping_type": "no_mapping",
    "direction": "torch_to_tvm",
    "torch_pattern": null,
    "tvm_pattern": null,
    "arg_mapping": {},
    "example_pairs": [],
    "constraints": "Not convertible",
    "notes": "NO_MAPPING: This is a distributed data distribution primitive for data parallelism (slicing and distributing tensors across GPUs). The TVM `scatter` operators perform index-based tensor updates, which is a different semantic operation.",
    "confidence": 0.2
  },
  {
    "torch_api": "torch.nn.parallel.scatter_gather.scatter",
    "tvm_api": null,
    "mapping_type": "no_mapping",
    "direction": "torch_to_tvm",
    "torch_pattern": null,
    "tvm_pattern": null,
    "arg_mapping": {},
    "example_pairs": [],
    "constraints": "Not convertible",
    "notes": "NO_MAPPING: This is a distributed data distribution primitive for data parallelism (slicing and distributing tensors across GPUs). The TVM `scatter` operators perform index-based tensor updates, which is a different semantic operation.",
    "confidence": 0.2
  },
  {
    "torch_api": "torch.nn.parallel.scatter_gather.gather",
    "tvm_api": null,
    "mapping_type": "no_mapping",
    "direction": "torch_to_tvm",
    "torch_pattern": null,
    "tvm_pattern": null,
    "arg_mapping": {},
    "example_pairs": [],
    "constraints": "Not convertible",
    "notes": "NO_MAPPING: This is a distributed communication primitive (gathering tensors from multiple devices). The TVM `gather` operators perform tensor element selection based on indices, which is a different semantic operation.",
    "confidence": 0.2
  },
  {
    "torch_api": "torch.nn.utils.rnn.bind",
    "tvm_api": null,
    "mapping_type": "no_mapping",
    "direction": "torch_to_tvm",
    "torch_pattern": null,
    "tvm_pattern": null,
    "arg_mapping": {},
    "example_pairs": [],
    "constraints": "Not convertible",
    "notes": "NO_MAPPING: PyTorch's `bind` is a functional utility for `Optional` values. TVM's `bind` functions are for internal compiler/IR constructs (e.g., binding free variables in Relay or thread binding in TE/TIR) and do not correspond to this utility.",
    "confidence": 0.2
  },
  {
    "torch_api": "torch.onnx._internal.exporter._dispatching.dispatch",
    "tvm_api": null,
    "mapping_type": "no_mapping",
    "direction": "torch_to_tvm",
    "torch_pattern": null,
    "tvm_pattern": null,
    "arg_mapping": {},
    "example_pairs": [],
    "constraints": "Not convertible",
    "notes": "NO_MAPPING: This is an internal utility function for PyTorch's ONNX exporter to dispatch nodes to ONNX functions. TVM's `dispatch` candidate is an internal testing utility for scheduling, serving a completely different purpose.",
    "confidence": 0.2
  },
  {
    "torch_api": "torch.onnx._internal.torchscript_exporter.symbolic_helper.parse_args",
    "tvm_api": null,
    "mapping_type": "no_mapping",
    "direction": "torch_to_tvm",
    "torch_pattern": null,
    "tvm_pattern": null,
    "arg_mapping": {},
    "example_pairs": [],
    "constraints": "Not convertible",
    "notes": "NO_MAPPING: PyTorch's `parse_args` is an internal decorator for its ONNX symbolic exporter, used for type conversion. The TVM candidates are command-line argument parsing utilities, serving a completely different purpose.",
    "confidence": 0.2
  },
  {
    "torch_api": "torch.onnx._internal.torchscript_exporter.symbolic_opset10.div",
    "tvm_api": null,
    "mapping_type": "no_mapping",
    "direction": "torch_to_tvm",
    "torch_pattern": null,
    "tvm_pattern": null,
    "arg_mapping": {},
    "example_pairs": [],
    "constraints": "Not convertible as TVM's `tir.op.div` is for C/C++ style integer division (truncates towards zero), which does not match PyTorch's floating-point division or common integer division rounding modes.",
    "notes": "NO_MAPPING: PyTorch's `div` in the ONNX context usually implies true division (floating point) or flexible integer division with various rounding modes. The provided TVM `div` is a low-level TIR integer division with truncation.",
    "confidence": 0.3
  },
  {
    "torch_api": "torch.onnx._internal.torchscript_exporter.symbolic_opset10.sort",
    "tvm_api": "tvm.relay.op.algorithm.sort",
    "mapping_type": "direct",
    "direction": "torch_to_tvm",
    "torch_pattern": "values, indices = torch.sort(self, dim=axis_int, descending=descending_bool)",
    "tvm_pattern": "values = tvm.relay.op.algorithm.sort(data, axis=axis_int, is_ascend=int(not descending_bool))",
    "arg_mapping": {
      "self": "data",
      "dim": "axis",
      "descending": "is_ascend"
    },
    "example_pairs": [
      {
        "torch": "values, indices = torch.sort(input_tensor, dim=1, descending=True)",
        "tvm": "values = tvm.relay.op.algorithm.sort(input_tensor, axis=1, is_ascend=0)"
      }
    ],
    "constraints": "TVM's `sort` returns only the sorted values, not both values and indices as PyTorch's `sort` does by default. PyTorch `descending` boolean needs conversion to TVM `is_ascend` integer (True=0, False=1).",
    "notes": "Direct mapping for sorting values. TVM's `sort` currently only returns the sorted values, which is a limitation if indices are also required.",
    "confidence": 0.8
  },
  {
    "torch_api": "torch.onnx._internal.torchscript_exporter.symbolic_opset10.topk",
    "tvm_api": "tvm.relay.op.algorithm.topk",
    "mapping_type": "direct",
    "direction": "torch_to_tvm",
    "torch_pattern": "values, indices = torch.topk(self, k, dim=axis_int, largest=largest_bool, sorted=sorted_bool)",
    "tvm_pattern": "values_and_indices = tvm.relay.op.algorithm.topk(data, k=k_val, axis=axis_int, ret_type='both', is_ascend=not largest_bool)",
    "arg_mapping": {
      "self": "data",
      "k": "k",
      "dim": "axis",
      "largest": "is_ascend"
    },
    "example_pairs": [
      {
        "torch": "values, indices = torch.topk(input_tensor, 3, dim=1, largest=True, sorted=True)",
        "tvm": "values_and_indices = tvm.relay.op.algorithm.topk(input_tensor, k=3, axis=1, ret_type='both', is_ascend=False)"
      }
    ],
    "constraints": "PyTorch `largest` boolean needs conversion to TVM `is_ascend` boolean (`largest=True` implies `is_ascend=False` for descending order). TVM's `ret_type` needs to be set to 'both' to match PyTorch's default return of values and indices. The `sorted` argument in PyTorch determines if the returned elements are sorted (TVM's `topk` generally produces sorted results by default).",
    "notes": "Direct mapping for topk, with `largest` to `is_ascend` conversion and `ret_type` handling for values and indices.",
    "confidence": 0.9
  },
  {
    "torch_api": "torch.onnx._internal.torchscript_exporter.symbolic_opset10.flip",
    "tvm_api": "tvm.topi.transform.flip",
    "mapping_type": "composite",
    "direction": "torch_to_tvm",
    "torch_pattern": "output = torch.flip(input, dims=dims_list)",
    "tvm_pattern": "result = input; for d in dims_list: result = tvm.topi.transform.flip(result, axis=d)",
    "arg_mapping": {
      "input": "a",
      "dims": "axis"
    },
    "example_pairs": [
      {
        "torch": "output = torch.flip(input_tensor, dims=[0, 2])",
        "tvm": "temp = tvm.topi.transform.flip(input_tensor, axis=0);\noutput = tvm.topi.transform.flip(temp, axis=2)"
      }
    ],
    "constraints": "TVM's `flip` (`topi.transform.flip`) takes a single `axis`. If PyTorch `dims` specifies multiple axes, a composite mapping involving iterating through multiple `tvm.topi.transform.flip` calls is required.",
    "notes": "Composite mapping to handle multiple flip axes as separate operations, as TVM's `flip` supports a single axis.",
    "confidence": 0.8
  },
  {
    "torch_api": "torch.onnx._internal.torchscript_exporter.symbolic_opset10.fmod",
    "tvm_api": "tvm.tir.op.fmod",
    "mapping_type": "direct",
    "direction": "torch_to_tvm",
    "torch_pattern": "torch.fmod(input, other)",
    "tvm_pattern": "tvm.tir.op.fmod(x, y)",
    "arg_mapping": {
      "input": "x",
      "other": "y"
    },
    "example_pairs": [
      {
        "torch": "output = torch.fmod(input_tensor, other_tensor)",
        "tvm": "output = tvm.tir.op.fmod(input_tensor, other_tensor)"
      }
    ],
    "constraints": "Mapping is to `tir.op.fmod`, which is a low-level TIR intrinsic for floating-point remainder with same sign as dividend. For Relay graphs, a Relay-level `fmod` operation would be preferable if available and performing the same operation.",
    "notes": "Direct mapping to the TIR `fmod` intrinsic, which provides the specified floating-point remainder behavior.",
    "confidence": 0.85
  },
  {
    "torch_api": "torch.onnx._internal.torchscript_exporter.symbolic_opset10.isinf",
    "tvm_api": "tvm.relay.op.tensor.isinf",
    "mapping_type": "direct",
    "direction": "torch_to_tvm",
    "torch_pattern": "torch.isinf(input)",
    "tvm_pattern": "tvm.relay.op.tensor.isinf(data)",
    "arg_mapping": {
      "input": "data"
    },
    "example_pairs": [
      {
        "torch": "output = torch.isinf(input_tensor)",
        "tvm": "output = tvm.relay.op.tensor.isinf(input_tensor)"
      }
    ],
    "constraints": "None.",
    "notes": "Direct mapping for element-wise infinity check.",
    "confidence": 0.98
  },
  {
    "torch_api": "torch.onnx._internal.torchscript_exporter.symbolic_opset10.isfinite",
    "tvm_api": "tvm.relay.op.tensor.isfinite",
    "mapping_type": "direct",
    "direction": "torch_to_tvm",
    "torch_pattern": "torch.isfinite(input)",
    "tvm_pattern": "tvm.relay.op.tensor.isfinite(data)",
    "arg_mapping": {
      "input": "data"
    },
    "example_pairs": [
      {
        "torch": "output = torch.isfinite(input_tensor)",
        "tvm": "output = tvm.relay.op.tensor.isfinite(input_tensor)"
      }
    ],
    "constraints": "None.",
    "notes": "Direct mapping for element-wise finiteness check.",
    "confidence": 0.98
  },
  {
    "torch_api": "torch.onnx._internal.torchscript_exporter.symbolic_opset10.dequantize",
    "tvm_api": "tvm.relay.qnn.op.qnn.dequantize",
    "mapping_type": "composite",
    "direction": "torch_to_tvm",
    "torch_pattern": "torch.dequantize(input)",
    "tvm_pattern": "tvm.relay.qnn.op.dequantize(data, input_scale, input_zero_point, axis=-1)",
    "arg_mapping": {
      "input": "data"
    },
    "example_pairs": [
      {
        "torch": "output = torch.dequantize(quantized_input_tensor)",
        "tvm": "# Assuming scale and zero_point are available from quantized_input_tensor's metadata\noutput = tvm.relay.qnn.op.dequantize(quantized_input_tensor, input_scale=scale_val, input_zero_point=zp_val, axis=-1)"
      }
    ],
    "constraints": "TVM's `dequantize` explicitly requires `input_scale` and `input_zero_point` as separate arguments, which might need to be extracted from PyTorch's quantized tensor metadata or passed as external context during conversion. The `axis` argument defaults to -1 in TVM.",
    "notes": "Composite mapping as TVM requires explicit scale and zero_point parameters that PyTorch might implicitly carry within the quantized tensor.",
    "confidence": 0.7
  },
  {
    "torch_api": "torch.onnx._internal.torchscript_exporter.symbolic_opset11.gather",
    "tvm_api": "tvm.relay.op.transform.gather",
    "mapping_type": "direct",
    "direction": "torch_to_tvm",
    "torch_pattern": "output = torch.gather(self, dim=axis_int, index=index_tensor, sparse_grad=False)",
    "tvm_pattern": "output = tvm.relay.op.transform.gather(data, axis=axis_int, indices=indices_tensor)",
    "arg_mapping": {
      "self": "data",
      "dim": "axis",
      "index": "indices"
    },
    "example_pairs": [
      {
        "torch": "output = torch.gather(input_tensor, dim=1, index=index_tensor)",
        "tvm": "output = tvm.relay.op.transform.gather(input_tensor, axis=1, indices=index_tensor)"
      }
    ],
    "constraints": "PyTorch's `sparse_grad` argument (default False) is not directly exposed in TVM's `gather` op.",
    "notes": "Direct mapping for the element-wise gather operation.",
    "confidence": 0.95
  },
  {
    "torch_api": "torch.onnx._internal.torchscript_exporter.symbolic_opset11.scatter",
    "tvm_api": "tvm.relay.op.transform.scatter",
    "mapping_type": "direct",
    "direction": "torch_to_tvm",
    "torch_pattern": "output = torch.scatter(self, dim=axis_int, index=index_tensor, src=src_tensor)",
    "tvm_pattern": "output = tvm.relay.op.transform.scatter(data, indices=indices_tensor, updates=updates_tensor, axis=axis_int)",
    "arg_mapping": {
      "self": "data",
      "dim": "axis",
      "index": "indices",
      "src": "updates"
    },
    "example_pairs": [
      {
        "torch": "output = torch.scatter(input_tensor, dim=1, index=index_tensor, src=src_tensor)",
        "tvm": "output = tvm.relay.op.transform.scatter(input_tensor, indices=index_tensor, updates=src_tensor, axis=1)"
      }
    ],
    "constraints": "None.",
    "notes": "Direct mapping for the element-wise scatter update operation.",
    "confidence": 0.95
  },
  {
    "torch_api": "torch.onnx._internal.torchscript_exporter.symbolic_opset11.cumsum",
    "tvm_api": "tvm.relay.op.transform.cumsum",
    "mapping_type": "direct",
    "direction": "torch_to_tvm",
    "torch_pattern": "output = torch.cumsum(self, dim=axis_int, dtype=dtype_enum)",
    "tvm_pattern": "output = tvm.relay.op.transform.cumsum(data, axis=axis_int, dtype=dtype_str, exclusive=False)",
    "arg_mapping": {
      "self": "data",
      "dim": "axis",
      "dtype": "dtype"
    },
    "example_pairs": [
      {
        "torch": "output = torch.cumsum(input_tensor, dim=0, dtype=torch.float32)",
        "tvm": "output = tvm.relay.op.transform.cumsum(input_tensor, axis=0, dtype='float32', exclusive=False)"
      }
    ],
    "constraints": "TVM's `cumsum` has an `exclusive` argument (default False for inclusive sum) that matches PyTorch's default inclusive behavior. PyTorch `dtype` enum needs to be mapped to TVM string dtype.",
    "notes": "Direct mapping for cumulative sum.",
    "confidence": 0.95
  },
  {
    "torch_api": "torch.onnx._internal.torchscript_exporter.symbolic_opset11.add",
    "tvm_api": "tvm.relay.op.tensor.add",
    "mapping_type": "composite",
    "direction": "torch_to_tvm",
    "torch_pattern": "output = torch.add(self, other, alpha=alpha_val)",
    "tvm_pattern": "scaled_other = tvm.relay.op.tensor.multiply(alpha_val, rhs); output = tvm.relay.op.tensor.add(lhs, scaled_other)",
    "arg_mapping": {
      "self": "lhs",
      "other": "rhs",
      "alpha": "alpha_val"
    },
    "example_pairs": [
      {
        "torch": "output = torch.add(tensor_a, tensor_b, alpha=2.0)",
        "tvm": "scaled_b = tvm.relay.op.tensor.multiply(tvm.relay.const(2.0, 'float32'), tensor_b);\noutput = tvm.relay.op.tensor.add(tensor_a, scaled_b)"
      },
      {
        "torch": "output = torch.add(tensor_a, tensor_b)",
        "tvm": "output = tvm.relay.op.tensor.add(tensor_a, tensor_b)"
      }
    ],
    "constraints": "PyTorch's `alpha` argument in `add` requires a composite mapping (multiplication followed by addition) if `alpha` is specified and not 1 or None. TVM's `relay.op.tensor.add` performs simple element-wise addition.",
    "notes": "Composite mapping to handle the `alpha` parameter by explicitly performing a multiplication before addition if `alpha` is specified and not 1. If `alpha` is 1 or None, it simplifies to a direct add.",
    "confidence": 0.85
  },
  {
    "torch_api": "torch.onnx._internal.torchscript_exporter.symbolic_opset11.stack",
    "tvm_api": "tvm.relay.op.tensor.stack",
    "mapping_type": "direct",
    "direction": "torch_to_tvm",
    "torch_pattern": "output_list = torch.stack(tensor_list, dim=axis_int)",
    "tvm_pattern": "output_tuple = tvm.relay.op.tensor.stack(data_list, axis=axis_int)",
    "arg_mapping": {
      "tensor_list": "data",
      "dim": "axis"
    },
    "example_pairs": [
      {
        "torch": "output = torch.stack([tensor1, tensor2], dim=0)",
        "tvm": "output = tvm.relay.op.tensor.stack([tensor1, tensor2], axis=0)"
      }
    ],
    "constraints": "TVM's `stack` expects the input tensors as a Python list or tuple as the `data` argument.",
    "notes": "Direct mapping for stacking tensors along a new dimension.",
    "confidence": 0.95
  },
  {
    "torch_api": "torch.onnx._internal.torchscript_exporter.symbolic_opset11.topk",
    "tvm_api": "tvm.relay.op.algorithm.topk",
    "mapping_type": "direct",
    "direction": "torch_to_tvm",
    "torch_pattern": "values, indices = torch.topk(self, k, dim=axis_int, largest=largest_bool, sorted=sorted_bool)",
    "tvm_pattern": "values_and_indices = tvm.relay.op.algorithm.topk(data, k=k_val, axis=axis_int, ret_type='both', is_ascend=not largest_bool)",
    "arg_mapping": {
      "self": "data",
      "k": "k",
      "dim": "axis",
      "largest": "is_ascend"
    },
    "example_pairs": [
      {
        "torch": "values, indices = torch.topk(input_tensor, 3, dim=1, largest=True, sorted=True)",
        "tvm": "values_and_indices = tvm.relay.op.algorithm.topk(input_tensor, k=3, axis=1, ret_type='both', is_ascend=False)"
      }
    ],
    "constraints": "PyTorch `largest` boolean needs conversion to TVM `is_ascend` boolean (`largest=True` implies `is_ascend=False` for descending order). TVM's `ret_type` needs to be set to 'both' to match PyTorch's default return of values and indices. The `sorted` argument in PyTorch determines if the returned elements are sorted (TVM's `topk` generally produces sorted results by default).",
    "notes": "Direct mapping for topk, with `largest` to `is_ascend` conversion and `ret_type` handling for values and indices.",
    "confidence": 0.9
  },
  {
    "torch_api": "torch.onnx._internal.torchscript_exporter.symbolic_opset11.sort",
    "tvm_api": "tvm.relay.op.algorithm.sort",
    "mapping_type": "direct",
    "direction": "torch_to_tvm",
    "torch_pattern": "values, indices = torch.sort(self, dim=axis_int, descending=descending_bool)",
    "tvm_pattern": "values = tvm.relay.op.algorithm.sort(data, axis=axis_int, is_ascend=int(not descending_bool))",
    "arg_mapping": {
      "self": "data",
      "dim": "axis",
      "descending": "is_ascend"
    },
    "example_pairs": [
      {
        "torch": "values, indices = torch.sort(input_tensor, dim=1, descending=True)",
        "tvm": "values = tvm.relay.op.algorithm.sort(input_tensor, axis=1, is_ascend=0)"
      }
    ],
    "constraints": "TVM's `sort` returns only the sorted values, not both values and indices as PyTorch's `sort` does by default. PyTorch `descending` boolean needs conversion to TVM `is_ascend` integer (True=0, False=1).",
    "notes": "Direct mapping for sorting values. TVM's `sort` currently only returns the sorted values, which is a limitation if indices are also required.",
    "confidence": 0.8
  },
  {
    "torch_api": "torch.onnx._internal.torchscript_exporter.symbolic_opset11.argsort",
    "tvm_api": "tvm.relay.op.algorithm.argsort",
    "mapping_type": "direct",
    "direction": "torch_to_tvm",
    "torch_pattern": "indices = torch.argsort(self, dim=axis_int, descending=descending_bool)",
    "tvm_pattern": "indices = tvm.relay.op.algorithm.argsort(data, axis=axis_int, is_ascend=int(not descending_bool))",
    "arg_mapping": {
      "self": "data",
      "dim": "axis",
      "descending": "is_ascend"
    },
    "example_pairs": [
      {
        "torch": "indices = torch.argsort(input_tensor, dim=1, descending=True)",
        "tvm": "indices = tvm.relay.op.algorithm.argsort(input_tensor, axis=1, is_ascend=0)"
      }
    ],
    "constraints": "PyTorch `descending` boolean needs conversion to TVM `is_ascend` integer (True=0, False=1). TVM's `argsort` returns indices, matching PyTorch's behavior.",
    "notes": "Direct mapping for argsort, returning the indices of the sorted elements.",
    "confidence": 0.9
  },
  {
    "torch_api": "torch.onnx._internal.torchscript_exporter.symbolic_opset11.round",
    "tvm_api": "tvm.relay.op.tensor.round",
    "mapping_type": "composite",
    "direction": "torch_to_tvm",
    "torch_pattern": "output = torch.round(self, decimals=decimals_int)",
    "tvm_pattern": "output = tvm.relay.op.tensor.round(data) # if decimals == 0; else requires multiplication/division",
    "arg_mapping": {
      "self": "data",
      "decimals": "decimals"
    },
    "example_pairs": [
      {
        "torch": "output = torch.round(input_tensor)",
        "tvm": "output = tvm.relay.op.tensor.round(input_tensor)"
      },
      {
        "torch": "output = torch.round(input_tensor, decimals=2)",
        "tvm": "multiplier = tvm.relay.const(pow(10, 2), 'float32');\ntemp = tvm.relay.op.tensor.multiply(input_tensor, multiplier);\ntemp = tvm.relay.op.tensor.round(temp);\noutput = tvm.relay.op.tensor.divide(temp, multiplier)"
      }
    ],
    "constraints": "TVM's `round` operation (at Relay level) typically rounds to the nearest integer (equivalent to `decimals=0`). For non-zero `decimals`, a composite mapping involving multiplication, rounding, and division is required.",
    "notes": "Composite mapping for non-zero `decimals`. For `decimals=0`, it's a direct mapping.",
    "confidence": 0.8
  },
  {
    "torch_api": "torch.onnx._internal.torchscript_exporter.symbolic_opset11.split",
    "tvm_api": "tvm.relay.op.transform.split",
    "mapping_type": "direct",
    "direction": "torch_to_tvm",
    "torch_pattern": "output_list = torch.split(self, split_size_or_sizes_val, dim=axis_int)",
    "tvm_pattern": "output_tuple = tvm.relay.op.transform.split(data, indices_or_sections=split_points_list, axis=axis_int)",
    "arg_mapping": {
      "self": "data",
      "split_size_or_sizes": "indices_or_sections",
      "dim": "axis"
    },
    "example_pairs": [
      {
        "torch": "tensors = torch.split(input_tensor, 2, dim=0)",
        "tvm": "tensors_tuple = tvm.relay.op.transform.split(input_tensor, indices_or_sections=2, axis=0)"
      },
      {
        "torch": "tensors = torch.split(input_tensor, [1, 2, 3], dim=1)",
        "tvm": "tensors_tuple = tvm.relay.op.transform.split(input_tensor, indices_or_sections=(1, 3), axis=1)"
      }
    ],
    "constraints": "TVM's `split` returns a tuple of tensors. If `split_size_or_sizes` is a list of sizes in PyTorch, it needs to be converted to a list of split *indices* (cumulative sums) for TVM's `indices_or_sections` (e.g., `[1, 2, 3]` -> `(1, 1+2)` for 2 splits).",
    "notes": "Direct mapping, assuming `split_size_or_sizes` conversion for list of sizes. TVM output is a tuple.",
    "confidence": 0.9
  },
  {
    "torch_api": "torch.onnx._internal.torchscript_exporter.symbolic_opset11.unbind",
    "tvm_api": "tvm.relay.frontend.common.unbind",
    "mapping_type": "direct",
    "direction": "torch_to_tvm",
    "torch_pattern": "output_tuple = torch.unbind(self, dim=axis_int)",
    "tvm_pattern": "output_list = tvm.relay.frontend.common.unbind(data, axis=axis_int)",
    "arg_mapping": {
      "self": "data",
      "dim": "axis"
    },
    "example_pairs": [
      {
        "torch": "tensors = torch.unbind(input_tensor, dim=0)",
        "tvm": "tensors_list = tvm.relay.frontend.common.unbind(input_tensor, axis=0)"
      }
    ],
    "constraints": "TVM's `unbind` (from `relay.frontend.common`) returns a list of tensors, while PyTorch's `unbind` returns a tuple. This is a minor syntactic difference in Python.",
    "notes": "Direct mapping for unbinding a tensor into a sequence of slices.",
    "confidence": 0.95
  },
  {
    "torch_api": "torch.onnx._internal.torchscript_exporter.symbolic_opset11.pad",
    "tvm_api": "tvm.relay.op.nn.nn.pad",
    "mapping_type": "composite",
    "direction": "torch_to_tvm",
    "torch_pattern": "torch.pad(input, pad_list, mode=mode_str, value=value_scalar)",
    "tvm_pattern": "tvm.relay.op.nn.pad(data, pad_width=converted_pad_width, pad_mode=converted_mode_str, pad_value=value_scalar)",
    "arg_mapping": {
      "input": "data",
      "pad": "pad_width",
      "mode": "pad_mode",
      "value": "pad_value"
    },
    "example_pairs": [
      {
        "torch": "output = torch.pad(input_tensor, (1, 1, 2, 2), mode='constant', value=0.0)",
        "tvm": "# Assuming input_tensor is 4D (N,C,H,W), pad (1,1,2,2) means padding 1 to W, 2 to H\nconverted_pad_width = ((0,0),(0,0),(2,2),(1,1))\noutput = tvm.relay.op.nn.pad(input_tensor, converted_pad_width, pad_mode='constant', pad_value=0.0)"
      },
      {
        "torch": "output = torch.pad(input_tensor, (1, 1), mode='replicate')",
        "tvm": "# Assuming input_tensor is 2D (H,W), pad (1,1) means padding 1 to W\nconverted_pad_width = ((0,0),(1,1))\noutput = tvm.relay.op.nn.pad(input_tensor, converted_pad_width, pad_mode='edge')"
      }
    ],
    "constraints": "The PyTorch `pad` argument (list of ints) requires conversion to TVM's `pad_width` format. The order of dimensions for padding is reversed. PyTorch `mode='replicate'` maps to TVM `pad_mode='edge'`. `mode='circular'` is not supported by TVM's `pad` op directly.",
    "notes": "Composite mapping due to the required conversion of padding arguments format and mapping of 'replicate' mode.",
    "confidence": 0.8
  },
  {
    "torch_api": "torch.onnx._internal.torchscript_exporter.symbolic_opset11.arange",
    "tvm_api": "tvm.relay.op.transform.arange",
    "mapping_type": "direct",
    "direction": "torch_to_tvm",
    "torch_pattern": "output = torch.arange(start_val, end_val, step_val, dtype=dtype_enum)",
    "tvm_pattern": "output = tvm.relay.op.transform.arange(start_val, stop_val, step_val, dtype=dtype_str)",
    "arg_mapping": {
      "start": "start",
      "end": "stop",
      "step": "step",
      "dtype": "dtype"
    },
    "example_pairs": [
      {
        "torch": "output = torch.arange(5)",
        "tvm": "output = tvm.relay.op.transform.arange(0, 5, 1, dtype='float32')"
      },
      {
        "torch": "output = torch.arange(1, 5, 2, dtype=torch.int64)",
        "tvm": "output = tvm.relay.op.transform.arange(1, 5, 2, dtype='int64')"
      }
    ],
    "constraints": "PyTorch's various call signatures for `arange` (e.g., `arange(end)`) need to be mapped to TVM's `(start, stop, step)` signature with appropriate defaults. PyTorch `dtype` enum needs to be mapped to TVM string dtype.",
    "notes": "Direct mapping for generating evenly spaced values. TVM's `arange` parameter defaults align with PyTorch's common usage.",
    "confidence": 0.95
  },
  {
    "torch_api": "torch.onnx._internal.torchscript_exporter.symbolic_opset11.squeeze",
    "tvm_api": "tvm.relay.op.transform.squeeze",
    "mapping_type": "direct",
    "direction": "torch_to_tvm",
    "torch_pattern": "output = torch.squeeze(self, dim=axis_val)",
    "tvm_pattern": "output = tvm.relay.op.transform.squeeze(data, axis=axis_val)",
    "arg_mapping": {
      "self": "data",
      "dim": "axis"
    },
    "example_pairs": [
      {
        "torch": "output = torch.squeeze(input_tensor, dim=0)",
        "tvm": "output = tvm.relay.op.transform.squeeze(input_tensor, axis=0)"
      },
      {
        "torch": "output = torch.squeeze(input_tensor)",
        "tvm": "output = tvm.relay.op.transform.squeeze(input_tensor, axis=None)"
      }
    ],
    "constraints": "None.",
    "notes": "Direct mapping for removing single-dimensional entries from the shape.",
    "confidence": 0.98
  },
  {
    "torch_api": "torch.onnx._internal.torchscript_exporter.symbolic_opset11.flatten",
    "tvm_api": "tvm.relay.op.transform.reshape",
    "mapping_type": "composite",
    "direction": "torch_to_tvm",
    "torch_pattern": "output = torch.flatten(input, start_dim=start_dim_int, end_dim=end_dim_int)",
    "tvm_pattern": "output_shape = calculate_flatten_shape(input.shape, start_dim_int, end_dim_int); output = tvm.relay.op.transform.reshape(input, newshape=output_shape)",
    "arg_mapping": {
      "input": "input",
      "start_dim": "start_dim",
      "end_dim": "end_dim"
    },
    "example_pairs": [
      {
        "torch": "output = torch.flatten(input_tensor, start_dim=1)",
        "tvm": "N, C, H, W = input_tensor.shape;\noutput = tvm.relay.op.transform.reshape(input_tensor, newshape=[N, C * H * W])"
      },
      {
        "torch": "output = torch.flatten(input_tensor, start_dim=0, end_dim=1)",
        "tvm": "N, C, H, W = input_tensor.shape;\noutput = tvm.relay.op.transform.reshape(input_tensor, newshape=[N * C, H, W])"
      }
    ],
    "constraints": "PyTorch `flatten` with arbitrary `start_dim` and `end_dim` maps to a `reshape` operation in TVM. This requires calculating the `newshape` based on input dimensions and the `start_dim`/`end_dim` parameters. `tvm.topi.nn.flatten` is a special case (flattening all but the first dimension).",
    "notes": "Composite mapping using `relay.reshape` to achieve the desired flattening behavior for arbitrary dimension ranges.",
    "confidence": 0.8
  },
  {
    "torch_api": "torch.onnx._internal.torchscript_exporter.symbolic_opset11.normal",
    "tvm_api": "tvm.relay.op.random.kernel.normal",
    "mapping_type": "composite",
    "direction": "torch_to_tvm",
    "torch_pattern": "output = torch.normal(mean=mean_val, std=std_val, size=size_tuple, generator=gen_obj, dtype=dtype_enum)",
    "tvm_pattern": "key = tvm.relay.op.random.threefry_key(seed_val); key, output = tvm.relay.op.random.normal(key, shape=size_tuple, dtype=dtype_str, mean=mean_val, scale=std_val)",
    "arg_mapping": {
      "mean": "mean",
      "std": "scale",
      "sizes": "shape",
      "dtype": "dtype"
    },
    "example_pairs": [
      {
        "torch": "output = torch.normal(mean=0.0, std=1.0, size=(2, 3), dtype=torch.float32)",
        "tvm": "key_seed = 0; # Or a dynamic key from a previous op\nkey_init = tvm.relay.op.random.threefry_key(key_seed);\nkey_new, output = tvm.relay.op.random.normal(key_init, shape=(2, 3), dtype='float32', mean=0.0, scale=1.0)"
      }
    ],
    "constraints": "TVM's random operations require an explicit random `key` (generator state) as input and return an updated `key` along with the random values. PyTorch's `generator` argument is a different API for managing random state. If `sizes` is None in PyTorch, the shape should be inferred from `mean`.",
    "notes": "Composite mapping due to the explicit random key management in TVM's random ops, and the internal composition (`std * RandomNormalLike + mean`) described in the PyTorch source for generating normal samples.",
    "confidence": 0.75
  },
  {
    "torch_api": "torch.onnx._internal.torchscript_exporter.symbolic_opset12.einsum",
    "tvm_api": "tvm.relay.op.tensor.einsum",
    "mapping_type": "direct",
    "direction": "torch_to_tvm",
    "torch_pattern": "output = torch.einsum(equation_str, tensor_list)",
    "tvm_pattern": "output = tvm.relay.op.tensor.einsum(data_tuple, equation_str)",
    "arg_mapping": {
      "equation": "equation",
      "tensor_list": "data"
    },
    "example_pairs": [
      {
        "torch": "output = torch.einsum('ij,jk->ik', A, B)",
        "tvm": "output = tvm.relay.op.tensor.einsum((A, B), 'ij,jk->ik')"
      }
    ],
    "constraints": "TVM's `einsum` expects the input tensors as a tuple (or list) as the `data` argument.",
    "notes": "Direct mapping for Einstein summation.",
    "confidence": 0.95
  },
  {
    "torch_api": "torch.onnx._internal.torchscript_exporter.symbolic_opset12.dropout",
    "tvm_api": "tvm.relay.op.nn.nn.dropout",
    "mapping_type": "direct",
    "direction": "torch_to_tvm",
    "torch_pattern": "output = torch.dropout(input, p=rate_val, train=train_bool)",
    "tvm_pattern": "output = tvm.relay.op.nn.dropout(data, rate=rate_val)",
    "arg_mapping": {
      "input": "data",
      "p": "rate"
    },
    "example_pairs": [
      {
        "torch": "output = torch.dropout(input_tensor, p=0.5, train=True)",
        "tvm": "output = tvm.relay.op.nn.dropout(input_tensor, rate=0.5)"
      }
    ],
    "constraints": "TVM's `dropout` operator only takes `data` and `rate`. The `train` argument is implicitly handled by TVM's graph optimization passes (e.g., typically optimized away for inference graphs, or kept for training graphs).",
    "notes": "Direct mapping for the core dropout operation.",
    "confidence": 0.9
  },
  {
    "torch_api": "torch.onnx._internal.torchscript_exporter.symbolic_opset12.nll_loss",
    "tvm_api": "tvm.relay.op.nn.nn.nll_loss",
    "mapping_type": "direct",
    "direction": "torch_to_tvm",
    "torch_pattern": "output = torch.nll_loss(self, target, weight=weight_tensor, reduction=reduction_str, ignore_index=ignore_idx)",
    "tvm_pattern": "output = tvm.relay.op.nn.nll_loss(predictions, targets, weights, reduction=reduction_str, ignore_index=ignore_idx)",
    "arg_mapping": {
      "self": "predictions",
      "target": "targets",
      "weight": "weights",
      "reduction": "reduction",
      "ignore_index": "ignore_index"
    },
    "example_pairs": [
      {
        "torch": "output = torch.nll_loss(logits, labels, weight=class_weights, reduction='mean', ignore_index=-1)",
        "tvm": "output = tvm.relay.op.nn.nll_loss(logits, labels, class_weights, reduction='mean', ignore_index=-1)"
      }
    ],
    "constraints": "None.",
    "notes": "Direct mapping for Negative Log Likelihood Loss.",
    "confidence": 0.95
  },
  {
    "torch_api": "torch.onnx._internal.torchscript_exporter.symbolic_opset12.argmax",
    "tvm_api": "tvm.relay.op.reduce.argmax",
    "mapping_type": "direct",
    "direction": "torch_to_tvm",
    "torch_pattern": "output = torch.argmax(input, dim=axis_val, keepdim=keepdim_bool)",
    "tvm_pattern": "output = tvm.relay.op.reduce.argmax(data, axis=axis_val, keepdims=keepdim_bool)",
    "arg_mapping": {
      "input": "data",
      "dim": "axis",
      "keepdim": "keepdims"
    },
    "example_pairs": [
      {
        "torch": "output = torch.argmax(input_tensor, dim=1, keepdim=False)",
        "tvm": "output = tvm.relay.op.reduce.argmax(input_tensor, axis=1, keepdims=False)"
      }
    ],
    "constraints": "TVM's `argmax` has additional arguments `exclude` and `select_last_index` which are not present in PyTorch's `argmax` and assume default values (False).",
    "notes": "Direct mapping for finding indices of maximum values along an axis.",
    "confidence": 0.95
  },
  {
    "torch_api": "torch.onnx._internal.torchscript_exporter.symbolic_opset12.argmin",
    "tvm_api": "tvm.relay.op.reduce.argmin",
    "mapping_type": "direct",
    "direction": "torch_to_tvm",
    "torch_pattern": "output = torch.argmin(input, dim=axis_val, keepdim=keepdim_bool)",
    "tvm_pattern": "output = tvm.relay.op.reduce.argmin(data, axis=axis_val, keepdims=keepdim_bool)",
    "arg_mapping": {
      "input": "data",
      "dim": "axis",
      "keepdim": "keepdims"
    },
    "example_pairs": [
      {
        "torch": "output = torch.argmin(input_tensor, dim=1, keepdim=False)",
        "tvm": "output = tvm.relay.op.reduce.argmin(input_tensor, axis=1, keepdims=False)"
      }
    ],
    "constraints": "TVM's `argmin` has additional arguments `exclude` and `select_last_index` which are not present in PyTorch's `argmin` and assume default values (False).",
    "notes": "Direct mapping for finding indices of minimum values along an axis.",
    "confidence": 0.95
  },
  {
    "torch_api": "torch.onnx._internal.torchscript_exporter.symbolic_opset12.tensordot",
    "tvm_api": "tvm.topi.transform.tensordot",
    "mapping_type": "direct",
    "direction": "torch_to_tvm",
    "torch_pattern": "output = torch.tensordot(input_a, input_b, dims_a, dims_b)",
    "tvm_pattern": "output = tvm.topi.transform.tensordot(a, b, axes=(dims_a, dims_b))",
    "arg_mapping": {
      "input_a": "a",
      "input_b": "b",
      "dims_a": "axes[0]",
      "dims_b": "axes[1]"
    },
    "example_pairs": [
      {
        "torch": "output = torch.tensordot(A, B, dims_a=[2], dims_b=[0])",
        "tvm": "output = tvm.topi.transform.tensordot(A, B, axes=([2], [0]))"
      }
    ],
    "constraints": "PyTorch's `out` parameter is explicitly noted as not supported by PyTorch's own symbolic exporter, aligning with TVM's `tensordot` signature.",
    "notes": "Direct mapping for tensordot operation. The `axes` argument format matches conceptual usage.",
    "confidence": 0.95
  },
  {
    "torch_api": "torch.onnx._internal.torchscript_exporter.symbolic_opset13.softmax",
    "tvm_api": "tvm.relay.op.nn.nn.softmax",
    "mapping_type": "direct",
    "direction": "torch_to_tvm",
    "torch_pattern": "output = torch.softmax(input, dim=axis_int, dtype=dtype_enum)",
    "tvm_pattern": "output = tvm.relay.op.nn.softmax(data, axis=axis_int)",
    "arg_mapping": {
      "input": "data",
      "dim": "axis"
    },
    "example_pairs": [
      {
        "torch": "output = torch.softmax(input_tensor, dim=1)",
        "tvm": "output = tvm.relay.op.nn.softmax(input_tensor, axis=1)"
      }
    ],
    "constraints": "The `dtype` argument might require an explicit `relay.cast` operation if the output dtype differs from the input.",
    "notes": "Direct mapping for the Softmax activation function.",
    "confidence": 0.98
  },
  {
    "torch_api": "torch.onnx._internal.torchscript_exporter.symbolic_opset13.log_softmax",
    "tvm_api": "tvm.relay.op.nn.nn.log_softmax",
    "mapping_type": "direct",
    "direction": "torch_to_tvm",
    "torch_pattern": "output = torch.log_softmax(input, dim=axis_int, dtype=dtype_enum)",
    "tvm_pattern": "output = tvm.relay.op.nn.log_softmax(data, axis=axis_int)",
    "arg_mapping": {
      "input": "data",
      "dim": "axis"
    },
    "example_pairs": [
      {
        "torch": "output = torch.log_softmax(input_tensor, dim=1)",
        "tvm": "output = tvm.relay.op.nn.log_softmax(input_tensor, axis=1)"
      }
    ],
    "constraints": "The `dtype` argument might require an explicit `relay.cast` operation if the output dtype differs from the input.",
    "notes": "Direct mapping for the Log Softmax activation function.",
    "confidence": 0.98
  },
  {
    "torch_api": "torch.split",
    "tvm_api": "tvm.relay.op.transform.split",
    "mapping_type": "direct",
    "direction": "torch_to_tvm",
    "torch_pattern": "torch.split({{self}}, {{split_size_or_sizes}}, dim={{dim}})",
    "tvm_pattern": "tvm.relay.op.transform.split({{data}}, {{indices_or_sections}}, axis={{axis}})",
    "arg_mapping": {
      "self": "data",
      "split_size_or_sizes": "indices_or_sections",
      "dim": "axis"
    },
    "example_pairs": [
      {
        "torch": "result = torch.split(x, 2, dim=0)",
        "tvm": "result = tvm.relay.op.transform.split(x, 2, axis=0)"
      },
      {
        "torch": "result = torch.split(x, [1, 3, 2], dim=1)",
        "tvm": "result = tvm.relay.op.transform.split(x, [1, 3, 2], axis=1)"
      }
    ],
    "constraints": "Supports static split sizes or sections. Dynamic number of outputs is not directly supported by this TVM op in general relay graph construction.",
    "notes": "Maps to TVM's generic tensor split operation. The PyTorch `_outputs` argument is for ONNX export hints, not a core functional difference in this static case.",
    "confidence": 0.95
  },
  {
    "torch_api": "torch.unbind",
    "tvm_api": "tvm.relay.frontend.common.unbind",
    "mapping_type": "direct",
    "direction": "torch_to_tvm",
    "torch_pattern": "torch.unbind({{self}}, dim={{dim}})",
    "tvm_pattern": "tvm.relay.frontend.common.unbind({{data}}, axis={{axis}})",
    "arg_mapping": {
      "self": "data",
      "dim": "axis"
    },
    "example_pairs": [
      {
        "torch": "tensors = torch.unbind(x, dim=0)",
        "tvm": "tensors = tvm.relay.frontend.common.unbind(x, axis=0)"
      }
    ],
    "constraints": "Dynamic number of outputs should be inferable or explicitly handled during compilation, consistent with PyTorch's ONNX export constraints for opset 9+.",
    "notes": "TVM's unbind performs the exact same operation of removing a dimension and returning slices.",
    "confidence": 0.95
  },
  {
    "torch_api": "torch.where",
    "tvm_api": "tvm.relay.op.transform.where",
    "mapping_type": "direct",
    "direction": "torch_to_tvm",
    "torch_pattern": "torch.where({{condition}}, {{self}}, {{other}})",
    "tvm_pattern": "tvm.relay.op.transform.where({{condition}}, {{x}}, {{y}})",
    "arg_mapping": {
      "condition": "condition",
      "self": "x",
      "other": "y"
    },
    "example_pairs": [
      {
        "torch": "result = torch.where(cond, a, b)",
        "tvm": "result = tvm.relay.op.transform.where(cond, a, b)"
      }
    ],
    "constraints": "Assumes `self` and `other` are provided. The PyTorch case where `self is None` (acting like `nonzero`) is not covered by this direct mapping.",
    "notes": "Maps the primary functionality of PyTorch's `where` for element-wise selection based on a condition.",
    "confidence": 0.95
  },
  {
    "torch_api": "torch.tile",
    "tvm_api": "tvm.relay.op.transform.tile",
    "mapping_type": "direct",
    "direction": "torch_to_tvm",
    "torch_pattern": "torch.tile({{self}}, {{dims}})",
    "tvm_pattern": "tvm.relay.op.transform.tile({{data}}, {{reps}})",
    "arg_mapping": {
      "self": "data",
      "dims": "reps"
    },
    "example_pairs": [
      {
        "torch": "result = torch.tile(x, (2, 3))",
        "tvm": "result = tvm.relay.op.transform.tile(x, (2, 3))"
      }
    ],
    "constraints": "None. The TVM op directly implements repeating the array as described.",
    "notes": "Directly maps the tensor tiling/replication operation.",
    "confidence": 0.95
  },
  {
    "torch_api": "torch.hardswish",
    "tvm_api": null,
    "mapping_type": "no_mapping",
    "direction": "torch_to_tvm",
    "torch_pattern": null,
    "tvm_pattern": null,
    "arg_mapping": {},
    "example_pairs": [],
    "constraints": "Not convertible",
    "notes": "NO_MAPPING: The provided TVM `hardswish` (tvm.relay.qnn.op.qnn.hardswish) is for quantized operations, requiring `scale` and `zero_point`. The PyTorch `aten::hardswish` is a floating-point operation, which is not directly available in the provided TVM snippets as a non-quantized op.",
    "confidence": 0.2
  },
  {
    "torch_api": "torch.reshape",
    "tvm_api": "tvm.relay.op.transform.reshape",
    "mapping_type": "direct",
    "direction": "torch_to_tvm",
    "torch_pattern": "torch.reshape({{self}}, {{shape}})",
    "tvm_pattern": "tvm.relay.op.transform.reshape({{data}}, {{newshape}})",
    "arg_mapping": {
      "self": "data",
      "shape": "newshape"
    },
    "example_pairs": [
      {
        "torch": "result = torch.reshape(x, (2, -1, 4))",
        "tvm": "result = tvm.relay.op.transform.reshape(x, (2, -1, 4))"
      }
    ],
    "constraints": "TVM's reshape supports special values like 0 (copy) and -1 (infer dimension), similar to NumPy/PyTorch.",
    "notes": "Directly maps the tensor reshape operation.",
    "confidence": 0.95
  },
  {
    "torch_api": "torch.batch_norm",
    "tvm_api": "tvm.relay.op.nn.nn.batch_norm",
    "mapping_type": "direct",
    "direction": "torch_to_tvm",
    "torch_pattern": "torch.batch_norm({{input}}, {{weight}}, {{bias}}, {{running_mean}}, {{running_var}}, training={{training}}, momentum={{momentum}}, eps={{eps}}, cudnn_enabled={{cudnn_enabled}})",
    "tvm_pattern": "tvm.relay.op.nn.nn.batch_norm({{data}}, {{gamma}}, {{beta}}, {{moving_mean}}, {{moving_var}}, axis={{axis}}, epsilon={{epsilon}})",
    "arg_mapping": {
      "input": "data",
      "weight": "gamma",
      "bias": "beta",
      "running_mean": "moving_mean",
      "running_var": "moving_var",
      "eps": "epsilon"
    },
    "example_pairs": [
      {
        "torch": "output = torch.batch_norm(x, w, b, rm, rv, True, 0.1, 1e-5, True)",
        "tvm": "output = tvm.relay.op.nn.nn.batch_norm(x, w, b, rm, rv, axis=1, epsilon=1e-5)"
      }
    ],
    "constraints": "TVM's `batch_norm` op focuses on the normalization computation. PyTorch's `training`, `momentum`, `cudnn_enabled` parameters are typically handled at a graph pass or scheduling level in TVM, not directly as op parameters in the Relay definition. Default `axis` for TVM is 1.",
    "notes": "Core batch normalization logic is a direct match. Training-specific behaviors often require distinct graph patterns in Relay.",
    "confidence": 0.9
  },
  {
    "torch_api": "torch.scatter_add",
    "tvm_api": "tvm.relay.op.transform.scatter_add",
    "mapping_type": "direct",
    "direction": "torch_to_tvm",
    "torch_pattern": "torch.scatter_add({{self}}, dim={{dim}}, index={{index}}, src={{src}})",
    "tvm_pattern": "tvm.relay.op.transform.scatter_add({{data}}, {{indices}}, {{updates}}, axis={{axis}})",
    "arg_mapping": {
      "self": "data",
      "dim": "axis",
      "index": "indices",
      "src": "updates"
    },
    "example_pairs": [
      {
        "torch": "output = torch.scatter_add(input_data, 0, indices, source_data)",
        "tvm": "output = tvm.relay.op.transform.scatter_add(input_data, indices, source_data, axis=0)"
      }
    ],
    "constraints": "PyTorch's symbolic export code handles complex dynamic shape scenarios for `src` and `index` that might require pre-processing or careful handling in TVM. For static shapes, it's a direct functional match.",
    "notes": "Directly maps the scatter-add operation, where values from `src` are added to `self` at `index` positions along `dim`.",
    "confidence": 0.9
  },
  {
    "torch_api": "torch.layer_norm",
    "tvm_api": "tvm.relay.op.nn.nn.layer_norm",
    "mapping_type": "direct",
    "direction": "torch_to_tvm",
    "torch_pattern": "torch.layer_norm({{input}}, {{normalized_shape}}, {{weight}}, {{bias}}, eps={{eps}}, cudnn_enable={{cudnn_enable}})",
    "tvm_pattern": "tvm.relay.op.nn.nn.layer_norm({{data}}, {{gamma}}, {{beta}}, axis={{axis}}, epsilon={{epsilon}})",
    "arg_mapping": {
      "input": "data",
      "weight": "gamma",
      "bias": "beta",
      "eps": "epsilon",
      "normalized_shape": "axis"
    },
    "example_pairs": [
      {
        "torch": "output = torch.layer_norm(x, [10], w, b, 1e-5, False)",
        "tvm": "output = tvm.relay.op.nn.nn.layer_norm(x, w, b, axis=-len([10]), epsilon=1e-5)"
      }
    ],
    "constraints": "PyTorch's `normalized_shape` determines the last `D` dimensions to normalize, which corresponds to `axis = -len(normalized_shape)` in TVM. `cudnn_enable` is an implementation detail for optimization.",
    "notes": "Directly maps the core layer normalization computation. `center` and `scale` parameters in TVM's `layer_norm` (default True) are implicitly handled by providing `gamma` and `beta`.",
    "confidence": 0.95
  },
  {
    "torch_api": "torch.stft",
    "tvm_api": "tvm.relay.op.transform.stft",
    "mapping_type": "direct",
    "direction": "torch_to_tvm",
    "torch_pattern": "torch.stft({{input}}, {{n_fft}}, hop_length={{hop_length}}, win_length={{win_length}}, window={{window}}, normalized={{normalized}}, onesided={{onesided}}, return_complex={{return_complex}})",
    "tvm_pattern": "tvm.relay.op.transform.stft({{data}}, {{n_fft}}, hop_length={{hop_length}}, win_length={{win_length}}, window={{window}}, normalized={{normalized}}, onesided={{onesided}})",
    "arg_mapping": {
      "input": "data",
      "n_fft": "n_fft",
      "hop_length": "hop_length",
      "win_length": "win_length",
      "window": "window",
      "normalized": "normalized",
      "onesided": "onesided"
    },
    "example_pairs": [
      {
        "torch": "output = torch.stft(x, 2048, hop_length=512, window=hann_window)",
        "tvm": "output = tvm.relay.op.transform.stft(x, 2048, hop_length=512, window=hann_window)"
      }
    ],
    "constraints": "The `return_complex` (PyTorch default `False`) and `align_to_window` arguments in PyTorch are not directly exposed in the TVM Relay `stft` signature. Assuming `return_complex=False` by default for TVM if complex tensors are not natively supported, or that real/imag parts are returned separately if supported. `align_to_window` relates to padding behavior which might be an implicit part of TVM's `stft` implementation.",
    "notes": "Directly maps the Short-Time Fourier Transform. The core parameters are aligned.",
    "confidence": 0.85
  },
  {
    "torch_api": "torch.max",
    "tvm_api": "tvm.relay.op.reduce.max",
    "mapping_type": "direct",
    "direction": "torch_to_tvm",
    "torch_pattern": "torch.max({{self}}, dim={{dim}}, keepdim={{keepdim}})",
    "tvm_pattern": "tvm.relay.op.reduce.max({{data}}, axis={{axis}}, keepdims={{keepdims}})",
    "arg_mapping": {
      "self": "data",
      "dim": "axis",
      "keepdim": "keepdims"
    },
    "example_pairs": [
      {
        "torch": "values, indices = torch.max(x, dim=1, keepdim=True)",
        "tvm": "values = tvm.relay.op.reduce.max(x, axis=1, keepdims=True) # TVM reduce ops typically return only the reduced value, not indices."
      }
    ],
    "constraints": "This mapping is for the reduction form `torch.max(input, dim, keepdim)`. The element-wise comparison form `torch.max(input, other)` is better mapped to `tvm.relay.op.tensor.maximum`. TVM's reduce ops typically return only the maximum value, not the indices, unlike PyTorch's `torch.max` which returns `(values, indices)`.",
    "notes": "Maps the reduction functionality of `torch.max`. The return of indices would require a composite mapping involving `argmax` or similar if available.",
    "confidence": 0.85
  },
  {
    "torch_api": "torch.maximum",
    "tvm_api": "tvm.relay.op.tensor.maximum",
    "mapping_type": "direct",
    "direction": "torch_to_tvm",
    "torch_pattern": "torch.maximum({{input}}, {{other}})",
    "tvm_pattern": "tvm.relay.op.tensor.maximum({{lhs}}, {{rhs}})",
    "arg_mapping": {
      "input": "lhs",
      "other": "rhs"
    },
    "example_pairs": [
      {
        "torch": "result = torch.maximum(a, b)",
        "tvm": "result = tvm.relay.op.tensor.maximum(a, b)"
      }
    ],
    "constraints": "Performs element-wise maximum with NumPy-style broadcasting.",
    "notes": "Directly maps element-wise maximum with broadcasting.",
    "confidence": 0.95
  },
  {
    "torch_api": "torch.min",
    "tvm_api": "tvm.relay.op.reduce.min",
    "mapping_type": "direct",
    "direction": "torch_to_tvm",
    "torch_pattern": "torch.min({{self}}, dim={{dim}}, keepdim={{keepdim}})",
    "tvm_pattern": "tvm.relay.op.reduce.min({{data}}, axis={{axis}}, keepdims={{keepdims}})",
    "arg_mapping": {
      "self": "data",
      "dim": "axis",
      "keepdim": "keepdims"
    },
    "example_pairs": [
      {
        "torch": "values, indices = torch.min(x, dim=1, keepdim=True)",
        "tvm": "values = tvm.relay.op.reduce.min(x, axis=1, keepdims=True) # TVM reduce ops typically return only the reduced value, not indices."
      }
    ],
    "constraints": "This mapping is for the reduction form `torch.min(input, dim, keepdim)`. The element-wise comparison form `torch.min(input, other)` is better mapped to `tvm.relay.op.tensor.minimum`. TVM's reduce ops typically return only the minimum value, not the indices, unlike PyTorch's `torch.min` which returns `(values, indices)`.",
    "notes": "Maps the reduction functionality of `torch.min`. The return of indices would require a composite mapping involving `argmin` or similar if available.",
    "confidence": 0.85
  },
  {
    "torch_api": "torch.minimum",
    "tvm_api": "tvm.relay.op.tensor.minimum",
    "mapping_type": "direct",
    "direction": "torch_to_tvm",
    "torch_pattern": "torch.minimum({{input}}, {{other}})",
    "tvm_pattern": "tvm.relay.op.tensor.minimum({{lhs}}, {{rhs}})",
    "arg_mapping": {
      "input": "lhs",
      "other": "rhs"
    },
    "example_pairs": [
      {
        "torch": "result = torch.minimum(a, b)",
        "tvm": "result = tvm.relay.op.tensor.minimum(a, b)"
      }
    ],
    "constraints": "Performs element-wise minimum with NumPy-style broadcasting.",
    "notes": "Directly maps element-wise minimum with broadcasting.",
    "confidence": 0.95
  },
  {
    "torch_api": "torch.max",
    "tvm_api": "tvm.relay.op.reduce.max",
    "mapping_type": "direct",
    "direction": "torch_to_tvm",
    "torch_pattern": "torch.max({{self}}, dim={{dim}}, keepdim={{keepdim}})",
    "tvm_pattern": "tvm.relay.op.reduce.max({{data}}, axis={{axis}}, keepdims={{keepdims}})",
    "arg_mapping": {
      "self": "data",
      "dim": "axis",
      "keepdim": "keepdims"
    },
    "example_pairs": [
      {
        "torch": "values, indices = torch.max(x, dim=1, keepdim=True)",
        "tvm": "values = tvm.relay.op.reduce.max(x, axis=1, keepdims=True)"
      }
    ],
    "constraints": "This mapping is for the reduction form `torch.max(input, dim, keepdim)`. The element-wise comparison form `torch.max(input, other)` is better mapped to `tvm.relay.op.tensor.maximum`. TVM's reduce ops typically return only the maximum value, not the indices, unlike PyTorch's `torch.max` which returns `(values, indices)`.",
    "notes": "Same as API 11, considering the reduction form.",
    "confidence": 0.85
  },
  {
    "torch_api": "torch.min",
    "tvm_api": "tvm.relay.op.reduce.min",
    "mapping_type": "direct",
    "direction": "torch_to_tvm",
    "torch_pattern": "torch.min({{self}}, dim={{dim}}, keepdim={{keepdim}})",
    "tvm_pattern": "tvm.relay.op.reduce.min({{data}}, axis={{axis}}, keepdims={{keepdims}})",
    "arg_mapping": {
      "self": "data",
      "dim": "axis",
      "keepdim": "keepdims"
    },
    "example_pairs": [
      {
        "torch": "values, indices = torch.min(x, dim=1, keepdim=True)",
        "tvm": "values = tvm.relay.op.reduce.min(x, axis=1, keepdims=True)"
      }
    ],
    "constraints": "This mapping is for the reduction form `torch.min(input, dim, keepdim)`. The element-wise comparison form `torch.min(input, other)` is better mapped to `tvm.relay.op.tensor.minimum`. TVM's reduce ops typically return only the minimum value, not the indices, unlike PyTorch's `torch.min` which returns `(values, indices)`.",
    "notes": "Same as API 13, considering the reduction form.",
    "confidence": 0.85
  },
  {
    "torch_api": "torch.matmul",
    "tvm_api": "tvm.relay.op.nn.nn.matmul",
    "mapping_type": "direct",
    "direction": "torch_to_tvm",
    "torch_pattern": "torch.matmul({{self}}, {{other}})",
    "tvm_pattern": "tvm.relay.op.nn.nn.matmul({{tensor_a}}, {{tensor_b}})",
    "arg_mapping": {
      "self": "tensor_a",
      "other": "tensor_b"
    },
    "example_pairs": [
      {
        "torch": "result = torch.matmul(a, b)",
        "tvm": "result = tvm.relay.op.nn.nn.matmul(a, b)"
      }
    ],
    "constraints": "TVM's matmul implicitly handles broadcasting and different matrix/vector multiplication types that `torch.matmul` covers.",
    "notes": "Directly maps the matrix multiplication operation.",
    "confidence": 0.95
  },
  {
    "torch_api": "torch.prelu",
    "tvm_api": "tvm.relay.op.nn.nn.prelu",
    "mapping_type": "direct",
    "direction": "torch_to_tvm",
    "torch_pattern": "torch.prelu({{self}}, {{weight}})",
    "tvm_pattern": "tvm.relay.op.nn.nn.prelu({{data}}, {{alpha}}, axis={{axis}})",
    "arg_mapping": {
      "self": "data",
      "weight": "alpha"
    },
    "example_pairs": [
      {
        "torch": "result = torch.prelu(x, alpha_tensor)",
        "tvm": "result = tvm.relay.op.nn.nn.prelu(x, alpha_tensor, axis=1)"
      }
    ],
    "constraints": "TVM's `prelu` has an `axis` parameter (default 1) for channel-wise alpha. PyTorch's `weight` (`alpha`) broadcasting behavior should align, or custom `axis` might be needed.",
    "notes": "Directly maps the PReLU activation function.",
    "confidence": 0.9
  },
  {
    "torch_api": "torch.flatten",
    "tvm_api": "tvm.relay.op.transform.reshape",
    "mapping_type": "composite",
    "direction": "torch_to_tvm",
    "torch_pattern": "torch.flatten({{input}}, start_dim={{start_dim}}, end_dim={{end_dim}})",
    "tvm_pattern": "tvm.relay.op.transform.reshape({{data}}, {{newshape}})",
    "arg_mapping": {
      "input": "data",
      "start_dim": "calculated_start_dim",
      "end_dim": "calculated_end_dim"
    },
    "example_pairs": [
      {
        "torch": "result = torch.flatten(x, start_dim=1)",
        "tvm": "# Assuming x has shape (N, C, H, W)\n# newshape would be (N, C*H*W)\nresult = tvm.relay.op.transform.reshape(x, (x.shape[0], -1))"
      },
      {
        "torch": "result = torch.flatten(x, start_dim=0, end_dim=1)",
        "tvm": "# Assuming x has shape (N, C, H, W)\n# newshape would be (N*C, H, W)\nresult = tvm.relay.op.transform.reshape(x, (-1, x.shape[2], x.shape[3]))"
      }
    ],
    "constraints": "PyTorch's `flatten` is more flexible, allowing flattening a range of dimensions. TVM's `topi.nn.flatten` is fixed to flattening all but the first dimension. `tvm.relay.op.transform.reshape` can achieve arbitrary flattening by constructing the appropriate `newshape` tuple based on `start_dim` and `end_dim` and the input's original shape.",
    "notes": "Mapping involves computing the `newshape` parameter for `reshape` based on the input tensor's rank and the `start_dim` and `end_dim` values. For example, `flatten(x, start_dim=S, end_dim=E)` would mean the dimensions `[S, ..., E]` are collapsed into one.",
    "confidence": 0.8
  },
  {
    "torch_api": "torch.empty",
    "tvm_api": "tvm.runtime.ndarray.empty",
    "mapping_type": "direct",
    "direction": "torch_to_tvm",
    "torch_pattern": "torch.empty({{sizes}}, dtype={{dtype}}, device={{device}})",
    "tvm_pattern": "tvm.runtime.ndarray.empty({{shape}}, dtype={{dtype}}, device={{device}})",
    "arg_mapping": {
      "sizes": "shape",
      "dtype": "dtype",
      "device": "device"
    },
    "example_pairs": [
      {
        "torch": "x = torch.empty((2, 3), dtype=torch.float32, device='cuda')",
        "tvm": "x = tvm.runtime.ndarray.empty((2, 3), dtype='float32', device=tvm.cuda(0))"
      }
    ],
    "constraints": "PyTorch's `layout`, `pin_memory`, `memory_format` are not directly mapped at this TVM API level.",
    "notes": "Creates an uninitialized tensor on the specified device with the given shape and data type.",
    "confidence": 0.95
  },
  {
    "torch_api": "torch.zeros",
    "tvm_api": "tvm.relay.op.tensor.zeros",
    "mapping_type": "direct",
    "direction": "torch_to_tvm",
    "torch_pattern": "torch.zeros({{sizes}}, dtype={{dtype}})",
    "tvm_pattern": "tvm.relay.op.tensor.zeros({{shape}}, {{dtype}})",
    "arg_mapping": {
      "sizes": "shape",
      "dtype": "dtype"
    },
    "example_pairs": [
      {
        "torch": "x = torch.zeros((2, 3), dtype=torch.float32)",
        "tvm": "x = tvm.relay.op.tensor.zeros((2, 3), 'float32')"
      }
    ],
    "constraints": "PyTorch's `layout`, `device`, `pin_memory` are not directly mapped at this TVM API level.",
    "notes": "Creates a tensor of the specified shape and dtype, filled with zeros. This corresponds to a constant fill operation with value 0.",
    "confidence": 0.95
  },
  {
    "torch_api": "torch.zeros_like",
    "tvm_api": "tvm.relay.op.tensor.zeros_like",
    "mapping_type": "direct",
    "direction": "torch_to_tvm",
    "torch_pattern": "torch.zeros_like({{input}})",
    "tvm_pattern": "tvm.relay.op.tensor.zeros_like({{data}})",
    "arg_mapping": {
      "input": "data"
    },
    "example_pairs": [
      {
        "torch": "x = torch.randn(2, 3); y = torch.zeros_like(x)",
        "tvm": "x = tvm.relay.op.tensor.ones((2,3), 'float32'); y = tvm.relay.op.tensor.zeros_like(x)"
      }
    ],
    "constraints": "PyTorch's `dtype`, `layout`, `device`, `pin_memory`, `memory_format` are not directly mapped at this TVM API level; TVM's `zeros_like` infers from `data`.",
    "notes": "Creates a tensor with the same shape and dtype as the input, filled with zeros.",
    "confidence": 0.95
  },
  {
    "torch_api": "torch.ones",
    "tvm_api": "tvm.relay.op.tensor.ones",
    "mapping_type": "direct",
    "direction": "torch_to_tvm",
    "torch_pattern": "torch.ones({{sizes}}, dtype={{dtype}})",
    "tvm_pattern": "tvm.relay.op.tensor.ones({{shape}}, {{dtype}})",
    "arg_mapping": {
      "sizes": "shape",
      "dtype": "dtype"
    },
    "example_pairs": [
      {
        "torch": "x = torch.ones((2, 3), dtype=torch.float32)",
        "tvm": "x = tvm.relay.op.tensor.ones((2, 3), 'float32')"
      }
    ],
    "constraints": "PyTorch's `layout`, `device`, `pin_memory` are not directly mapped at this TVM API level.",
    "notes": "Creates a tensor of the specified shape and dtype, filled with ones. This corresponds to a constant fill operation with value 1.",
    "confidence": 0.95
  },
  {
    "torch_api": "torch.ones_like",
    "tvm_api": "tvm.relay.op.tensor.ones_like",
    "mapping_type": "direct",
    "direction": "torch_to_tvm",
    "torch_pattern": "torch.ones_like({{input}})",
    "tvm_pattern": "tvm.relay.op.tensor.ones_like({{data}})",
    "arg_mapping": {
      "input": "data"
    },
    "example_pairs": [
      {
        "torch": "x = torch.randn(2, 3); y = torch.ones_like(x)",
        "tvm": "x = tvm.relay.op.tensor.zeros((2,3), 'float32'); y = tvm.relay.op.tensor.ones_like(x)"
      }
    ],
    "constraints": "PyTorch's `dtype`, `layout`, `device`, `pin_memory`, `memory_format` are not directly mapped at this TVM API level; TVM's `ones_like` infers from `data`.",
    "notes": "Creates a tensor with the same shape and dtype as the input, filled with ones.",
    "confidence": 0.95
  },
  {
    "torch_api": "torch.full",
    "tvm_api": "tvm.relay.op.transform.full",
    "mapping_type": "direct",
    "direction": "torch_to_tvm",
    "torch_pattern": "torch.full({{sizes}}, {{value}}, dtype={{dtype}})",
    "tvm_pattern": "tvm.relay.op.transform.full({{fill_value}}, shape={{shape}}, dtype={{dtype}})",
    "arg_mapping": {
      "sizes": "shape",
      "value": "fill_value",
      "dtype": "dtype"
    },
    "example_pairs": [
      {
        "torch": "x = torch.full((2, 3), 7.0, dtype=torch.float32)",
        "tvm": "x = tvm.relay.op.transform.full(tvm.relay.const(7.0, 'float32'), shape=(2, 3), dtype='float32')"
      }
    ],
    "constraints": "PyTorch's `layout`, `device`, `pin_memory` are not directly mapped at this TVM API level. The `fill_value` must be a scalar expression or a constant.",
    "notes": "Creates a tensor of the specified shape and dtype, filled with a given scalar value.",
    "confidence": 0.95
  },
  {
    "torch_api": "torch.full_like",
    "tvm_api": "tvm.relay.op.transform.full_like",
    "mapping_type": "direct",
    "direction": "torch_to_tvm",
    "torch_pattern": "torch.full_like({{input}}, {{fill_value}})",
    "tvm_pattern": "tvm.relay.op.transform.full_like({{data}}, {{fill_value}})",
    "arg_mapping": {
      "input": "data",
      "fill_value": "fill_value"
    },
    "example_pairs": [
      {
        "torch": "x = torch.randn(2, 3); y = torch.full_like(x, 7.0)",
        "tvm": "x = tvm.relay.op.tensor.zeros((2,3), 'float32'); y = tvm.relay.op.transform.full_like(x, tvm.relay.const(7.0, 'float32'))"
      }
    ],
    "constraints": "PyTorch's `dtype`, `layout`, `device`, `pin_memory`, `memory_format` are not directly mapped at this TVM API level; TVM's `full_like` infers shape/dtype from `data`. The `fill_value` must be a scalar expression or a constant.",
    "notes": "Creates a tensor with the same shape and dtype as the input, filled with a given scalar value.",
    "confidence": 0.95
  },
  {
    "torch_api": "torch.reshape",
    "tvm_api": "tvm.relay.op.transform.reshape",
    "mapping_type": "direct",
    "direction": "torch_to_tvm",
    "torch_pattern": "torch.reshape({{self}}, {{shape}})",
    "tvm_pattern": "tvm.relay.op.transform.reshape({{data}}, {{newshape}})",
    "arg_mapping": {
      "self": "data",
      "shape": "newshape"
    },
    "example_pairs": [
      {
        "torch": "result = torch.reshape(x, (2, -1, 4))",
        "tvm": "result = tvm.relay.op.transform.reshape(x, (2, -1, 4))"
      }
    ],
    "constraints": "TVM's reshape supports special values like 0 (copy) and -1 (infer dimension), similar to NumPy/PyTorch.",
    "notes": "Directly maps the tensor reshape operation. Same as API 6.",
    "confidence": 0.95
  },
  {
    "torch_api": "torch.add",
    "tvm_api": [
      "tvm.relay.op.tensor.add",
      "tvm.relay.op.tensor.mul"
    ],
    "mapping_type": "composite",
    "direction": "torch_to_tvm",
    "torch_pattern": "torch.add({{self}}, {{other}}, alpha={{alpha}})",
    "tvm_pattern": "tvm.relay.op.tensor.add({{lhs}}, tvm.relay.op.tensor.mul({{alpha}}, {{rhs}}))",
    "arg_mapping": {
      "self": "lhs",
      "other": "rhs",
      "alpha": "alpha"
    },
    "example_pairs": [
      {
        "torch": "result = torch.add(a, b, alpha=0.5)",
        "tvm": "result = tvm.relay.op.tensor.add(a, tvm.relay.op.tensor.mul(tvm.relay.const(0.5, 'float32'), b))"
      },
      {
        "torch": "result = torch.add(a, b)",
        "tvm": "result = tvm.relay.op.tensor.add(a, b)"
      }
    ],
    "constraints": "When `alpha` is not 1 (or None), it requires a multiplication before addition.",
    "notes": "PyTorch's `add` with `alpha` performs `input + alpha * other`. If `alpha` is 1 or not provided, it's a direct `add`. Otherwise, it's a composite of `mul` and `add`.",
    "confidence": 0.9
  },
  {
    "torch_api": "torch.mul",
    "tvm_api": null,
    "mapping_type": "no_mapping",
    "direction": "torch_to_tvm",
    "torch_pattern": null,
    "tvm_pattern": null,
    "arg_mapping": {},
    "example_pairs": [],
    "constraints": "Not convertible",
    "notes": "NO_MAPPING: The provided TVM `mul` (tvm.relay.qnn.op.qnn.mul) is for quantized operations. The PyTorch `aten::mul` is a general floating-point (or boolean, then maps to `and`) multiplication, which is not directly available in the provided TVM snippets as a non-quantized op (though `tvm.relay.op.tensor.multiply` or `tvm.relay.op.tensor.mul` likely exists but not in snippet).",
    "confidence": 0.2
  },
  {
    "torch_api": "torch.div",
    "tvm_api": [
      "tvm.relay.op.tensor.divide",
      "tvm.relay.op.tensor.floor_divide",
      "tvm.relay.op.tensor.trunc_divide"
    ],
    "mapping_type": "composite",
    "direction": "torch_to_tvm",
    "torch_pattern": "torch.div({{self}}, {{other}}, rounding_mode={{rounding_mode}})",
    "tvm_pattern": "tvm.relay.op.tensor.divide({{lhs}}, {{rhs}}) OR tvm.relay.op.tensor.floor_divide({{lhs}}, {{rhs}}) OR tvm.relay.op.tensor.trunc_divide({{lhs}}, {{rhs}})",
    "arg_mapping": {
      "self": "lhs",
      "other": "rhs",
      "rounding_mode": "rounding_mode"
    },
    "example_pairs": [
      {
        "torch": "result = torch.div(a, b)",
        "tvm": "result = tvm.relay.op.tensor.divide(a, b)"
      },
      {
        "torch": "result = torch.div(a, b, rounding_mode='floor')",
        "tvm": "result = tvm.relay.op.tensor.floor_divide(a, b)"
      }
    ],
    "constraints": "PyTorch's `div` handles various rounding modes. This requires conditional mapping in TVM: `true_divide` (default) to `relay.op.tensor.divide`, `floor` to `relay.op.tensor.floor_divide`, `trunc` to `relay.op.tensor.trunc_divide`.",
    "notes": "The mapping depends on the `rounding_mode` argument. The PyTorch symbolic export explicitly dispatches to internal `true_divide`, `_floor_divide`, etc.",
    "confidence": 0.9
  },
  {
    "torch_api": "torch.floor_divide",
    "tvm_api": "tvm.relay.op.tensor.trunc_divide",
    "mapping_type": "direct",
    "direction": "torch_to_tvm",
    "torch_pattern": "torch.floor_divide({{self}}, {{other}})",
    "tvm_pattern": "tvm.relay.op.tensor.trunc_divide({{lhs}}, {{rhs}})",
    "arg_mapping": {
      "self": "lhs",
      "other": "rhs"
    },
    "example_pairs": [
      {
        "torch": "result = torch.floor_divide(a, b)",
        "tvm": "result = tvm.relay.op.tensor.trunc_divide(a, b)"
      }
    ],
    "constraints": "Based on the PyTorch symbolic export's internal note, `aten::floor_divide` is 'deprecated behavior' and 'actually truncates', mapping to `_trunc_divide`. Thus, it should map to TVM's `trunc_divide` rather than `floor_divide`.",
    "notes": "Maps to TVM's truncating division, reflecting PyTorch's actual implementation behavior for `floor_divide`.",
    "confidence": 0.9
  },
  {
    "torch_api": "torch.stack",
    "tvm_api": "tvm.relay.op.tensor.stack",
    "mapping_type": "direct",
    "direction": "torch_to_tvm",
    "torch_pattern": "torch.stack({{tensor_list}}, dim={{dim}})",
    "tvm_pattern": "tvm.relay.op.tensor.stack({{data}}, axis={{axis}})",
    "arg_mapping": {
      "tensor_list": "data",
      "dim": "axis"
    },
    "example_pairs": [
      {
        "torch": "result = torch.stack([x, y, z], dim=0)",
        "tvm": "result = tvm.relay.op.tensor.stack((x, y, z), axis=0)"
      }
    ],
    "constraints": "The `tensor_list` must be a list or tuple of tensors. Empty list of tensors is not supported by TVM's stack.",
    "notes": "Directly maps the tensor stacking operation, which involves unsqueezing and concatenating along a new dimension.",
    "confidence": 0.95
  },
  {
    "torch_api": "torch.matmul",
    "tvm_api": "tvm.relay.op.nn.nn.matmul",
    "mapping_type": "direct",
    "direction": "torch_to_tvm",
    "torch_pattern": "torch.matmul({{self}}, {{other}})",
    "tvm_pattern": "tvm.relay.op.nn.nn.matmul({{tensor_a}}, {{tensor_b}})",
    "arg_mapping": {
      "self": "tensor_a",
      "other": "tensor_b"
    },
    "example_pairs": [
      {
        "torch": "result = torch.matmul(a, b)",
        "tvm": "result = tvm.relay.op.nn.nn.matmul(a, b)"
      }
    ],
    "constraints": "TVM's matmul implicitly handles broadcasting and different matrix/vector multiplication types that `torch.matmul` covers.",
    "notes": "Directly maps the matrix multiplication operation. Same as API 17.",
    "confidence": 0.95
  },
  {
    "torch_api": "torch.sqrt",
    "tvm_api": "tvm.relay.op.tensor.sqrt",
    "mapping_type": "direct",
    "direction": "torch_to_tvm",
    "torch_pattern": "torch.sqrt({{self}})",
    "tvm_pattern": "tvm.relay.op.tensor.sqrt({{data}})",
    "arg_mapping": {
      "self": "data"
    },
    "example_pairs": [
      {
        "torch": "result = torch.sqrt(x)",
        "tvm": "result = tvm.relay.op.tensor.sqrt(x)"
      }
    ],
    "constraints": "PyTorch's symbolic export includes explicit casting of integer inputs to float. This casting would be a prerequisite in TVM if integer `sqrt` is not desired or supported for `relay.op.tensor.sqrt`.",
    "notes": "Directly maps the element-wise square root function.",
    "confidence": 0.95
  },
  {
    "torch_api": "torch.rsqrt",
    "tvm_api": "tvm.relay.op.tensor.rsqrt",
    "mapping_type": "direct",
    "direction": "torch_to_tvm",
    "torch_pattern": "torch.rsqrt({{self}})",
    "tvm_pattern": "tvm.relay.op.tensor.rsqrt({{data}})",
    "arg_mapping": {
      "self": "data"
    },
    "example_pairs": [
      {
        "torch": "result = torch.rsqrt(x)",
        "tvm": "result = tvm.relay.op.tensor.rsqrt(x)"
      }
    ],
    "constraints": "None. TVM's `rsqrt` directly computes the reciprocal square root.",
    "notes": "Directly maps the element-wise reciprocal square root function.",
    "confidence": 0.95
  },
  {
    "torch_api": "torch.tanh",
    "tvm_api": "tvm.relay.op.tensor.tanh",
    "mapping_type": "direct",
    "direction": "torch_to_tvm",
    "torch_pattern": "torch.tanh({{self}})",
    "tvm_pattern": "tvm.relay.op.tensor.tanh({{data}})",
    "arg_mapping": {
      "self": "data"
    },
    "example_pairs": [
      {
        "torch": "result = torch.tanh(x)",
        "tvm": "result = tvm.relay.op.tensor.tanh(x)"
      }
    ],
    "constraints": "None. TVM's `tanh` directly computes the hyperbolic tangent.",
    "notes": "Directly maps the element-wise hyperbolic tangent function.",
    "confidence": 0.95
  },
  {
    "torch_api": "torch.sin",
    "tvm_api": "tvm.relay.op.tensor.sin",
    "mapping_type": "direct",
    "direction": "torch_to_tvm",
    "torch_pattern": "torch.sin({{self}})",
    "tvm_pattern": "tvm.relay.op.tensor.sin({{data}})",
    "arg_mapping": {
      "self": "data"
    },
    "example_pairs": [
      {
        "torch": "result = torch.sin(x)",
        "tvm": "result = tvm.relay.op.tensor.sin(x)"
      }
    ],
    "constraints": "None. TVM's `sin` directly computes the sine function.",
    "notes": "Directly maps the element-wise sine function.",
    "confidence": 0.95
  },
  {
    "torch_api": "torch.cos",
    "tvm_api": "tvm.relay.op.tensor.cos",
    "mapping_type": "direct",
    "direction": "torch_to_tvm",
    "torch_pattern": "torch.cos({{self}})",
    "tvm_pattern": "tvm.relay.op.tensor.cos({{data}})",
    "arg_mapping": {
      "self": "data"
    },
    "example_pairs": [
      {
        "torch": "result = torch.cos(x)",
        "tvm": "result = tvm.relay.op.tensor.cos(x)"
      }
    ],
    "constraints": "None. TVM's `cos` directly computes the cosine function.",
    "notes": "Directly maps the element-wise cosine function.",
    "confidence": 0.95
  },
  {
    "torch_api": "torch.tan",
    "tvm_api": "tvm.relay.op.tensor.tan",
    "mapping_type": "direct",
    "direction": "torch_to_tvm",
    "torch_pattern": "torch.tan({{self}})",
    "tvm_pattern": "tvm.relay.op.tensor.tan({{data}})",
    "arg_mapping": {
      "self": "data"
    },
    "example_pairs": [
      {
        "torch": "result = torch.tan(x)",
        "tvm": "result = tvm.relay.op.tensor.tan(x)"
      }
    ],
    "constraints": "None. TVM's `tan` directly computes the tangent function.",
    "notes": "Directly maps the element-wise tangent function.",
    "confidence": 0.95
  },
  {
    "torch_api": "torch.asin",
    "tvm_api": "tvm.relay.op.tensor.asin",
    "mapping_type": "direct",
    "direction": "torch_to_tvm",
    "torch_pattern": "torch.asin({{self}})",
    "tvm_pattern": "tvm.relay.op.tensor.asin({{data}})",
    "arg_mapping": {
      "self": "data"
    },
    "example_pairs": [
      {
        "torch": "result = torch.asin(x)",
        "tvm": "result = tvm.relay.op.tensor.asin(x)"
      }
    ],
    "constraints": "None. TVM's `asin` directly computes the arc sine function.",
    "notes": "Directly maps the element-wise arc sine function.",
    "confidence": 0.95
  },
  {
    "torch_api": "torch.acos",
    "tvm_api": "tvm.relay.op.tensor.acos",
    "mapping_type": "direct",
    "direction": "torch_to_tvm",
    "torch_pattern": "torch.acos({{self}})",
    "tvm_pattern": "tvm.relay.op.tensor.acos({{data}})",
    "arg_mapping": {
      "self": "data"
    },
    "example_pairs": [
      {
        "torch": "result = torch.acos(x)",
        "tvm": "result = tvm.relay.op.tensor.acos(x)"
      }
    ],
    "constraints": "None. TVM's `acos` directly computes the arc cosine function.",
    "notes": "Directly maps the element-wise arc cosine function.",
    "confidence": 0.95
  },
  {
    "torch_api": "torch.atan",
    "tvm_api": "tvm.relay.op.tensor.atan",
    "mapping_type": "direct",
    "direction": "torch_to_tvm",
    "torch_pattern": "torch.atan({{self}})",
    "tvm_pattern": "tvm.relay.op.tensor.atan({{data}})",
    "arg_mapping": {
      "self": "data"
    },
    "example_pairs": [
      {
        "torch": "result = torch.atan(x)",
        "tvm": "result = tvm.relay.op.tensor.atan(x)"
      }
    ],
    "constraints": "None. TVM's `atan` directly computes the arc tangent function.",
    "notes": "Directly maps the element-wise arc tangent function.",
    "confidence": 0.95
  },
  {
    "torch_api": "torch.atan2",
    "tvm_api": "tvm.tir.op.atan2",
    "mapping_type": "direct",
    "direction": "torch_to_tvm",
    "torch_pattern": "torch.atan2({{self}}, {{other}})",
    "tvm_pattern": "tvm.tir.op.atan2({{x1}}, {{x2}})",
    "arg_mapping": {
      "self": "x1",
      "other": "x2"
    },
    "example_pairs": [
      {
        "torch": "result = torch.atan2(y_coords, x_coords)",
        "tvm": "result = tvm.tir.op.atan2(y_coords, x_coords)"
      }
    ],
    "constraints": "TVM's `tir.op.atan2` is a primitive operator. While the PyTorch symbolic export shows a complex subgraph for ONNX compatibility (handling quadrants), the conceptual mathematical function is a direct match.",
    "notes": "Maps the 2-argument arc tangent function.",
    "confidence": 0.9
  },
  {
    "torch_api": "torch.sigmoid",
    "tvm_api": "tvm.relay.op.tensor.sigmoid",
    "mapping_type": "direct",
    "direction": "torch_to_tvm",
    "torch_pattern": "torch.sigmoid({{self}})",
    "tvm_pattern": "tvm.relay.op.tensor.sigmoid({{data}})",
    "arg_mapping": {
      "self": "data"
    },
    "example_pairs": [
      {
        "torch": "result = torch.sigmoid(x)",
        "tvm": "result = tvm.relay.op.tensor.sigmoid(x)"
      }
    ],
    "constraints": "None. TVM's `sigmoid` directly computes the sigmoid function.",
    "notes": "Directly maps the element-wise sigmoid function.",
    "confidence": 0.95
  },
  {
    "torch_api": "torch.sign",
    "tvm_api": "tvm.relay.op.tensor.sign",
    "mapping_type": "direct",
    "direction": "torch_to_tvm",
    "torch_pattern": "torch.sign({{self}})",
    "tvm_pattern": "tvm.relay.op.tensor.sign({{data}})",
    "arg_mapping": {
      "self": "data"
    },
    "example_pairs": [
      {
        "torch": "result = torch.sign(x)",
        "tvm": "result = tvm.relay.op.tensor.sign(x)"
      }
    ],
    "constraints": "None. TVM's `sign` directly computes the sign of each element.",
    "notes": "Directly maps the element-wise sign function.",
    "confidence": 0.95
  },
  {
    "torch_api": "torch.cumsum",
    "tvm_api": "tvm.relay.op.transform.cumsum",
    "mapping_type": "direct",
    "direction": "torch_to_tvm",
    "torch_pattern": "torch.cumsum({{input}}, dim={{dim}}, dtype={{dtype}})",
    "tvm_pattern": "tvm.relay.op.transform.cumsum({{data}}, axis={{axis}}, dtype={{dtype}}, exclusive=False)",
    "arg_mapping": {
      "input": "data",
      "dim": "axis",
      "dtype": "dtype"
    },
    "example_pairs": [
      {
        "torch": "result = torch.cumsum(x, dim=0, dtype=torch.float32)",
        "tvm": "result = tvm.relay.op.transform.cumsum(x, axis=0, dtype='float32', exclusive=False)"
      }
    ],
    "constraints": "TVM's `cumsum` has an `exclusive` parameter (default `False`), corresponding to PyTorch's inclusive `cumsum`. PyTorch's symbolic export indicates specific ONNX opset limitations, but functionally, TVM's `cumsum` is a direct match.",
    "notes": "Directly maps the cumulative sum operation.",
    "confidence": 0.9
  },
  {
    "torch_api": "torch.broadcast_to",
    "tvm_api": "tvm.relay.op.transform.broadcast_to",
    "mapping_type": "direct",
    "direction": "torch_to_tvm",
    "torch_pattern": "torch.broadcast_to({{self}}, {{size}})",
    "tvm_pattern": "tvm.relay.op.transform.broadcast_to({{data}}, {{shape}})",
    "arg_mapping": {
      "self": "data",
      "size": "shape"
    },
    "example_pairs": [
      {
        "torch": "result = torch.broadcast_to(x, (3, 4, 5))",
        "tvm": "result = tvm.relay.op.transform.broadcast_to(x, (3, 4, 5))"
      }
    ],
    "constraints": "The `size` argument should be a tuple or list of integers representing the target shape. PyTorch's symbolic export handles `-1` for unchanged dimensions and converting lists, which would be pre-processed before calling the TVM op.",
    "notes": "Directly maps the NumPy-style broadcasting operation.",
    "confidence": 0.95
  },
  {
    "torch_api": "torch.transpose",
    "tvm_api": "tvm.relay.op.transform.transpose",
    "mapping_type": "composite",
    "direction": "torch_to_tvm",
    "torch_pattern": "torch.transpose({{self}}, {{dim0}}, {{dim1}})",
    "tvm_pattern": "tvm.relay.op.transform.transpose({{data}}, axes={{axes}})",
    "arg_mapping": {
      "self": "data",
      "dim0": "calculated_dim0_idx",
      "dim1": "calculated_dim1_idx"
    },
    "example_pairs": [
      {
        "torch": "result = torch.transpose(x, 0, 1)",
        "tvm": "# For input of rank R, construct axes = list(range(R)), then swap axes[0] and axes[1]\naxes = list(range(len(x.shape)))\naxes[0], axes[1] = axes[1], axes[0]\nresult = tvm.relay.op.transform.transpose(x, axes=axes)"
      }
    ],
    "constraints": "PyTorch's `transpose` swaps two specific dimensions. TVM's `transpose` requires a full permutation of axes. A helper logic is needed to construct the `axes` list by swapping `dim0` and `dim1` in the original dimension order.",
    "notes": "Requires a pre-computation of the `axes` permutation list for `tvm.relay.op.transform.transpose` based on the input tensor's rank and the two dimensions to be swapped.",
    "confidence": 0.8
  },
  {
    "torch_api": "torch.split",
    "tvm_api": "tvm.relay.op.transform.split",
    "mapping_type": "direct",
    "direction": "torch_to_tvm",
    "torch_pattern": "torch.split({{self}}, {{split_size_or_sizes}}, dim={{dim}})",
    "tvm_pattern": "tvm.relay.op.transform.split({{data}}, {{indices_or_sections}}, axis={{axis}})",
    "arg_mapping": {
      "self": "data",
      "split_size_or_sizes": "indices_or_sections",
      "dim": "axis"
    },
    "example_pairs": [
      {
        "torch": "result = torch.split(x, 2, dim=0)",
        "tvm": "result = tvm.relay.op.transform.split(x, 2, axis=0)"
      }
    ],
    "constraints": "Supports static split sizes or sections. PyTorch's opset 9 symbolic export explicitly states 'Dynamic number of outputs not supported' and 'Unknown dimension size not supported', making it align with TVM's static split behavior.",
    "notes": "Same as API 1, confirming direct mapping under static constraints.",
    "confidence": 0.95
  },
  {
    "torch_api": "torch.unbind",
    "tvm_api": "tvm.relay.frontend.common.unbind",
    "mapping_type": "direct",
    "direction": "torch_to_tvm",
    "torch_pattern": "torch.unbind({{self}}, dim={{dim}})",
    "tvm_pattern": "tvm.relay.frontend.common.unbind({{data}}, axis={{axis}})",
    "arg_mapping": {
      "self": "data",
      "dim": "axis"
    },
    "example_pairs": [
      {
        "torch": "tensors = torch.unbind(x, dim=0)",
        "tvm": "tensors = tvm.relay.frontend.common.unbind(x, axis=0)"
      }
    ],
    "constraints": "PyTorch's opset 9 symbolic export explicitly states 'Dynamic number of outputs not supported', implying `_outputs` must be statically known. This aligns with TVM's functional expectation.",
    "notes": "Same as API 2, confirming direct mapping under static constraints.",
    "confidence": 0.95
  },
  {
    "torch_api": "torch.squeeze",
    "tvm_api": "tvm.relay.op.transform.squeeze",
    "mapping_type": "direct",
    "direction": "torch_to_tvm",
    "torch_pattern": "torch.squeeze({{self}}, dim={{dim}})",
    "tvm_pattern": "tvm.relay.op.transform.squeeze({{data}}, axis={{axis}})",
    "arg_mapping": {
      "self": "data",
      "dim": "axis"
    },
    "example_pairs": [
      {
        "torch": "result = torch.squeeze(x)",
        "tvm": "result = tvm.relay.op.transform.squeeze(x)"
      },
      {
        "torch": "result = torch.squeeze(x, dim=0)",
        "tvm": "result = tvm.relay.op.transform.squeeze(x, axis=0)"
      }
    ],
    "constraints": "If a specified `axis` has dimension greater than 1, an error is raised (PyTorch and TVM behavior). Negative dimensions are handled by calculating absolute index based on rank.",
    "notes": "Directly maps the operation to remove single-dimensional entries from the shape.",
    "confidence": 0.95
  },
  {
    "torch_api": "torch.prelu",
    "tvm_api": "tvm.relay.op.nn.nn.prelu",
    "mapping_type": "direct",
    "direction": "torch_to_tvm",
    "torch_pattern": "torch.prelu({{self}}, {{weight}})",
    "tvm_pattern": "tvm.relay.op.nn.nn.prelu({{data}}, {{alpha}}, axis={{axis}})",
    "arg_mapping": {
      "self": "data",
      "weight": "alpha"
    },
    "example_pairs": [
      {
        "torch": "result = torch.prelu(x, alpha_tensor)",
        "tvm": "result = tvm.relay.op.nn.nn.prelu(x, alpha_tensor, axis=1)"
      }
    ],
    "constraints": "TVM's `prelu` has an `axis` parameter (default 1) for channel-wise alpha. PyTorch's `weight` (`alpha`) broadcasting behavior should align, or custom `axis` might be needed.",
    "notes": "Directly maps the PReLU activation function. Same as API 18.",
    "confidence": 0.9
  },
  {
    "torch_api": "torch.relu",
    "tvm_api": "tvm.relay.op.nn.nn.relu",
    "mapping_type": "direct",
    "direction": "torch_to_tvm",
    "torch_pattern": "torch.relu({{input}})",
    "tvm_pattern": "tvm.relay.op.nn.nn.relu({{data}})",
    "arg_mapping": {
      "input": "data"
    },
    "example_pairs": [
      {
        "torch": "result = torch.relu(x)",
        "tvm": "result = tvm.relay.op.nn.nn.relu(x)"
      }
    ],
    "constraints": "None. TVM's `relu` directly computes `max(x, 0)`.",
    "notes": "Directly maps the ReLU activation function.",
    "confidence": 0.95
  },
  {
    "torch_api": "torch.ceil",
    "tvm_api": "tvm.relay.op.tensor.ceil",
    "mapping_type": "direct",
    "direction": "torch_to_tvm",
    "torch_pattern": "torch.ceil({{input}})",
    "tvm_pattern": "tvm.relay.op.tensor.ceil({{data}})",
    "arg_mapping": {
      "input": "data"
    },
    "example_pairs": [
      {
        "torch": "result = torch.ceil(x)",
        "tvm": "result = tvm.relay.op.tensor.ceil(x)"
      }
    ],
    "constraints": "None. TVM's `ceil` directly computes the element-wise ceiling.",
    "notes": "Directly maps the element-wise ceiling function.",
    "confidence": 0.95
  },
  {
    "torch_api": "torch.floor",
    "tvm_api": "tvm.relay.op.tensor.floor",
    "mapping_type": "direct",
    "direction": "torch_to_tvm",
    "torch_pattern": "torch.floor({{input}})",
    "tvm_pattern": "tvm.relay.op.tensor.floor({{data}})",
    "arg_mapping": {
      "input": "data"
    },
    "example_pairs": [
      {
        "torch": "result = torch.floor(x)",
        "tvm": "result = tvm.relay.op.tensor.floor(x)"
      }
    ],
    "constraints": "None. TVM's `floor` directly computes the element-wise floor.",
    "notes": "Directly maps the element-wise floor function.",
    "confidence": 0.95
  },
  {
    "torch_api": "torch.leaky_relu",
    "tvm_api": "tvm.relay.op.nn.nn.leaky_relu",
    "mapping_type": "direct",
    "direction": "torch_to_tvm",
    "torch_pattern": "torch.leaky_relu({{input}}, negative_slope={{negative_slope}}, inplace={{inplace}})",
    "tvm_pattern": "tvm.relay.op.nn.nn.leaky_relu({{data}}, alpha={{alpha}})",
    "arg_mapping": {
      "input": "data",
      "negative_slope": "alpha"
    },
    "example_pairs": [
      {
        "torch": "result = torch.leaky_relu(x, 0.1)",
        "tvm": "result = tvm.relay.op.nn.nn.leaky_relu(x, alpha=0.1)"
      }
    ],
    "constraints": "The `inplace` parameter in PyTorch is an optimization hint and is not directly mapped as an operator argument in TVM Relay, which focuses on functional graph representation.",
    "notes": "Directly maps the Leaky ReLU activation function.",
    "confidence": 0.95
  },
  {
    "torch_api": "torch.softmax",
    "tvm_api": "tvm.relay.op.nn.nn.softmax",
    "mapping_type": "direct",
    "direction": "torch_to_tvm",
    "torch_pattern": "torch.softmax({{input}}, dim={{dim}}, dtype={{dtype}})",
    "tvm_pattern": "tvm.relay.op.nn.nn.softmax({{data}}, axis={{axis}})",
    "arg_mapping": {
      "input": "data",
      "dim": "axis"
    },
    "example_pairs": [
      {
        "torch": "result = torch.softmax(x, dim=1)",
        "tvm": "result = tvm.relay.op.nn.nn.softmax(x, axis=1)"
      }
    ],
    "constraints": "The `dtype` argument in PyTorch is for specifying the output data type (if different from input), which might require an explicit `cast` operation in TVM if needed. TVM's `softmax` `axis` directly corresponds to PyTorch's `dim`.",
    "notes": "Directly maps the softmax activation. PyTorch's symbolic export might add transposes for ONNX compatibility, but TVM's native op can handle any axis.",
    "confidence": 0.95
  },
  {
    "torch_api": "torch.pad",
    "tvm_api": "tvm.relay.op.nn.nn.pad",
    "mapping_type": "direct",
    "direction": "torch_to_tvm",
    "torch_pattern": "torch.pad({{input}}, {{pad}}, mode={{mode}}, value={{value}})",
    "tvm_pattern": "tvm.relay.op.nn.nn.pad({{data}}, {{pad_width}}, pad_value={{pad_value}}, pad_mode={{pad_mode}})",
    "arg_mapping": {
      "input": "data",
      "pad": "pad_width",
      "mode": "pad_mode",
      "value": "pad_value"
    },
    "example_pairs": [
      {
        "torch": "result = torch.pad(x, (1, 1, 2, 2), mode='constant', value=0)",
        "tvm": "result = tvm.relay.op.nn.nn.pad(x, ((0,0),(2,2),(1,1),(1,1)), pad_value=0.0, pad_mode='constant') # Pad width format is ((before_N, after_N), ...)"
      }
    ],
    "constraints": "TVM's `pad_width` format is `((before_1, after_1), ..., (before_N, after_N))` for N dimensions, which needs to be constructed from PyTorch's `pad` argument (which is usually `(padding_left, padding_right, padding_top, padding_bottom, ...)`). TVM's `pad_mode` directly supports 'constant', 'edge', 'reflect'. 'circular' mode (supported by PyTorch) is not directly available in TVM's `pad` op.",
    "notes": "Directly maps common padding modes. `pad_width` construction needs care for multi-dimensional padding.",
    "confidence": 0.85
  },
  {
    "torch_api": "torch.bitwise_not",
    "tvm_api": "tvm.relay.op.tensor.logical_not",
    "mapping_type": "direct",
    "direction": "torch_to_tvm",
    "torch_pattern": "torch.bitwise_not({{input}})",
    "tvm_pattern": "tvm.relay.op.tensor.logical_not({{data}})",
    "arg_mapping": {
      "input": "data"
    },
    "example_pairs": [
      {
        "torch": "result = torch.bitwise_not(bool_tensor)",
        "tvm": "result = tvm.relay.op.tensor.logical_not(bool_tensor)"
      }
    ],
    "constraints": "The PyTorch symbolic export explicitly restricts `bitwise_not` to boolean inputs, mapping it to ONNX `Not`. TVM's `relay.op.tensor.logical_not` is the equivalent for boolean tensors. For non-boolean (integer) inputs, it's a `no_mapping` based on PyTorch's explicit restriction.",
    "notes": "Maps to logical NOT for boolean tensors, aligning with PyTorch's ONNX export behavior.",
    "confidence": 0.8
  },
  {
    "torch_api": "torch.bitwise_or",
    "tvm_api": "tvm.relay.op.tensor.logical_or",
    "mapping_type": "direct",
    "direction": "torch_to_tvm",
    "torch_pattern": "torch.bitwise_or({{self}}, {{other}})",
    "tvm_pattern": "tvm.relay.op.tensor.logical_or({{lhs}}, {{rhs}})",
    "arg_mapping": {
      "self": "lhs",
      "other": "rhs"
    },
    "example_pairs": [
      {
        "torch": "result = torch.bitwise_or(bool_a, bool_b)",
        "tvm": "result = tvm.relay.op.tensor.logical_or(bool_a, bool_b)"
      }
    ],
    "constraints": "The PyTorch symbolic export explicitly restricts `bitwise_or` to boolean inputs, mapping it to ONNX `Or`. TVM's `relay.op.tensor.logical_or` is the equivalent for boolean tensors. For non-boolean (integer) inputs, it's a `no_mapping` based on PyTorch's explicit restriction.",
    "notes": "Maps to logical OR for boolean tensors, aligning with PyTorch's ONNX export behavior.",
    "confidence": 0.8
  },
  {
    "torch_api": "torch.logical_and",
    "tvm_api": "tvm.relay.op.tensor.logical_and",
    "mapping_type": "direct",
    "direction": "torch_to_tvm",
    "torch_pattern": "torch.logical_and({{input}}, {{other}})",
    "tvm_pattern": "tvm.relay.op.tensor.logical_and({{lhs}}, {{rhs}})",
    "arg_mapping": {
      "input": "lhs",
      "other": "rhs"
    },
    "example_pairs": [
      {
        "torch": "result = torch.logical_and(a, b)",
        "tvm": "result = tvm.relay.op.tensor.logical_and(a, b)"
      }
    ],
    "constraints": "PyTorch's symbolic export will cast inputs to Bool before applying logical AND.",
    "notes": "Directly maps the element-wise logical AND operation for boolean tensors.",
    "confidence": 0.95
  },
  {
    "torch_api": "torch.logical_or",
    "tvm_api": "tvm.relay.op.tensor.logical_or",
    "mapping_type": "direct",
    "direction": "torch_to_tvm",
    "torch_pattern": "torch.logical_or({{input}}, {{other}})",
    "tvm_pattern": "tvm.relay.op.tensor.logical_or({{lhs}}, {{rhs}})",
    "arg_mapping": {
      "input": "lhs",
      "other": "rhs"
    },
    "example_pairs": [
      {
        "torch": "result = torch.logical_or(a, b)",
        "tvm": "result = tvm.relay.op.tensor.logical_or(a, b)"
      }
    ],
    "constraints": "PyTorch's symbolic export will cast inputs to Bool before applying logical OR.",
    "notes": "Directly maps the element-wise logical OR operation for boolean tensors.",
    "confidence": 0.95
  },
  {
    "torch_api": "torch.logical_xor",
    "tvm_api": "tvm.relay.op.tensor.logical_xor",
    "mapping_type": "direct",
    "direction": "torch_to_tvm",
    "torch_pattern": "torch.logical_xor({{input}}, {{other}})",
    "tvm_pattern": "tvm.relay.op.tensor.logical_xor({{lhs}}, {{rhs}})",
    "arg_mapping": {
      "input": "lhs",
      "other": "rhs"
    },
    "example_pairs": [
      {
        "torch": "result = torch.logical_xor(a, b)",
        "tvm": "result = tvm.relay.op.tensor.logical_xor(a, b)"
      }
    ],
    "constraints": "PyTorch's symbolic export will cast inputs to Bool before applying logical XOR.",
    "notes": "Directly maps the element-wise logical XOR operation for boolean tensors.",
    "confidence": 0.95
  },
  {
    "torch_api": "torch.logical_not",
    "tvm_api": "tvm.relay.op.tensor.logical_not",
    "mapping_type": "direct",
    "direction": "torch_to_tvm",
    "torch_pattern": "torch.logical_not({{input}})",
    "tvm_pattern": "tvm.relay.op.tensor.logical_not({{data}})",
    "arg_mapping": {
      "input": "data"
    },
    "example_pairs": [
      {
        "torch": "result = torch.logical_not(a)",
        "tvm": "result = tvm.relay.op.tensor.logical_not(a)"
      }
    ],
    "constraints": "PyTorch's symbolic export will cast inputs to Bool before applying logical NOT.",
    "notes": "Directly maps the element-wise logical NOT operation for boolean tensors.",
    "confidence": 0.95
  },
  {
    "torch_api": "torch.where",
    "tvm_api": "tvm.relay.op.transform.where",
    "mapping_type": "direct",
    "direction": "torch_to_tvm",
    "torch_pattern": "torch.where({{condition}}, {{self}}, {{other}})",
    "tvm_pattern": "tvm.relay.op.transform.where({{condition}}, {{x}}, {{y}})",
    "arg_mapping": {
      "condition": "condition",
      "self": "x",
      "other": "y"
    },
    "example_pairs": [
      {
        "torch": "result = torch.where(cond, a, b)",
        "tvm": "result = tvm.relay.op.transform.where(cond, a, b)"
      }
    ],
    "constraints": "Assumes `self` and `other` are provided. The PyTorch case where `self is None` (acting like `nonzero`) is not covered by this direct mapping. PyTorch's symbolic export includes explicit casting of the condition to Bool.",
    "notes": "Maps the primary functionality of PyTorch's `where` for element-wise selection based on a condition. Same as API 3.",
    "confidence": 0.95
  },
  {
    "torch_api": "torch.log_softmax",
    "tvm_api": "tvm.relay.op.nn.nn.log_softmax",
    "mapping_type": "direct",
    "direction": "torch_to_tvm",
    "torch_pattern": "torch.log_softmax({{input}}, dim={{dim}}, dtype={{dtype}})",
    "tvm_pattern": "tvm.relay.op.nn.nn.log_softmax({{data}}, axis={{axis}})",
    "arg_mapping": {
      "input": "data",
      "dim": "axis"
    },
    "example_pairs": [
      {
        "torch": "result = torch.log_softmax(x, dim=1)",
        "tvm": "result = tvm.relay.op.nn.nn.log_softmax(x, axis=1)"
      }
    ],
    "constraints": "The `dtype` argument in PyTorch is for specifying the output data type (if different from input), which might require an explicit `cast` operation in TVM if needed. TVM's `log_softmax` `axis` directly corresponds to PyTorch's `dim`.",
    "notes": "Directly maps the log softmax activation. PyTorch's symbolic export might add transposes for ONNX compatibility, but TVM's native op can handle any axis.",
    "confidence": 0.95
  },
  {
    "torch_api": "torch.onnx._internal.torchscript_exporter.symbolic_opset9.conv1d",
    "tvm_api": "tvm.relay.op.nn.nn.conv1d",
    "mapping_type": "direct",
    "direction": "torch_to_tvm",
    "torch_pattern": "conv1d({{input}}, {{weight}}, bias={{bias}}, stride={{stride}}, padding={{padding}}, dilation={{dilation}}, groups={{groups}})",
    "tvm_pattern": "tvm.relay.op.nn.nn.conv1d({{data}}, {{weight}}, strides={{strides}}, padding={{padding}}, dilation={{dilation}}, groups={{groups}})",
    "arg_mapping": {
      "input": "data",
      "weight": "weight",
      "stride": "strides",
      "padding": "padding",
      "dilation": "dilation",
      "groups": "groups",
      "bias": "N/A (separate op needed for bias)"
    },
    "example_pairs": [
      {
        "torch": "out = torch.conv1d(input_tensor, weight_tensor, stride=1, padding=0, dilation=1, groups=1)",
        "tvm": "out = tvm.relay.op.nn.nn.conv1d(input_tensor_tvm, weight_tensor_tvm, strides=1, padding=0, dilation=1, groups=1)"
      }
    ],
    "constraints": "PyTorch's 'bias' argument is not directly part of TVM's 'conv1d' operator; it would typically be a separate add operation in Relay. PyTorch's 'padding' can be a string ('valid', 'same') which needs conversion to numeric padding values for TVM.",
    "notes": "Maps the 1D convolution operation. Bias handling requires an additional 'add' operation in TVM Relay. 'padding' string values like 'valid'/'same' need to be resolved to numerical padding.",
    "confidence": 0.9
  },
  {
    "torch_api": "torch.onnx._internal.torchscript_exporter.symbolic_opset9.conv2d",
    "tvm_api": "tvm.relay.op.nn.nn.conv2d",
    "mapping_type": "direct",
    "direction": "torch_to_tvm",
    "torch_pattern": "conv2d({{input}}, {{weight}}, bias={{bias}}, stride={{stride}}, padding={{padding}}, dilation={{dilation}}, groups={{groups}})",
    "tvm_pattern": "tvm.relay.op.nn.nn.conv2d({{data}}, {{weight}}, strides={{strides}}, padding={{padding}}, dilation={{dilation}}, groups={{groups}})",
    "arg_mapping": {
      "input": "data",
      "weight": "weight",
      "stride": "strides",
      "padding": "padding",
      "dilation": "dilation",
      "groups": "groups",
      "bias": "N/A (separate op needed for bias)"
    },
    "example_pairs": [
      {
        "torch": "out = torch.conv2d(input_tensor, weight_tensor, stride=(1,1), padding=(0,0), dilation=(1,1), groups=1)",
        "tvm": "out = tvm.relay.op.nn.nn.conv2d(input_tensor_tvm, weight_tensor_tvm, strides=(1,1), padding=(0,0), dilation=(1,1), groups=1)"
      }
    ],
    "constraints": "PyTorch's 'bias' argument is not directly part of TVM's 'conv2d' operator; it would typically be a separate add operation in Relay. PyTorch's 'padding' can be a string ('valid', 'same') which needs conversion to numeric padding values for TVM.",
    "notes": "Maps the 2D convolution operation. Bias handling requires an additional 'add' operation in TVM Relay. 'padding' string values like 'valid'/'same' need to be resolved to numerical padding.",
    "confidence": 0.9
  },
  {
    "torch_api": "torch.onnx._internal.torchscript_exporter.symbolic_opset9.conv3d",
    "tvm_api": "tvm.relay.op.nn.nn.conv3d",
    "mapping_type": "direct",
    "direction": "torch_to_tvm",
    "torch_pattern": "conv3d({{input}}, {{weight}}, bias={{bias}}, stride={{stride}}, padding={{padding}}, dilation={{dilation}}, groups={{groups}})",
    "tvm_pattern": "tvm.relay.op.nn.nn.conv3d({{data}}, {{weight}}, strides={{strides}}, padding={{padding}}, dilation={{dilation}}, groups={{groups}})",
    "arg_mapping": {
      "input": "data",
      "weight": "weight",
      "stride": "strides",
      "padding": "padding",
      "dilation": "dilation",
      "groups": "groups",
      "bias": "N/A (separate op needed for bias)"
    },
    "example_pairs": [
      {
        "torch": "out = torch.conv3d(input_tensor, weight_tensor, stride=(1,1,1), padding=(0,0,0), dilation=(1,1,1), groups=1)",
        "tvm": "out = tvm.relay.op.nn.nn.conv3d(input_tensor_tvm, weight_tensor_tvm, strides=(1,1,1), padding=(0,0,0), dilation=(1,1,1), groups=1)"
      }
    ],
    "constraints": "PyTorch's 'bias' argument is not directly part of TVM's 'conv3d' operator; it would typically be a separate add operation in Relay. PyTorch's 'padding' can be a string ('valid', 'same') which needs conversion to numeric padding values for TVM.",
    "notes": "Maps the 3D convolution operation. Bias handling requires an additional 'add' operation in TVM Relay. 'padding' string values like 'valid'/'same' need to be resolved to numerical padding.",
    "confidence": 0.9
  },
  {
    "torch_api": "torch.onnx._internal.torchscript_exporter.symbolic_opset9.batch_norm",
    "tvm_api": "tvm.relay.op.nn.nn.batch_norm",
    "mapping_type": "direct",
    "direction": "torch_to_tvm",
    "torch_pattern": "batch_norm({{input}}, {{weight}}, {{bias}}, {{running_mean}}, {{running_var}}, training={{training}}, momentum={{momentum}}, eps={{eps}}, cudnn_enabled={{cudnn_enabled}})",
    "tvm_pattern": "tvm.relay.op.nn.nn.batch_norm({{data}}, {{gamma}}, {{beta}}, {{moving_mean}}, {{moving_var}}, axis=1, epsilon={{epsilon}}, center=True, scale=True)",
    "arg_mapping": {
      "input": "data",
      "weight": "gamma",
      "bias": "beta",
      "running_mean": "moving_mean",
      "running_var": "moving_var",
      "eps": "epsilon",
      "training": "N/A (handled by context)",
      "momentum": "N/A",
      "cudnn_enabled": "N/A"
    },
    "example_pairs": [
      {
        "torch": "out = torch.batch_norm(input_tensor, weight_tensor, bias_tensor, running_mean_tensor, running_var_tensor, training=False, momentum=0.1, eps=1e-5)",
        "tvm": "out = tvm.relay.op.nn.nn.batch_norm(input_tensor_tvm, weight_tensor_tvm, bias_tensor_tvm, running_mean_tensor_tvm, running_var_tensor_tvm, epsilon=1e-5)"
      }
    ],
    "constraints": "TVM's batch_norm primarily represents the inference mode. The 'training', 'momentum', and 'cudnn_enabled' parameters from PyTorch are not directly mapped. TVM's 'axis' defaults to 1 (channel dimension), which is common for PyTorch's NCHW layout.",
    "notes": "Maps batch normalization. PyTorch's training-related parameters are not directly exposed in the TVM Relay operator, assuming inference mode. 'gamma' and 'beta' correspond to PyTorch's 'weight' and 'bias'.",
    "confidence": 0.95
  },
  {
    "torch_api": "torch.onnx._internal.torchscript_exporter.symbolic_opset9.layer_norm",
    "tvm_api": "tvm.relay.op.nn.nn.layer_norm",
    "mapping_type": "direct",
    "direction": "torch_to_tvm",
    "torch_pattern": "layer_norm({{input}}, {{normalized_shape}}, {{weight}}, {{bias}}, {{eps}}, cudnn_enable={{cudnn_enable}})",
    "tvm_pattern": "tvm.relay.op.nn.nn.layer_norm({{data}}, {{gamma}}, {{beta}}, axis={{axis}}, epsilon={{epsilon}}, center=True, scale=True)",
    "arg_mapping": {
      "input": "data",
      "weight": "gamma",
      "bias": "beta",
      "eps": "epsilon",
      "normalized_shape": "axis (requires conversion)",
      "cudnn_enable": "N/A"
    },
    "example_pairs": [
      {
        "torch": "out = torch.layer_norm(input_tensor, (10, 20), weight_tensor, bias_tensor, 1e-5)",
        "tvm": "out = tvm.relay.op.nn.nn.layer_norm(input_tensor_tvm, weight_tensor_tvm, bias_tensor_tvm, axis=[-2, -1], epsilon=1e-5)"
      }
    ],
    "constraints": "PyTorch's 'normalized_shape' needs to be converted to a specific 'axis' (or tuple of axes) for TVM's 'layer_norm'. 'cudnn_enable' is not directly mapped. TVM's 'center' and 'scale' default to True, matching PyTorch's typical behavior with weight and bias.",
    "notes": "Maps layer normalization. The 'normalized_shape' from PyTorch determines the axes over which normalization is applied in TVM.",
    "confidence": 0.95
  },
  {
    "torch_api": "torch.onnx._internal.torchscript_exporter.symbolic_opset9.instance_norm",
    "tvm_api": "tvm.relay.op.nn.nn.instance_norm",
    "mapping_type": "direct",
    "direction": "torch_to_tvm",
    "torch_pattern": "instance_norm({{input}}, {{weight}}, {{bias}}, {{running_mean}}, {{running_var}}, use_input_stats={{use_input_stats}}, momentum={{momentum}}, eps={{eps}}, cudnn_enabled={{cudnn_enabled}})",
    "tvm_pattern": "tvm.relay.op.nn.nn.instance_norm({{data}}, {{gamma}}, {{beta}}, axis=1, epsilon={{epsilon}}, center=True, scale=True)",
    "arg_mapping": {
      "input": "data",
      "weight": "gamma",
      "bias": "beta",
      "eps": "epsilon",
      "running_mean": "N/A",
      "running_var": "N/A",
      "use_input_stats": "N/A",
      "momentum": "N/A",
      "cudnn_enabled": "N/A"
    },
    "example_pairs": [
      {
        "torch": "out = torch.instance_norm(input_tensor, weight_tensor, bias_tensor, None, None, True, 0.1, 1e-5, True)",
        "tvm": "out = tvm.relay.op.nn.nn.instance_norm(input_tensor_tvm, weight_tensor_tvm, bias_tensor_tvm, epsilon=1e-5)"
      }
    ],
    "constraints": "TVM's instance_norm in Relay is typically for inference. PyTorch's 'running_mean', 'running_var', 'use_input_stats', 'momentum', and 'cudnn_enabled' are not directly mapped. TVM's 'axis' defaults to 1 (channel dimension), which is common. 'center' and 'scale' default to True, matching PyTorch's behavior with weight and bias.",
    "notes": "Maps instance normalization. Similar to batch_norm, training-specific parameters are not directly mapped.",
    "confidence": 0.9
  },
  {
    "torch_api": "torch.onnx._internal.torchscript_exporter.symbolic_opset9.abs",
    "tvm_api": "tvm.relay.op.tensor.abs",
    "mapping_type": "direct",
    "direction": "torch_to_tvm",
    "torch_pattern": "abs({{self}})",
    "tvm_pattern": "tvm.relay.op.tensor.abs({{data}})",
    "arg_mapping": {
      "self": "data"
    },
    "example_pairs": [
      {
        "torch": "out = torch.abs(input_tensor)",
        "tvm": "out = tvm.relay.op.tensor.abs(input_tensor_tvm)"
      }
    ],
    "constraints": "",
    "notes": "Maps the element-wise absolute value operation.",
    "confidence": 0.98
  },
  {
    "torch_api": "torch.onnx._internal.torchscript_exporter.symbolic_opset9.log",
    "tvm_api": "tvm.relay.op.tensor.log",
    "mapping_type": "direct",
    "direction": "torch_to_tvm",
    "torch_pattern": "log({{self}})",
    "tvm_pattern": "tvm.relay.op.tensor.log({{data}})",
    "arg_mapping": {
      "self": "data"
    },
    "example_pairs": [
      {
        "torch": "out = torch.log(input_tensor)",
        "tvm": "out = tvm.relay.op.tensor.log(input_tensor_tvm)"
      }
    ],
    "constraints": "",
    "notes": "Maps the element-wise natural logarithm operation.",
    "confidence": 0.98
  },
  {
    "torch_api": "torch.onnx._internal.torchscript_exporter.symbolic_opset9.log1p",
    "tvm_api": [
      "tvm.relay.op.tensor.log",
      "tvm.relay.op.tensor.add"
    ],
    "mapping_type": "composite",
    "direction": "torch_to_tvm",
    "torch_pattern": "log1p({{self}})",
    "tvm_pattern": "tvm.relay.op.tensor.log(tvm.relay.op.tensor.add({{data}}, tvm.relay.const(1.0, dtype={{data.dtype}})))",
    "arg_mapping": {
      "self": "data"
    },
    "example_pairs": [
      {
        "torch": "out = torch.log1p(input_tensor)",
        "tvm": "out = tvm.relay.op.tensor.log(tvm.relay.op.tensor.add(input_tensor_tvm, tvm.relay.const(1.0, dtype=input_tensor_tvm.dtype)))"
      }
    ],
    "constraints": "Requires data type of the constant 1.0 to match the input tensor's data type. PyTorch's ONNX exporter implements log1p as log(1 + x).",
    "notes": "Maps the log(1+x) operation by composing `add` and `log`. There isn't a direct high-level Relay operator `log1p` in the provided snippets, but TVM's TIR has a direct `log1p` intrinsic.",
    "confidence": 0.85
  },
  {
    "torch_api": "torch.onnx._internal.torchscript_exporter.symbolic_opset9.log10",
    "tvm_api": "tvm.relay.op.tensor.log10",
    "mapping_type": "direct",
    "direction": "torch_to_tvm",
    "torch_pattern": "log10({{self}})",
    "tvm_pattern": "tvm.relay.op.tensor.log10({{data}})",
    "arg_mapping": {
      "self": "data"
    },
    "example_pairs": [
      {
        "torch": "out = torch.log10(input_tensor)",
        "tvm": "out = tvm.relay.op.tensor.log10(input_tensor_tvm)"
      }
    ],
    "constraints": "",
    "notes": "Maps the element-wise base-10 logarithm operation. Although PyTorch's ONNX exporter uses a composite (log(x) / log(10)), TVM Relay has a direct 'log10' operator.",
    "confidence": 0.98
  },
  {
    "torch_api": "torch.onnx._internal.torchscript_exporter.symbolic_opset9.max",
    "tvm_api": "tvm.relay.op.reduce.max",
    "mapping_type": "direct",
    "direction": "torch_to_tvm",
    "torch_pattern": "max({{self}}, dim={{dim}}, keepdim={{keepdim}})",
    "tvm_pattern": "tvm.relay.op.reduce.max({{data}}, axis={{axis}}, keepdims={{keepdims}})",
    "arg_mapping": {
      "self": "data",
      "dim": "axis",
      "keepdim": "keepdims"
    },
    "example_pairs": [
      {
        "torch": "out = torch.max(input_tensor, dim=1, keepdim=True)",
        "tvm": "out = tvm.relay.op.reduce.max(input_tensor_tvm, axis=1, keepdims=True)"
      }
    ],
    "constraints": "This mapping is for the reduction form of torch.max (e.g., max over a dimension). The element-wise form (torch.max(x, y)) is handled by torch.maximum -> tvm.relay.op.tensor.maximum.",
    "notes": "Maps the reduction operation for finding the maximum value along specified dimensions.",
    "confidence": 0.9
  },
  {
    "torch_api": "torch.onnx._internal.torchscript_exporter.symbolic_opset9.maximum",
    "tvm_api": "tvm.relay.op.tensor.maximum",
    "mapping_type": "direct",
    "direction": "torch_to_tvm",
    "torch_pattern": "maximum({{input}}, {{other}})",
    "tvm_pattern": "tvm.relay.op.tensor.maximum({{lhs}}, {{rhs}})",
    "arg_mapping": {
      "input": "lhs",
      "other": "rhs"
    },
    "example_pairs": [
      {
        "torch": "out = torch.maximum(input_tensor_a, input_tensor_b)",
        "tvm": "out = tvm.relay.op.tensor.maximum(input_tensor_a_tvm, input_tensor_b_tvm)"
      }
    ],
    "constraints": "",
    "notes": "Maps the element-wise maximum operation, supporting broadcasting.",
    "confidence": 0.98
  },
  {
    "torch_api": "torch.onnx._internal.torchscript_exporter.symbolic_opset9.min",
    "tvm_api": "tvm.relay.op.reduce.min",
    "mapping_type": "direct",
    "direction": "torch_to_tvm",
    "torch_pattern": "min({{self}}, dim={{dim}}, keepdim={{keepdim}})",
    "tvm_pattern": "tvm.relay.op.reduce.min({{data}}, axis={{axis}}, keepdims={{keepdims}})",
    "arg_mapping": {
      "self": "data",
      "dim": "axis",
      "keepdim": "keepdims"
    },
    "example_pairs": [
      {
        "torch": "out = torch.min(input_tensor, dim=1, keepdim=True)",
        "tvm": "out = tvm.relay.op.reduce.min(input_tensor_tvm, axis=1, keepdims=True)"
      }
    ],
    "constraints": "This mapping is for the reduction form of torch.min (e.g., min over a dimension). The element-wise form (torch.min(x, y)) is handled by torch.minimum -> tvm.relay.op.tensor.minimum.",
    "notes": "Maps the reduction operation for finding the minimum value along specified dimensions.",
    "confidence": 0.9
  },
  {
    "torch_api": "torch.onnx._internal.torchscript_exporter.symbolic_opset9.minimum",
    "tvm_api": "tvm.relay.op.tensor.minimum",
    "mapping_type": "direct",
    "direction": "torch_to_tvm",
    "torch_pattern": "minimum({{input}}, {{other}})",
    "tvm_pattern": "tvm.relay.op.tensor.minimum({{lhs}}, {{rhs}})",
    "arg_mapping": {
      "input": "lhs",
      "other": "rhs"
    },
    "example_pairs": [
      {
        "torch": "out = torch.minimum(input_tensor_a, input_tensor_b)",
        "tvm": "out = tvm.relay.op.tensor.minimum(input_tensor_a_tvm, input_tensor_b_tvm)"
      }
    ],
    "constraints": "",
    "notes": "Maps the element-wise minimum operation, supporting broadcasting.",
    "confidence": 0.98
  },
  {
    "torch_api": "torch.onnx._internal.torchscript_exporter.symbolic_opset9.exp",
    "tvm_api": "tvm.relay.op.tensor.exp",
    "mapping_type": "direct",
    "direction": "torch_to_tvm",
    "torch_pattern": "exp({{self}})",
    "tvm_pattern": "tvm.relay.op.tensor.exp({{data}})",
    "arg_mapping": {
      "self": "data"
    },
    "example_pairs": [
      {
        "torch": "out = torch.exp(input_tensor)",
        "tvm": "out = tvm.relay.op.tensor.exp(input_tensor_tvm)"
      }
    ],
    "constraints": "",
    "notes": "Maps the element-wise exponential function.",
    "confidence": 0.98
  },
  {
    "torch_api": "torch.onnx._internal.torchscript_exporter.symbolic_opset9.dropout",
    "tvm_api": "tvm.relay.op.nn.nn.dropout",
    "mapping_type": "direct",
    "direction": "torch_to_tvm",
    "torch_pattern": "dropout({{input}}, p={{p}}, train={{train}})",
    "tvm_pattern": "tvm.relay.op.nn.nn.dropout({{data}}, rate={{rate}})",
    "arg_mapping": {
      "input": "data",
      "p": "rate",
      "train": "N/A (conditional behavior)"
    },
    "example_pairs": [
      {
        "torch": "out = torch.dropout(input_tensor, p=0.5, train=True)",
        "tvm": "out = tvm.relay.op.nn.nn.dropout(input_tensor_tvm, rate=0.5)"
      }
    ],
    "constraints": "This mapping assumes 'train' is True. If 'train' is False, PyTorch's dropout is a no-op, which would map to an identity operation in TVM Relay or be optimized away. TVM's 'dropout' operator represents the behavior of applying dropout.",
    "notes": "Maps the dropout operation. The 'train' parameter in PyTorch determines if dropout is applied or if it's an identity operation.",
    "confidence": 0.9
  },
  {
    "torch_api": "torch.onnx._internal.torchscript_exporter.symbolic_opset9.empty",
    "tvm_api": "tvm.relay.op.tensor.zeros",
    "mapping_type": "composite",
    "direction": "torch_to_tvm",
    "torch_pattern": "empty({{sizes}}, dtype={{dtype}}, layout={{layout}}, device={{device}}, pin_memory={{pin_memory}}, memory_format={{memory_format}})",
    "tvm_pattern": "tvm.relay.op.tensor.zeros(shape={{shape}}, dtype={{dtype}})",
    "arg_mapping": {
      "sizes": "shape",
      "dtype": "dtype",
      "layout": "N/A",
      "device": "N/A",
      "pin_memory": "N/A",
      "memory_format": "N/A"
    },
    "example_pairs": [
      {
        "torch": "out = torch.empty((2, 3), dtype=torch.float32)",
        "tvm": "out = tvm.relay.op.tensor.zeros(shape=(2, 3), dtype='float32')"
      }
    ],
    "constraints": "PyTorch's symbolic `empty` explicitly calls `zeros` for ONNX export, implying it produces a zero-filled tensor. TVM's `tvm.runtime.ndarray.empty` creates uninitialized memory but is a runtime API, not a graph operator. Therefore, mapping to `zeros` is based on PyTorch's ONNX export behavior.",
    "notes": "Maps the creation of an empty tensor by assuming it's initialized to zeros, based on PyTorch's ONNX export implementation. Other parameters like layout, device, pin_memory are not directly mapped in Relay graph ops.",
    "confidence": 0.8
  },
  {
    "torch_api": "torch.onnx._internal.torchscript_exporter.symbolic_opset9.zeros",
    "tvm_api": "tvm.relay.op.tensor.zeros",
    "mapping_type": "direct",
    "direction": "torch_to_tvm",
    "torch_pattern": "zeros({{sizes}}, dtype={{dtype}}, layout={{layout}}, device={{device}}, pin_memory={{pin_memory}})",
    "tvm_pattern": "tvm.relay.op.tensor.zeros(shape={{shape}}, dtype={{dtype}})",
    "arg_mapping": {
      "sizes": "shape",
      "dtype": "dtype",
      "layout": "N/A",
      "device": "N/A",
      "pin_memory": "N/A"
    },
    "example_pairs": [
      {
        "torch": "out = torch.zeros((2, 3), dtype=torch.float32)",
        "tvm": "out = tvm.relay.op.tensor.zeros(shape=(2, 3), dtype='float32')"
      }
    ],
    "constraints": "Layout, device, and pin_memory parameters are not directly mapped in TVM Relay graph operators.",
    "notes": "Maps the creation of a tensor filled with zeros.",
    "confidence": 0.95
  },
  {
    "torch_api": "torch.onnx._internal.torchscript_exporter.symbolic_opset9.zeros_like",
    "tvm_api": "tvm.relay.op.tensor.zeros_like",
    "mapping_type": "direct",
    "direction": "torch_to_tvm",
    "torch_pattern": "zeros_like({{input}}, dtype={{dtype}}, layout={{layout}}, device={{device}}, pin_memory={{pin_memory}}, memory_format={{memory_format}})",
    "tvm_pattern": "tvm.relay.op.tensor.zeros_like({{data}})",
    "arg_mapping": {
      "input": "data",
      "dtype": "N/A (inferred from data)",
      "layout": "N/A",
      "device": "N/A",
      "pin_memory": "N/A",
      "memory_format": "N/A"
    },
    "example_pairs": [
      {
        "torch": "out = torch.zeros_like(input_tensor)",
        "tvm": "out = tvm.relay.op.tensor.zeros_like(input_tensor_tvm)"
      }
    ],
    "constraints": "TVM's 'zeros_like' infers the dtype from the input 'data', unlike PyTorch which allows an explicit 'dtype' override. Other parameters are not directly mapped.",
    "notes": "Maps the creation of a tensor filled with zeros, with the same shape and dtype as a given input tensor.",
    "confidence": 0.9
  },
  {
    "torch_api": "torch.onnx._internal.torchscript_exporter.symbolic_opset9.ones",
    "tvm_api": "tvm.relay.op.tensor.ones",
    "mapping_type": "direct",
    "direction": "torch_to_tvm",
    "torch_pattern": "ones({{sizes}}, dtype={{dtype}}, layout={{layout}}, device={{device}}, pin_memory={{pin_memory}})",
    "tvm_pattern": "tvm.relay.op.tensor.ones(shape={{shape}}, dtype={{dtype}})",
    "arg_mapping": {
      "sizes": "shape",
      "dtype": "dtype",
      "layout": "N/A",
      "device": "N/A",
      "pin_memory": "N/A"
    },
    "example_pairs": [
      {
        "torch": "out = torch.ones((2, 3), dtype=torch.float32)",
        "tvm": "out = tvm.relay.op.tensor.ones(shape=(2, 3), dtype='float32')"
      }
    ],
    "constraints": "Layout, device, and pin_memory parameters are not directly mapped in TVM Relay graph operators.",
    "notes": "Maps the creation of a tensor filled with ones.",
    "confidence": 0.95
  },
  {
    "torch_api": "torch.onnx._internal.torchscript_exporter.symbolic_opset9.ones_like",
    "tvm_api": "tvm.relay.op.tensor.ones_like",
    "mapping_type": "direct",
    "direction": "torch_to_tvm",
    "torch_pattern": "ones_like({{input}}, dtype={{dtype}}, layout={{layout}}, device={{device}}, pin_memory={{pin_memory}}, memory_format={{memory_format}})",
    "tvm_pattern": "tvm.relay.op.tensor.ones_like({{data}})",
    "arg_mapping": {
      "input": "data",
      "dtype": "N/A (inferred from data)",
      "layout": "N/A",
      "device": "N/A",
      "pin_memory": "N/A",
      "memory_format": "N/A"
    },
    "example_pairs": [
      {
        "torch": "out = torch.ones_like(input_tensor)",
        "tvm": "out = tvm.relay.op.tensor.ones_like(input_tensor_tvm)"
      }
    ],
    "constraints": "TVM's 'ones_like' infers the dtype from the input 'data', unlike PyTorch which allows an explicit 'dtype' override. Other parameters are not directly mapped.",
    "notes": "Maps the creation of a tensor filled with ones, with the same shape and dtype as a given input tensor.",
    "confidence": 0.9
  },
  {
    "torch_api": "torch.onnx._internal.torchscript_exporter.symbolic_opset9.full",
    "tvm_api": "tvm.relay.op.transform.full",
    "mapping_type": "direct",
    "direction": "torch_to_tvm",
    "torch_pattern": "full({{sizes}}, {{value}}, dtype={{dtype}}, layout={{layout}}, device={{device}}, pin_memory={{pin_memory}})",
    "tvm_pattern": "tvm.relay.op.transform.full(fill_value={{fill_value}}, shape={{shape}}, dtype={{dtype}})",
    "arg_mapping": {
      "sizes": "shape",
      "value": "fill_value",
      "dtype": "dtype",
      "layout": "N/A",
      "device": "N/A",
      "pin_memory": "N/A"
    },
    "example_pairs": [
      {
        "torch": "out = torch.full((2, 3), 42.0, dtype=torch.float32)",
        "tvm": "out = tvm.relay.op.transform.full(fill_value=tvm.relay.const(42.0, 'float32'), shape=(2, 3), dtype='float32')"
      }
    ],
    "constraints": "TVM's 'fill_value' must be a Relay expression (e.g., a constant). Layout, device, and pin_memory parameters are not directly mapped. PyTorch handles cases where 'value' is not a constant by using a composite 'zeros' + 'add'. This mapping assumes 'value' can be represented as a TVM constant.",
    "notes": "Maps the creation of a tensor filled with a specified scalar value. The fill value in TVM needs to be a Relay expression.",
    "confidence": 0.9
  },
  {
    "torch_api": "torch.onnx._internal.torchscript_exporter.symbolic_opset9.full_like",
    "tvm_api": "tvm.relay.op.transform.full_like",
    "mapping_type": "direct",
    "direction": "torch_to_tvm",
    "torch_pattern": "full_like({{input}}, {{fill_value}}, dtype={{dtype}}, layout={{layout}}, device={{device}}, pin_memory={{pin_memory}}, memory_format={{memory_format}})",
    "tvm_pattern": "tvm.relay.op.transform.full_like({{data}}, fill_value={{fill_value}})",
    "arg_mapping": {
      "input": "data",
      "fill_value": "fill_value",
      "dtype": "N/A (inferred from data)",
      "layout": "N/A",
      "device": "N/A",
      "pin_memory": "N/A",
      "memory_format": "N/A"
    },
    "example_pairs": [
      {
        "torch": "out = torch.full_like(input_tensor, 42.0)",
        "tvm": "out = tvm.relay.op.transform.full_like(input_tensor_tvm, fill_value=tvm.relay.const(42.0, input_tensor_tvm.dtype))"
      }
    ],
    "constraints": "TVM's 'full_like' infers the dtype from the input 'data', unlike PyTorch which allows an explicit 'dtype' override. Other parameters are not directly mapped. TVM's 'fill_value' must be a Relay expression (e.g., a constant).",
    "notes": "Maps the creation of a tensor filled with a scalar value, with the same shape and dtype as a given input tensor.",
    "confidence": 0.9
  },
  {
    "torch_api": "torch.onnx._internal.torchscript_exporter.symbolic_opset9.hardswish",
    "tvm_api": null,
    "mapping_type": "no_mapping",
    "direction": "torch_to_tvm",
    "torch_pattern": null,
    "tvm_pattern": null,
    "arg_mapping": {},
    "example_pairs": [],
    "constraints": "Not convertible to a direct non-quantized Relay operator based on provided snippets. PyTorch's symbolic op is a composite of 'hardsigmoid' and 'mul'.",
    "notes": "NO_MAPPING: Only a quantized 'hardswish' operator (`tvm.relay.qnn.op.qnn.hardswish`) is available in the provided TVM snippets. A non-quantized version would require a composite of 'hardsigmoid' and 'mul', but a non-quantized 'hardsigmoid' Relay op is not provided.",
    "confidence": 0.4
  },
  {
    "torch_api": "torch.onnx._internal.torchscript_exporter.symbolic_opset9.sort",
    "tvm_api": "tvm.relay.op.algorithm.sort",
    "mapping_type": "direct",
    "direction": "torch_to_tvm",
    "torch_pattern": "sort({{self}}, dim={{dim}}, descending={{descending}}, out={{out}})",
    "tvm_pattern": "tvm.relay.op.algorithm.sort({{data}}, axis={{axis}}, is_ascend={{is_ascend}})",
    "arg_mapping": {
      "self": "data",
      "dim": "axis",
      "descending": "is_ascend (inverted)",
      "out": "N/A"
    },
    "example_pairs": [
      {
        "torch": "sorted_values, sorted_indices = torch.sort(input_tensor, dim=-1, descending=True)",
        "tvm": "sorted_values = tvm.relay.op.algorithm.sort(input_tensor_tvm, axis=-1, is_ascend=False)"
      }
    ],
    "constraints": "TVM's `relay.op.algorithm.sort` typically returns only the sorted values, unlike PyTorch's `sort` which returns both sorted values and their indices. For indices, a separate `argsort` or `topk` with `ret_type='indices'` would be needed. The 'out' parameter is not supported.",
    "notes": "Maps the sorting operation. The `descending` boolean needs to be inverted for `is_ascend`. Returns only sorted values.",
    "confidence": 0.8
  },
  {
    "torch_api": "torch.onnx._internal.torchscript_exporter.symbolic_opset9.topk",
    "tvm_api": "tvm.relay.op.algorithm.topk",
    "mapping_type": "direct",
    "direction": "torch_to_tvm",
    "torch_pattern": "topk({{self}}, k={{k}}, dim={{dim}}, largest={{largest}}, sorted={{sorted}}, out={{out}})",
    "tvm_pattern": "tvm.relay.op.algorithm.topk({{data}}, k={{k_val}}, axis={{axis}}, ret_type=\"both\", is_ascend={{is_ascend}}, dtype=\"int32\")",
    "arg_mapping": {
      "self": "data",
      "k": "k_val",
      "dim": "axis",
      "largest": "is_ascend (inverted)",
      "sorted": "N/A (TVM output is always sorted by default, order controlled by is_ascend)",
      "out": "N/A"
    },
    "example_pairs": [
      {
        "torch": "values, indices = torch.topk(input_tensor, k=3, dim=-1, largest=True, sorted=True)",
        "tvm": "values_indices_tuple = tvm.relay.op.algorithm.topk(input_tensor_tvm, k=3, axis=-1, ret_type=\"both\", is_ascend=False, dtype=\"int32\")"
      }
    ],
    "constraints": "PyTorch's 'largest' boolean needs to be inverted for TVM's 'is_ascend'. TVM's `topk` outputs a tuple when `ret_type='both'`. The 'sorted' parameter in PyTorch is implicitly handled by TVM's `topk` which outputs sorted results. The 'out' parameter is not supported.",
    "notes": "Maps the top-k elements selection operation, returning both values and indices.",
    "confidence": 0.9
  },
  {
    "torch_api": "torch.onnx._internal.torchscript_exporter.symbolic_opset9.lstm",
    "tvm_api": null,
    "mapping_type": "no_mapping",
    "direction": "torch_to_tvm",
    "torch_pattern": null,
    "tvm_pattern": null,
    "arg_mapping": {},
    "example_pairs": [],
    "constraints": "Not convertible to a direct Relay operator based on provided snippets.",
    "notes": "NO_MAPPING: `aten::lstm` is a complex high-level RNN operation in PyTorch. The provided TVM candidates only include `tvm.topi.nn.lstm`, which is a Tensor Expression (TE) level implementation. A direct mapping to a high-level Relay operator is not available in the snippets.",
    "confidence": 0.3
  },
  {
    "torch_api": "torch.onnx._internal.torchscript_exporter.symbolic_opset9.rand",
    "tvm_api": null,
    "mapping_type": "no_mapping",
    "direction": "torch_to_tvm",
    "torch_pattern": null,
    "tvm_pattern": null,
    "arg_mapping": {},
    "example_pairs": [],
    "constraints": "Not convertible to a Relay graph operator for random number generation.",
    "notes": "NO_MAPPING: The `tvm.relay.testing.__init__.rand` is a utility for creating numpy-backed NDArrays for testing, not a Relay graph operator for generating random numbers as part of a computation graph. No direct `relay.op` for uniform random generation is provided.",
    "confidence": 0.4
  },
  {
    "torch_api": "torch.onnx._internal.torchscript_exporter.symbolic_opset9.erf",
    "tvm_api": "tvm.relay.op.tensor.erf",
    "mapping_type": "direct",
    "direction": "torch_to_tvm",
    "torch_pattern": "erf({{input}})",
    "tvm_pattern": "tvm.relay.op.tensor.erf({{data}})",
    "arg_mapping": {
      "input": "data"
    },
    "example_pairs": [
      {
        "torch": "out = torch.erf(input_tensor)",
        "tvm": "out = tvm.relay.op.tensor.erf(input_tensor_tvm)"
      }
    ],
    "constraints": "",
    "notes": "Maps the element-wise error function.",
    "confidence": 0.98
  },
  {
    "torch_api": "torch.onnx._internal.torchscript_exporter.symbolic_opset9.flatten",
    "tvm_api": "tvm.topi.nn.flatten",
    "mapping_type": "direct",
    "direction": "torch_to_tvm",
    "torch_pattern": "flatten({{input}}, start_dim={{start_dim}}, end_dim={{end_dim}})",
    "tvm_pattern": "tvm.topi.nn.flatten({{data}})",
    "arg_mapping": {
      "input": "data",
      "start_dim": "N/A (implies 1)",
      "end_dim": "N/A (implies -1)"
    },
    "example_pairs": [
      {
        "torch": "out = torch.flatten(input_tensor, start_dim=1, end_dim=-1)",
        "tvm": "out = tvm.topi.nn.flatten(input_tensor_tvm)"
      }
    ],
    "constraints": "TVM's `topi.nn.flatten` specifically flattens all dimensions after the first (batch dimension) into a single dimension, resulting in a 2D tensor. This corresponds to `torch.flatten(input, start_dim=1, end_dim=-1)`. More general `start_dim` and `end_dim` values in PyTorch's `flatten` would require `tvm.relay.op.transform.reshape`.",
    "notes": "Maps the common case of flattening a tensor into a 2D shape `(batch, C*H*W)`. For more flexible flattening, `reshape` is typically used.",
    "confidence": 0.85
  },
  {
    "torch_api": "torch.onnx._internal.torchscript_exporter.symbolic_opset9.isnan",
    "tvm_api": "tvm.relay.op.tensor.isnan",
    "mapping_type": "direct",
    "direction": "torch_to_tvm",
    "torch_pattern": "isnan({{input}})",
    "tvm_pattern": "tvm.relay.op.tensor.isnan({{data}})",
    "arg_mapping": {
      "input": "data"
    },
    "example_pairs": [
      {
        "torch": "out = torch.isnan(input_tensor)",
        "tvm": "out = tvm.relay.op.tensor.isnan(input_tensor_tvm)"
      }
    ],
    "constraints": "",
    "notes": "Maps the element-wise 'is NaN' check.",
    "confidence": 0.98
  },
  {
    "torch_api": "torch.onnx._internal.torchscript_exporter.symbolic_opset9.argmax",
    "tvm_api": "tvm.relay.op.reduce.argmax",
    "mapping_type": "direct",
    "direction": "torch_to_tvm",
    "torch_pattern": "argmax({{input}}, dim={{dim}}, keepdim={{keepdim}})",
    "tvm_pattern": "tvm.relay.op.reduce.argmax({{data}}, axis={{axis}}, keepdims={{keepdims}}, select_last_index=False)",
    "arg_mapping": {
      "input": "data",
      "dim": "axis",
      "keepdim": "keepdims"
    },
    "example_pairs": [
      {
        "torch": "out = torch.argmax(input_tensor, dim=1, keepdim=True)",
        "tvm": "out = tvm.relay.op.reduce.argmax(input_tensor_tvm, axis=1, keepdims=True, select_last_index=False)"
      }
    ],
    "constraints": "TVM's 'select_last_index' parameter defaults to False, which matches PyTorch's default behavior of returning the first index in case of ties.",
    "notes": "Maps the operation to find the index of the maximum value along an axis.",
    "confidence": 0.95
  },
  {
    "torch_api": "torch.onnx._internal.torchscript_exporter.symbolic_opset9.argmin",
    "tvm_api": "tvm.relay.op.reduce.argmin",
    "mapping_type": "direct",
    "direction": "torch_to_tvm",
    "torch_pattern": "argmin({{input}}, dim={{dim}}, keepdim={{keepdim}})",
    "tvm_pattern": "tvm.relay.op.reduce.argmin({{data}}, axis={{axis}}, keepdims={{keepdims}}, select_last_index=False)",
    "arg_mapping": {
      "input": "data",
      "dim": "axis",
      "keepdim": "keepdims"
    },
    "example_pairs": [
      {
        "torch": "out = torch.argmin(input_tensor, dim=1, keepdim=True)",
        "tvm": "out = tvm.relay.op.reduce.argmin(input_tensor_tvm, axis=1, keepdims=True, select_last_index=False)"
      }
    ],
    "constraints": "TVM's 'select_last_index' parameter defaults to False, which matches PyTorch's default behavior of returning the first index in case of ties.",
    "notes": "Maps the operation to find the index of the minimum value along an axis.",
    "confidence": 0.95
  },
  {
    "torch_api": "torch.onnx._internal.torchscript_exporter.symbolic_opset9.scatter",
    "tvm_api": "tvm.relay.op.transform.scatter",
    "mapping_type": "direct",
    "direction": "torch_to_tvm",
    "torch_pattern": "scatter({{self}}, {{dim}}, {{index}}, {{src}})",
    "tvm_pattern": "tvm.relay.op.transform.scatter(data={{data}}, indices={{indices}}, updates={{updates}}, axis={{axis}})",
    "arg_mapping": {
      "self": "data",
      "dim": "axis",
      "index": "indices",
      "src": "updates"
    },
    "example_pairs": [
      {
        "torch": "out = torch.scatter(data_tensor, 0, index_tensor, src_tensor)",
        "tvm": "out = tvm.relay.op.transform.scatter(data=data_tensor_tvm, indices=index_tensor_tvm, updates=src_tensor_tvm, axis=0)"
      }
    ],
    "constraints": "PyTorch's 'src' can be a scalar, which is handled by expanding it to match 'index' shape. TVM's 'updates' must be a tensor. The behavior for scalar 'src' needs explicit expansion in TVM if applicable.",
    "notes": "Maps the scatter operation, updating elements of a tensor at specified indices.",
    "confidence": 0.9
  },
  {
    "torch_api": "torch.onnx._internal.torchscript_exporter.symbolic_opset9.scatter_add",
    "tvm_api": "tvm.relay.op.transform.scatter_add",
    "mapping_type": "direct",
    "direction": "torch_to_tvm",
    "torch_pattern": "scatter_add({{self}}, {{dim}}, {{index}}, {{src}})",
    "tvm_pattern": "tvm.relay.op.transform.scatter_add(data={{data}}, indices={{indices}}, updates={{updates}}, axis={{axis}})",
    "arg_mapping": {
      "self": "data",
      "dim": "axis",
      "index": "indices",
      "src": "updates"
    },
    "example_pairs": [
      {
        "torch": "out = torch.scatter_add(data_tensor, 0, index_tensor, src_tensor)",
        "tvm": "out = tvm.relay.op.transform.scatter_add(data=data_tensor_tvm, indices=index_tensor_tvm, updates=src_tensor_tvm, axis=0)"
      }
    ],
    "constraints": "PyTorch's symbolic `scatter_add` is implemented as a composite of `zeros_like`, `scatter`, and `add`, but TVM has a direct `scatter_add` operator. Input validation or type casting logic in PyTorch's exporter might need consideration.",
    "notes": "Maps the scatter_add operation, adding elements from 'updates' to 'data' at specified indices.",
    "confidence": 0.95
  },
  {
    "torch_api": "torch.onnx._internal.torchscript_exporter.symbolic_opset9.log2",
    "tvm_api": "tvm.relay.op.tensor.log2",
    "mapping_type": "direct",
    "direction": "torch_to_tvm",
    "torch_pattern": "log2({{self}})",
    "tvm_pattern": "tvm.relay.op.tensor.log2({{data}})",
    "arg_mapping": {
      "self": "data"
    },
    "example_pairs": [
      {
        "torch": "out = torch.log2(input_tensor)",
        "tvm": "out = tvm.relay.op.tensor.log2(input_tensor_tvm)"
      }
    ],
    "constraints": "",
    "notes": "Maps the element-wise base-2 logarithm operation. Although PyTorch's ONNX exporter uses a composite (log(x) / log(2)), TVM Relay has a direct 'log2' operator.",
    "confidence": 0.98
  },
  {
    "torch_api": "torch.onnx._internal.torchscript_exporter.symbolic_opset9.one_hot",
    "tvm_api": "tvm.relay.op.transform.one_hot",
    "mapping_type": "direct",
    "direction": "torch_to_tvm",
    "torch_pattern": "one_hot({{self}}, {{num_classes}})",
    "tvm_pattern": "tvm.relay.op.transform.one_hot(indices={{indices}}, on_value={{on_value}}, off_value={{off_value}}, depth={{depth}}, axis={{axis}}, dtype={{dtype}})",
    "arg_mapping": {
      "self": "indices",
      "num_classes": "depth",
      "on_value": "tvm.relay.const(1, dtype={{indices.dtype}})",
      "off_value": "tvm.relay.const(0, dtype={{indices.dtype}})",
      "axis": "-1",
      "dtype": "N/A (inferred from indices or explicit)"
    },
    "example_pairs": [
      {
        "torch": "out = torch.one_hot(index_tensor, num_classes=5)",
        "tvm": "out = tvm.relay.op.transform.one_hot(indices=index_tensor_tvm, on_value=tvm.relay.const(1, dtype=index_tensor_tvm.dtype), off_value=tvm.relay.const(0, dtype=index_tensor_tvm.dtype), depth=5, axis=-1, dtype=index_tensor_tvm.dtype)"
      }
    ],
    "constraints": "TVM's `one_hot` requires explicit `on_value`, `off_value`, `axis`, and `dtype` parameters. PyTorch's ONNX export implicitly uses `[0, 1]` for values and `axis_i=-1`. The `dtype` for TVM would need to be inferred or explicitly specified, typically matching the `indices` dtype or the desired output type.",
    "notes": "Maps the one-hot encoding operation. Implicit values and axis in PyTorch's ONNX export need to be made explicit for TVM.",
    "confidence": 0.85
  },
  {
    "torch_api": "torch.onnx._internal.torchscript_exporter.symbolic_opset9.gather",
    "tvm_api": "tvm.relay.op.transform.gather",
    "mapping_type": "direct",
    "direction": "torch_to_tvm",
    "torch_pattern": "gather({{self}}, {{dim}}, {{index}}, sparse_grad={{sparse_grad}})",
    "tvm_pattern": "tvm.relay.op.transform.gather(data={{data}}, axis={{axis}}, indices={{indices}})",
    "arg_mapping": {
      "self": "data",
      "dim": "axis",
      "index": "indices",
      "sparse_grad": "N/A"
    },
    "example_pairs": [
      {
        "torch": "out = torch.gather(data_tensor, 1, index_tensor)",
        "tvm": "out = tvm.relay.op.transform.gather(data=data_tensor_tvm, axis=1, indices=index_tensor_tvm)"
      }
    ],
    "constraints": "PyTorch's ONNX exporter uses a complex composite involving `OneHot`, `Cast`, `Mul`, `ReduceSum` to implement `gather`, possibly due to ONNX opset limitations. TVM's `gather` is a direct operator. The `sparse_grad` parameter is not mapped.",
    "notes": "Maps the gather operation, extracting elements along an axis using indices.",
    "confidence": 0.9
  },
  {
    "torch_api": "torch.onnx._internal.torchscript_exporter.symbolic_opset9.std",
    "tvm_api": "tvm.relay.op.reduce.std",
    "mapping_type": "direct",
    "direction": "torch_to_tvm",
    "torch_pattern": "std({{input}}, dim={{dim}}, correction={{correction}}, keepdim={{keepdim}})",
    "tvm_pattern": "tvm.relay.op.reduce.std({{data}}, axis={{axis}}, keepdims={{keepdims}}, unbiased={{unbiased}})",
    "arg_mapping": {
      "input": "data",
      "dim": "axis",
      "keepdim": "keepdims",
      "correction": "unbiased (true if correction=1, false if correction=0)"
    },
    "example_pairs": [
      {
        "torch": "out = torch.std(input_tensor, dim=1, correction=1, keepdim=False)",
        "tvm": "out = tvm.relay.op.reduce.std(input_tensor_tvm, axis=1, keepdims=False, unbiased=True)"
      }
    ],
    "constraints": "PyTorch's `std` typically takes `unbiased=True` as default (corresponding to `correction=1`). The mapping of `correction` to `unbiased` requires checking the default behavior of PyTorch's `std` regarding biased/unbiased calculation.",
    "notes": "Maps the standard deviation reduction operation. The `correction` parameter in PyTorch corresponds to `unbiased` in TVM.",
    "confidence": 0.9
  },
  {
    "torch_api": "torch.onnx._internal.torchscript_exporter.symbolic_opset9.var",
    "tvm_api": null,
    "mapping_type": "no_mapping",
    "direction": "torch_to_tvm",
    "torch_pattern": null,
    "tvm_pattern": null,
    "arg_mapping": {},
    "example_pairs": [],
    "constraints": "Not convertible to a direct public Relay operator for variance reduction.",
    "notes": "NO_MAPPING: PyTorch's `var` calculates the variance. While TVM's internal `relay.op.reduce._variance` exists (used by `std`), there is no public `tvm.relay.op.reduce.var` function exposed in the provided snippets for a direct mapping.",
    "confidence": 0.4
  },
  {
    "torch_api": "torch.onnx._internal.torchscript_exporter.symbolic_opset9.logsumexp",
    "tvm_api": "tvm.relay.op.reduce.logsumexp",
    "mapping_type": "direct",
    "direction": "torch_to_tvm",
    "torch_pattern": "logsumexp({{input}}, dim={{dim}}, keepdim={{keepdim}})",
    "tvm_pattern": "tvm.relay.op.reduce.logsumexp({{data}}, axis={{axis}}, keepdims={{keepdims}})",
    "arg_mapping": {
      "input": "data",
      "dim": "axis",
      "keepdim": "keepdims"
    },
    "example_pairs": [
      {
        "torch": "out = torch.logsumexp(input_tensor, dim=1, keepdim=True)",
        "tvm": "out = tvm.relay.op.reduce.logsumexp(input_tensor_tvm, axis=1, keepdims=True)"
      }
    ],
    "constraints": "",
    "notes": "Maps the log-sum-exp reduction operation.",
    "confidence": 0.95
  },
  {
    "torch_api": "torch.onnx._internal.torchscript_exporter.symbolic_opset9.arange",
    "tvm_api": "tvm.relay.op.transform.arange",
    "mapping_type": "direct",
    "direction": "torch_to_tvm",
    "torch_pattern": "arange({{start}}, stop={{stop}}, step={{step}}, dtype={{dtype}}, layout={{layout}}, device={{device}}, pin_memory={{pin_memory}})",
    "tvm_pattern": "tvm.relay.op.transform.arange(start={{start}}, stop={{stop}}, step={{step}}, dtype={{dtype}})",
    "arg_mapping": {
      "start": "start",
      "stop": "stop",
      "step": "step",
      "dtype": "dtype",
      "layout": "N/A",
      "device": "N/A",
      "pin_memory": "N/A"
    },
    "example_pairs": [
      {
        "torch": "out = torch.arange(0, 10, 1, dtype=torch.int32)",
        "tvm": "out = tvm.relay.op.transform.arange(start=tvm.relay.const(0, 'int32'), stop=tvm.relay.const(10, 'int32'), step=tvm.relay.const(1, 'int32'), dtype='int32')"
      }
    ],
    "constraints": "Layout, device, and pin_memory parameters are not directly mapped. TVM `start`, `stop`, `step` should be Relay expressions (e.g., constants) and their dtypes should align with the specified `dtype`.",
    "notes": "Maps the creation of a tensor with evenly spaced values within a given interval.",
    "confidence": 0.95
  },
  {
    "torch_api": "torch.onnx._internal.torchscript_exporter.symbolic_opset9.multinomial",
    "tvm_api": null,
    "mapping_type": "no_mapping",
    "direction": "torch_to_tvm",
    "torch_pattern": null,
    "tvm_pattern": null,
    "arg_mapping": {},
    "example_pairs": [],
    "constraints": "Not convertible due to parameter mismatch and random generation specifics.",
    "notes": "NO_MAPPING: TVM's `multinomial` (`tvm.relay.op.random.kernel.multinomial`) requires an explicit `key` for random number generation, which is not directly available or mapped from the PyTorch symbolic API. Additionally, the PyTorch ONNX export often processes probability inputs via a `log` operation before passing to ONNX `Multinomial`, while TVM's `multinomial` explicitly expects `probs` (probabilities).",
    "confidence": 0.3
  },
  {
    "torch_api": "torch.onnx._internal.torchscript_exporter.symbolic_opset9.meshgrid",
    "tvm_api": "tvm.relay.op.transform.meshgrid",
    "mapping_type": "direct",
    "direction": "torch_to_tvm",
    "torch_pattern": "meshgrid({{tensor_list}}, indexing={{indexing}})",
    "tvm_pattern": "tvm.relay.op.transform.meshgrid(data={{data}}, indexing={{indexing}})",
    "arg_mapping": {
      "tensor_list": "data",
      "indexing": "indexing"
    },
    "example_pairs": [
      {
        "torch": "grid_x, grid_y = torch.meshgrid([x_coords, y_coords], indexing='ij')",
        "tvm": "grid_xy_tuple = tvm.relay.op.transform.meshgrid(data=[x_coords_tvm, y_coords_tvm], indexing='ij')"
      }
    ],
    "constraints": "TVM's `meshgrid` returns a tuple of tensors, matching the PyTorch behavior.",
    "notes": "Maps the meshgrid operation to create coordinate matrices from vectors.",
    "confidence": 0.95
  },
  {
    "torch_api": "torch.onnx._internal.torchscript_exporter.symbolic_opset9.group_norm",
    "tvm_api": "tvm.relay.op.nn.nn.group_norm",
    "mapping_type": "direct",
    "direction": "torch_to_tvm",
    "torch_pattern": "group_norm({{input}}, {{num_groups}}, {{weight}}, {{bias}}, {{eps}}, cudnn_enabled={{cudnn_enabled}})",
    "tvm_pattern": "tvm.relay.op.nn.nn.group_norm({{data}}, {{gamma}}, {{beta}}, num_groups={{num_groups}}, axis=1, epsilon={{epsilon}}, center=True, scale=True)",
    "arg_mapping": {
      "input": "data",
      "num_groups": "num_groups",
      "weight": "gamma",
      "bias": "beta",
      "eps": "epsilon",
      "cudnn_enabled": "N/A"
    },
    "example_pairs": [
      {
        "torch": "out = torch.group_norm(input_tensor, 2, weight_tensor, bias_tensor, 1e-5)",
        "tvm": "out = tvm.relay.op.nn.nn.group_norm(input_tensor_tvm, gamma=weight_tensor_tvm, beta=bias_tensor_tvm, num_groups=2, epsilon=1e-5)"
      }
    ],
    "constraints": "TVM's 'axis' defaults to 1 (channel dimension), which is common for group norm. 'cudnn_enabled' is not directly mapped. 'center' and 'scale' default to True, matching PyTorch's behavior with weight and bias.",
    "notes": "Maps group normalization. The PyTorch symbolic op involves a composite of reshape and instance_norm, but TVM has a direct 'group_norm' operator.",
    "confidence": 0.95
  },
  {
    "torch_api": "torch.onnx._internal.torchscript_exporter.symbolic_opset9.take",
    "tvm_api": "tvm.relay.op.transform.take",
    "mapping_type": "direct",
    "direction": "torch_to_tvm",
    "torch_pattern": "take({{self}}, {{index}})",
    "tvm_pattern": "tvm.relay.op.transform.take(data={{data}}, indices={{indices}}, axis=None, batch_dims=0, mode=\"clip\")",
    "arg_mapping": {
      "self": "data",
      "index": "indices"
    },
    "example_pairs": [
      {
        "torch": "out = torch.take(data_tensor, index_tensor)",
        "tvm": "out = tvm.relay.op.transform.take(data=data_tensor_tvm, indices=index_tensor_tvm, axis=None)"
      }
    ],
    "constraints": "PyTorch's `take` implicitly flattens the input and then reshapes the output to match the index tensor. TVM's `take` with `axis=None` performs a similar flatten-and-index behavior, with output shape matching `indices` shape. Default `batch_dims=0` and `mode='clip'` are assumed.",
    "notes": "Maps the take operation, selecting elements from a flattened input tensor based on indices.",
    "confidence": 0.9
  },
  {
    "torch_api": "torch.profiler._utils.argmax",
    "tvm_api": null,
    "mapping_type": "no_mapping",
    "direction": "torch_to_tvm",
    "torch_pattern": null,
    "tvm_pattern": null,
    "arg_mapping": {},
    "example_pairs": [],
    "constraints": "Not convertible to a TVM tensor operation.",
    "notes": "NO_MAPPING: This is a Python utility function for finding the index of the maximum element in a Python sequence, not a tensor computation operation. It is distinct from `aten::argmax` which operates on tensors.",
    "confidence": 0.2
  },
  {
    "torch_api": "torch.profiler.itt.range",
    "tvm_api": null,
    "mapping_type": "no_mapping",
    "direction": "torch_to_tvm",
    "torch_pattern": null,
    "tvm_pattern": null,
    "arg_mapping": {},
    "example_pairs": [],
    "constraints": "Not convertible to a TVM operation or IR construct.",
    "notes": "NO_MAPPING: This is a Python context manager for ITT (Intel Trace Collector and Analyzer) tracing, used for profiling. It is not a computational primitive or an IR construct in TVM.",
    "confidence": 0.2
  },
  {
    "torch_api": "torch.sparse.__init__.sum",
    "tvm_api": null,
    "mapping_type": "no_mapping",
    "direction": "torch_to_tvm",
    "torch_pattern": null,
    "tvm_pattern": null,
    "arg_mapping": {},
    "example_pairs": [],
    "constraints": "Not convertible to a dense TVM sum operation due to sparse tensor semantics.",
    "notes": "NO_MAPPING: This PyTorch API is specifically for summing over *sparse* tensors. The provided TVM `relay.op.reduce.sum` operates on *dense* tensors. While TVM Relay supports sparse operations, a direct equivalent for `torch.sparse.sum` is not provided in the snippets.",
    "confidence": 0.3
  },
  {
    "torch_api": "torch.sparse._triton_ops_meta.main",
    "tvm_api": null,
    "mapping_type": "no_mapping",
    "direction": "torch_to_tvm",
    "torch_pattern": null,
    "tvm_pattern": null,
    "arg_mapping": {},
    "example_pairs": [],
    "constraints": "Not convertible to a TVM operation or program entry point.",
    "notes": "NO_MAPPING: This is an internal utility function within PyTorch for benchmarking Triton sparse operations. It is not a computational primitive.",
    "confidence": 0.2
  },
  {
    "torch_api": "torch.testing._comparison.assert_allclose",
    "tvm_api": "tvm.testing.utils.assert_allclose",
    "mapping_type": "direct",
    "direction": "torch_to_tvm",
    "torch_pattern": "assert_allclose({{actual}}, {{expected}}, rtol={{rtol}}, atol={{atol}}, equal_nan={{equal_nan}}, msg={{msg}})",
    "tvm_pattern": "tvm.testing.utils.assert_allclose(actual={{actual}}, desired={{desired}}, rtol={{rtol}}, atol={{atol}})",
    "arg_mapping": {
      "actual": "actual",
      "expected": "desired",
      "rtol": "rtol",
      "atol": "atol",
      "equal_nan": "N/A (implicit numpy behavior)",
      "msg": "N/A"
    },
    "example_pairs": [
      {
        "torch": "torch.testing.assert_allclose(actual_tensor, expected_tensor, rtol=1e-5, atol=1e-8)",
        "tvm": "tvm.testing.utils.assert_allclose(actual=actual_tensor_tvm, desired=expected_tensor_tvm, rtol=1e-5, atol=1e-8)"
      }
    ],
    "constraints": "TVM's `assert_allclose` (based on numpy) does not expose `equal_nan` or `msg` parameters directly. Its `equal_nan` behavior follows numpy's default.",
    "notes": "Maps the utility function for asserting approximate equality of two arrays/tensors.",
    "confidence": 0.98
  },
  {
    "torch_api": "torch.testing._internal.common_quantized.ceil_div",
    "tvm_api": "tvm.topi.utils.ceil_div",
    "mapping_type": "direct",
    "direction": "torch_to_tvm",
    "torch_pattern": "ceil_div({{a}}, {{b}})",
    "tvm_pattern": "tvm.topi.utils.ceil_div({{a}}, {{b}})",
    "arg_mapping": {
      "a": "a",
      "b": "b"
    },
    "example_pairs": [
      {
        "torch": "res = ceil_div(10, 3)",
        "tvm": "res = tvm.topi.utils.ceil_div(10, 3)"
      }
    ],
    "constraints": "TVM's `ceil_div` is a utility function typically used at the TE or TIR level, not a Relay graph operator.",
    "notes": "Maps the ceiling division utility function.",
    "confidence": 0.95
  },
  {
    "torch_api": "torch.utils._zip.main",
    "tvm_api": null,
    "mapping_type": "no_mapping",
    "direction": "torch_to_tvm",
    "torch_pattern": null,
    "tvm_pattern": null,
    "arg_mapping": {},
    "example_pairs": [],
    "constraints": "Not convertible to a TVM operation or program entry point.",
    "notes": "NO_MAPPING: This is a Python utility function for zipping source files. It is not a computational primitive.",
    "confidence": 0.2
  },
  {
    "torch_api": "torch.utils.checkpoint.checkpoint",
    "tvm_api": "tvm.relay.op.annotation.annotation.checkpoint",
    "mapping_type": "direct",
    "direction": "torch_to_tvm",
    "torch_pattern": "checkpoint({{function}}, *args, use_reentrant={{use_reentrant}}, context_fn={{context_fn}}, determinism_check={{determinism_check}}, debug={{debug}}, early_stop={{early_stop}}, **kwargs)",
    "tvm_pattern": "tvm.relay.op.annotation.annotation.checkpoint({{data}})",
    "arg_mapping": {
      "function": "N/A (the expression derived from function application)",
      "args": "data",
      "use_reentrant": "N/A",
      "context_fn": "N/A",
      "determinism_check": "N/A",
      "debug": "N/A",
      "early_stop": "N/A",
      "kwargs": "N/A"
    },
    "example_pairs": [
      {
        "torch": "output = torch.utils.checkpoint.checkpoint(my_function, input_tensor)",
        "tvm": "output = tvm.relay.op.annotation.annotation.checkpoint(output_of_my_function_tvm)"
      }
    ],
    "constraints": "PyTorch's `checkpoint` is a higher-level function that takes a Python callable and its arguments, managing the recomputation logic. TVM's `checkpoint` is an annotation on a Relay expression, marking a point in the graph for memory optimization through recomputation. It's a conceptual mapping of intent rather than a direct function call equivalence.",
    "notes": "Maps the activation checkpointing mechanism. The TVM API is an annotation to mark an expression for recomputation during backward passes for memory savings.",
    "confidence": 0.8
  },
  {
    "torch_api": "torch.utils.collect_env.main",
    "tvm_api": null,
    "mapping_type": "no_mapping",
    "direction": "torch_to_tvm",
    "torch_pattern": null,
    "tvm_pattern": null,
    "arg_mapping": {},
    "example_pairs": [],
    "constraints": "Not convertible to a TVM operation or program entry point.",
    "notes": "NO_MAPPING: This is a Python utility function for collecting and displaying environment information. It is not a computational primitive.",
    "confidence": 0.2
  },
  {
    "torch_api": "torch.utils.cpp_extension.load",
    "tvm_api": null,
    "mapping_type": "no_mapping",
    "direction": "torch_to_tvm",
    "torch_pattern": null,
    "tvm_pattern": null,
    "arg_mapping": {},
    "example_pairs": [],
    "constraints": "Not convertible to a TVM operation or IR instruction.",
    "notes": "NO_MAPPING: This is a Python utility function for JIT compiling and loading C++ extensions. It is not a tensor computation or an IR instruction.",
    "confidence": 0.2
  },
  {
    "torch_api": "torch.utils.dlpack.from_dlpack",
    "tvm_api": "tvm.runtime.ndarray.from_dlpack",
    "mapping_type": "direct",
    "direction": "torch_to_tvm",
    "torch_pattern": "from_dlpack({{ext_tensor}}, device={{device}}, copy={{copy}})",
    "tvm_pattern": "tvm.runtime.ndarray.from_dlpack({{dltensor}})",
    "arg_mapping": {
      "ext_tensor": "dltensor",
      "device": "N/A",
      "copy": "N/A"
    },
    "example_pairs": [
      {
        "torch": "torch_tensor = torch.utils.dlpack.from_dlpack(dlpack_tensor)",
        "tvm": "tvm_ndarray = tvm.runtime.ndarray.from_dlpack(dlpack_tensor_capsule)"
      }
    ],
    "constraints": "TVM's `from_dlpack` directly wraps the DLPack tensor without additional `device` or `copy` parameters as it assumes direct consumption of the capsule.",
    "notes": "Maps the conversion of a DLPack tensor capsule to a TVM NDArray, sharing memory.",
    "confidence": 0.98
  },
  {
    "torch_api": "torch.utils.show_pickle.main",
    "tvm_api": null,
    "mapping_type": "no_mapping",
    "direction": "torch_to_tvm",
    "torch_pattern": null,
    "tvm_pattern": null,
    "arg_mapping": {},
    "example_pairs": [],
    "constraints": "Not convertible to a TVM operation or program entry point.",
    "notes": "NO_MAPPING: This is a Python utility function for displaying the contents of pickle files. It is not a computational primitive.",
    "confidence": 0.2
  },
  {
    "torch_api": "torch.utils.benchmark.examples.compare.main",
    "tvm_api": null,
    "mapping_type": "no_mapping",
    "direction": "torch_to_tvm",
    "torch_pattern": null,
    "tvm_pattern": null,
    "arg_mapping": {},
    "example_pairs": [],
    "constraints": "Not convertible to a TVM operation or program entry point.",
    "notes": "NO_MAPPING: This is a Python example script for benchmarking PyTorch operations. It is not a computational primitive.",
    "confidence": 0.2
  },
  {
    "torch_api": "torch.utils.benchmark.examples.fuzzer.main",
    "tvm_api": null,
    "mapping_type": "no_mapping",
    "direction": "torch_to_tvm",
    "torch_pattern": null,
    "tvm_pattern": null,
    "arg_mapping": {},
    "example_pairs": [],
    "constraints": "Not convertible to a TVM operation or program entry point.",
    "notes": "NO_MAPPING: This is a Python example script for benchmarking PyTorch operations using a fuzzer. It is not a computational primitive.",
    "confidence": 0.2
  },
  {
    "torch_api": "torch.utils.benchmark.examples.op_benchmark.main",
    "tvm_api": null,
    "mapping_type": "no_mapping",
    "direction": "torch_to_tvm",
    "torch_pattern": null,
    "tvm_pattern": null,
    "arg_mapping": {},
    "example_pairs": [],
    "constraints": "Not convertible to a TVM operation or program entry point.",
    "notes": "NO_MAPPING: This is a Python example script for benchmarking PyTorch operations. It is not a computational primitive.",
    "confidence": 0.2
  },
  {
    "torch_api": "torch.utils.benchmark.examples.simple_timeit.main",
    "tvm_api": null,
    "mapping_type": "no_mapping",
    "direction": "torch_to_tvm",
    "torch_pattern": null,
    "tvm_pattern": null,
    "arg_mapping": {},
    "example_pairs": [],
    "constraints": "Not convertible to a TVM operation or program entry point.",
    "notes": "NO_MAPPING: This is a Python example script for benchmarking PyTorch operations using simple timeit. It is not a computational primitive.",
    "confidence": 0.2
  },
  {
    "torch_api": "torch.utils.benchmark.examples.sparse.compare.main",
    "tvm_api": null,
    "mapping_type": "no_mapping",
    "direction": "torch_to_tvm",
    "torch_pattern": null,
    "tvm_pattern": null,
    "arg_mapping": {},
    "example_pairs": [],
    "constraints": "Not convertible to a TVM operation or program entry point.",
    "notes": "NO_MAPPING: This is a Python example script for benchmarking PyTorch sparse operations. It is not a computational primitive.",
    "confidence": 0.2
  },
  {
    "torch_api": "torch.utils.benchmark.examples.sparse.fuzzer.main",
    "tvm_api": null,
    "mapping_type": "no_mapping",
    "direction": "torch_to_tvm",
    "torch_pattern": null,
    "tvm_pattern": null,
    "arg_mapping": {},
    "example_pairs": [],
    "constraints": "Not convertible to a TVM operation or program entry point.",
    "notes": "NO_MAPPING: This is a Python example script for benchmarking PyTorch sparse operations using a fuzzer. It is not a computational primitive.",
    "confidence": 0.2
  },
  {
    "torch_api": "torch.utils.benchmark.examples.sparse.op_benchmark.main",
    "tvm_api": null,
    "mapping_type": "no_mapping",
    "direction": "torch_to_tvm",
    "torch_pattern": null,
    "tvm_pattern": null,
    "arg_mapping": {},
    "example_pairs": [],
    "constraints": "Not convertible to a TVM operation or program entry point.",
    "notes": "NO_MAPPING: This is a Python example script for benchmarking PyTorch sparse operations. It is not a computational primitive.",
    "confidence": 0.2
  },
  {
    "torch_api": "torch.utils.benchmark.utils.fuzzer.prod",
    "tvm_api": null,
    "mapping_type": "no_mapping",
    "direction": "torch_to_tvm",
    "torch_pattern": null,
    "tvm_pattern": null,
    "arg_mapping": {},
    "example_pairs": [],
    "constraints": "Not convertible to a TVM tensor operation.",
    "notes": "NO_MAPPING: This is a Python utility function for computing the product of elements in a sequence, typically for calculating tensor sizes. It is not a tensor computation operation itself.",
    "confidence": 0.2
  },
  {
    "torch_api": "torch.utils.bottleneck.__main__.parse_args",
    "tvm_api": null,
    "mapping_type": "no_mapping",
    "direction": "torch_to_tvm",
    "torch_pattern": null,
    "tvm_pattern": null,
    "arg_mapping": {},
    "example_pairs": [],
    "constraints": "Not convertible",
    "notes": "NO_MAPPING: The TVM `parse_args` functions provided parse arguments for microTVM debug tools or TorchBench testing, which are semantically unrelated to parsing arguments for a script to be run and profiled, as done by the PyTorch API.",
    "confidence": 0.9
  },
  {
    "torch_api": "torch.utils.bottleneck.__main__.main",
    "tvm_api": null,
    "mapping_type": "no_mapping",
    "direction": "torch_to_tvm",
    "torch_pattern": null,
    "tvm_pattern": null,
    "arg_mapping": {},
    "example_pairs": [],
    "constraints": "Not convertible",
    "notes": "NO_MAPPING: The TVM `main` functions provided are entry points for specific TVM utilities (measure record distillation, ONNX/Relay model tuning) and have no semantic equivalence to the PyTorch `main` function, which is designed to profile arbitrary user scripts.",
    "confidence": 0.9
  },
  {
    "torch_api": "torch.utils.data.datapipes.gen_pyi.main",
    "tvm_api": null,
    "mapping_type": "no_mapping",
    "direction": "torch_to_tvm",
    "torch_pattern": null,
    "tvm_pattern": null,
    "arg_mapping": {},
    "example_pairs": [],
    "constraints": "Not convertible",
    "notes": "NO_MAPPING: The TVM `main` functions provided are entry points for specific TVM utilities (measure record distillation, ONNX/Relay model tuning) and have no semantic equivalence to the PyTorch `main` function, which is designed to generate `.pyi` files for DataPipes.",
    "confidence": 0.9
  },
  {
    "torch_api": "torch.utils.data.datapipes.dataframe.dataframe_wrapper.concat",
    "tvm_api": null,
    "mapping_type": "no_mapping",
    "direction": "torch_to_tvm",
    "torch_pattern": null,
    "tvm_pattern": null,
    "arg_mapping": {},
    "example_pairs": [],
    "constraints": "Not convertible",
    "notes": "NO_MAPPING: The PyTorch `concat` is a wrapper for `pandas.concat` for data manipulation. The TVM `concat` is a Relay graph transformation for fake quantization, operating on `relay.qnn.op.concatenate` expressions. They are functionally distinct.",
    "confidence": 0.95
  },
  {
    "torch_api": "torch.utils.model_dump.__init__.main",
    "tvm_api": null,
    "mapping_type": "no_mapping",
    "direction": "torch_to_tvm",
    "torch_pattern": null,
    "tvm_pattern": null,
    "arg_mapping": {},
    "example_pairs": [],
    "constraints": "Not convertible",
    "notes": "NO_MAPPING: The TVM `main` functions provided are entry points for specific TVM utilities (measure record distillation, ONNX/Relay model tuning) and have no semantic equivalence to the PyTorch `main` function, which is designed to dump PyTorch model information.",
    "confidence": 0.9
  },
  {
    "torch_api": "torch.xpu.__init__.init",
    "tvm_api": null,
    "mapping_type": "no_mapping",
    "direction": "torch_to_tvm",
    "torch_pattern": null,
    "tvm_pattern": null,
    "arg_mapping": {},
    "example_pairs": [],
    "constraints": "Not convertible",
    "notes": "NO_MAPPING: The PyTorch `init` initializes the XPU runtime state. The TVM `init` is an internal function used for building TIR (Tensor IR) block initialization statements. These are fundamentally different operations.",
    "confidence": 0.95
  }
]